[INFO] Scanning for projects...
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building Spark Project Datalog 1.6.4-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-enforcer-plugin:1.4.1:enforce (enforce-versions) @ spark-datalog_2.11 ---
[INFO] 
[INFO] --- scala-maven-plugin:3.2.2:add-source (eclipse-add-source) @ spark-datalog_2.11 ---
[INFO] Add Source directory: C:\java\BigDatalogLatest\datalog\src\main\scala
[INFO] Add Test Source directory: C:\java\BigDatalogLatest\datalog\src\test\scala
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.0:build-classpath (default-cli) @ spark-datalog_2.11 ---
[INFO] Dependencies classpath:
C:\Users\Mike\.m2\repository\mx4j\mx4j\3.0.2\mx4j-3.0.2.jar;C:\Users\Mike\.m2\repository\io\dropwizard\metrics\metrics-core\3.1.2\metrics-core-3.1.2.jar;C:\Users\Mike\.m2\repository\com\univocity\univocity-parsers\2.2.1\univocity-parsers-2.2.1.jar;C:\Users\Mike\.m2\repository\org\apache\parquet\parquet-format\2.3.1\parquet-format-2.3.1.jar;C:\Users\Mike\.m2\repository\net\java\dev\jets3t\jets3t\0.9.3\jets3t-0.9.3.jar;C:\Users\Mike\.m2\repository\com\google\protobuf\protobuf-java\2.5.0\protobuf-java-2.5.0.jar;C:\Users\Mike\.m2\repository\com\fasterxml\jackson\core\jackson-databind\2.6.5\jackson-databind-2.6.5.jar;C:\Users\Mike\.m2\repository\io\dropwizard\metrics\metrics-jvm\3.1.2\metrics-jvm-3.1.2.jar;C:\Users\Mike\.m2\repository\org\codehaus\janino\janino\3.0.0\janino-3.0.0.jar;C:\Users\Mike\.m2\repository\org\tachyonproject\tachyon-client\0.8.2\tachyon-client-0.8.2.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-hdfs\2.6.5\hadoop-hdfs-2.6.5.jar;C:\Users\Mike\.m2\repository\org\fusesource\leveldbjni\leveldbjni-all\1.8\leveldbjni-all-1.8.jar;C:\Users\Mike\.m2\repository\io\dropwizard\metrics\metrics-json\3.1.2\metrics-json-3.1.2.jar;C:\Users\Mike\.m2\repository\org\apache\commons\commons-crypto\1.0.0\commons-crypto-1.0.0.jar;C:\Users\Mike\.m2\repository\com\typesafe\config\1.3.0\config-1.3.0.jar;C:\Users\Mike\.m2\repository\commons-io\commons-io\2.4\commons-io-2.4.jar;C:\Users\Mike\.m2\repository\org\apache\commons\commons-lang3\3.5\commons-lang3-3.5.jar;C:\Users\Mike\.m2\repository\org\codehaus\jackson\jackson-jaxrs\1.9.13\jackson-jaxrs-1.9.13.jar;C:\Users\Mike\.m2\repository\org\scala-lang\scala-reflect\2.11.8\scala-reflect-2.11.8.jar;C:\Users\Mike\.m2\repository\org\json4s\json4s-jackson_2.11\3.2.11\json4s-jackson_2.11-3.2.11.jar;C:\Users\Mike\.m2\repository\com\esotericsoftware\minlog\1.3.0\minlog-1.3.0.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-network-shuffle_2.11\1.6.4-SNAPSHOT\spark-network-shuffle_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\javax\mail\mail\1.4.7\mail-1.4.7.jar;C:\Users\Mike\.m2\repository\org\codehaus\jackson\jackson-core-asl\1.9.13\jackson-core-asl-1.9.13.jar;C:\Users\Mike\.m2\repository\com\sun\jersey\jersey-server\1.9.1\jersey-server-1.9.1.jar;C:\Users\Mike\.m2\repository\org\tachyonproject\tachyon-underfs-local\0.8.2\tachyon-underfs-local-0.8.2.jar;C:\Users\Mike\.m2\repository\org\bouncycastle\bcprov-jdk15on\1.51\bcprov-jdk15on-1.51.jar;C:\Users\Mike\.m2\repository\net\jpountz\lz4\lz4\1.3.0\lz4-1.3.0.jar;C:\Users\Mike\.m2\repository\org\apache\parquet\parquet-jackson\1.8.2\parquet-jackson-1.8.2.jar;C:\Users\Mike\.m2\repository\org\tachyonproject\tachyon-underfs-hdfs\0.8.2\tachyon-underfs-hdfs-0.8.2.jar;C:\Users\Mike\.m2\repository\org\apache\mesos\mesos\0.21.1\mesos-0.21.1-shaded-protobuf.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-unsafe_2.11\1.6.4-SNAPSHOT\spark-unsafe_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\org\scala-lang\modules\scala-java8-compat_2.11\0.7.0\scala-java8-compat_2.11-0.7.0.jar;C:\Users\Mike\.m2\repository\com\google\code\findbugs\jsr305\1.3.9\jsr305-1.3.9.jar;C:\Users\Mike\.m2\repository\io\aeron\aeron-client\1.1.0\aeron-client-1.1.0.jar;C:\Users\Mike\.m2\repository\io\aeron\aeron-driver\1.1.0\aeron-driver-1.1.0.jar;C:\Users\Mike\.m2\repository\javax\xml\bind\jaxb-api\2.2.2\jaxb-api-2.2.2.jar;C:\Users\Mike\.m2\repository\com\twitter\chill-java\0.8.0\chill-java-0.8.0.jar;C:\Users\Mike\.m2\repository\commons-lang\commons-lang\2.6\commons-lang-2.6.jar;C:\Users\Mike\.m2\repository\org\apache\zookeeper\zookeeper\3.4.6\zookeeper-3.4.6.jar;C:\Users\Mike\.m2\repository\org\tukaani\xz\1.0\xz-1.0.jar;C:\Users\Mike\.m2\repository\javax\activation\activation\1.1.1\activation-1.1.1.jar;C:\Users\Mike\.m2\repository\asm\asm\3.1\asm-3.1.jar;C:\Users\Mike\.m2\repository\commons-codec\commons-codec\1.10\commons-codec-1.10.jar;C:\Users\Mike\.m2\repository\it\unimi\dsi\fastutil\7.0.7\fastutil-7.0.7.jar;C:\Users\Mike\.m2\repository\org\apache\parquet\parquet-column\1.8.2\parquet-column-1.8.2.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-yarn-api\2.6.5\hadoop-yarn-api-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\ivy\ivy\2.4.0\ivy-2.4.0.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-common\2.6.5\hadoop-common-2.6.5.jar;C:\Users\Mike\.m2\repository\org\reactivestreams\reactive-streams\1.0.0\reactive-streams-1.0.0.jar;C:\Users\Mike\.m2\repository\commons-beanutils\commons-beanutils-core\1.8.0\commons-beanutils-core-1.8.0.jar;C:\Users\Mike\.m2\repository\javax\servlet\javax.servlet-api\3.1.0\javax.servlet-api-3.1.0.jar;C:\Users\Mike\.m2\repository\org\apache\commons\commons-math3\3.4.1\commons-math3-3.4.1.jar;C:\Users\Mike\.m2\repository\javax\xml\stream\stax-api\1.0-2\stax-api-1.0-2.jar;C:\Users\Mike\.m2\repository\com\typesafe\akka\akka-actor_2.11\2.4.17\akka-actor_2.11-2.4.17.jar;C:\Users\Mike\.m2\repository\org\apache\avro\avro\1.7.7\avro-1.7.7.jar;C:\Users\Mike\.m2\repository\org\codehaus\jackson\jackson-xc\1.9.13\jackson-xc-1.9.13.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-app\2.6.5\hadoop-mapreduce-client-app-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-yarn-server-common\2.6.5\hadoop-yarn-server-common-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-launcher_2.11\1.6.4-SNAPSHOT\spark-launcher_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\io\netty\netty-all\4.0.43.Final\netty-all-4.0.43.Final.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-yarn-common\2.6.5\hadoop-yarn-common-2.6.5.jar;C:\Users\Mike\.m2\repository\oro\oro\2.0.8\oro-2.0.8.jar;C:\Users\Mike\.m2\repository\org\scala-lang\scala-compiler\2.11.8\scala-compiler-2.11.8.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-annotations\2.6.5\hadoop-annotations-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\curator\curator-framework\2.6.0\curator-framework-2.6.0.jar;C:\Users\Mike\.m2\repository\com\typesafe\akka\akka-slf4j_2.11\2.4.17\akka-slf4j_2.11-2.4.17.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-sql_2.11\1.6.4-SNAPSHOT\spark-sql_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-core_2.11\1.6.4-SNAPSHOT\spark-core_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\org\apache\parquet\parquet-common\1.8.2\parquet-common-1.8.2.jar;C:\Users\Mike\.m2\repository\org\roaringbitmap\RoaringBitmap\0.5.11\RoaringBitmap-0.5.11.jar;C:\Users\Mike\.m2\repository\log4j\log4j\1.2.17\log4j-1.2.17.jar;C:\Users\Mike\.m2\repository\org\scala-lang\scala-library\2.11.8\scala-library-2.11.8.jar;C:\Users\Mike\.m2\repository\com\typesafe\ssl-config-core_2.11\0.2.1\ssl-config-core_2.11-0.2.1.jar;C:\Users\Mike\.m2\repository\org\apache\commons\commons-compress\1.4.1\commons-compress-1.4.1.jar;C:\Users\Mike\.m2\repository\org\apache\directory\server\apacheds-kerberos-codec\2.0.0-M15\apacheds-kerberos-codec-2.0.0-M15.jar;C:\Users\Mike\.m2\repository\org\apache\curator\curator-recipes\2.6.0\curator-recipes-2.6.0.jar;C:\Users\Mike\.m2\repository\com\fasterxml\jackson\core\jackson-annotations\2.6.5\jackson-annotations-2.6.5.jar;C:\Users\Mike\.m2\repository\com\jamesmurty\utils\java-xmlbuilder\1.0\java-xmlbuilder-1.0.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-auth\2.6.5\hadoop-auth-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-shuffle\2.6.5\hadoop-mapreduce-client-shuffle-2.6.5.jar;C:\Users\Mike\.m2\repository\org\slf4j\slf4j-api\1.7.16\slf4j-api-1.7.16.jar;C:\Users\Mike\.m2\repository\org\apache\xbean\xbean-asm5-shaded\4.4\xbean-asm5-shaded-4.4.jar;C:\Users\Mike\.m2\repository\org\apache\httpcomponents\httpclient\4.5.2\httpclient-4.5.2.jar;C:\Users\Mike\.m2\repository\org\json4s\json4s-core_2.11\3.2.11\json4s-core_2.11-3.2.11.jar;C:\Users\Mike\.m2\repository\org\mortbay\jetty\jetty-util\6.1.26\jetty-util-6.1.26.jar;C:\Users\Mike\.m2\repository\org\antlr\antlr4-runtime\4.5.3\antlr4-runtime-4.5.3.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-core\2.6.5\hadoop-mapreduce-client-core-2.6.5.jar;C:\Users\Mike\.m2\repository\org\codehaus\jackson\jackson-mapper-asl\1.9.13\jackson-mapper-asl-1.9.13.jar;C:\Users\Mike\.m2\repository\com\typesafe\akka\akka-remote_2.11\2.4.17\akka-remote_2.11-2.4.17.jar;C:\Users\Mike\.m2\repository\org\uncommons\maths\uncommons-maths\1.2.2a\uncommons-maths-1.2.2a.jar;C:\Users\Mike\.m2\repository\com\esotericsoftware\kryo-shaded\3.0.3\kryo-shaded-3.0.3.jar;C:\Users\Mike\.m2\repository\io\netty\netty\3.9.9.Final\netty-3.9.9.Final.jar;C:\Users\Mike\.m2\repository\org\apache\avro\avro-mapred\1.7.7\avro-mapred-1.7.7-hadoop2.jar;C:\Users\Mike\.m2\repository\com\typesafe\akka\akka-protobuf_2.11\2.4.17\akka-protobuf_2.11-2.4.17.jar;C:\Users\Mike\.m2\repository\com\fasterxml\jackson\module\jackson-module-paranamer\2.6.5\jackson-module-paranamer-2.6.5.jar;C:\Users\Mike\.m2\repository\xmlenc\xmlenc\0.52\xmlenc-0.52.jar;C:\Users\Mike\.m2\repository\com\ning\compress-lzf\1.0.3\compress-lzf-1.0.3.jar;C:\Users\Mike\.m2\repository\org\apache\parquet\parquet-encoding\1.8.2\parquet-encoding-1.8.2.jar;C:\Users\Mike\.m2\repository\org\apache\directory\api\api-util\1.0.0-M20\api-util-1.0.0-M20.jar;C:\Users\Mike\.m2\repository\com\fasterxml\jackson\module\jackson-module-scala_2.11\2.6.5\jackson-module-scala_2.11-2.6.5.jar;C:\Users\Mike\.m2\repository\commons-net\commons-net\2.2\commons-net-2.2.jar;C:\Users\Mike\.m2\repository\com\google\code\gson\gson\2.2.4\gson-2.2.4.jar;C:\Users\Mike\.m2\repository\org\agrona\agrona\0.9.2\agrona-0.9.2.jar;C:\Users\Mike\.m2\repository\org\json4s\json4s-ast_2.11\3.2.11\json4s-ast_2.11-3.2.11.jar;C:\Users\Mike\.m2\repository\org\apache\directory\api\api-asn1-api\1.0.0-M20\api-asn1-api-1.0.0-M20.jar;C:\Users\Mike\.m2\repository\org\scala-lang\scalap\2.11.8\scalap-2.11.8.jar;C:\Users\Mike\.m2\repository\com\clearspring\analytics\stream\2.7.0\stream-2.7.0.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-tags_2.11\1.6.4-SNAPSHOT\spark-tags_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\org\apache\curator\curator-client\2.6.0\curator-client-2.6.0.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-common\2.6.5\hadoop-mapreduce-client-common-2.6.5.jar;C:\Users\Mike\.m2\repository\com\thoughtworks\paranamer\paranamer\2.6\paranamer-2.6.jar;C:\Users\Mike\.m2\repository\commons-configuration\commons-configuration\1.6\commons-configuration-1.6.jar;C:\Users\Mike\.m2\repository\commons-digester\commons-digester\1.8\commons-digester-1.8.jar;C:\Users\Mike\.m2\repository\org\slf4j\jul-to-slf4j\1.7.16\jul-to-slf4j-1.7.16.jar;C:\Users\Mike\.m2\repository\com\sun\jersey\jersey-core\1.9.1\jersey-core-1.9.1.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-mapreduce-client-jobclient\2.6.5\hadoop-mapreduce-client-jobclient-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\directory\server\apacheds-i18n\2.0.0-M15\apacheds-i18n-2.0.0-M15.jar;C:\Users\Mike\.m2\repository\commons-beanutils\commons-beanutils\1.7.0\commons-beanutils-1.7.0.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-network-common_2.11\1.6.4-SNAPSHOT\spark-network-common_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\org\codehaus\janino\commons-compiler\3.0.0\commons-compiler-3.0.0.jar;C:\Users\Mike\.m2\repository\net\razorvine\pyrolite\4.19\pyrolite-4.19.jar;C:\Users\Mike\.m2\repository\org\apache\spark\spark-catalyst_2.11\1.6.4-SNAPSHOT\spark-catalyst_2.11-1.6.4-SNAPSHOT.jar;C:\Users\Mike\.m2\repository\org\htrace\htrace-core\3.0.4\htrace-core-3.0.4.jar;C:\Users\Mike\.m2\repository\org\apache\parquet\parquet-hadoop\1.8.2\parquet-hadoop-1.8.2.jar;C:\Users\Mike\.m2\repository\org\scala-lang\modules\scala-xml_2.11\1.0.2\scala-xml_2.11-1.0.2.jar;C:\Users\Mike\.m2\repository\com\fasterxml\jackson\core\jackson-core\2.6.5\jackson-core-2.6.5.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-client\2.6.5\hadoop-client-2.6.5.jar;C:\Users\Mike\.m2\repository\org\scala-lang\modules\scala-parser-combinators_2.11\1.0.4\scala-parser-combinators_2.11-1.0.4.jar;C:\Users\Mike\.m2\repository\commons-cli\commons-cli\1.2\commons-cli-1.2.jar;C:\Users\Mike\.m2\repository\io\dropwizard\metrics\metrics-graphite\3.1.2\metrics-graphite-3.1.2.jar;C:\Users\Mike\.m2\repository\xerces\xercesImpl\2.9.1\xercesImpl-2.9.1.jar;C:\Users\Mike\.m2\repository\net\iharder\base64\2.3.8\base64-2.3.8.jar;C:\Users\Mike\.m2\repository\org\objenesis\objenesis\2.1\objenesis-2.1.jar;C:\Users\Mike\.m2\repository\org\slf4j\slf4j-log4j12\1.7.16\slf4j-log4j12-1.7.16.jar;C:\Users\Mike\.m2\repository\org\xerial\snappy\snappy-java\1.1.2.6\snappy-java-1.1.2.6.jar;C:\Users\Mike\.m2\repository\com\typesafe\akka\akka-stream_2.11\2.4.17\akka-stream_2.11-2.4.17.jar;C:\Users\Mike\.m2\repository\org\spark-project\spark\unused\1.0.0\unused-1.0.0.jar;C:\Users\Mike\.m2\repository\org\apache\avro\avro-ipc\1.7.7\avro-ipc-1.7.7.jar;C:\Users\Mike\.m2\repository\net\sf\py4j\py4j\0.10.4\py4j-0.10.4.jar;C:\Users\Mike\.m2\repository\commons-collections\commons-collections\3.2.2\commons-collections-3.2.2.jar;C:\Users\Mike\.m2\repository\com\twitter\chill_2.11\0.8.0\chill_2.11-0.8.0.jar;C:\Users\Mike\.m2\repository\org\tachyonproject\tachyon-underfs-s3\0.8.2\tachyon-underfs-s3-0.8.2.jar;C:\Users\Mike\.m2\repository\org\apache\hadoop\hadoop-yarn-client\2.6.5\hadoop-yarn-client-2.6.5.jar;C:\Users\Mike\.m2\repository\org\slf4j\jcl-over-slf4j\1.7.16\jcl-over-slf4j-1.7.16.jar;C:\Users\Mike\.m2\repository\DeALS\DeALS\0.6\DeALS-0.6.jar;C:\Users\Mike\.m2\repository\commons-httpclient\commons-httpclient\3.1\commons-httpclient-3.1.jar;C:\Users\Mike\.m2\repository\org\apache\httpcomponents\httpcore\4.4.4\httpcore-4.4.4.jar
[INFO] 
[INFO] --- maven-remote-resources-plugin:1.5:process (default) @ spark-datalog_2.11 ---
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ spark-datalog_2.11 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory C:\java\BigDatalogLatest\datalog\src\main\resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- scala-maven-plugin:3.2.2:compile (scala-compile-first) @ spark-datalog_2.11 ---
[WARNING] Zinc server is not available at port 3030 - reverting to normal incremental compile
[INFO] Using incremental compilation
[INFO] Compiling 32 Scala sources and 9 Java sources to C:\java\BigDatalogLatest\datalog\target\scala-2.11\classes...
[WARNING] warning: No processor claimed any of these annotations: com.google.common.annotations.VisibleForTesting,javax.annotation.Nullable
[WARNING] 1 warning
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:compile (default-compile) @ spark-datalog_2.11 ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-antrun-plugin:1.8:run (create-tmp-dir) @ spark-datalog_2.11 ---
[INFO] Executing tasks

main:
[INFO] Executed tasks
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ spark-datalog_2.11 ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 3 resources
[INFO] Copying 3 resources
[INFO] 
[INFO] --- scala-maven-plugin:3.2.2:testCompile (scala-test-compile-first) @ spark-datalog_2.11 ---
[WARNING] Zinc server is not available at port 3030 - reverting to normal incremental compile
[INFO] Using incremental compilation
[INFO] Compiling 5 Scala sources to C:\java\BigDatalogLatest\datalog\target\scala-2.11\test-classes...
[INFO] 
[INFO] --- maven-compiler-plugin:3.6.1:testCompile (default-testCompile) @ spark-datalog_2.11 ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- maven-dependency-plugin:3.0.0:build-classpath (generate-test-classpath) @ spark-datalog_2.11 ---
[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (default-test) @ spark-datalog_2.11 ---

-------------------------------------------------------
 T E S T S
-------------------------------------------------------

Results :

Tests run: 0, Failures: 0, Errors: 0, Skipped: 0

[INFO] 
[INFO] --- maven-surefire-plugin:2.19.1:test (test) @ spark-datalog_2.11 ---
[INFO] Skipping execution of surefire because it has already been run for this configuration
[INFO] 
[INFO] --- scalatest-maven-plugin:1.0:test (test) @ spark-datalog_2.11 ---
[36mDiscovery starting.[0m
[36mDiscovery completed in 558 milliseconds.[0m
[36mRun starting. Expected test count is: 50[0m
[32mAggregatesOverRecursionQuerySuite:[0m
log4j:ERROR Could not read configuration file from URL [file:src/test/resources/log4j.properties].
java.io.FileNotFoundException: src\test\resources\log4j.properties (The system cannot find the file specified)
	at java.io.FileInputStream.open0(Native Method)
	at java.io.FileInputStream.open(Unknown Source)
	at java.io.FileInputStream.<init>(Unknown Source)
	at java.io.FileInputStream.<init>(Unknown Source)
	at sun.net.www.protocol.file.FileURLConnection.connect(Unknown Source)
	at sun.net.www.protocol.file.FileURLConnection.getInputStream(Unknown Source)
	at org.apache.log4j.PropertyConfigurator.doConfigure(PropertyConfigurator.java:557)
	at org.apache.log4j.helpers.OptionConverter.selectAndConfigure(OptionConverter.java:526)
	at org.apache.log4j.LogManager.<clinit>(LogManager.java:127)
	at org.apache.spark.Logging$class.initializeLogging(Logging.scala:121)
	at org.apache.spark.Logging$class.initializeIfNecessary(Logging.scala:106)
	at org.apache.spark.Logging$class.log(Logging.scala:50)
	at org.apache.spark.SparkContext.log(SparkContext.scala:78)
	at org.apache.spark.Logging$class.logInfo(Logging.scala:58)
	at org.apache.spark.SparkContext.logInfo(SparkContext.scala:78)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:210)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$11.apply$mcV$sp(RecursiveQuerySuites.scala:212)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$11.apply(RecursiveQuerySuites.scala:205)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$11.apply(RecursiveQuerySuites.scala:205)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
log4j:ERROR Ignoring configuration file [file:src/test/resources/log4j.properties].
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
17/03/27 22:25:10 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:10 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/03/27 22:25:10 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:10 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:10 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:11 INFO Utils: Successfully started service 'sparkDriver' on port 51343.
17/03/27 22:25:11 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:11 INFO Remoting: Starting remoting
17/03/27 22:25:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@192.168.1.208:51357]
17/03/27 22:25:11 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51357.
17/03/27 22:25:11 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:11 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:11 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-ae6c193c-eea7-4e47-a858-134f0d1ab8b6
17/03/27 22:25:11 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:12 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51375.
17/03/27 22:25:12 INFO NettyBlockTransferService: Server created on 51375
17/03/27 22:25:12 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:12 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51375 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51375)
17/03/27 22:25:12 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:12 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667912094
17/03/27 22:25:14 INFO AggregatesOverRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:14 INFO BigDatalogContext: BigDatalog Query: "stratified_shortest_path(A,B,C)"
17/03/27 22:25:14 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:14 INFO BigDatalogContext: 
0: (X, To, min(C) as C) <AGGREGATE>
 1: path(X, To, C) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
 Exit Rules: 
  2: arc(From, To, D) <BASE_RELATION>
 Recursive Rules: 
  2: (X, To, C1 + D as C) <DISTINCT PROJECT>
   3: (0.Z = 1.From) <JOIN>
    4: path(X, Z, C1) <RECURSIVE_RELATION>
    4: arc(From, To, D) <BASE_RELATION>
17/03/27 22:25:14 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:14 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:14 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_stratified_shortest_path
+- 'Aggregate ['path.X,'path.To], ['path.X,'path.To,unresolvedalias('min('path.C) AS C#10)]
   +- 'Subquery path
      +- 'Recursion path, true, [1,0,0]
         :- 'UnresolvedRelation `arc`, None
         +- 'Project ['path1.X,'arc2.To,unresolvedalias(('path1.C1 + 'arc2.D) AS C#9)]
            +- 'Join Inner, Some(('path1.Z = 'arc2.From))
               :- Subquery path1
               :  +- LinearRecursiveRelation path, [X#6,Z#7,C1#8], [1,0,0]
               +- 'BroadcastHint
                  +- 'Subquery arc2
                     +- 'Project [*]
                        +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
X: int, To: int, C: int
Subquery aggregate_stratified_shortest_path
+- Aggregate [X#6,To#1], [X#6,To#1,(min(C#9),mode=Complete,isDistinct=false) AS C#10]
   +- Subquery path
      +- Recursion path, true, [1,0,0]
         :- Subquery arc
         :  +- LogicalRDD [From#0,To#1,D#2], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [X#6,To#1,(C1#8 + D#2) AS C#9]
            +- Join Inner, Some((Z#7 = From#0))
               :- Subquery path1
               :  +- LinearRecursiveRelation path, [X#6,Z#7,C1#8], [1,0,0]
               +- BroadcastHint
                  +- Subquery arc2
                     +- Project [From#0,To#1,D#2]
                        +- Subquery arc
                           +- LogicalRDD [From#0,To#1,D#2], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [X#6,To#1], [X#6,To#1,(min(C#9),mode=Complete,isDistinct=false) AS C#10]
+- Recursion path, true, [1,0,0]
   :- LogicalRDD [From#0,To#1,D#2], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [X#6,To#1,(C1#8 + D#2) AS C#9]
      +- Join Inner, Some((Z#7 = From#0))
         :- LinearRecursiveRelation path, [X#6,Z#7,C1#8], [1,0,0]
         +- BroadcastHint
            +- Project [From#0,To#1,D#2]
               +- LogicalRDD [From#0,To#1,D#2], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[X#6,To#1], functions=[(min(C#9),mode=Final,isDistinct=false)], output=[X#6,To#1,C#10])
+- TungstenAggregate(key=[X#6,To#1], functions=[(min(C#9),mode=Partial,isDistinct=false)], output=[X#6,To#1,min#13])
   +- Recursion [X#6,To#1,C#9] (Linear) [path][1,0,0]
      :- TungstenExchange hashpartitioning(From#0,5), None
      :  +- ConvertToUnsafe
      :     +- Scan ExistingRDD[From#0,To#1,D#2] 
      +- Project [X#6,To#1,(C1#8 + D#2) AS C#9]
         +- BroadcastHashJoin [Z#7], [From#0], BuildRight
            :- LinearRecursiveRelation [X#6,Z#7,C1#8](path)
            +- Project [From#0,To#1,D#2]
               +- Scan ExistingRDD[From#0,To#1,D#2]
17/03/27 22:25:14 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:15 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:15 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:15 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:15 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:15 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:15 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:15 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:15 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:15 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at run at null:-1), which has no missing parents
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:15 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51375 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:15 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:15 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at run at null:-1)
17/03/27 22:25:15 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:15 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2362 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:15 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:15 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:15 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:15 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:15 INFO GenerateUnsafeProjection: Code generated in 169.42806 ms
17/03/27 22:25:15 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1500 bytes result sent to driver
17/03/27 22:25:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1500 bytes result sent to driver
17/03/27 22:25:15 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1500 bytes result sent to driver
17/03/27 22:25:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1500 bytes result sent to driver
17/03/27 22:25:15 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:15 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:15 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1549 bytes result sent to driver
17/03/27 22:25:15 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 259 ms on localhost (1/5)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 11 ms on localhost (2/5)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 265 ms on localhost (3/5)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 268 ms on localhost (4/5)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 288 ms on localhost (5/5)
17/03/27 22:25:15 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.296 s
17/03/27 22:25:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:15 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.401782 s
17/03/27 22:25:15 INFO GenerateUnsafeProjection: Code generated in 7.97698 ms
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 2.0 GB)
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 300.0 B, free 2.0 GB)
17/03/27 22:25:15 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51375 (size: 300.0 B, free: 2.0 GB)
17/03/27 22:25:15 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:15 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:15 INFO Recursion: Fixed Point Iteration # 1, time: 483ms
17/03/27 22:25:15 INFO DAGScheduler: Registering RDD 5 (execute at Recursion.scala:189)
17/03/27 22:25:15 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:15 INFO DAGScheduler: Final stage: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:15 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:15 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:15 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:15 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51375 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:15 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:15 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at execute at Recursion.scala:189)
17/03/27 22:25:15 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:15 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2361 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:15 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:15 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:15 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:15 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:15 INFO GenerateMutableProjection: Code generated in 4.699552 ms
17/03/27 22:25:15 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:25:15 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:15 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 62 ms on localhost (1/5)
17/03/27 22:25:15 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:25:15 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:25:15 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 68 ms on localhost (2/5)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 69 ms on localhost (3/5)
17/03/27 22:25:15 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:25:15 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1222 bytes result sent to driver
17/03/27 22:25:15 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 75 ms on localhost (4/5)
17/03/27 22:25:15 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 18 ms on localhost (5/5)
17/03/27 22:25:15 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:15 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.079 s
17/03/27 22:25:15 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:15 INFO DAGScheduler: running: Set()
17/03/27 22:25:15 INFO DAGScheduler: waiting: Set(FixedPointResultStage 2)
17/03/27 22:25:15 INFO DAGScheduler: failed: Set()
17/03/27 22:25:15 INFO DAGScheduler: Submitting FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.5 KB, free 2.0 GB)
17/03/27 22:25:15 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 2.0 GB)
17/03/27 22:25:15 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:51375 (size: 7.1 KB, free: 2.0 GB)
17/03/27 22:25:15 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:15 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:15 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:15 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:15 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:15 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:15 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:15 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:15 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:15 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_17_3 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_17_2 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_7_0 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:15 INFO CacheManager: Partition rdd_7_1 not found, computing it
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/03/27 22:25:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 9.5 MB, free 2038.7 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 9.5 MB, free 2029.2 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_7_1 in memory on localhost:51375 (size: 9.5 MB, free: 2038.7 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_7_3 in memory on localhost:51375 (size: 9.5 MB, free: 2029.2 MB)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:25:16 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_3 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_3 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:25:16 INFO GenerateUnsafeProjection: Code generated in 7.427743 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 9.5 MB, free 2019.7 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 9.5 MB, free 2010.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_7_2 in memory on localhost:51375 (size: 9.5 MB, free: 2019.7 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_7_0 in memory on localhost:51375 (size: 9.5 MB, free: 2010.2 MB)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_2 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_2 locally
17/03/27 22:25:16 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_0 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_0 locally
17/03/27 22:25:16 INFO GenerateUnsafeProjection: Code generated in 6.783241 ms
17/03/27 22:25:16 INFO GenerateUnsafeProjection: Code generated in 13.638163 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 8 took 1 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 8 took 1 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 9.5 MB, free 2000.6 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 9.5 MB, free 1991.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_11_3 in memory on localhost:51375 (size: 9.5 MB, free: 2000.6 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:51375 (size: 9.5 MB, free: 1991.1 MB)
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 2 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 4 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 9.5 MB, free 1981.6 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:51375 (size: 9.5 MB, free: 1981.6 MB)
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 4 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 9.5 MB, free 1972.0 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_11_0 in memory on localhost:51375 (size: 9.5 MB, free: 1972.1 MB)
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 4 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 9.5 MB, free 1962.5 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 9.5 MB, free 1953.0 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_13_2 in memory on localhost:51375 (size: 9.5 MB, free: 1962.5 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:51375 (size: 9.5 MB, free: 1953.0 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_11_2 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_11_1 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 9.5 MB, free 1943.5 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_13_3 in memory on localhost:51375 (size: 9.5 MB, free: 1943.5 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_11_3 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 9.5 MB, free 1933.9 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_13_0 in memory on localhost:51375 (size: 9.5 MB, free: 1934.0 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_11_0 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 9.5 MB, free 1924.4 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_17_1 in memory on localhost:51375 (size: 9.5 MB, free: 1924.4 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_17_2 stored as values in memory (estimated size 9.5 MB, free 1914.9 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_17_2 in memory on localhost:51375 (size: 9.5 MB, free: 1914.9 MB)
17/03/27 22:25:16 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 3260 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:16 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:16 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 510 ms on localhost (1/5)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_17_4 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_7_4 not found, computing it
17/03/27 22:25:16 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_17_3 stored as values in memory (estimated size 9.5 MB, free 1905.3 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_17_3 in memory on localhost:51375 (size: 9.5 MB, free: 1905.4 MB)
17/03/27 22:25:16 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3260 bytes result sent to driver
17/03/27 22:25:16 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 3315 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 517 ms on localhost (2/5)
17/03/27 22:25:16 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 517 ms on localhost (3/5)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 9.5 MB, free 1895.9 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:51375 (size: 9.5 MB, free: 1895.9 MB)
17/03/27 22:25:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 3315 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 541 ms on localhost (4/5)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 9.4 MB, free 1886.5 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_7_4 in memory on localhost:51375 (size: 9.4 MB, free: 1886.5 MB)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_11_4 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_4 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_7_4 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_11_4 stored as values in memory (estimated size 9.4 MB, free 1877.0 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_11_4 in memory on localhost:51375 (size: 9.4 MB, free: 1877.1 MB)
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 6 for rdd 8 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 9.4 MB, free 1867.6 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_13_4 in memory on localhost:51375 (size: 9.4 MB, free: 1867.6 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_11_4 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_17_4 stored as values in memory (estimated size 9.4 MB, free 1858.2 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_17_4 in memory on localhost:51375 (size: 9.4 MB, free: 1858.2 MB)
17/03/27 22:25:16 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 3315 bytes result sent to driver
17/03/27 22:25:16 INFO DAGScheduler: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204) finished in 0.679 s
17/03/27 22:25:16 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 167 ms on localhost (5/5)
17/03/27 22:25:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:16 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:16 INFO Recursion: Fixed Point Iteration # 2, time: 814ms
17/03/27 22:25:16 INFO DAGScheduler: Submitting FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 1858.2 MB)
17/03/27 22:25:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1858.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:51375 (size: 7.3 KB, free: 1858.2 MB)
17/03/27 22:25:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:16 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30)
17/03/27 22:25:16 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:16 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:16 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:16 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:16 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_27_2 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_27_3 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_27_0 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_27_1 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_13_2 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_2 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 4 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO CacheManager: Partition rdd_23_3 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_13_3 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_3 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 2 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO CacheManager: Partition rdd_23_0 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_13_0 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_0 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 6 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_13_1 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_1 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 6 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 9.6 MB, free 1848.5 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_23_2 stored as values in memory (estimated size 9.6 MB, free 1838.9 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_23_2 in memory on localhost:51375 (size: 9.6 MB, free: 1848.6 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:51375 (size: 9.6 MB, free: 1839.0 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_2 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_0 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 24 took 1 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_23_1 stored as values in memory (estimated size 9.6 MB, free 1829.3 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_23_1 in memory on localhost:51375 (size: 9.6 MB, free: 1829.3 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_1 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_23_3 stored as values in memory (estimated size 9.6 MB, free 1819.7 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_23_3 in memory on localhost:51375 (size: 9.6 MB, free: 1819.7 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_3 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_27_2 stored as values in memory (estimated size 9.6 MB, free 1810.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_27_2 in memory on localhost:51375 (size: 9.6 MB, free: 1810.1 MB)
17/03/27 22:25:16 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:16 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 146 ms on localhost (1/5)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_27_4 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_23_4 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_13_4 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 9 for rdd 14 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_27_0 stored as values in memory (estimated size 9.7 MB, free 1800.4 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_27_0 in memory on localhost:51375 (size: 9.7 MB, free: 1800.5 MB)
17/03/27 22:25:16 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO MemoryStore: Block rdd_27_1 stored as values in memory (estimated size 9.6 MB, free 1790.8 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_27_1 in memory on localhost:51375 (size: 9.6 MB, free: 1790.8 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_27_3 stored as values in memory (estimated size 9.6 MB, free 1781.2 MB)
17/03/27 22:25:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 187 ms on localhost (2/5)
17/03/27 22:25:16 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_27_3 in memory on localhost:51375 (size: 9.6 MB, free: 1781.2 MB)
17/03/27 22:25:16 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 197 ms on localhost (3/5)
17/03/27 22:25:16 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 197 ms on localhost (4/5)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_23_4 stored as values in memory (estimated size 9.5 MB, free 1771.7 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_23_4 in memory on localhost:51375 (size: 9.5 MB, free: 1771.7 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_27_4 stored as values in memory (estimated size 9.5 MB, free 1762.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_27_4 in memory on localhost:51375 (size: 9.5 MB, free: 1762.2 MB)
17/03/27 22:25:16 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 145 ms on localhost (5/5)
17/03/27 22:25:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:16 INFO DAGScheduler: FixedPointResultStage 3 (runFixedPointJob at Recursion.scala:204) finished in 0.292 s
17/03/27 22:25:16 INFO CachedRDDManager: Unpersisting 3 rdds for iteration 0
17/03/27 22:25:16 INFO ZippedPartitionsRDD2: Removing RDD 11 from persistence list
17/03/27 22:25:16 INFO MapPartitionsRDD: Removing RDD 7 from persistence list
17/03/27 22:25:16 INFO ZippedPartitionsRDD2: Removing RDD 13 from persistence list
17/03/27 22:25:16 INFO CachedRDDManager: CleanUpIteration took 10 ms
17/03/27 22:25:16 INFO Recursion: Fixed Point Iteration # 3, time: 319ms
17/03/27 22:25:16 INFO DAGScheduler: Submitting FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[36] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.8 KB, free 1762.1 MB)
17/03/27 22:25:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1762.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:51375 (size: 6.4 KB, free: 1904.7 MB)
17/03/27 22:25:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:16 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[36] at RDD at SetRDD.scala:30)
17/03/27 22:25:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:16 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:16 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:16 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_35_0 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_35_1 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_31_0 not found, computing it
17/03/27 22:25:16 INFO CacheManager: Partition rdd_31_1 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_23_1 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_1 locally
17/03/27 22:25:16 INFO CacheManager: Partition rdd_35_3 not found, computing it
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 6 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO BlockManager: Found block rdd_23_0 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_0 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 8 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO CacheManager: Partition rdd_35_2 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Removing RDD 7
17/03/27 22:25:16 INFO BlockManager: Removing RDD 11
17/03/27 22:25:16 INFO BlockManager: Removing RDD 13
17/03/27 22:25:16 INFO CacheManager: Partition rdd_31_3 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_23_3 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_3 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 2 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO CacheManager: Partition rdd_31_2 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_23_2 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_2 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 4 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_31_3 stored as values in memory (estimated size 9.7 MB, free 1895.0 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_31_3 in memory on localhost:51375 (size: 9.7 MB, free: 1895.1 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_3 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 32 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_31_2 stored as values in memory (estimated size 9.7 MB, free 1885.4 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_31_2 in memory on localhost:51375 (size: 9.7 MB, free: 1885.4 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_2 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 32 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_31_1 stored as values in memory (estimated size 9.7 MB, free 1875.7 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_31_1 in memory on localhost:51375 (size: 9.7 MB, free: 1875.7 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_1 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 32 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_31_0 stored as values in memory (estimated size 9.7 MB, free 1866.0 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_31_0 in memory on localhost:51375 (size: 9.7 MB, free: 1866.1 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_0 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 32 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_35_2 stored as values in memory (estimated size 9.7 MB, free 1856.4 MB)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_35_3 stored as values in memory (estimated size 9.7 MB, free 1846.7 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_35_3 in memory on localhost:51375 (size: 9.7 MB, free: 1856.4 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_35_2 in memory on localhost:51375 (size: 9.7 MB, free: 1846.8 MB)
17/03/27 22:25:16 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:16 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:16 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 163 ms on localhost (1/5)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_35_4 not found, computing it
17/03/27 22:25:16 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 166 ms on localhost (2/5)
17/03/27 22:25:16 INFO CacheManager: Partition rdd_31_4 not found, computing it
17/03/27 22:25:16 INFO BlockManager: Found block rdd_23_4 locally
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_4 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Union set size 12 for rdd 24 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_35_1 stored as values in memory (estimated size 9.6 MB, free 1837.1 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_35_1 in memory on localhost:51375 (size: 9.6 MB, free: 1837.1 MB)
17/03/27 22:25:16 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 175 ms on localhost (3/5)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 9.6 MB, free 1827.5 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_35_0 in memory on localhost:51375 (size: 9.6 MB, free: 1827.5 MB)
17/03/27 22:25:16 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 201 ms on localhost (4/5)
17/03/27 22:25:16 INFO MemoryStore: Block rdd_31_4 stored as values in memory (estimated size 9.6 MB, free 1817.9 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_31_4 in memory on localhost:51375 (size: 9.6 MB, free: 1818.0 MB)
17/03/27 22:25:16 INFO BlockManager: Found block rdd_27_4 locally
17/03/27 22:25:16 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 32 took 0 ms
17/03/27 22:25:16 INFO MemoryStore: Block rdd_35_4 stored as values in memory (estimated size 9.6 MB, free 1808.3 MB)
17/03/27 22:25:16 INFO BlockManagerInfo: Added rdd_35_4 in memory on localhost:51375 (size: 9.6 MB, free: 1808.4 MB)
17/03/27 22:25:16 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 2989 bytes result sent to driver
17/03/27 22:25:16 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 91 ms on localhost (5/5)
17/03/27 22:25:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:16 INFO DAGScheduler: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204) finished in 0.248 s
17/03/27 22:25:16 INFO CachedRDDManager: Unpersisting 2 rdds for iteration 1
17/03/27 22:25:16 INFO ZippedPartitionsRDD2: Removing RDD 17 from persistence list
17/03/27 22:25:16 INFO BlockManager: Removing RDD 17
17/03/27 22:25:16 INFO ZippedPartitionsRDD2: Removing RDD 23 from persistence list
17/03/27 22:25:16 INFO CachedRDDManager: CleanUpIteration took 2 ms
17/03/27 22:25:16 INFO Recursion: Fixed Point Iteration # 4, time: 265ms
17/03/27 22:25:16 INFO BlockManager: Removing RDD 23
17/03/27 22:25:16 INFO DAGScheduler: Submitting FixedPointResultStage 5 (SetRDD.diffRDD SetRDD[44] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.8 KB, free 1903.8 MB)
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.4 KB, free 1903.8 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:51375 (size: 6.4 KB, free: 1903.8 MB)
17/03/27 22:25:17 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:17 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 5 (SetRDD.diffRDD SetRDD[44] at RDD at SetRDD.scala:30)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:17 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 26, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 27, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 28, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:17 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:25:17 INFO Executor: Running task 1.0 in stage 5.0 (TID 26)
17/03/27 22:25:17 INFO Executor: Running task 2.0 in stage 5.0 (TID 27)
17/03/27 22:25:17 INFO Executor: Running task 3.0 in stage 5.0 (TID 28)
17/03/27 22:25:17 INFO CacheManager: Partition rdd_43_0 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_43_2 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_43_1 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_39_0 not found, computing it
17/03/27 22:25:17 INFO BlockManager: Found block rdd_31_0 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_0 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Union set size 8 for rdd 32 took 0 ms
17/03/27 22:25:17 INFO CacheManager: Partition rdd_39_2 not found, computing it
17/03/27 22:25:17 INFO BlockManager: Found block rdd_31_2 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_2 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Union set size 4 for rdd 32 took 0 ms
17/03/27 22:25:17 INFO CacheManager: Partition rdd_43_3 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_39_1 not found, computing it
17/03/27 22:25:17 INFO BlockManager: Found block rdd_31_1 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_1 locally
17/03/27 22:25:17 INFO CacheManager: Partition rdd_39_3 not found, computing it
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Union set size 6 for rdd 32 took 0 ms
17/03/27 22:25:17 INFO BlockManager: Found block rdd_31_3 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_3 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Union set size 2 for rdd 32 took 0 ms
17/03/27 22:25:17 INFO MemoryStore: Block rdd_39_3 stored as values in memory (estimated size 9.7 MB, free 1894.0 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_39_3 in memory on localhost:51375 (size: 9.7 MB, free: 1894.1 MB)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_3 locally
17/03/27 22:25:17 INFO MemoryStore: Block rdd_39_0 stored as values in memory (estimated size 9.7 MB, free 1884.3 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_39_0 in memory on localhost:51375 (size: 9.7 MB, free: 1884.4 MB)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_0 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 40 took 0 ms
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 40 took 0 ms
17/03/27 22:25:17 INFO MemoryStore: Block rdd_39_2 stored as values in memory (estimated size 9.7 MB, free 1874.6 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_39_2 in memory on localhost:51375 (size: 9.7 MB, free: 1874.7 MB)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_2 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 40 took 0 ms
17/03/27 22:25:17 INFO MemoryStore: Block rdd_39_1 stored as values in memory (estimated size 9.7 MB, free 1864.9 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_39_1 in memory on localhost:51375 (size: 9.7 MB, free: 1865.0 MB)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_1 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 40 took 0 ms
17/03/27 22:25:17 INFO MemoryStore: Block rdd_43_0 stored as values in memory (estimated size 9.7 MB, free 1855.2 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_43_0 in memory on localhost:51375 (size: 9.7 MB, free: 1855.2 MB)
17/03/27 22:25:17 INFO MemoryStore: Block rdd_43_3 stored as values in memory (estimated size 9.7 MB, free 1845.4 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_43_3 in memory on localhost:51375 (size: 9.7 MB, free: 1845.5 MB)
17/03/27 22:25:17 INFO Executor: Finished task 3.0 in stage 5.0 (TID 28). 2989 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 28) in 207 ms on localhost (1/5)
17/03/27 22:25:17 INFO MemoryStore: Block rdd_43_2 stored as values in memory (estimated size 9.7 MB, free 1835.8 MB)
17/03/27 22:25:17 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 2989 bytes result sent to driver
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_43_2 in memory on localhost:51375 (size: 9.7 MB, free: 1835.8 MB)
17/03/27 22:25:17 INFO Executor: Running task 4.0 in stage 5.0 (TID 29)
17/03/27 22:25:17 INFO Executor: Finished task 2.0 in stage 5.0 (TID 27). 2989 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 240 ms on localhost (2/5)
17/03/27 22:25:17 INFO CacheManager: Partition rdd_43_4 not found, computing it
17/03/27 22:25:17 INFO MemoryStore: Block rdd_43_1 stored as values in memory (estimated size 9.6 MB, free 1826.1 MB)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 27) in 242 ms on localhost (3/5)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_43_1 in memory on localhost:51375 (size: 9.6 MB, free: 1826.2 MB)
17/03/27 22:25:17 INFO CacheManager: Partition rdd_39_4 not found, computing it
17/03/27 22:25:17 INFO BlockManager: Found block rdd_31_4 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_4 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Union set size 14 for rdd 32 took 0 ms
17/03/27 22:25:17 INFO Executor: Finished task 1.0 in stage 5.0 (TID 26). 2989 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 26) in 250 ms on localhost (4/5)
17/03/27 22:25:17 INFO MemoryStore: Block rdd_39_4 stored as values in memory (estimated size 9.6 MB, free 1816.5 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_39_4 in memory on localhost:51375 (size: 9.6 MB, free: 1816.6 MB)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_35_4 locally
17/03/27 22:25:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 40 took 0 ms
17/03/27 22:25:17 INFO MemoryStore: Block rdd_43_4 stored as values in memory (estimated size 9.6 MB, free 1806.9 MB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added rdd_43_4 in memory on localhost:51375 (size: 9.6 MB, free: 1807.0 MB)
17/03/27 22:25:17 INFO Executor: Finished task 4.0 in stage 5.0 (TID 29). 2989 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 29) in 143 ms on localhost (5/5)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:17 INFO DAGScheduler: FixedPointResultStage 5 (runFixedPointJob at Recursion.scala:204) finished in 0.351 s
17/03/27 22:25:17 INFO DAGScheduler: Fixed Point reached for job 1
17/03/27 22:25:17 INFO DAGScheduler: Fixed Point Job 1 finished: runFixedPointJob at Recursion.scala:204, took 1.765542 s
17/03/27 22:25:17 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:17 INFO DAGScheduler: Got job 2 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:17 INFO DAGScheduler: Final stage: ResultStage 6 (collect at QuerySuite.scala:64)
17/03/27 22:25:17 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:17 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:17 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[48] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 17.3 KB, free 1806.9 MB)
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.1 KB, free 1806.9 MB)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 15
17/03/27 22:25:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:51375 (size: 8.1 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:17 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[48] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:17 INFO BlockManager: Removing RDD 7
17/03/27 22:25:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 32, localhost, partition 2,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 33, localhost, partition 3,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:17 INFO Executor: Running task 0.0 in stage 6.0 (TID 30)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned RDD 7
17/03/27 22:25:17 INFO Executor: Running task 1.0 in stage 6.0 (TID 31)
17/03/27 22:25:17 INFO Executor: Running task 2.0 in stage 6.0 (TID 32)
17/03/27 22:25:17 INFO Executor: Running task 3.0 in stage 6.0 (TID 33)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_39_0 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_39_3 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_39_2 locally
17/03/27 22:25:17 INFO BlockManager: Found block rdd_39_1 locally
17/03/27 22:25:17 INFO ContextCleaner: Cleaned shuffle 0
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:51375 in memory (size: 6.4 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO GenerateMutableProjection: Code generated in 3.467955 ms
17/03/27 22:25:17 INFO GenerateUnsafeProjection: Code generated in 4.48451 ms
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 26
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 25
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:51375 in memory (size: 6.4 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO GenerateMutableProjection: Code generated in 13.212736 ms
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 24
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 23
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:51375 in memory (size: 7.3 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 22
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 21
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:51375 in memory (size: 7.1 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 20
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 19
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:51375 in memory (size: 2.8 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 18
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 17
17/03/27 22:25:17 INFO BlockManager: Removing RDD 11
17/03/27 22:25:17 INFO ContextCleaner: Cleaned RDD 11
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:51375 in memory (size: 2.7 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 16
17/03/27 22:25:17 INFO GenerateUnsafeRowJoiner: Code generated in 6.10709 ms
17/03/27 22:25:17 INFO Executor: Finished task 0.0 in stage 6.0 (TID 30). 4179 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 1.0 in stage 6.0 (TID 31). 4102 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 3.0 in stage 6.0 (TID 33). 3935 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 2.0 in stage 6.0 (TID 32). 4025 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 34, localhost, partition 4,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:17 INFO Executor: Running task 4.0 in stage 6.0 (TID 34)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 31) in 121 ms on localhost (1/5)
17/03/27 22:25:17 INFO BlockManager: Found block rdd_39_4 locally
17/03/27 22:25:17 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 33) in 122 ms on localhost (2/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 32) in 123 ms on localhost (3/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 30) in 125 ms on localhost (4/5)
17/03/27 22:25:17 INFO Executor: Finished task 4.0 in stage 6.0 (TID 34). 4256 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 34) in 13 ms on localhost (5/5)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:17 INFO DAGScheduler: ResultStage 6 (collect at QuerySuite.scala:64) finished in 0.131 s
17/03/27 22:25:17 INFO DAGScheduler: Job 2 finished: collect at QuerySuite.scala:64, took 0.152762 s
17/03/27 22:25:17 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:51375 in memory (size: 8.1 KB, free: 1807.0 MB)
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 28
17/03/27 22:25:17 INFO ContextCleaner: Cleaned accumulator 27
17/03/27 22:25:17 INFO AggregatesOverRecursionQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:17 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:17 INFO BlockManager: BlockManager stopped
17/03/27 22:25:17 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:17 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:17 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:17 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:17 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:17 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:17 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:17 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:17 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:17 INFO Utils: Successfully started service 'sparkDriver' on port 51401.
17/03/27 22:25:17 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:17 INFO Remoting: Starting remoting
17/03/27 22:25:17 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51414]
17/03/27 22:25:17 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51414.
17/03/27 22:25:17 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:17 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:17 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-62213cc2-0363-4b1d-b1a0-aad7b48c2bfb
17/03/27 22:25:17 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:17 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:17 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:17 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51431.
17/03/27 22:25:17 INFO NettyBlockTransferService: Server created on 51431
17/03/27 22:25:17 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:17 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51431 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51431)
17/03/27 22:25:17 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:17 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667917726
17/03/27 22:25:17 INFO AggregatesOverRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:17 INFO BigDatalogContext: BigDatalog Query: "stratified_shortest_path(A,B,C)"
17/03/27 22:25:17 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:17 INFO BigDatalogContext: 
0: (X, To, min(C) as C) <AGGREGATE>
 1: path(X, To, C) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
 Exit Rules: 
  2: arc(From, To, D) <BASE_RELATION>
 Recursive Rules: 
  2: (X, To, C1 + D as C) <DISTINCT PROJECT>
   3: (0.Z = 1.From) <JOIN>
    4: path(X, Z, C1) <RECURSIVE_RELATION>
    4: arc(From, To, D) <BASE_RELATION>
17/03/27 22:25:17 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:17 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:17 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_stratified_shortest_path
+- 'Aggregate ['path.X,'path.To], ['path.X,'path.To,unresolvedalias('min('path.C) AS C#27)]
   +- 'Subquery path
      +- 'Recursion path, true, [1,0,0]
         :- 'UnresolvedRelation `arc`, None
         +- 'Project ['path1.X,'arc2.To,unresolvedalias(('path1.C1 + 'arc2.D) AS C#26)]
            +- 'Join Inner, Some(('path1.Z = 'arc2.From))
               :- Subquery path1
               :  +- LinearRecursiveRelation path, [X#23,Z#24,C1#25], [1,0,0]
               +- 'BroadcastHint
                  +- 'Subquery arc2
                     +- 'Project [*]
                        +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
X: int, To: int, C: int
Subquery aggregate_stratified_shortest_path
+- Aggregate [X#23,To#18], [X#23,To#18,(min(C#26),mode=Complete,isDistinct=false) AS C#27]
   +- Subquery path
      +- Recursion path, true, [1,0,0]
         :- Subquery arc
         :  +- LogicalRDD [From#17,To#18,D#19], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [X#23,To#18,(C1#25 + D#19) AS C#26]
            +- Join Inner, Some((Z#24 = From#17))
               :- Subquery path1
               :  +- LinearRecursiveRelation path, [X#23,Z#24,C1#25], [1,0,0]
               +- BroadcastHint
                  +- Subquery arc2
                     +- Project [From#17,To#18,D#19]
                        +- Subquery arc
                           +- LogicalRDD [From#17,To#18,D#19], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [X#23,To#18], [X#23,To#18,(min(C#26),mode=Complete,isDistinct=false) AS C#27]
+- Recursion path, true, [1,0,0]
   :- LogicalRDD [From#17,To#18,D#19], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [X#23,To#18,(C1#25 + D#19) AS C#26]
      +- Join Inner, Some((Z#24 = From#17))
         :- LinearRecursiveRelation path, [X#23,Z#24,C1#25], [1,0,0]
         +- BroadcastHint
            +- Project [From#17,To#18,D#19]
               +- LogicalRDD [From#17,To#18,D#19], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[X#23,To#18], functions=[(min(C#26),mode=Final,isDistinct=false)], output=[X#23,To#18,C#27])
+- TungstenAggregate(key=[X#23,To#18], functions=[(min(C#26),mode=Partial,isDistinct=false)], output=[X#23,To#18,min#30])
   +- Recursion [X#23,To#18,C#26] (Linear) [path][1,0,0]
      :- TungstenExchange hashpartitioning(From#17,5), None
      :  +- ConvertToUnsafe
      :     +- Scan ExistingRDD[From#17,To#18,D#19] 
      +- Project [X#23,To#18,(C1#25 + D#19) AS C#26]
         +- BroadcastHashJoin [Z#24], [From#17], BuildRight
            :- LinearRecursiveRelation [X#23,Z#24,C1#25](path)
            +- Project [From#17,To#18,D#19]
               +- Scan ExistingRDD[From#17,To#18,D#19]
17/03/27 22:25:17 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:17 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:17 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:17 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:17 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:17 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:17 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:17 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:17 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:17 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[8] at run at null:-1), which has no missing parents
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51431 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:17 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:17 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at run at null:-1)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:17 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2362 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2403 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:17 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:17 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:17 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:17 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:17 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1549 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1500 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:17 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1549 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:17 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1549 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1549 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13 ms on localhost (1/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 5 ms on localhost (2/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 14 ms on localhost (3/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 14 ms on localhost (4/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 14 ms on localhost (5/5)
17/03/27 22:25:17 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.015 s
17/03/27 22:25:17 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.021577 s
17/03/27 22:25:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.4 KB, free 2.0 GB)
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 320.0 B, free 2.0 GB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51431 (size: 320.0 B, free: 2.0 GB)
17/03/27 22:25:17 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:17 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:17 INFO Recursion: Fixed Point Iteration # 1, time: 49ms
17/03/27 22:25:17 INFO DAGScheduler: Registering RDD 3 (execute at Recursion.scala:189)
17/03/27 22:25:17 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:17 INFO DAGScheduler: Final stage: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51431 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:17 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at execute at Recursion.scala:189)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2392 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:17 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:17 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:17 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 29 ms on localhost (1/5)
17/03/27 22:25:17 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:17 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 55 ms on localhost (2/5)
17/03/27 22:25:17 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1222 bytes result sent to driver
17/03/27 22:25:17 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:25:17 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 62 ms on localhost (3/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 35 ms on localhost (4/5)
17/03/27 22:25:17 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 65 ms on localhost (5/5)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:17 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.065 s
17/03/27 22:25:17 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:17 INFO DAGScheduler: running: Set()
17/03/27 22:25:17 INFO DAGScheduler: waiting: Set(FixedPointResultStage 2)
17/03/27 22:25:17 INFO DAGScheduler: failed: Set()
17/03/27 22:25:17 INFO DAGScheduler: Submitting FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.5 KB, free 2.0 GB)
17/03/27 22:25:17 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 2.0 GB)
17/03/27 22:25:17 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:51431 (size: 7.1 KB, free: 2.0 GB)
17/03/27 22:25:17 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:17 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:17 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:17 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:17 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:17 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:17 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:17 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:17 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:17 INFO CacheManager: Partition rdd_17_3 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:17 INFO CacheManager: Partition rdd_17_2 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:18 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/03/27 22:25:18 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 10.6 MB, free 2037.6 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:51431 (size: 10.6 MB, free: 2037.6 MB)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:18 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 10.6 MB, free 2027.0 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:51431 (size: 10.6 MB, free: 2027.0 MB)
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 4 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 4 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 10.6 MB, free 2016.4 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:51431 (size: 10.6 MB, free: 2016.4 MB)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 10.6 MB, free 2005.8 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:51431 (size: 10.6 MB, free: 2005.8 MB)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 10.6 MB, free 1995.2 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:51431 (size: 10.6 MB, free: 1995.2 MB)
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 6 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 10.6 MB, free 1984.5 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_11_0 in memory on localhost:51431 (size: 10.6 MB, free: 1984.6 MB)
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 8 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 10.6 MB, free 1973.9 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_11_3 in memory on localhost:51431 (size: 10.6 MB, free: 1974.0 MB)
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 10.6 MB, free 1963.3 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:51431 (size: 10.6 MB, free: 1963.3 MB)
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 10.6 MB, free 1952.7 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:51431 (size: 10.6 MB, free: 1952.7 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_11_1 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 10.6 MB, free 1942.1 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_13_0 in memory on localhost:51431 (size: 10.6 MB, free: 1942.1 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_11_0 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 10.6 MB, free 1931.5 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_13_3 in memory on localhost:51431 (size: 10.6 MB, free: 1931.5 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_11_3 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 10.6 MB, free 1920.8 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_13_2 in memory on localhost:51431 (size: 10.6 MB, free: 1920.9 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_11_2 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 10.6 MB, free 1910.2 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_17_1 in memory on localhost:51431 (size: 10.6 MB, free: 1910.2 MB)
17/03/27 22:25:18 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 3315 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 259 ms on localhost (1/5)
17/03/27 22:25:18 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_17_4 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 10.6 MB, free 1899.6 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:51431 (size: 10.6 MB, free: 1899.6 MB)
17/03/27 22:25:18 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 3315 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 280 ms on localhost (2/5)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_17_2 stored as values in memory (estimated size 10.6 MB, free 1889.0 MB)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_17_3 stored as values in memory (estimated size 10.6 MB, free 1878.4 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_17_2 in memory on localhost:51431 (size: 10.6 MB, free: 1889.0 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_17_3 in memory on localhost:51431 (size: 10.6 MB, free: 1878.4 MB)
17/03/27 22:25:18 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 3315 bytes result sent to driver
17/03/27 22:25:18 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3315 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 295 ms on localhost (3/5)
17/03/27 22:25:18 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 295 ms on localhost (4/5)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 10.5 MB, free 1867.9 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51431 (size: 10.5 MB, free: 1867.9 MB)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_11_4 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 4 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_11_4 stored as values in memory (estimated size 10.5 MB, free 1857.4 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_11_4 in memory on localhost:51431 (size: 10.5 MB, free: 1857.4 MB)
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 8 for rdd 7 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 10.5 MB, free 1846.9 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_13_4 in memory on localhost:51431 (size: 10.5 MB, free: 1846.9 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_11_4 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 8 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_17_4 stored as values in memory (estimated size 10.5 MB, free 1836.3 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_17_4 in memory on localhost:51431 (size: 10.5 MB, free: 1836.4 MB)
17/03/27 22:25:18 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 3315 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 204 ms on localhost (5/5)
17/03/27 22:25:18 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:18 INFO DAGScheduler: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204) finished in 0.463 s
17/03/27 22:25:18 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:18 INFO Recursion: Fixed Point Iteration # 2, time: 549ms
17/03/27 22:25:18 INFO DAGScheduler: Submitting FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:18 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 1836.3 MB)
17/03/27 22:25:18 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.3 KB, free 1836.3 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:51431 (size: 7.3 KB, free: 1836.4 MB)
17/03/27 22:25:18 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:18 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30)
17/03/27 22:25:18 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:18 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:18 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:18 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:18 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:18 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_27_0 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_27_1 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_27_2 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_27_3 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_23_0 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_13_0 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_0 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 8 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_13_1 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_1 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 6 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_13_2 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_2 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 2 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO CacheManager: Partition rdd_23_3 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_13_3 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_3 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 2 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_23_3 stored as values in memory (estimated size 10.7 MB, free 1825.6 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_23_3 in memory on localhost:51431 (size: 10.7 MB, free: 1825.7 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_3 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_23_1 stored as values in memory (estimated size 10.7 MB, free 1814.9 MB)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 10.7 MB, free 1804.2 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_23_1 in memory on localhost:51431 (size: 10.7 MB, free: 1815.0 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:51431 (size: 10.7 MB, free: 1804.2 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_1 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_0 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_23_2 stored as values in memory (estimated size 10.7 MB, free 1793.5 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_23_2 in memory on localhost:51431 (size: 10.7 MB, free: 1793.5 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_2 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_27_3 stored as values in memory (estimated size 10.7 MB, free 1782.8 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_27_3 in memory on localhost:51431 (size: 10.7 MB, free: 1782.8 MB)
17/03/27 22:25:18 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 2989 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 183 ms on localhost (1/5)
17/03/27 22:25:18 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:18 INFO CacheManager: Partition rdd_27_4 not found, computing it
17/03/27 22:25:18 INFO CacheManager: Partition rdd_23_4 not found, computing it
17/03/27 22:25:18 INFO BlockManager: Found block rdd_13_4 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Union set size 16 for rdd 14 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_27_0 stored as values in memory (estimated size 10.7 MB, free 1772.1 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_27_0 in memory on localhost:51431 (size: 10.7 MB, free: 1772.1 MB)
17/03/27 22:25:18 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 2989 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 221 ms on localhost (2/5)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_27_1 stored as values in memory (estimated size 10.7 MB, free 1761.4 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_27_1 in memory on localhost:51431 (size: 10.7 MB, free: 1761.4 MB)
17/03/27 22:25:18 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 2989 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 227 ms on localhost (3/5)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_27_2 stored as values in memory (estimated size 10.7 MB, free 1750.7 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_27_2 in memory on localhost:51431 (size: 10.7 MB, free: 1750.7 MB)
17/03/27 22:25:18 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 2989 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 240 ms on localhost (4/5)
17/03/27 22:25:18 INFO MemoryStore: Block rdd_23_4 stored as values in memory (estimated size 10.6 MB, free 1740.1 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_23_4 in memory on localhost:51431 (size: 10.6 MB, free: 1740.1 MB)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 24 took 0 ms
17/03/27 22:25:18 INFO MemoryStore: Block rdd_27_4 stored as values in memory (estimated size 10.6 MB, free 1729.5 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added rdd_27_4 in memory on localhost:51431 (size: 10.6 MB, free: 1729.5 MB)
17/03/27 22:25:18 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 2989 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 153 ms on localhost (5/5)
17/03/27 22:25:18 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:18 INFO DAGScheduler: FixedPointResultStage 3 (runFixedPointJob at Recursion.scala:204) finished in 0.338 s
17/03/27 22:25:18 INFO DAGScheduler: Fixed Point reached for job 1
17/03/27 22:25:18 INFO DAGScheduler: Fixed Point Job 1 finished: runFixedPointJob at Recursion.scala:204, took 0.899848 s
17/03/27 22:25:18 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:18 INFO DAGScheduler: Got job 2 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:18 INFO DAGScheduler: Final stage: ResultStage 4 (collect at QuerySuite.scala:64)
17/03/27 22:25:18 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:18 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:18 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[32] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:18 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.9 KB, free 1729.5 MB)
17/03/27 22:25:18 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.9 KB, free 1729.4 MB)
17/03/27 22:25:18 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:51431 (size: 8.9 KB, free: 1729.5 MB)
17/03/27 22:25:18 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:18 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 4 (MapPartitionsRDD[32] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:18 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:18 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:18 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:18 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:18 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:18 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:18 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_23_1 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_23_2 locally
17/03/27 22:25:18 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 3930 bytes result sent to driver
17/03/27 22:25:18 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 4097 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:25:18 INFO BlockManager: Found block rdd_23_3 locally
17/03/27 22:25:18 INFO BlockManager: Found block rdd_23_0 locally
17/03/27 22:25:18 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 22 ms on localhost (1/5)
17/03/27 22:25:18 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 22 ms on localhost (2/5)
17/03/27 22:25:18 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:18 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 3930 bytes result sent to driver
17/03/27 22:25:18 INFO BlockManager: Found block rdd_23_4 locally
17/03/27 22:25:18 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 4492 bytes result sent to driver
17/03/27 22:25:18 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 4184 bytes result sent to driver
17/03/27 22:25:18 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 32 ms on localhost (3/5)
17/03/27 22:25:18 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 15 ms on localhost (4/5)
17/03/27 22:25:18 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 33 ms on localhost (5/5)
17/03/27 22:25:18 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:18 INFO DAGScheduler: ResultStage 4 (collect at QuerySuite.scala:64) finished in 0.034 s
17/03/27 22:25:18 INFO DAGScheduler: Job 2 finished: collect at QuerySuite.scala:64, took 0.041251 s
17/03/27 22:25:18 INFO AggregatesOverRecursionQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:18 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:18 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:18 INFO BlockManager: BlockManager stopped
17/03/27 22:25:18 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:18 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:18 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:18 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:18 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:18 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:18 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:18 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[32m- Aggregates over Recursion - LL ShortestPaths - fff[0m
17/03/27 22:25:18 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:18 INFO Utils: Successfully started service 'sparkDriver' on port 51450.
17/03/27 22:25:18 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:18 INFO Remoting: Starting remoting
17/03/27 22:25:18 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51463]
17/03/27 22:25:18 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51463.
17/03/27 22:25:18 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:18 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:18 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-5e82660c-7292-4ad0-8df9-218e3ef23db8
17/03/27 22:25:18 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:18 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:18 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:19 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51480.
17/03/27 22:25:19 INFO NettyBlockTransferService: Server created on 51480
17/03/27 22:25:19 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:19 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51480 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51480)
17/03/27 22:25:19 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:19 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667918989
17/03/27 22:25:19 INFO AggregatesOverRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:19 INFO BigDatalogContext: BigDatalog Query: "stratified_shortest_path(A,B,C)"
17/03/27 22:25:19 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:19 INFO BigDatalogContext: 
0: (X, Y, min(C) as C) <AGGREGATE>
 1: path(X, Y, C) <RECURSIVE_CLIQUE>(Recursion: NONLINEAR, Evaluation Type: SemiNaive)
 Exit Rules: 
  2: arc(From, To, D) <BASE_RELATION>
 Recursive Rules: 
  2: (X, Y, C1 + C2 as C) <DISTINCT PROJECT>
   3: (0.Z = 1.Z) <JOIN>
    4: path(X, Z, C1) <RECURSIVE_RELATION>
    4: path(Z, Y, C2) <RECURSIVE_RELATION>
17/03/27 22:25:19 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:19 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:19 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_stratified_shortest_path
+- 'Aggregate ['path.X,'path.Y], ['path.X,'path.Y,unresolvedalias('min('path.C) AS C#47)]
   +- 'Subquery path
      +- 'Recursion path, false, [1,0,0]
         :- 'UnresolvedRelation `arc`, None
         +- 'Project ['path1.X,'path2.Y,unresolvedalias(('path1.C1 + 'path2.C2) AS C#46)]
            +- 'Join Inner, Some(('path1.Z = 'path2.Z))
               :- Subquery path1
               :  +- LinearRecursiveRelation path, [X#40,Z#41,C1#42], [1,0,0]
               +- Subquery path2
                  +- NonLinearRecursiveRelation path, [Z#43,Y#44,C2#45], [1,0,0]

== Analyzed Logical Plan ==
X: int, Y: int, C: int
Subquery aggregate_stratified_shortest_path
+- Aggregate [X#40,Y#44], [X#40,Y#44,(min(C#46),mode=Complete,isDistinct=false) AS C#47]
   +- Subquery path
      +- Recursion path, false, [1,0,0]
         :- Subquery arc
         :  +- LogicalRDD [From#34,To#35,D#36], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [X#40,Y#44,(C1#42 + C2#45) AS C#46]
            +- Join Inner, Some((Z#41 = Z#43))
               :- Subquery path1
               :  +- LinearRecursiveRelation path, [X#40,Z#41,C1#42], [1,0,0]
               +- Subquery path2
                  +- NonLinearRecursiveRelation path, [Z#43,Y#44,C2#45], [1,0,0]

== Optimized Logical Plan ==
Aggregate [X#40,Y#44], [X#40,Y#44,(min(C#46),mode=Complete,isDistinct=false) AS C#47]
+- Recursion path, false, [1,0,0]
   :- LogicalRDD [From#34,To#35,D#36], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [X#40,Y#44,(C1#42 + C2#45) AS C#46]
      +- Join Inner, Some((Z#41 = Z#43))
         :- LinearRecursiveRelation path, [X#40,Z#41,C1#42], [1,0,0]
         +- NonLinearRecursiveRelation path, [Z#43,Y#44,C2#45], [1,0,0]

== Physical Plan ==
TungstenAggregate(key=[X#40,Y#44], functions=[(min(C#46),mode=Final,isDistinct=false)], output=[X#40,Y#44,C#47])
+- TungstenAggregate(key=[X#40,Y#44], functions=[(min(C#46),mode=Partial,isDistinct=false)], output=[X#40,Y#44,min#50])
   +- Recursion [X#40,Y#44,C#46] (NonLinear) [path][1,0,0]
      :- TungstenExchange hashpartitioning(From#34,5), None
      :  +- ConvertToUnsafe
      :     +- Scan ExistingRDD[From#34,To#35,D#36] 
      +- TungstenExchange hashpartitioning(X#40,5), None
         +- Project [X#40,Y#44,(C1#42 + C2#45) AS C#46]
            +- SortMergeJoin [Z#41], [Z#43]
               :- Sort [Z#41 ASC], false, 0
               :  +- TungstenExchange hashpartitioning(Z#41,5), None
               :     +- LinearRecursiveRelation [X#40,Z#41,C1#42](path)
               +- Sort [Z#43 ASC], false, 0
                  +- NonLinearRecursiveRelation [Z#43,Y#44,C2#45](all_path)
17/03/27 22:25:19 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:19 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:19 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:19 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:19 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:19 INFO Recursion: Fixed Point Iteration # 1, time: 59ms
17/03/27 22:25:19 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:25:19 INFO DAGScheduler: Registering RDD 8 (mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 86 bytes
17/03/27 22:25:19 INFO DAGScheduler: Registering RDD 14 (execute at Recursion.scala:202)
17/03/27 22:25:19 INFO DAGScheduler: Registering RDD 20 (mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 86 bytes
17/03/27 22:25:19 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 86 bytes
17/03/27 22:25:19 INFO DAGScheduler: Registering RDD 26 (execute at Recursion.scala:228)
17/03/27 22:25:19 INFO DAGScheduler: Got job 0 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:19 INFO DAGScheduler: Final stage: FixedPointResultStage 9 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 8)
17/03/27 22:25:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 8)
17/03/27 22:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51480 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:19 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:25:19 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:19 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2361 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:19 INFO Executor: Running task 0.0 in stage 6.0 (TID 0)
17/03/27 22:25:19 INFO Executor: Running task 1.0 in stage 6.0 (TID 1)
17/03/27 22:25:19 INFO Executor: Running task 3.0 in stage 6.0 (TID 3)
17/03/27 22:25:19 INFO Executor: Running task 2.0 in stage 6.0 (TID 2)
17/03/27 22:25:19 INFO Executor: Finished task 1.0 in stage 6.0 (TID 1). 1222 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:19 INFO Executor: Running task 4.0 in stage 6.0 (TID 4)
17/03/27 22:25:19 INFO Executor: Finished task 2.0 in stage 6.0 (TID 2). 1222 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 1) in 84 ms on localhost (1/5)
17/03/27 22:25:19 INFO Executor: Finished task 3.0 in stage 6.0 (TID 3). 1222 bytes result sent to driver
17/03/27 22:25:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 0). 1222 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 2) in 123 ms on localhost (2/5)
17/03/27 22:25:19 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 3) in 127 ms on localhost (3/5)
17/03/27 22:25:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 0) in 130 ms on localhost (4/5)
17/03/27 22:25:19 INFO Executor: Finished task 4.0 in stage 6.0 (TID 4). 1222 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 4) in 97 ms on localhost (5/5)
17/03/27 22:25:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:19 INFO DAGScheduler: ShuffleMapStage 6 (execute at Recursion.scala:189) finished in 0.160 s
17/03/27 22:25:19 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:19 INFO DAGScheduler: running: Set()
17/03/27 22:25:19 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 5, ShuffleMapStage 7, ShuffleMapStage 4, ShuffleMapStage 8)
17/03/27 22:25:19 INFO DAGScheduler: failed: Set()
17/03/27 22:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[8] at mapPartitionsInternal at SetRDD.scala:92), which has no missing parents
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 2.0 GB)
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 2.0 GB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51480 (size: 4.0 KB, free: 2.0 GB)
17/03/27 22:25:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[8] at mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:19 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:19 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:19 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/03/27 22:25:19 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/03/27 22:25:19 INFO Executor: Running task 2.0 in stage 5.0 (TID 7)
17/03/27 22:25:19 INFO Executor: Running task 3.0 in stage 5.0 (TID 8)
17/03/27 22:25:19 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:19 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:19 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 107.6 MB, free 1940.6 MB)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 107.6 MB, free 1833.0 MB)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 107.6 MB, free 1725.3 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:51480 (size: 107.6 MB, free: 1940.6 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:51480 (size: 107.6 MB, free: 1833.0 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:51480 (size: 107.6 MB, free: 1725.4 MB)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 107.6 MB, free 1617.7 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:51480 (size: 107.6 MB, free: 1617.7 MB)
17/03/27 22:25:19 INFO GenerateMutableProjection: Code generated in 12.03048 ms
17/03/27 22:25:19 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1937 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 184 ms on localhost (1/5)
17/03/27 22:25:19 INFO Executor: Running task 4.0 in stage 5.0 (TID 9)
17/03/27 22:25:19 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1937 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 198 ms on localhost (2/5)
17/03/27 22:25:19 INFO Executor: Finished task 2.0 in stage 5.0 (TID 7). 1937 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 213 ms on localhost (3/5)
17/03/27 22:25:19 INFO Executor: Finished task 3.0 in stage 5.0 (TID 8). 1937 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 8) in 221 ms on localhost (4/5)
17/03/27 22:25:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:51480 in memory (size: 2.7 KB, free: 1617.7 MB)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 11.5 MB, free 1606.2 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51480 (size: 11.5 MB, free: 1606.2 MB)
17/03/27 22:25:19 INFO Executor: Finished task 4.0 in stage 5.0 (TID 9). 1937 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 9) in 117 ms on localhost (5/5)
17/03/27 22:25:19 INFO DAGScheduler: ShuffleMapStage 5 (mapPartitionsInternal at SetRDD.scala:92) finished in 0.300 s
17/03/27 22:25:19 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:19 INFO DAGScheduler: running: Set()
17/03/27 22:25:19 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 7, ShuffleMapStage 4, ShuffleMapStage 8)
17/03/27 22:25:19 INFO DAGScheduler: failed: Set()
17/03/27 22:25:19 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[14] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.5 KB, free 1606.2 MB)
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 1606.2 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51480 (size: 6.2 KB, free: 1606.2 MB)
17/03/27 22:25:19 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[14] at execute at Recursion.scala:202)
17/03/27 22:25:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks
17/03/27 22:25:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 10)
17/03/27 22:25:19 INFO Executor: Running task 1.0 in stage 7.0 (TID 11)
17/03/27 22:25:19 INFO Executor: Running task 2.0 in stage 7.0 (TID 12)
17/03/27 22:25:19 INFO Executor: Running task 3.0 in stage 7.0 (TID 13)
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO GenerateOrdering: Code generated in 12.248313 ms
17/03/27 22:25:19 INFO GenerateUnsafeProjection: Code generated in 6.579372 ms
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:19 INFO GenerateOrdering: Code generated in 4.250231 ms
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:19 INFO GenerateUnsafeProjection: Code generated in 5.702453 ms
17/03/27 22:25:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 10). 2990 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 104 ms on localhost (1/5)
17/03/27 22:25:19 INFO Executor: Finished task 2.0 in stage 7.0 (TID 12). 2990 bytes result sent to driver
17/03/27 22:25:19 INFO Executor: Running task 4.0 in stage 7.0 (TID 14)
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:19 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 112 ms on localhost (2/5)
17/03/27 22:25:19 INFO Executor: Finished task 4.0 in stage 7.0 (TID 14). 2990 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 13 ms on localhost (3/5)
17/03/27 22:25:19 INFO Executor: Finished task 3.0 in stage 7.0 (TID 13). 2990 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 140 ms on localhost (4/5)
17/03/27 22:25:19 INFO Executor: Finished task 1.0 in stage 7.0 (TID 11). 2990 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 151 ms on localhost (5/5)
17/03/27 22:25:19 INFO DAGScheduler: ShuffleMapStage 7 (execute at Recursion.scala:202) finished in 0.152 s
17/03/27 22:25:19 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:19 INFO DAGScheduler: running: Set()
17/03/27 22:25:19 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 4, ShuffleMapStage 8)
17/03/27 22:25:19 INFO DAGScheduler: failed: Set()
17/03/27 22:25:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/27 22:25:19 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at mapPartitionsInternal at SetRDD.scala:92), which has no missing parents
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.1 KB, free 1606.2 MB)
17/03/27 22:25:19 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1606.2 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:51480 (size: 4.4 KB, free: 1606.2 MB)
17/03/27 22:25:19 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:19 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:19 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:19 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO Executor: Running task 0.0 in stage 4.0 (TID 15)
17/03/27 22:25:19 INFO Executor: Running task 1.0 in stage 4.0 (TID 16)
17/03/27 22:25:19 INFO Executor: Running task 2.0 in stage 4.0 (TID 17)
17/03/27 22:25:19 INFO Executor: Running task 3.0 in stage 4.0 (TID 18)
17/03/27 22:25:19 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:19 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:19 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:19 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:19 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 267.3 MB, free 1338.9 MB)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_16_2 stored as values in memory (estimated size 267.3 MB, free 1071.7 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_16_3 in memory on localhost:51480 (size: 267.3 MB, free: 1338.9 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_16_2 in memory on localhost:51480 (size: 267.3 MB, free: 1071.7 MB)
17/03/27 22:25:19 INFO Executor: Finished task 3.0 in stage 4.0 (TID 18). 3087 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:19 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 18) in 80 ms on localhost (1/5)
17/03/27 22:25:19 INFO Executor: Running task 4.0 in stage 4.0 (TID 19)
17/03/27 22:25:19 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:19 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:19 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 7 took 1 ms
17/03/27 22:25:19 INFO Executor: Finished task 2.0 in stage 4.0 (TID 17). 3087 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 17) in 100 ms on localhost (2/5)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 267.3 MB, free 804.4 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_16_0 in memory on localhost:51480 (size: 267.3 MB, free: 804.4 MB)
17/03/27 22:25:19 INFO Executor: Finished task 0.0 in stage 4.0 (TID 15). 3087 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 15) in 123 ms on localhost (3/5)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 267.2 MB, free 537.2 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:51480 (size: 267.2 MB, free: 537.2 MB)
17/03/27 22:25:19 INFO Executor: Finished task 1.0 in stage 4.0 (TID 16). 3087 bytes result sent to driver
17/03/27 22:25:19 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 16) in 159 ms on localhost (4/5)
17/03/27 22:25:19 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 267.2 MB, free 270.0 MB)
17/03/27 22:25:19 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:51480 (size: 267.2 MB, free: 270.0 MB)
17/03/27 22:25:20 INFO Executor: Finished task 4.0 in stage 4.0 (TID 19). 3087 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 19) in 97 ms on localhost (5/5)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:20 INFO DAGScheduler: ShuffleMapStage 4 (mapPartitionsInternal at SetRDD.scala:92) finished in 0.178 s
17/03/27 22:25:20 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:20 INFO DAGScheduler: running: Set()
17/03/27 22:25:20 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:20 INFO DAGScheduler: failed: Set()
17/03/27 22:25:20 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[26] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.3 KB, free 270.0 MB)
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KB, free 270.0 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:51480 (size: 6.5 KB, free: 270.0 MB)
17/03/27 22:25:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[26] at execute at Recursion.scala:228)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 5 tasks
17/03/27 22:25:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2229 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2229 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2229 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2229 bytes)
17/03/27 22:25:20 INFO Executor: Running task 0.0 in stage 8.0 (TID 20)
17/03/27 22:25:20 INFO Executor: Running task 2.0 in stage 8.0 (TID 22)
17/03/27 22:25:20 INFO Executor: Running task 1.0 in stage 8.0 (TID 21)
17/03/27 22:25:20 INFO Executor: Running task 3.0 in stage 8.0 (TID 23)
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_18_2 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_16_2 locally
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_18_3 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_16_3 locally
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_18_0 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_16_0 locally
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_18_1 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_16_1 locally
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:20 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:51480 in memory (size: 4.4 KB, free: 270.0 MB)
17/03/27 22:25:20 INFO MemoryStore: 7 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:51480 (size: 4.0 KB)
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:51480 (size: 6.2 KB)
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:51480 in memory (size: 11.5 MB, free: 281.6 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_16_4 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_16_4 on localhost:51480 in memory (size: 267.2 MB, free: 548.8 MB)
17/03/27 22:25:20 INFO MemoryStore: 4 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:51480 (size: 6.5 KB)
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:51480 in memory (size: 107.6 MB, free: 656.4 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_16_2 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_16_2 on localhost:51480 in memory (size: 267.3 MB, free: 923.7 MB)
17/03/27 22:25:20 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:51480 in memory (size: 107.6 MB, free: 1031.3 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_16_3 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_16_3 on localhost:51480 in memory (size: 267.3 MB, free: 1298.5 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:51480 in memory (size: 107.6 MB, free: 1406.2 MB)
17/03/27 22:25:20 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_16_0 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_16_0 on localhost:51480 in memory (size: 267.3 MB, free: 1673.4 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:51480 in memory (size: 107.6 MB, free: 1781.1 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:51480 on disk (size: 6.2 KB)
17/03/27 22:25:20 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:51480 on disk (size: 4.0 KB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_18_3 stored as values in memory (estimated size 267.4 MB, free 1417.4 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_18_3 in memory on localhost:51480 (size: 267.4 MB, free: 1513.6 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_18_2 stored as values in memory (estimated size 267.4 MB, free 1150.0 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_18_2 in memory on localhost:51480 (size: 267.4 MB, free: 1246.2 MB)
17/03/27 22:25:20 INFO Executor: Finished task 3.0 in stage 8.0 (TID 23). 3615 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2229 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 23) in 294 ms on localhost (1/5)
17/03/27 22:25:20 INFO Executor: Running task 4.0 in stage 8.0 (TID 24)
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.3 KB, free 1150.0 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_18_0 stored as values in memory (estimated size 267.4 MB, free 882.6 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_18_0 in memory on localhost:51480 (size: 267.4 MB, free: 978.8 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_18_1 stored as values in memory (estimated size 267.4 MB, free 583.1 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_18_1 in memory on localhost:51480 (size: 267.4 MB, free: 711.3 MB)
17/03/27 22:25:20 INFO Executor: Finished task 0.0 in stage 8.0 (TID 20). 3832 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 20) in 313 ms on localhost (2/5)
17/03/27 22:25:20 INFO Executor: Finished task 2.0 in stage 8.0 (TID 22). 3675 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 22) in 322 ms on localhost (3/5)
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_18_4 not found, computing it
17/03/27 22:25:20 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO Executor: Finished task 1.0 in stage 8.0 (TID 21). 3966 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 21) in 349 ms on localhost (4/5)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 267.2 MB, free 412.0 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51480 (size: 267.2 MB, free: 444.1 MB)
17/03/27 22:25:20 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 7 took 1 ms
17/03/27 22:25:20 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 267.2 MB, free 144.8 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:51480 (size: 267.2 MB, free: 176.9 MB)
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Union set size 6 for rdd 7 took 0 ms
17/03/27 22:25:20 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_16_1 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_16_1 on localhost:51480 in memory (size: 267.2 MB, free: 444.1 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_18_4 stored as values in memory (estimated size 267.2 MB, free 144.8 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_18_4 in memory on localhost:51480 (size: 267.2 MB, free: 176.9 MB)
17/03/27 22:25:20 INFO Executor: Finished task 4.0 in stage 8.0 (TID 24). 3665 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 24) in 252 ms on localhost (5/5)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/27 22:25:20 INFO DAGScheduler: ShuffleMapStage 8 (execute at Recursion.scala:228) finished in 0.545 s
17/03/27 22:25:20 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:20 INFO DAGScheduler: running: Set()
17/03/27 22:25:20 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9)
17/03/27 22:25:20 INFO DAGScheduler: failed: Set()
17/03/27 22:25:20 INFO DAGScheduler: Submitting FixedPointResultStage 9 (SetRDD.diffRDD SetRDD[29] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 176.9 MB)
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.7 KB, free 176.8 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:51480 (size: 6.7 KB, free: 176.9 MB)
17/03/27 22:25:20 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:20 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 9 (SetRDD.diffRDD SetRDD[29] at RDD at SetRDD.scala:30)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks
17/03/27 22:25:20 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 26, localhost, partition 1,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 27, localhost, partition 2,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 28, localhost, partition 3,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:20 INFO Executor: Running task 0.0 in stage 9.0 (TID 25)
17/03/27 22:25:20 INFO Executor: Running task 1.0 in stage 9.0 (TID 26)
17/03/27 22:25:20 INFO Executor: Running task 2.0 in stage 9.0 (TID 27)
17/03/27 22:25:20 INFO Executor: Running task 3.0 in stage 9.0 (TID 28)
17/03/27 22:25:20 INFO CacheManager: Partition rdd_28_2 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_18_2 locally
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_28_1 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_18_1 locally
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 19 took 1 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 19 took 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_28_0 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_18_0 locally
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 4 for rdd 19 took 0 ms
17/03/27 22:25:20 INFO CacheManager: Partition rdd_28_3 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_18_3 locally
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 19 took 1 ms
17/03/27 22:25:20 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:51480 in memory (size: 267.2 MB, free: 444.1 MB)
17/03/27 22:25:20 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_16_4 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_16_4 on localhost:51480 in memory (size: 267.2 MB, free: 711.3 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_18_4 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_18_4 on localhost:51480 in memory (size: 267.2 MB, free: 978.5 MB)
17/03/27 22:25:20 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_5_piece0 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_5_piece0 to disk
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_5_piece0 on disk on localhost:51480 (size: 6.7 KB)
17/03/27 22:25:20 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:25:20 INFO BlockManager: Writing block broadcast_5 to disk
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_18_2 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_18_2 on localhost:51480 in memory (size: 267.4 MB, free: 1245.9 MB)
17/03/27 22:25:20 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_18_1 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_18_1 on localhost:51480 in memory (size: 267.4 MB, free: 1513.4 MB)
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_18_0 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_18_0 on localhost:51480 in memory (size: 267.4 MB, free: 1780.8 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_28_1 stored as values in memory (estimated size 267.3 MB, free 1513.5 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_28_1 in memory on localhost:51480 (size: 267.3 MB, free: 1513.5 MB)
17/03/27 22:25:20 INFO Executor: Finished task 1.0 in stage 9.0 (TID 26). 3396 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 29, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:20 INFO Executor: Running task 4.0 in stage 9.0 (TID 29)
17/03/27 22:25:20 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 26) in 80 ms on localhost (1/5)
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.9 KB, free 1513.5 MB)
17/03/27 22:25:20 INFO CacheManager: Partition rdd_28_4 not found, computing it
17/03/27 22:25:20 INFO CacheManager: Partition rdd_18_4 not found, computing it
17/03/27 22:25:20 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO MemoryStore: Block rdd_28_2 stored as values in memory (estimated size 267.3 MB, free 1246.3 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_28_2 in memory on localhost:51480 (size: 267.3 MB, free: 1246.3 MB)
17/03/27 22:25:20 INFO Executor: Finished task 2.0 in stage 9.0 (TID 27). 3484 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 27) in 88 ms on localhost (2/5)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_28_0 stored as values in memory (estimated size 267.2 MB, free 979.0 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_28_0 in memory on localhost:51480 (size: 267.2 MB, free: 979.0 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_28_3 stored as values in memory (estimated size 267.2 MB, free 711.8 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_28_3 in memory on localhost:51480 (size: 267.2 MB, free: 711.8 MB)
17/03/27 22:25:20 INFO Executor: Finished task 0.0 in stage 9.0 (TID 25). 3553 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 25) in 103 ms on localhost (3/5)
17/03/27 22:25:20 INFO Executor: Finished task 3.0 in stage 9.0 (TID 28). 3396 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 28) in 104 ms on localhost (4/5)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 267.2 MB, free 444.6 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51480 (size: 267.2 MB, free: 444.6 MB)
17/03/27 22:25:20 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:20 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 7 took 1 ms
17/03/27 22:25:20 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 267.2 MB, free 177.5 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:51480 (size: 267.2 MB, free: 177.5 MB)
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Union set size 6 for rdd 7 took 0 ms
17/03/27 22:25:20 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_28_1 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_28_1 on localhost:51480 in memory (size: 267.3 MB, free: 444.7 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_18_4 stored as values in memory (estimated size 267.2 MB, free 177.6 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_18_4 in memory on localhost:51480 (size: 267.2 MB, free: 177.6 MB)
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:20 INFO SetRDDHashSetPartition: Diff set size 6 for rdd 19 took 0 ms
17/03/27 22:25:20 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:20 INFO BlockManager: Dropping block rdd_18_3 from memory
17/03/27 22:25:20 INFO BlockManagerInfo: Removed rdd_18_3 on localhost:51480 in memory (size: 267.4 MB, free: 445.0 MB)
17/03/27 22:25:20 INFO MemoryStore: Block rdd_28_4 stored as values in memory (estimated size 267.2 MB, free 177.8 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added rdd_28_4 in memory on localhost:51480 (size: 267.2 MB, free: 177.8 MB)
17/03/27 22:25:20 INFO Executor: Finished task 4.0 in stage 9.0 (TID 29). 3561 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 29) in 252 ms on localhost (5/5)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/27 22:25:20 INFO DAGScheduler: FixedPointResultStage 9 (runFixedPointJob at Recursion.scala:204) finished in 0.332 s
17/03/27 22:25:20 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:20 INFO Recursion: Fixed Point Iteration # 2, time: 1728ms
17/03/27 22:25:20 INFO DAGScheduler: Registering RDD 36 (mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:20 INFO DAGScheduler: Registering RDD 42 (execute at Recursion.scala:228)
17/03/27 22:25:20 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[36] at mapPartitionsInternal at SetRDD.scala:92), which has no missing parents
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 6.4 KB, free 177.8 MB)
17/03/27 22:25:20 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.6 KB, free 177.8 MB)
17/03/27 22:25:20 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:51480 (size: 3.6 KB, free: 177.8 MB)
17/03/27 22:25:20 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[36] at mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Adding task set 10.0 with 5 tasks
17/03/27 22:25:20 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 2.0 in stage 10.0 (TID 31, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 3.0 in stage 10.0 (TID 32, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Starting task 4.0 in stage 10.0 (TID 33, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:20 INFO Executor: Running task 0.0 in stage 10.0 (TID 30)
17/03/27 22:25:20 INFO Executor: Running task 2.0 in stage 10.0 (TID 31)
17/03/27 22:25:20 INFO Executor: Running task 3.0 in stage 10.0 (TID 32)
17/03/27 22:25:20 INFO Executor: Running task 4.0 in stage 10.0 (TID 33)
17/03/27 22:25:20 INFO BlockManager: Found block rdd_28_2 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_28_4 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_28_0 locally
17/03/27 22:25:20 INFO BlockManager: Found block rdd_28_3 locally
17/03/27 22:25:20 INFO Executor: Finished task 2.0 in stage 10.0 (TID 31). 2372 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSetManager: Starting task 1.0 in stage 10.0 (TID 34, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:20 INFO TaskSetManager: Finished task 2.0 in stage 10.0 (TID 31) in 11 ms on localhost (1/5)
17/03/27 22:25:20 INFO Executor: Running task 1.0 in stage 10.0 (TID 34)
17/03/27 22:25:20 INFO CacheManager: Partition rdd_28_1 not found, computing it
17/03/27 22:25:20 INFO Executor: Finished task 3.0 in stage 10.0 (TID 32). 2372 bytes result sent to driver
17/03/27 22:25:20 ERROR Executor: Exception in task 1.0 in stage 10.0 (TID 34)
org.apache.spark.SparkException: Checkpoint block rdd_28_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:20 INFO TaskSetManager: Finished task 3.0 in stage 10.0 (TID 32) in 29 ms on localhost (2/5)
17/03/27 22:25:20 WARN TaskSetManager: Lost task 1.0 in stage 10.0 (TID 34, localhost): org.apache.spark.SparkException: Checkpoint block rdd_28_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:20 ERROR TaskSetManager: Task 1 in stage 10.0 failed 1 times; aborting job
17/03/27 22:25:20 INFO Executor: Finished task 0.0 in stage 10.0 (TID 30). 2372 bytes result sent to driver
17/03/27 22:25:20 INFO Executor: Finished task 4.0 in stage 10.0 (TID 33). 2372 bytes result sent to driver
17/03/27 22:25:20 INFO TaskSchedulerImpl: Cancelling stage 10
17/03/27 22:25:20 INFO TaskSchedulerImpl: Stage 10 was cancelled
17/03/27 22:25:20 INFO DAGScheduler: ShuffleMapStage 10 (mapPartitionsInternal at SetRDD.scala:92) failed in 0.058 s
17/03/27 22:25:20 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 30) in 60 ms on localhost (3/5)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/27 22:25:20 INFO DAGScheduler: Fixed Point Job 0 failed: runFixedPointJob at Recursion.scala:204, took 1.805174 s
17/03/27 22:25:20 INFO TaskSetManager: Finished task 4.0 in stage 10.0 (TID 33) in 60 ms on localhost (4/5)
17/03/27 22:25:20 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/03/27 22:25:20 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:20 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:20 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[31m- Aggregates over Recursion - NL ShortestPaths - fff *** FAILED ***[0m
[31m  org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[X#40,Y#44], functions=[(min(C#46),mode=Final,isDistinct=false)], output=[X#40,Y#44,C#47])[0m
[31m+- TungstenAggregate(key=[X#40,Y#44], functions=[(min(C#46),mode=Partial,isDistinct=false)], output=[X#40,Y#44,min#53])[0m
[31m   +- Recursion [X#40,Y#44,C#46] (NonLinear) [path][1,0,0][0m
[31m      :- TungstenExchange hashpartitioning(From#34,5), None[0m
[31m      :  +- ConvertToUnsafe[0m
[31m      :     +- Scan ExistingRDD[From#34,To#35,D#36] [0m
[31m      +- TungstenExchange hashpartitioning(X#40,5), None[0m
[31m         +- Project [X#40,Y#44,(C1#42 + C2#45) AS C#46][0m
[31m            +- SortMergeJoin [Z#41], [Z#43][0m
[31m               :- Sort [Z#41 ASC], false, 0[0m
[31m               :  +- TungstenExchange hashpartitioning(Z#41,5), None[0m
[31m               :     +- LinearRecursiveRelation [X#40,Z#41,C1#42](path)[0m
[31m               +- Sort [Z#43 ASC], false, 0[0m
[31m                  +- NonLinearRecursiveRelation [Z#43,Y#44,C2#45](all_path)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)[0m
[31m  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)[0m
[31m  at org.apache.spark.sql.DataFrame.rdd$lzycompute(DataFrame.scala:1638)[0m
[31m  at org.apache.spark.sql.DataFrame.rdd(DataFrame.scala:1635)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[X#40,Y#44], functions=[(min(C#46),mode=Partial,isDistinct=false)], output=[X#40,Y#44,min#53])[0m
[31m+- Recursion [X#40,Y#44,C#46] (NonLinear) [path][1,0,0][0m
[31m   :- TungstenExchange hashpartitioning(From#34,5), None[0m
[31m   :  +- ConvertToUnsafe[0m
[31m   :     +- Scan ExistingRDD[From#34,To#35,D#36] [0m
[31m   +- TungstenExchange hashpartitioning(X#40,5), None[0m
[31m      +- Project [X#40,Y#44,(C1#42 + C2#45) AS C#46][0m
[31m         +- SortMergeJoin [Z#41], [Z#43][0m
[31m            :- Sort [Z#41 ASC], false, 0[0m
[31m            :  +- TungstenExchange hashpartitioning(Z#41,5), None[0m
[31m            :     +- LinearRecursiveRelation [X#40,Z#41,C1#42](path)[0m
[31m            +- Sort [Z#43 ASC], false, 0[0m
[31m               +- NonLinearRecursiveRelation [Z#43,Y#44,C2#45](all_path)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 10.0 failed 1 times, most recent failure: Lost task 1.0 in stage 10.0 (TID 34, localhost): org.apache.spark.SparkException: Checkpoint block rdd_28_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_28_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)[0m
[31m  ...[0m
17/03/27 22:25:21 INFO Utils: Successfully started service 'sparkDriver' on port 51501.
17/03/27 22:25:21 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:21 INFO Remoting: Starting remoting
17/03/27 22:25:21 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51514]
17/03/27 22:25:21 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51514.
17/03/27 22:25:21 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:21 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:21 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-d9eb60a2-120e-49b5-b8e2-e8f19de42e3f
17/03/27 22:25:21 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:21 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:21 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:21 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51531.
17/03/27 22:25:21 INFO NettyBlockTransferService: Server created on 51531
17/03/27 22:25:21 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:21 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51531 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51531)
17/03/27 22:25:21 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:21 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667921091
17/03/27 22:25:21 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$12.apply$mcV$sp(RecursiveQuerySuites.scala:226)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$12.apply(RecursiveQuerySuites.scala:217)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$12.apply(RecursiveQuerySuites.scala:217)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$13.apply$mcV$sp(RecursiveQuerySuites.scala:238)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$13.apply(RecursiveQuerySuites.scala:231)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$13.apply(RecursiveQuerySuites.scala:231)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:21 INFO AggregatesOverRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:21 INFO BigDatalogContext: BigDatalog Query: "stratified_shortest_path(A,B,C)"
17/03/27 22:25:21 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:21 INFO BigDatalogContext: 
0: (From, Y, min(C) as C) <AGGREGATE>
 1: path(From, Y, C) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
 Exit Rules: 
  2: arc(From, To, D) <BASE_RELATION>
 Recursive Rules: 
  2: (From, Y, D + C2 as C) <DISTINCT PROJECT>
   3: (0.To = 1.Z) <JOIN>
    4: arc(From, To, D) <BASE_RELATION>
    4: path(Z, Y, C2) <RECURSIVE_RELATION>
17/03/27 22:25:21 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:21 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:21 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_stratified_shortest_path
+- 'Aggregate ['path.From,'path.Y], ['path.From,'path.Y,unresolvedalias('min('path.C) AS C#64)]
   +- 'Subquery path
      +- 'Recursion path, true, [0,1,0]
         :- 'UnresolvedRelation `arc`, None
         +- 'Project ['arc1.From,'path2.Y,unresolvedalias(('arc1.D + 'path2.C2) AS C#63)]
            +- 'Join Inner, Some(('arc1.To = 'path2.Z))
               :- 'BroadcastHint
               :  +- 'Subquery arc1
               :     +- 'Project [*]
               :        +- 'UnresolvedRelation `arc`, None
               +- Subquery path2
                  +- LinearRecursiveRelation path, [Z#60,Y#61,C2#62], [0,1,0]

== Analyzed Logical Plan ==
From: int, Y: int, C: int
Subquery aggregate_stratified_shortest_path
+- Aggregate [From#54,Y#61], [From#54,Y#61,(min(C#63),mode=Complete,isDistinct=false) AS C#64]
   +- Subquery path
      +- Recursion path, true, [0,1,0]
         :- Subquery arc
         :  +- LogicalRDD [From#54,To#55,D#56], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [From#54,Y#61,(D#56 + C2#62) AS C#63]
            +- Join Inner, Some((To#55 = Z#60))
               :- BroadcastHint
               :  +- Subquery arc1
               :     +- Project [From#54,To#55,D#56]
               :        +- Subquery arc
               :           +- LogicalRDD [From#54,To#55,D#56], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Subquery path2
                  +- LinearRecursiveRelation path, [Z#60,Y#61,C2#62], [0,1,0]

== Optimized Logical Plan ==
Aggregate [From#54,Y#61], [From#54,Y#61,(min(C#63),mode=Complete,isDistinct=false) AS C#64]
+- Recursion path, true, [0,1,0]
   :- LogicalRDD [From#54,To#55,D#56], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [From#54,Y#61,(D#56 + C2#62) AS C#63]
      +- Join Inner, Some((To#55 = Z#60))
         :- BroadcastHint
         :  +- Project [From#54,To#55,D#56]
         :     +- LogicalRDD [From#54,To#55,D#56], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- LinearRecursiveRelation path, [Z#60,Y#61,C2#62], [0,1,0]

== Physical Plan ==
TungstenAggregate(key=[From#54,Y#61], functions=[(min(C#63),mode=Final,isDistinct=false)], output=[From#54,Y#61,C#64])
+- TungstenAggregate(key=[From#54,Y#61], functions=[(min(C#63),mode=Partial,isDistinct=false)], output=[From#54,Y#61,min#67])
   +- Recursion [From#54,Y#61,C#63] (Linear) [path][0,1,0]
      :- TungstenExchange hashpartitioning(To#55,5), None
      :  +- ConvertToUnsafe
      :     +- Scan ExistingRDD[From#54,To#55,D#56] 
      +- Project [From#54,Y#61,(D#56 + C2#62) AS C#63]
         +- BroadcastHashJoin [To#55], [Z#60], BuildLeft
            :- Project [From#54,To#55,D#56]
            :  +- Scan ExistingRDD[From#54,To#55,D#56] 
            +- LinearRecursiveRelation [Z#60,Y#61,C2#62](path)
17/03/27 22:25:21 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:21 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:21 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:21 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:21 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:21 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:21 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:21 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:21 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:21 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[8] at run at null:-1), which has no missing parents
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51531 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:21 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:21 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at run at null:-1)
17/03/27 22:25:21 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:21 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2362 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:21 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:21 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:21 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:21 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:21 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1500 bytes result sent to driver
17/03/27 22:25:21 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1500 bytes result sent to driver
17/03/27 22:25:21 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1500 bytes result sent to driver
17/03/27 22:25:21 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1500 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:21 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:21 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1549 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13 ms on localhost (1/5)
17/03/27 22:25:21 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 5 ms on localhost (2/5)
17/03/27 22:25:21 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 13 ms on localhost (3/5)
17/03/27 22:25:21 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 13 ms on localhost (4/5)
17/03/27 22:25:21 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 14 ms on localhost (5/5)
17/03/27 22:25:21 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:21 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.015 s
17/03/27 22:25:21 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.023035 s
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.6 KB, free 2.0 GB)
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 316.0 B, free 2.0 GB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51531 (size: 316.0 B, free: 2.0 GB)
17/03/27 22:25:21 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:21 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:21 INFO Recursion: Fixed Point Iteration # 1, time: 46ms
17/03/27 22:25:21 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:25:21 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:21 INFO DAGScheduler: Final stage: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:21 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51531 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:21 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:21 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:25:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2361 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:21 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:21 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:21 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 52 ms on localhost (1/5)
17/03/27 22:25:21 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:21 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 60 ms on localhost (2/5)
17/03/27 22:25:21 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1222 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 20 ms on localhost (3/5)
17/03/27 22:25:21 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 81 ms on localhost (4/5)
17/03/27 22:25:21 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 86 ms on localhost (5/5)
17/03/27 22:25:21 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.087 s
17/03/27 22:25:21 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:21 INFO DAGScheduler: running: Set()
17/03/27 22:25:21 INFO DAGScheduler: waiting: Set(FixedPointResultStage 2)
17/03/27 22:25:21 INFO DAGScheduler: failed: Set()
17/03/27 22:25:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:21 INFO DAGScheduler: Submitting FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.5 KB, free 2.0 GB)
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.1 KB, free 2.0 GB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:51531 (size: 7.1 KB, free: 2.0 GB)
17/03/27 22:25:21 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:21 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:21 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:21 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:21 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:21 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:21 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:21 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:21 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_17_3 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO CacheManager: Partition rdd_17_2 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 268.8 MB, free 1779.4 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:51531 (size: 268.8 MB, free: 1779.5 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 268.8 MB, free 1510.7 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 268.8 MB, free 1241.9 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:51531 (size: 268.8 MB, free: 1510.7 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:51531 (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 268.8 MB, free 973.1 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:51531 (size: 268.8 MB, free: 973.1 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 8 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:51531 (size: 2.7 KB)
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:51531 (size: 316.0 B)
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:51531 (size: 2.8 KB)
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:25:21 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:51531 (size: 7.1 KB)
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:51531 in memory (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 268.8 MB, free 973.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_3 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:51531 in memory (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 268.8 MB, free 973.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 268.8 MB, free 704.4 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_0 in memory on localhost:51531 (size: 268.8 MB, free: 704.4 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Union set size 5 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:51531 in memory (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 268.8 MB, free 704.4 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:51531 (size: 268.8 MB, free: 704.4 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Union set size 5 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:51531 in memory (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:21 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_11_3 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_11_3 on localhost:51531 in memory (size: 268.8 MB, free: 1242.0 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 268.8 MB, free 973.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_13_3 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_11_1 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_11_1 on localhost:51531 in memory (size: 268.8 MB, free: 1242.0 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 268.8 MB, free 973.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 268.8 MB, free 704.4 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_13_0 in memory on localhost:51531 (size: 268.8 MB, free: 704.4 MB)
17/03/27 22:25:21 INFO BlockManager: Found block rdd_11_0 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_11_2 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_11_2 on localhost:51531 in memory (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 268.8 MB, free 704.4 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_13_2 in memory on localhost:51531 (size: 268.8 MB, free: 704.4 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_13_3 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_13_3 on localhost:51531 in memory (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_13_1 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_13_1 on localhost:51531 in memory (size: 268.8 MB, free: 1242.0 MB)
17/03/27 22:25:21 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_13_0 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_13_0 on localhost:51531 in memory (size: 268.8 MB, free: 1510.7 MB)
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_11_0 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_11_0 on localhost:51531 in memory (size: 268.8 MB, free: 1779.5 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 268.8 MB, free 1510.7 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:51531 (size: 268.8 MB, free: 1510.7 MB)
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 268.8 MB, free 1242.0 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:51531 (size: 268.8 MB, free: 1242.0 MB)
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 268.8 MB, free 973.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 4120 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:21 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:21 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 464 ms on localhost (1/5)
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.5 KB, free 973.2 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_17_4 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:25:21 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 268.8 MB, free 704.4 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:51531 (size: 268.8 MB, free: 704.4 MB)
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_13_2 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_13_2 on localhost:51531 in memory (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_17_0 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_17_0 on localhost:51531 in memory (size: 268.8 MB, free: 1242.0 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 268.8 MB, free 973.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_3 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:51531 in memory (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 14 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 268.8 MB, free 973.1 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:51531 (size: 268.8 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:51531 in memory (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 268.8 MB, free 973.1 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:51531 (size: 268.8 MB, free: 973.1 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 268.8 MB, free 704.3 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51531 (size: 268.8 MB, free: 704.3 MB)
17/03/27 22:25:21 INFO CacheManager: Partition rdd_11_4 not found, computing it
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:21 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:21 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 672.3 MB)
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:21 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:51531 in memory (size: 268.8 MB, free: 973.1 MB)
17/03/27 22:25:21 INFO MemoryStore: Will not store rdd_11_4 as it would require dropping another block from the same RDD
17/03/27 22:25:21 WARN MemoryStore: Not enough space to cache rdd_11_4 in memory! (computed 268.8 MB so far)
17/03/27 22:25:21 INFO MemoryStore: Memory use = 1107.1 MB (blocks) + 856.4 MB (scratch space shared across 5 tasks(s)) = 1963.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:21 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:21 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_11_3 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_11_3 on localhost:51531 in memory (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO BlockManager: Dropping block rdd_11_1 from memory
17/03/27 22:25:21 INFO BlockManagerInfo: Removed rdd_11_1 on localhost:51531 in memory (size: 268.8 MB, free: 1510.7 MB)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 268.8 MB, free 1209.9 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_17_1 in memory on localhost:51531 (size: 268.8 MB, free: 1241.9 MB)
17/03/27 22:25:21 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 3810 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 613 ms on localhost (2/5)
17/03/27 22:25:21 INFO MemoryStore: Block rdd_17_3 stored as values in memory (estimated size 268.7 MB, free 941.2 MB)
17/03/27 22:25:21 INFO BlockManagerInfo: Added rdd_17_3 in memory on localhost:51531 (size: 268.7 MB, free: 973.2 MB)
17/03/27 22:25:21 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 3611 bytes result sent to driver
17/03/27 22:25:21 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 620 ms on localhost (3/5)
17/03/27 22:25:22 INFO MemoryStore: Block rdd_17_2 stored as values in memory (estimated size 268.7 MB, free 672.4 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_17_2 in memory on localhost:51531 (size: 268.7 MB, free: 704.4 MB)
17/03/27 22:25:22 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3851 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 638 ms on localhost (4/5)
17/03/27 22:25:22 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 268.7 MB, free 403.8 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_13_4 in memory on localhost:51531 (size: 268.7 MB, free: 435.8 MB)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_11_4 not found, computing it
17/03/27 22:25:22 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:22 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:22 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:22 INFO MemoryStore: Block rdd_11_4 stored as values in memory (estimated size 236.7 MB, free 199.1 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_11_4 in memory on localhost:51531 (size: 236.7 MB, free: 199.1 MB)
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 14 took 0 ms
17/03/27 22:25:22 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:22 INFO BlockManager: Dropping block rdd_11_2 from memory
17/03/27 22:25:22 INFO BlockManagerInfo: Removed rdd_11_2 on localhost:51531 in memory (size: 268.8 MB, free: 467.9 MB)
17/03/27 22:25:22 INFO MemoryStore: Block rdd_17_4 stored as values in memory (estimated size 236.7 MB, free 231.2 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_17_4 in memory on localhost:51531 (size: 236.7 MB, free: 231.2 MB)
17/03/27 22:25:22 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 3589 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 364 ms on localhost (5/5)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:22 INFO DAGScheduler: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204) finished in 0.827 s
17/03/27 22:25:22 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:22 INFO Recursion: Fixed Point Iteration # 2, time: 931ms
17/03/27 22:25:22 INFO DAGScheduler: Submitting FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.8 KB, free 231.2 MB)
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.3 KB, free 231.2 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:51531 (size: 7.3 KB, free: 231.2 MB)
17/03/27 22:25:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:22 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:22 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 16, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 17, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 18, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:22 INFO Executor: Running task 1.0 in stage 3.0 (TID 15)
17/03/27 22:25:22 INFO Executor: Running task 2.0 in stage 3.0 (TID 16)
17/03/27 22:25:22 INFO Executor: Running task 3.0 in stage 3.0 (TID 17)
17/03/27 22:25:22 INFO Executor: Running task 4.0 in stage 3.0 (TID 18)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_27_1 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_27_3 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_27_4 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_27_2 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_23_4 not found, computing it
17/03/27 22:25:22 INFO BlockManager: Found block rdd_13_4 locally
17/03/27 22:25:22 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:22 INFO CacheManager: Partition rdd_23_3 not found, computing it
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Union set size 7 for rdd 14 took 0 ms
17/03/27 22:25:22 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:22 ERROR Executor: Exception in task 1.0 in stage 3.0 (TID 15)
org.apache.spark.SparkException: Checkpoint block rdd_13_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:25:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 19, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:22 ERROR Executor: Exception in task 3.0 in stage 3.0 (TID 17)
org.apache.spark.SparkException: Checkpoint block rdd_13_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 19)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:22 ERROR Executor: Exception in task 2.0 in stage 3.0 (TID 16)
org.apache.spark.SparkException: Checkpoint block rdd_13_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:22 WARN TaskSetManager: Lost task 1.0 in stage 3.0 (TID 15, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:22 ERROR TaskSetManager: Task 1 in stage 3.0 failed 1 times; aborting job
17/03/27 22:25:22 INFO TaskSchedulerImpl: Cancelling stage 3
17/03/27 22:25:22 INFO TaskSchedulerImpl: Stage 3 was cancelled
17/03/27 22:25:22 INFO DAGScheduler: FixedPointResultStage 3 (runFixedPointJob at Recursion.scala:204) failed in 0.020 s
17/03/27 22:25:22 WARN TaskSetManager: Lost task 3.0 in stage 3.0 (TID 17, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:22 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 0.963263 s
17/03/27 22:25:22 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:22 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:22 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:22 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:22 INFO Executor: Executor is trying to kill task 0.0 in stage 3.0 (TID 19)
17/03/27 22:25:22 INFO Executor: Executor is trying to kill task 4.0 in stage 3.0 (TID 18)
17/03/27 22:25:22 WARN TaskSetManager: Lost task 2.0 in stage 3.0 (TID 16, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:22 INFO CacheManager: Partition rdd_27_0 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_23_0 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:22 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 19)
org.apache.spark.SparkException: Checkpoint block rdd_13_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:22 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 19, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[31m- Aggregates over Recursion - RL ShortestPaths - fff *** FAILED ***[0m
[31m  org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[From#54,Y#61], functions=[(min(C#63),mode=Final,isDistinct=false)], output=[From#54,Y#61,C#64])[0m
[31m+- TungstenAggregate(key=[From#54,Y#61], functions=[(min(C#63),mode=Partial,isDistinct=false)], output=[From#54,Y#61,min#70])[0m
[31m   +- Recursion [From#54,Y#61,C#63] (Linear) [path][0,1,0][0m
[31m      :- TungstenExchange hashpartitioning(To#55,5), None[0m
[31m      :  +- ConvertToUnsafe[0m
[31m      :     +- Scan ExistingRDD[From#54,To#55,D#56] [0m
[31m      +- Project [From#54,Y#61,(D#56 + C2#62) AS C#63][0m
[31m         +- BroadcastHashJoin [To#55], [Z#60], BuildLeft[0m
[31m            :- Project [From#54,To#55,D#56][0m
[31m            :  +- Scan ExistingRDD[From#54,To#55,D#56] [0m
[31m            +- LinearRecursiveRelation [Z#60,Y#61,C2#62](path)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)[0m
[31m  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)[0m
[31m  at org.apache.spark.sql.DataFrame.rdd$lzycompute(DataFrame.scala:1638)[0m
[31m  at org.apache.spark.sql.DataFrame.rdd(DataFrame.scala:1635)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[From#54,Y#61], functions=[(min(C#63),mode=Partial,isDistinct=false)], output=[From#54,Y#61,min#70])[0m
[31m+- Recursion [From#54,Y#61,C#63] (Linear) [path][0,1,0][0m
[31m   :- TungstenExchange hashpartitioning(To#55,5), None[0m
[31m   :  +- ConvertToUnsafe[0m
[31m   :     +- Scan ExistingRDD[From#54,To#55,D#56] [0m
[31m   +- Project [From#54,Y#61,(D#56 + C2#62) AS C#63][0m
[31m      +- BroadcastHashJoin [To#55], [Z#60], BuildLeft[0m
[31m         :- Project [From#54,To#55,D#56][0m
[31m         :  +- Scan ExistingRDD[From#54,To#55,D#56] [0m
[31m         +- LinearRecursiveRelation [Z#60,Y#61,C2#62](path)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 3.0 failed 1 times, most recent failure: Lost task 1.0 in stage 3.0 (TID 15, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_13_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  ...[0m
17/03/27 22:25:22 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:22 INFO BlockManager: Dropping block rdd_17_1 from memory
17/03/27 22:25:22 INFO BlockManagerInfo: Removed rdd_17_1 on localhost:51531 in memory (size: 268.8 MB, free: 500.0 MB)
17/03/27 22:25:22 INFO Utils: Successfully started service 'sparkDriver' on port 51550.
17/03/27 22:25:22 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:22 INFO Remoting: Starting remoting
17/03/27 22:25:22 INFO MemoryStore: Block rdd_23_4 stored as values in memory (estimated size 237.7 MB, free 262.3 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_23_4 in memory on localhost:51531 (size: 237.7 MB, free: 262.4 MB)
17/03/27 22:25:22 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 230.3 MB)
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 24 took 1 ms
17/03/27 22:25:22 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51563.
17/03/27 22:25:22 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:22 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:22 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-f8280f9f-e5ab-47e2-9d98-433848e74121
17/03/27 22:25:22 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:22 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51563]
17/03/27 22:25:22 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:22 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:22 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:22 INFO BlockManager: Dropping block rdd_17_3 from memory
17/03/27 22:25:22 INFO BlockManagerInfo: Removed rdd_17_3 on localhost:51531 in memory (size: 268.7 MB, free: 531.1 MB)
17/03/27 22:25:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51580.
17/03/27 22:25:22 INFO NettyBlockTransferService: Server created on 51580
17/03/27 22:25:22 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:22 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51580 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51580)
17/03/27 22:25:22 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:22 INFO MemoryStore: Block rdd_27_4 stored as values in memory (estimated size 238.2 MB, free 260.9 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_27_4 in memory on localhost:51531 (size: 238.2 MB, free: 292.9 MB)
17/03/27 22:25:22 INFO Executor: Executor killed task 4.0 in stage 3.0 (TID 18)
17/03/27 22:25:22 WARN TaskSetManager: Lost task 4.0 in stage 3.0 (TID 18, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:22 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667922389
17/03/27 22:25:22 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$13.apply$mcV$sp(RecursiveQuerySuites.scala:238)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$13.apply(RecursiveQuerySuites.scala:231)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$13.apply(RecursiveQuerySuites.scala:231)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$14.apply$mcV$sp(RecursiveQuerySuites.scala:254)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$14.apply(RecursiveQuerySuites.scala:243)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$14.apply(RecursiveQuerySuites.scala:243)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:22 INFO AggregatesOverRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:22 INFO BigDatalogContext: BigDatalog Query: "stratified_shortest_path(0,B,C)"
17/03/27 22:25:22 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:22 INFO BigDatalogContext: 
0: (0, To, C) <PROJECT>
 1: (To, min(C) as C) <AGGREGATE>
  2: path(To, C) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
  Exit Rules: 
   3: (To, D) <PROJECT>
    4: From = 0 <FILTER>
     5: arc(From, To, D) <BASE_RELATION>
  Recursive Rules: 
   3: (To, C1 + D as C) <DISTINCT PROJECT>
    4: (0.Z = 1.From) <JOIN>
     5: path(Z, C1) <RECURSIVE_RELATION>
     5: arc(From, To, D) <BASE_RELATION>
17/03/27 22:25:22 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:22 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:22 INFO BigDatalogContext: == Parsed Logical Plan ==
'Project [0 AS c_1#80,'aggregate_stratified_shortest_path.To,'aggregate_stratified_shortest_path.C]
+- 'Subquery aggregate_stratified_shortest_path
   +- 'Aggregate ['path.To], ['path.To,unresolvedalias('min('path.C) AS C#79)]
      +- 'Subquery path
         +- 'Recursion path, true, [1,0]
            :- 'Project ['arc.To,'arc.D]
            :  +- 'Filter ('arc.From = 0)
            :     +- 'UnresolvedRelation `arc`, None
            +- 'Project ['arc2.To,unresolvedalias(('path1.C1 + 'arc2.D) AS C#78)]
               +- 'Join Inner, Some(('path1.Z = 'arc2.From))
                  :- Subquery path1
                  :  +- LinearRecursiveRelation path, [Z#76,C1#77], [1,0]
                  +- 'BroadcastHint
                     +- 'Subquery arc2
                        +- 'Project [*]
                           +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
c_1: int, To: int, C: int
Project [0 AS c_1#80,To#72,C#79]
+- Subquery aggregate_stratified_shortest_path
   +- Aggregate [To#72], [To#72,(min(C#78),mode=Complete,isDistinct=false) AS C#79]
      +- Subquery path
         +- Recursion path, true, [1,0]
            :- Project [To#72,D#73]
            :  +- Filter (From#71 = 0)
            :     +- Subquery arc
            :        +- LogicalRDD [From#71,To#72,D#73], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
            +- Project [To#72,(C1#77 + D#73) AS C#78]
               +- Join Inner, Some((Z#76 = From#71))
                  :- Subquery path1
                  :  +- LinearRecursiveRelation path, [Z#76,C1#77], [1,0]
                  +- BroadcastHint
                     +- Subquery arc2
                        +- Project [From#71,To#72,D#73]
                           +- Subquery arc
                              +- LogicalRDD [From#71,To#72,D#73], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Project [0 AS c_1#80,To#72,C#79]
+- Aggregate [To#72], [To#72,(min(C#78),mode=Complete,isDistinct=false) AS C#79]
   +- Recursion path, true, [1,0]
      :- Project [To#72,D#73]
      :  +- Filter (From#71 = 0)
      :     +- LogicalRDD [From#71,To#72,D#73], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [To#72,(C1#77 + D#73) AS C#78]
         +- Join Inner, Some((Z#76 = From#71))
            :- LinearRecursiveRelation path, [Z#76,C1#77], [1,0]
            +- BroadcastHint
               +- Project [From#71,To#72,D#73]
                  +- LogicalRDD [From#71,To#72,D#73], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Project [0 AS c_1#80,To#72,C#79]
+- TungstenAggregate(key=[To#72], functions=[(min(C#78),mode=Final,isDistinct=false)], output=[To#72,C#79])
   +- TungstenAggregate(key=[To#72], functions=[(min(C#78),mode=Partial,isDistinct=false)], output=[To#72,min#83])
      +- Recursion [To#72,C#78] (Linear) [path][1,0]
         :- TungstenExchange hashpartitioning(To#72,5), None
         :  +- Project [To#72,D#73]
         :     +- Filter (From#71 = 0)
         :        +- Scan ExistingRDD[From#71,To#72,D#73] 
         +- TungstenExchange hashpartitioning(To#72,5), None
            +- Project [To#72,(C1#77 + D#73) AS C#78]
               +- BroadcastHashJoin [Z#76], [From#71], BuildRight
                  :- LinearRecursiveRelation [Z#76,C1#77](path)
                  +- Project [From#71,To#72,D#73]
                     +- Scan ExistingRDD[From#71,To#72,D#73]
17/03/27 22:25:22 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:22 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:22 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:22 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:22 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:22 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:22 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:22 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:22 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:22 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at run at null:-1), which has no missing parents
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51580 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:22 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:22 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at run at null:-1)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:22 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2362 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:22 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:22 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:22 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1500 bytes result sent to driver
17/03/27 22:25:22 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1500 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:22 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:22 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:22 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:22 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1549 bytes result sent to driver
17/03/27 22:25:22 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1500 bytes result sent to driver
17/03/27 22:25:22 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1500 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9 ms on localhost (1/5)
17/03/27 22:25:22 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 9 ms on localhost (2/5)
17/03/27 22:25:22 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 9 ms on localhost (3/5)
17/03/27 22:25:22 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 4 ms on localhost (4/5)
17/03/27 22:25:22 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 10 ms on localhost (5/5)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:22 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.010 s
17/03/27 22:25:22 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.013549 s
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.5 KB, free 2.0 GB)
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 300.0 B, free 2.0 GB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51580 (size: 300.0 B, free: 2.0 GB)
17/03/27 22:25:22 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:22 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:22 INFO Recursion: Fixed Point Iteration # 1, time: 51ms
17/03/27 22:25:22 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:25:22 INFO DAGScheduler: Registering RDD 12 (execute at Recursion.scala:202)
17/03/27 22:25:22 INFO DAGScheduler: Registering RDD 20 (execute at Recursion.scala:228)
17/03/27 22:25:22 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:22 INFO DAGScheduler: Final stage: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:22 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.9 KB, free 2.0 GB)
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:51580 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:22 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:22 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:22 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2361 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:22 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:22 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:22 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:22 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:22 INFO GeneratePredicate: Code generated in 4.758509 ms
17/03/27 22:25:22 INFO GenerateUnsafeProjection: Code generated in 7.565207 ms
17/03/27 22:25:22 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1400 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 27 ms on localhost (1/5)
17/03/27 22:25:22 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1400 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 30 ms on localhost (2/5)
17/03/27 22:25:22 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1400 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 41 ms on localhost (3/5)
17/03/27 22:25:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1400 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 42 ms on localhost (4/5)
17/03/27 22:25:22 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1400 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 30 ms on localhost (5/5)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:22 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.057 s
17/03/27 22:25:22 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:22 INFO DAGScheduler: running: Set()
17/03/27 22:25:22 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:25:22 INFO DAGScheduler: failed: Set()
17/03/27 22:25:22 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.0 KB, free 2.0 GB)
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.2 KB, free 2.0 GB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:51580 (size: 6.2 KB, free: 2.0 GB)
17/03/27 22:25:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:22 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:22 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:22 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:22 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:22 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 238.7 MB, free 1809.5 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:51580 (size: 238.7 MB, free: 1809.5 MB)
17/03/27 22:25:22 INFO GenerateUnsafeProjection: Code generated in 8.255012 ms
17/03/27 22:25:22 INFO GenerateUnsafeProjection: Code generated in 13.526454 ms
17/03/27 22:25:22 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2210 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 128 ms on localhost (1/5)
17/03/27 22:25:22 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 238.8 MB, free 1570.7 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:51580 (size: 238.8 MB, free: 1570.8 MB)
17/03/27 22:25:22 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 238.8 MB, free 1332.0 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:51580 (size: 238.8 MB, free: 1332.0 MB)
17/03/27 22:25:22 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 238.8 MB, free 1093.2 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:51580 (size: 238.8 MB, free: 1093.3 MB)
17/03/27 22:25:22 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2210 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 178 ms on localhost (2/5)
17/03/27 22:25:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2210 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 180 ms on localhost (3/5)
17/03/27 22:25:22 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 2210 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 191 ms on localhost (4/5)
17/03/27 22:25:22 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 238.6 MB, free 854.6 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51580 (size: 238.6 MB, free: 854.6 MB)
17/03/27 22:25:22 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2210 bytes result sent to driver
17/03/27 22:25:22 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 120 ms on localhost (5/5)
17/03/27 22:25:22 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:202) finished in 0.247 s
17/03/27 22:25:22 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:22 INFO DAGScheduler: running: Set()
17/03/27 22:25:22 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:25:22 INFO DAGScheduler: failed: Set()
17/03/27 22:25:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:22 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.8 KB, free 854.6 MB)
17/03/27 22:25:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.5 KB, free 854.6 MB)
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:51580 (size: 6.5 KB, free: 854.6 MB)
17/03/27 22:25:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:22 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at execute at Recursion.scala:228)
17/03/27 22:25:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:22 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:22 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:22 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:22 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:22 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:25:22 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:22 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:25:22 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:22 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:25:22 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:22 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:22 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 7 took 1 ms
17/03/27 22:25:22 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 1 ms
17/03/27 22:25:22 INFO MemoryStore: 8 blocks selected for dropping
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:51580 (size: 2.7 KB)
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:51580 (size: 300.0 B)
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:51580 (size: 3.7 KB)
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:51580 (size: 6.2 KB)
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:25:22 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:25:22 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:51580 in memory (size: 238.6 MB, free: 1093.3 MB)
17/03/27 22:25:22 INFO MemoryStore: 5 blocks selected for dropping
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:25:22 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:51580 (size: 6.5 KB)
17/03/27 22:25:22 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:25:22 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:25:22 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:25:22 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:51580 in memory (size: 238.8 MB, free: 1332.0 MB)
17/03/27 22:25:22 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:22 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:51580 in memory (size: 238.8 MB, free: 1570.8 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 238.7 MB, free 1332.1 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 238.7 MB, free 1093.4 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:51580 (size: 238.7 MB, free: 1332.1 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 238.7 MB, free 854.6 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_2 in memory on localhost:51580 (size: 238.7 MB, free: 1093.4 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_3 in memory on localhost:51580 (size: 238.7 MB, free: 854.6 MB)
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 822.6 MB)
17/03/27 22:25:23 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 3980 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:23 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:23 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 106 ms on localhost (1/5)
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.8 KB, free 822.6 MB)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 3360 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 113 ms on localhost (2/5)
17/03/27 22:25:23 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 3360 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 124 ms on localhost (3/5)
17/03/27 22:25:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:51580 on disk (size: 6.5 KB)
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 102
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 101
17/03/27 22:25:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:51580 on disk (size: 6.2 KB)
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 100
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 99
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 270.8 MB, free 551.9 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_0 in memory on localhost:51580 (size: 270.8 MB, free: 583.9 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:51580 on disk (size: 3.7 KB)
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 98
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 97
17/03/27 22:25:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 3768 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 157 ms on localhost (4/5)
17/03/27 22:25:23 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:51580 on disk (size: 2.7 KB)
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 96
17/03/27 22:25:23 INFO ContextCleaner: Cleaned accumulator 95
17/03/27 22:25:23 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 238.6 MB, free 313.3 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:51580 (size: 238.6 MB, free: 345.3 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:51580 in memory (size: 238.8 MB, free: 584.0 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_4 stored as values in memory (estimated size 238.6 MB, free 313.4 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_4 in memory on localhost:51580 (size: 238.6 MB, free: 345.4 MB)
17/03/27 22:25:23 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 2331 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 188 ms on localhost (5/5)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:23 INFO DAGScheduler: ShuffleMapStage 3 (execute at Recursion.scala:228) finished in 0.294 s
17/03/27 22:25:23 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:23 INFO DAGScheduler: running: Set()
17/03/27 22:25:23 INFO DAGScheduler: waiting: Set(FixedPointResultStage 4)
17/03/27 22:25:23 INFO DAGScheduler: failed: Set()
17/03/27 22:25:23 INFO DAGScheduler: Submitting FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[23] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 313.4 MB)
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.8 KB, free 313.4 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:51580 (size: 6.8 KB, free: 345.4 MB)
17/03/27 22:25:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:23 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[23] at RDD at SetRDD.scala:30)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:23 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 20, localhost, partition 3,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 21, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 22, localhost, partition 0,NODE_LOCAL, 2408 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 23, localhost, partition 1,NODE_LOCAL, 2408 bytes)
17/03/27 22:25:23 INFO Executor: Running task 3.0 in stage 4.0 (TID 20)
17/03/27 22:25:23 INFO Executor: Running task 4.0 in stage 4.0 (TID 21)
17/03/27 22:25:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 22)
17/03/27 22:25:23 INFO Executor: Running task 1.0 in stage 4.0 (TID 23)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_22_0 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_22_3 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_22_4 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_22_1 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_14_3 locally
17/03/27 22:25:23 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 0 for rdd 7 took 1 ms
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:23 INFO BlockManager: Found block rdd_14_4 locally
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 0 for rdd 7 took 0 ms
17/03/27 22:25:23 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:51580 in memory (size: 238.7 MB, free: 584.1 MB)
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_2 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_2 on localhost:51580 in memory (size: 238.7 MB, free: 822.8 MB)
17/03/27 22:25:23 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_0 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_0 on localhost:51580 in memory (size: 270.8 MB, free: 1093.6 MB)
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:23 INFO MemoryStore: 4 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_5_piece0 from memory
17/03/27 22:25:23 INFO BlockManager: Writing block broadcast_5_piece0 to disk
17/03/27 22:25:23 INFO BlockManagerInfo: Added broadcast_5_piece0 on disk on localhost:51580 (size: 6.8 KB)
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:25:23 INFO BlockManager: Writing block broadcast_5 to disk
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_3 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_3 on localhost:51580 in memory (size: 238.7 MB, free: 1332.3 MB)
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_4 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_4 on localhost:51580 in memory (size: 238.6 MB, free: 1570.9 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 206.7 MB, free 1364.2 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 206.7 MB, free 1157.5 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_16_3 in memory on localhost:51580 (size: 206.7 MB, free: 1364.2 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:51580 (size: 206.7 MB, free: 1157.5 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 17 took 1 ms
17/03/27 22:25:23 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 1 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 206.7 MB, free 950.7 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:51580 (size: 206.7 MB, free: 950.7 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 206.7 MB, free 744.0 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:51580 (size: 206.7 MB, free: 744.0 MB)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:51580 in memory (size: 238.7 MB, free: 982.7 MB)
17/03/27 22:25:23 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:51580 in memory (size: 238.6 MB, free: 1221.3 MB)
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_16_3 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_16_3 on localhost:51580 in memory (size: 206.7 MB, free: 1428.0 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_22_3 stored as values in memory (estimated size 206.7 MB, free 1221.3 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_22_3 in memory on localhost:51580 (size: 206.7 MB, free: 1221.3 MB)
17/03/27 22:25:23 INFO Executor: Finished task 3.0 in stage 4.0 (TID 20). 3391 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 24, localhost, partition 2,NODE_LOCAL, 2408 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 20) in 189 ms on localhost (1/5)
17/03/27 22:25:23 INFO Executor: Running task 2.0 in stage 4.0 (TID 24)
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 1221.3 MB)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_22_2 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 206.8 MB, free 1014.5 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_0 in memory on localhost:51580 (size: 206.8 MB, free: 1014.5 MB)
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_22_4 stored as values in memory (estimated size 206.8 MB, free 807.8 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_22_4 in memory on localhost:51580 (size: 206.8 MB, free: 807.8 MB)
17/03/27 22:25:23 INFO Executor: Finished task 4.0 in stage 4.0 (TID 21). 3599 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 21) in 217 ms on localhost (2/5)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 206.7 MB, free 601.0 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:51580 (size: 206.7 MB, free: 601.1 MB)
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 3 for rdd 7 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:51580 in memory (size: 206.7 MB, free: 807.8 MB)
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:51580 in memory (size: 206.7 MB, free: 1014.5 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 206.7 MB, free 807.8 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:51580 (size: 206.7 MB, free: 807.8 MB)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 7 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 206.7 MB, free 601.1 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_16_0 in memory on localhost:51580 (size: 206.7 MB, free: 601.1 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 206.7 MB, free 394.3 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:51580 (size: 206.7 MB, free: 394.4 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_16_4 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_16_4 on localhost:51580 in memory (size: 206.7 MB, free: 601.1 MB)
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_0 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_0 on localhost:51580 in memory (size: 206.8 MB, free: 807.9 MB)
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:51580 in memory (size: 206.7 MB, free: 1014.6 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 206.7 MB, free 807.8 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_14_2 in memory on localhost:51580 (size: 206.7 MB, free: 807.8 MB)
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 1 for rdd 7 took 0 ms
17/03/27 22:25:23 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 206.7 MB, free 601.1 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:51580 (size: 206.7 MB, free: 601.1 MB)
17/03/27 22:25:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 22). 3811 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 22) in 385 ms on localhost (3/5)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_22_1 stored as values in memory (estimated size 206.7 MB, free 394.4 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_22_1 in memory on localhost:51580 (size: 206.7 MB, free: 394.4 MB)
17/03/27 22:25:23 INFO Executor: Finished task 1.0 in stage 4.0 (TID 23). 4000 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 23) in 394 ms on localhost (4/5)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_16_2 stored as values in memory (estimated size 206.6 MB, free 187.8 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_16_2 in memory on localhost:51580 (size: 206.6 MB, free: 187.8 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 17 took 1 ms
17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:51580 in memory (size: 206.7 MB, free: 394.5 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_22_2 stored as values in memory (estimated size 206.6 MB, free 187.9 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_22_2 in memory on localhost:51580 (size: 206.6 MB, free: 187.9 MB)
17/03/27 22:25:23 INFO Executor: Finished task 2.0 in stage 4.0 (TID 24). 3492 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 24) in 330 ms on localhost (5/5)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:23 INFO DAGScheduler: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204) finished in 0.519 s
17/03/27 22:25:23 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:23 INFO Recursion: Fixed Point Iteration # 2, time: 1144ms
17/03/27 22:25:23 INFO DAGScheduler: Registering RDD 32 (execute at Recursion.scala:228)
17/03/27 22:25:23 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[32] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.2 KB, free 187.9 MB)
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.7 KB, free 187.9 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:51580 (size: 5.7 KB, free: 187.9 MB)
17/03/27 22:25:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:23 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[32] at execute at Recursion.scala:228)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 26, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 27, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 28, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:23 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:25:23 INFO Executor: Running task 1.0 in stage 5.0 (TID 26)
17/03/27 22:25:23 INFO Executor: Running task 2.0 in stage 5.0 (TID 27)
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_0 locally
17/03/27 22:25:23 INFO Executor: Running task 3.0 in stage 5.0 (TID 28)
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_2 locally
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 155.9 MB)
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_1 locally
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_3 locally
17/03/27 22:25:23 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 2645 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 9 ms on localhost (1/5)
17/03/27 22:25:23 INFO Executor: Running task 4.0 in stage 5.0 (TID 29)
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_4 locally
17/03/27 22:25:23 INFO Executor: Finished task 4.0 in stage 5.0 (TID 29). 2645 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 29) in 8 ms on localhost (2/5)
17/03/27 22:25:23 INFO Executor: Finished task 3.0 in stage 5.0 (TID 28). 2645 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 28) in 25 ms on localhost (3/5)
17/03/27 22:25:23 INFO Executor: Finished task 1.0 in stage 5.0 (TID 26). 2645 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 26) in 34 ms on localhost (4/5)
17/03/27 22:25:23 INFO Executor: Finished task 2.0 in stage 5.0 (TID 27). 2645 bytes result sent to driver
17/03/27 22:25:23 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 27) in 42 ms on localhost (5/5)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:23 INFO DAGScheduler: ShuffleMapStage 5 (execute at Recursion.scala:228) finished in 0.042 s
17/03/27 22:25:23 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:23 INFO DAGScheduler: running: Set()
17/03/27 22:25:23 INFO DAGScheduler: waiting: Set(FixedPointResultStage 6)
17/03/27 22:25:23 INFO DAGScheduler: failed: Set()
17/03/27 22:25:23 INFO DAGScheduler: Submitting FixedPointResultStage 6 (SetRDD.diffRDD SetRDD[35] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.3 KB, free 155.8 MB)
17/03/27 22:25:23 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 7.0 KB, free 155.8 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:51580 (size: 7.0 KB, free: 187.9 MB)
17/03/27 22:25:23 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:23 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 6 (SetRDD.diffRDD SetRDD[35] at RDD at SetRDD.scala:30)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:23 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2414 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2414 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 32, localhost, partition 2,PROCESS_LOCAL, 2414 bytes)
17/03/27 22:25:23 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 33, localhost, partition 3,PROCESS_LOCAL, 2414 bytes)
17/03/27 22:25:23 INFO Executor: Running task 0.0 in stage 6.0 (TID 30)
17/03/27 22:25:23 INFO Executor: Running task 3.0 in stage 6.0 (TID 33)
17/03/27 22:25:23 INFO Executor: Running task 2.0 in stage 6.0 (TID 32)
17/03/27 22:25:23 INFO Executor: Running task 1.0 in stage 6.0 (TID 31)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_34_0 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_34_1 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_34_3 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_34_2 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_28_3 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_28_0 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_16_0 locally
17/03/27 22:25:23 INFO CacheManager: Partition rdd_28_2 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_0 locally
17/03/27 22:25:23 INFO CacheManager: Partition rdd_28_1 not found, computing it
17/03/27 22:25:23 INFO BlockManager: Found block rdd_16_2 locally
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_2 locally
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 2 for rdd 17 took 0 ms
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 3 for rdd 17 took 0 ms
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:25:23 ERROR Executor: Exception in task 3.0 in stage 6.0 (TID 33)
org.apache.spark.SparkException: Checkpoint block rdd_16_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:23 INFO BlockManager: Found block rdd_16_1 locally
17/03/27 22:25:23 INFO BlockManager: Found block rdd_22_1 locally
17/03/27 22:25:23 INFO SetRDDHashSetPartition: Union set size 3 for rdd 17 took 0 ms
17/03/27 22:25:23 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 34, localhost, partition 4,PROCESS_LOCAL, 2414 bytes)
17/03/27 22:25:23 WARN TaskSetManager: Lost task 3.0 in stage 6.0 (TID 33, localhost): org.apache.spark.SparkException: Checkpoint block rdd_16_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:23 ERROR TaskSetManager: Task 3 in stage 6.0 failed 1 times; aborting job
17/03/27 22:25:23 INFO TaskSchedulerImpl: Cancelling stage 6
17/03/27 22:25:23 INFO TaskSchedulerImpl: Stage 6 was cancelled
17/03/27 22:25:23 INFO DAGScheduler: FixedPointResultStage 6 (runFixedPointJob at Recursion.scala:204) failed in 0.007 s
17/03/27 22:25:23 INFO Executor: Running task 4.0 in stage 6.0 (TID 34)
17/03/27 22:25:23 INFO Executor: Executor is trying to kill task 0.0 in stage 6.0 (TID 30)
17/03/27 22:25:23 INFO Executor: Executor is trying to kill task 4.0 in stage 6.0 (TID 34)
17/03/27 22:25:23 INFO Executor: Executor is trying to kill task 1.0 in stage 6.0 (TID 31)
17/03/27 22:25:23 INFO Executor: Executor is trying to kill task 2.0 in stage 6.0 (TID 32)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_34_4 not found, computing it
17/03/27 22:25:23 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 1.209506 s
17/03/27 22:25:23 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:23 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:23 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:23 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:23 INFO CacheManager: Partition rdd_28_4 not found, computing it
17/03/27 22:25:23 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:23 ERROR Executor: Exception in task 4.0 in stage 6.0 (TID 34)
org.apache.spark.SparkException: Checkpoint block rdd_16_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
[31m- Aggregates over Recursion - LL - bff *** FAILED ***[0m
[31m  org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[To#72], functions=[(min(C#78),mode=Final,isDistinct=false)], output=[To#72,C#79])[0m
[31m+- TungstenAggregate(key=[To#72], functions=[(min(C#78),mode=Partial,isDistinct=false)], output=[To#72,min#86])[0m
[31m   +- Recursion [To#72,C#78] (Linear) [path][1,0][0m
[31m      :- TungstenExchange hashpartitioning(To#72,5), None[0m
[31m      :  +- Project [To#72,D#73][0m
[31m      :     +- Filter (From#71 = 0)[0m
[31m      :        +- Scan ExistingRDD[From#71,To#72,D#73] [0m
[31m      +- TungstenExchange hashpartitioning(To#72,5), None[0m
[31m         +- Project [To#72,(C1#77 + D#73) AS C#78][0m
[31m            +- BroadcastHashJoin [Z#76], [From#71], BuildRight[0m
[31m               :- LinearRecursiveRelation [Z#76,C1#77](path)[0m
[31m               +- Project [From#71,To#72,D#73][0m
[31m                  +- Scan ExistingRDD[From#71,To#72,D#73][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.Project.doExecute(basicOperators.scala:46)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[To#72], functions=[(min(C#78),mode=Partial,isDistinct=false)], output=[To#72,min#86])[0m
[31m+- Recursion [To#72,C#78] (Linear) [path][1,0][0m
[31m   :- TungstenExchange hashpartitioning(To#72,5), None[0m
[31m   :  +- Project [To#72,D#73][0m
[31m   :     +- Filter (From#71 = 0)[0m
[31m   :        +- Scan ExistingRDD[From#71,To#72,D#73] [0m
[31m   +- TungstenExchange hashpartitioning(To#72,5), None[0m
[31m      +- Project [To#72,(C1#77 + D#73) AS C#78][0m
[31m         +- BroadcastHashJoin [Z#76], [From#71], BuildRight[0m
[31m            :- LinearRecursiveRelation [Z#76,C1#77](path)[0m
[31m            +- Project [From#71,To#72,D#73][0m
[31m               +- Scan ExistingRDD[From#71,To#72,D#73][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 6.0 failed 1 times, most recent failure: Lost task 3.0 in stage 6.0 (TID 33, localhost): org.apache.spark.SparkException: Checkpoint block rdd_16_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_16_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  ...[0m
17/03/27 22:25:23 WARN TaskSetManager: Lost task 4.0 in stage 6.0 (TID 34, localhost): org.apache.spark.SparkException: Checkpoint block rdd_16_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_14_2 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_14_2 on localhost:51580 in memory (size: 206.7 MB, free: 394.6 MB)
17/03/27 22:25:23 INFO MemoryStore: 4 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_6_piece0 from memory
17/03/27 22:25:23 INFO BlockManager: Writing block broadcast_6_piece0 to disk
17/03/27 22:25:23 INFO BlockManagerInfo: Added broadcast_6_piece0 on disk on localhost:51580 (size: 5.7 KB)
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_22_3 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_22_3 on localhost:51580 in memory (size: 206.7 MB, free: 601.3 MB)
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_6 from memory
17/03/27 22:25:23 INFO BlockManager: Writing block broadcast_6 to disk
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_22_4 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_22_4 on localhost:51580 in memory (size: 206.8 MB, free: 808.1 MB)
17/03/27 22:25:23 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:23 INFO BlockManager: Dropping block broadcast_7_piece0 from memory
17/03/27 22:25:23 INFO BlockManager: Writing block broadcast_7_piece0 to disk
17/03/27 22:25:23 INFO BlockManagerInfo: Added broadcast_7_piece0 on disk on localhost:51580 (size: 7.0 KB)
17/03/27 22:25:23 INFO BlockManager: Dropping block rdd_16_0 from memory
17/03/27 22:25:23 INFO BlockManagerInfo: Removed rdd_16_0 on localhost:51580 in memory (size: 206.7 MB, free: 1014.8 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_28_2 stored as values in memory (estimated size 174.9 MB, free 839.9 MB)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_28_0 stored as values in memory (estimated size 174.9 MB, free 665.1 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_28_2 in memory on localhost:51580 (size: 174.9 MB, free: 840.0 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_28_0 in memory on localhost:51580 (size: 174.9 MB, free: 665.1 MB)
[32mNonMonotonicAggregateQuerySuite:[0m
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:23 INFO Executor: Executor killed task 2.0 in stage 6.0 (TID 32)
17/03/27 22:25:23 INFO Executor: Executor killed task 0.0 in stage 6.0 (TID 30)
17/03/27 22:25:23 INFO Utils: Successfully started service 'sparkDriver' on port 51600.
17/03/27 22:25:23 WARN TaskSetManager: Lost task 2.0 in stage 6.0 (TID 32, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:23 WARN TaskSetManager: Lost task 0.0 in stage 6.0 (TID 30, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:23 INFO MemoryStore: Block rdd_28_1 stored as values in memory (estimated size 175.0 MB, free 490.0 MB)
17/03/27 22:25:23 INFO BlockManagerInfo: Added rdd_28_1 in memory on localhost:51580 (size: 175.0 MB, free: 490.0 MB)
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:23 INFO Executor: Executor killed task 1.0 in stage 6.0 (TID 31)
17/03/27 22:25:23 WARN TaskSetManager: Lost task 1.0 in stage 6.0 (TID 31, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:23 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:23 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:23 INFO Remoting: Starting remoting
17/03/27 22:25:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51614]
17/03/27 22:25:24 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51614.
17/03/27 22:25:24 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:24 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:24 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-66821aa9-f4df-44dd-8a2a-c42fce7682e3
17/03/27 22:25:24 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:24 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:24 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51631.
17/03/27 22:25:24 INFO NettyBlockTransferService: Server created on 51631
17/03/27 22:25:24 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51631 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51631)
17/03/27 22:25:24 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:24 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667924025
17/03/27 22:25:24 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$14.apply$mcV$sp(RecursiveQuerySuites.scala:254)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$14.apply(RecursiveQuerySuites.scala:243)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesOverRecursionQuerySuite$$anonfun$14.apply(RecursiveQuerySuites.scala:243)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.NonMonotonicAggregateQuerySuite$$anonfun$10.apply$mcV$sp(NonRecursiveQuerySuites.scala:119)
	at edu.ucla.cs.wis.bigdatalog.spark.NonMonotonicAggregateQuerySuite$$anonfun$10.apply(NonRecursiveQuerySuites.scala:117)
	at edu.ucla.cs.wis.bigdatalog.spark.NonMonotonicAggregateQuerySuite$$anonfun$10.apply(NonRecursiveQuerySuites.scala:117)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:24 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:24 INFO BigDatalogContext: BigDatalog Query: "max_price(M)."
17/03/27 22:25:24 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:24 INFO BigDatalogContext: 
0: (max(Price) as M) <AGGREGATE>
 1: (Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:24 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:24 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:24 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_max_price
+- 'Aggregate [unresolvedalias('max('price.Price) AS M#90)]
   +- 'Project ['price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
M: int
Subquery aggregate_max_price
+- Aggregate [(max(Price#87),mode=Complete,isDistinct=false) AS M#90]
   +- Project [Price#87]
      +- Subquery price
         +- LogicalRDD [Price#87,ItemName#88,ItemGroup#89], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(max(Price#87),mode=Complete,isDistinct=false) AS M#90]
+- Project [Price#87]
   +- LogicalRDD [Price#87,ItemName#88,ItemGroup#89], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(max(Price#87),mode=Final,isDistinct=false)], output=[M#90])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(max(Price#87),mode=Partial,isDistinct=false)], output=[max#93])
      +- Project [Price#87]
         +- Scan ExistingRDD[Price#87,ItemName#88,ItemGroup#89]
17/03/27 22:25:24 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:24 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:24 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:24 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2.0 GB)
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51631 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:24 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:24 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:24 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 6.526621 ms
17/03/27 22:25:24 INFO GenerateMutableProjection: Code generated in 4.454101 ms
17/03/27 22:25:24 INFO GenerateUnsafeRowJoiner: Code generated in 4.453171 ms
17/03/27 22:25:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:24 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1491 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1491 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1491 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1491 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 48 ms on localhost (1/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 13 ms on localhost (2/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 49 ms on localhost (3/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 48 ms on localhost (4/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 48 ms on localhost (5/5)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:24 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.051 s
17/03/27 22:25:24 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:24 INFO DAGScheduler: running: Set()
17/03/27 22:25:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:24 INFO DAGScheduler: failed: Set()
17/03/27 22:25:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KB, free 2.0 GB)
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51631 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2708 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 5 ms on localhost (1/1)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:24 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.005 s
17/03/27 22:25:24 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.063380 s
17/03/27 22:25:24 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:24 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:24 INFO BlockManager: BlockManager stopped
17/03/27 22:25:24 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:24 INFO SparkContext: Successfully stopped SparkContext
[32m- max_price(max<Price>)[0m
17/03/27 22:25:24 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:24 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:24 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:24 INFO Utils: Successfully started service 'sparkDriver' on port 51648.
17/03/27 22:25:24 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:24 INFO Remoting: Starting remoting
17/03/27 22:25:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51661]
17/03/27 22:25:24 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51661.
17/03/27 22:25:24 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:24 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:24 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-560b34a8-dd12-43bf-bd0b-90c0ccc94969
17/03/27 22:25:24 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:24 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:24 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51678.
17/03/27 22:25:24 INFO NettyBlockTransferService: Server created on 51678
17/03/27 22:25:24 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51678 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51678)
17/03/27 22:25:24 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:24 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667924318
17/03/27 22:25:24 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:24 INFO BigDatalogContext: BigDatalog Query: "max_price(ItemGroup, M)."
17/03/27 22:25:24 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:24 INFO BigDatalogContext: 
0: (ItemGroup, max(Price) as M) <AGGREGATE>
 1: (Price, ItemGroup) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:24 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:24 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:24 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_max_price
+- 'Aggregate ['price.ItemGroup], ['price.ItemGroup,unresolvedalias('max('price.Price) AS M#100)]
   +- 'Project ['price.Price,'price.ItemGroup]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemGroup: string, M: int
Subquery aggregate_max_price
+- Aggregate [ItemGroup#99], [ItemGroup#99,(max(Price#97),mode=Complete,isDistinct=false) AS M#100]
   +- Project [Price#97,ItemGroup#99]
      +- Subquery price
         +- LogicalRDD [Price#97,ItemName#98,ItemGroup#99], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemGroup#99], [ItemGroup#99,(max(Price#97),mode=Complete,isDistinct=false) AS M#100]
+- Project [Price#97,ItemGroup#99]
   +- LogicalRDD [Price#97,ItemName#98,ItemGroup#99], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemGroup#99], functions=[(max(Price#97),mode=Final,isDistinct=false)], output=[ItemGroup#99,M#100])
+- TungstenExchange hashpartitioning(ItemGroup#99,5), None
   +- TungstenAggregate(key=[ItemGroup#99], functions=[(max(Price#97),mode=Partial,isDistinct=false)], output=[ItemGroup#99,max#103])
      +- Project [Price#97,ItemGroup#99]
         +- Scan ExistingRDD[Price#97,ItemName#98,ItemGroup#99]
17/03/27 22:25:24 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:24 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:24 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:24 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.9 KB, free 2.0 GB)
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51678 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:24 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:24 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:24 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 7.320688 ms
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 4.100354 ms
17/03/27 22:25:24 INFO GenerateUnsafeRowJoiner: Code generated in 9.081662 ms
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 10.374387 ms
17/03/27 22:25:24 INFO GenerateMutableProjection: Code generated in 10.655213 ms
17/03/27 22:25:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:24 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 145 ms on localhost (1/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 147 ms on localhost (2/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 55 ms on localhost (3/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 147 ms on localhost (4/5)
17/03/27 22:25:24 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 151 ms on localhost (5/5)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:24 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.152 s
17/03/27 22:25:24 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:24 INFO DAGScheduler: running: Set()
17/03/27 22:25:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:24 INFO DAGScheduler: failed: Set()
17/03/27 22:25:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 2.0 GB)
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:25:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51678 (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:25:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:24 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:24 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:24 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/03/27 22:25:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1669 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 7 ms on localhost (1/5)
17/03/27 22:25:24 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:24 INFO GenerateMutableProjection: Code generated in 4.834844 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 5.250031 ms
17/03/27 22:25:24 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2797 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2797 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2797 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2797 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 11 ms on localhost (2/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 18 ms on localhost (3/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 18 ms on localhost (4/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 18 ms on localhost (5/5)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:24 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.018 s
17/03/27 22:25:24 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.180912 s
17/03/27 22:25:24 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:24 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:24 INFO BlockManager: BlockManager stopped
17/03/27 22:25:24 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:24 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
[32m- max_price(ItemGroup, max<Price>)[0m
17/03/27 22:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:24 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:24 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:24 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:24 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:24 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:24 INFO Utils: Successfully started service 'sparkDriver' on port 51696.
17/03/27 22:25:24 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:24 INFO Remoting: Starting remoting
17/03/27 22:25:24 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51709]
17/03/27 22:25:24 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51709.
17/03/27 22:25:24 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:24 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:24 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-35261ec1-e19d-4bf9-b2fe-716de8f0cd16
17/03/27 22:25:24 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:24 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:24 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:24 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51726.
17/03/27 22:25:24 INFO NettyBlockTransferService: Server created on 51726
17/03/27 22:25:24 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:24 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51726 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51726)
17/03/27 22:25:24 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:24 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667924725
17/03/27 22:25:24 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:24 INFO BigDatalogContext: BigDatalog Query: "max_price(ItemName, ItemGroup, M)."
17/03/27 22:25:24 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:24 INFO BigDatalogContext: 
0: (ItemName, ItemGroup, max(Price) as M) <AGGREGATE>
 1: (ItemName, ItemGroup, Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:24 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:24 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:24 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_max_price
+- 'Aggregate ['price.ItemName,'price.ItemGroup], ['price.ItemName,'price.ItemGroup,unresolvedalias('max('price.Price) AS M#110)]
   +- 'Project ['price.ItemName,'price.ItemGroup,'price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemName: string, ItemGroup: string, M: int
Subquery aggregate_max_price
+- Aggregate [ItemName#108,ItemGroup#109], [ItemName#108,ItemGroup#109,(max(Price#107),mode=Complete,isDistinct=false) AS M#110]
   +- Project [ItemName#108,ItemGroup#109,Price#107]
      +- Subquery price
         +- LogicalRDD [Price#107,ItemName#108,ItemGroup#109], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemName#108,ItemGroup#109], [ItemName#108,ItemGroup#109,(max(Price#107),mode=Complete,isDistinct=false) AS M#110]
+- Project [ItemName#108,ItemGroup#109,Price#107]
   +- LogicalRDD [Price#107,ItemName#108,ItemGroup#109], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemName#108,ItemGroup#109], functions=[(max(Price#107),mode=Final,isDistinct=false)], output=[ItemName#108,ItemGroup#109,M#110])
+- TungstenExchange hashpartitioning(ItemName#108,ItemGroup#109,5), None
   +- TungstenAggregate(key=[ItemName#108,ItemGroup#109], functions=[(max(Price#107),mode=Partial,isDistinct=false)], output=[ItemName#108,ItemGroup#109,max#113])
      +- Project [ItemName#108,ItemGroup#109,Price#107]
         +- Scan ExistingRDD[Price#107,ItemName#108,ItemGroup#109]
17/03/27 22:25:24 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:24 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:24 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:24 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:24 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.9 KB, free 2.0 GB)
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:24 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51726 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:24 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:24 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:24 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:24 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:24 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:24 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:24 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 6.915742 ms
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 4.551226 ms
17/03/27 22:25:24 INFO GenerateMutableProjection: Code generated in 5.165007 ms
17/03/27 22:25:24 INFO GenerateUnsafeRowJoiner: Code generated in 6.388535 ms
17/03/27 22:25:24 INFO GenerateMutableProjection: Code generated in 14.21688 ms
17/03/27 22:25:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:24 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 98 ms on localhost (1/5)
17/03/27 22:25:24 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 136 ms on localhost (2/5)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 138 ms on localhost (3/5)
17/03/27 22:25:24 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 144 ms on localhost (4/5)
17/03/27 22:25:24 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.145 s
17/03/27 22:25:24 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:24 INFO DAGScheduler: running: Set()
17/03/27 22:25:24 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:24 INFO DAGScheduler: failed: Set()
17/03/27 22:25:24 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.3 KB, free 2.0 GB)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 64 ms on localhost (5/5)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:24 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:25:24 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51726 (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:25:24 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:24 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:24 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:24 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:24 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:24 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:24 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO GenerateUnsafeProjection: Code generated in 4.676899 ms
17/03/27 22:25:24 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2968 bytes result sent to driver
17/03/27 22:25:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2881 bytes result sent to driver
17/03/27 22:25:24 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:24 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 17 ms on localhost (1/5)
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:24 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 18 ms on localhost (2/5)
17/03/27 22:25:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 2970 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2930 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 22 ms on localhost (3/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 6 ms on localhost (4/5)
17/03/27 22:25:25 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 3097 bytes result sent to driver
17/03/27 22:25:25 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.023 s
17/03/27 22:25:25 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 23 ms on localhost (5/5)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.178191 s
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:25 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:25 INFO BlockManager: BlockManager stopped
17/03/27 22:25:25 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:25 INFO SparkContext: Successfully stopped SparkContext
[32m- max_price(ItemName, ItemGroup, max<Price>)[0m
17/03/27 22:25:25 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:25 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriver' on port 51743.
17/03/27 22:25:25 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:25 INFO Remoting: Starting remoting
17/03/27 22:25:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51756]
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51756.
17/03/27 22:25:25 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:25 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:25 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-cd8e3aa5-8b20-4992-95c6-0e2aa3eecf78
17/03/27 22:25:25 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:25 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 133
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 132
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 131
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 130
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 129
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 128
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 127
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 126
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 125
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 124
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 123
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 122
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 121
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 120
17/03/27 22:25:25 INFO ContextCleaner: Cleaned accumulator 106
17/03/27 22:25:25 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51773.
17/03/27 22:25:25 INFO NettyBlockTransferService: Server created on 51773
17/03/27 22:25:25 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51773 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51773)
17/03/27 22:25:25 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:25 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667925106
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:25 INFO BigDatalogContext: BigDatalog Query: "min_price(M)."
17/03/27 22:25:25 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:25 INFO BigDatalogContext: 
0: (min(Price) as M) <AGGREGATE>
 1: (Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:25 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:25 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:25 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_min_price
+- 'Aggregate [unresolvedalias('min('price.Price) AS M#120)]
   +- 'Project ['price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
M: int
Subquery aggregate_min_price
+- Aggregate [(min(Price#117),mode=Complete,isDistinct=false) AS M#120]
   +- Project [Price#117]
      +- Subquery price
         +- LogicalRDD [Price#117,ItemName#118,ItemGroup#119], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(min(Price#117),mode=Complete,isDistinct=false) AS M#120]
+- Project [Price#117]
   +- LogicalRDD [Price#117,ItemName#118,ItemGroup#119], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(min(Price#117),mode=Final,isDistinct=false)], output=[M#120])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(min(Price#117),mode=Partial,isDistinct=false)], output=[min#123])
      +- Project [Price#117]
         +- Scan ExistingRDD[Price#117,ItemName#118,ItemGroup#119]
17/03/27 22:25:25 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:25 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:25 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:25 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2.0 GB)
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51773 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:25 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:25 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:25 INFO GenerateMutableProjection: Code generated in 4.434242 ms
17/03/27 22:25:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:25 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 36 ms on localhost (1/5)
17/03/27 22:25:25 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 36 ms on localhost (2/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 36 ms on localhost (3/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 9 ms on localhost (4/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37 ms on localhost (5/5)
17/03/27 22:25:25 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.037 s
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:25 INFO DAGScheduler: running: Set()
17/03/27 22:25:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:25 INFO DAGScheduler: failed: Set()
17/03/27 22:25:25 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KB, free 2.0 GB)
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51773 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2708 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 4 ms on localhost (1/1)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.005 s
17/03/27 22:25:25 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.048815 s
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:25 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:25 INFO BlockManager: BlockManager stopped
17/03/27 22:25:25 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:25 INFO SparkContext: Successfully stopped SparkContext
[32m- min_price(min<Price>)[0m
17/03/27 22:25:25 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:25 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriver' on port 51791.
17/03/27 22:25:25 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:25 INFO Remoting: Starting remoting
17/03/27 22:25:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51804]
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51804.
17/03/27 22:25:25 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:25 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:25 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-a5e7882c-2d38-475d-9986-c12c3d00307d
17/03/27 22:25:25 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:25 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:25 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51821.
17/03/27 22:25:25 INFO NettyBlockTransferService: Server created on 51821
17/03/27 22:25:25 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51821 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51821)
17/03/27 22:25:25 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:25 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667925353
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:25 INFO BigDatalogContext: BigDatalog Query: "min_price(ItemGroup, M)."
17/03/27 22:25:25 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:25 INFO BigDatalogContext: 
0: (ItemGroup, min(Price) as M) <AGGREGATE>
 1: (Price, ItemGroup) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:25 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:25 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:25 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_min_price
+- 'Aggregate ['price.ItemGroup], ['price.ItemGroup,unresolvedalias('min('price.Price) AS M#130)]
   +- 'Project ['price.Price,'price.ItemGroup]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemGroup: string, M: int
Subquery aggregate_min_price
+- Aggregate [ItemGroup#129], [ItemGroup#129,(min(Price#127),mode=Complete,isDistinct=false) AS M#130]
   +- Project [Price#127,ItemGroup#129]
      +- Subquery price
         +- LogicalRDD [Price#127,ItemName#128,ItemGroup#129], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemGroup#129], [ItemGroup#129,(min(Price#127),mode=Complete,isDistinct=false) AS M#130]
+- Project [Price#127,ItemGroup#129]
   +- LogicalRDD [Price#127,ItemName#128,ItemGroup#129], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemGroup#129], functions=[(min(Price#127),mode=Final,isDistinct=false)], output=[ItemGroup#129,M#130])
+- TungstenExchange hashpartitioning(ItemGroup#129,5), None
   +- TungstenAggregate(key=[ItemGroup#129], functions=[(min(Price#127),mode=Partial,isDistinct=false)], output=[ItemGroup#129,min#133])
      +- Project [Price#127,ItemGroup#129]
         +- Scan ExistingRDD[Price#127,ItemName#128,ItemGroup#129]
17/03/27 22:25:25 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:25 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:25 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:25 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.9 KB, free 2.0 GB)
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51821 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:25 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:25 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:25 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 36 ms on localhost (1/5)
17/03/27 22:25:25 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 50 ms on localhost (2/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 22 ms on localhost (3/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 52 ms on localhost (4/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 53 ms on localhost (5/5)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.054 s
17/03/27 22:25:25 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:25 INFO DAGScheduler: running: Set()
17/03/27 22:25:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:25 INFO DAGScheduler: failed: Set()
17/03/27 22:25:25 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 2.0 GB)
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:25:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51821 (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:25:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:25 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:25 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:25 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:25 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1669 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 5 ms on localhost (1/5)
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:25 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:25 INFO GenerateMutableProjection: Code generated in 7.616097 ms
17/03/27 22:25:25 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2797 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2797 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2797 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 11 ms on localhost (2/5)
17/03/27 22:25:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2797 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 15 ms on localhost (3/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 16 ms on localhost (4/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 16 ms on localhost (5/5)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.017 s
17/03/27 22:25:25 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.078901 s
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:25 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:25 INFO BlockManager: BlockManager stopped
17/03/27 22:25:25 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:25 INFO SparkContext: Successfully stopped SparkContext
[32m- min_price(ItemGroup, min<Price>)[0m
17/03/27 22:25:25 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:25 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriver' on port 51838.
17/03/27 22:25:25 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:25 INFO Remoting: Starting remoting
17/03/27 22:25:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51852]
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51852.
17/03/27 22:25:25 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:25 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:25 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-e22d30d0-d6e0-4d96-af14-b40342a93c77
17/03/27 22:25:25 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:25 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:25 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:25 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51869.
17/03/27 22:25:25 INFO NettyBlockTransferService: Server created on 51869
17/03/27 22:25:25 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:25 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51869 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51869)
17/03/27 22:25:25 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:25 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667925644
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:25 INFO BigDatalogContext: BigDatalog Query: "avg_price(A)."
17/03/27 22:25:25 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:25 INFO BigDatalogContext: 
0: (avg(Price) as A) <AGGREGATE>
 1: (Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:25 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:25 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:25 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_avg_price
+- 'Aggregate [unresolvedalias('avg('price.Price) AS A#140)]
   +- 'Project ['price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
A: double
Subquery aggregate_avg_price
+- Aggregate [(avg(cast(Price#137 as bigint)),mode=Complete,isDistinct=false) AS A#140]
   +- Project [Price#137]
      +- Subquery price
         +- LogicalRDD [Price#137,ItemName#138,ItemGroup#139], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(avg(cast(Price#137 as bigint)),mode=Complete,isDistinct=false) AS A#140]
+- Project [Price#137]
   +- LogicalRDD [Price#137,ItemName#138,ItemGroup#139], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(avg(cast(Price#137 as bigint)),mode=Final,isDistinct=false)], output=[A#140])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(avg(cast(Price#137 as bigint)),mode=Partial,isDistinct=false)], output=[sum#144,count#145L])
      +- Project [Price#137]
         +- Scan ExistingRDD[Price#137,ItemName#138,ItemGroup#139]
17/03/27 22:25:25 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:25 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:25 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:25 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:25 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:25 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.2 KB, free 2.0 GB)
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2.0 GB)
17/03/27 22:25:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51869 (size: 4.6 KB, free: 2.0 GB)
17/03/27 22:25:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:25 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:25 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:25 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:25 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:25 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:25 INFO GenerateMutableProjection: Code generated in 4.704206 ms
17/03/27 22:25:25 INFO GenerateMutableProjection: Code generated in 8.331037 ms
17/03/27 22:25:25 INFO GenerateUnsafeRowJoiner: Code generated in 5.80113 ms
17/03/27 22:25:25 INFO GenerateUnsafeProjection: Code generated in 4.811261 ms
17/03/27 22:25:25 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:25 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:25 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 60 ms on localhost (1/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 60 ms on localhost (2/5)
17/03/27 22:25:25 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 61 ms on localhost (3/5)
17/03/27 22:25:25 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 64 ms on localhost (4/5)
17/03/27 22:25:25 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1491 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 17 ms on localhost (5/5)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.070 s
17/03/27 22:25:25 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:25 INFO DAGScheduler: running: Set()
17/03/27 22:25:25 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:25 INFO DAGScheduler: failed: Set()
17/03/27 22:25:25 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.5 KB, free 2.0 GB)
17/03/27 22:25:25 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:25 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51869 (size: 5.2 KB, free: 2.0 GB)
17/03/27 22:25:25 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:25 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:25 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:25 INFO GenerateMutableProjection: Code generated in 3.710923 ms
17/03/27 22:25:25 INFO GenerateMutableProjection: Code generated in 3.21692 ms
17/03/27 22:25:25 INFO GenerateUnsafeProjection: Code generated in 6.53686 ms
17/03/27 22:25:25 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2710 bytes result sent to driver
17/03/27 22:25:25 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 25 ms on localhost (1/1)
17/03/27 22:25:25 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:25 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.025 s
17/03/27 22:25:25 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.101402 s
17/03/27 22:25:25 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:25 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:25 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:25 INFO BlockManager: BlockManager stopped
17/03/27 22:25:25 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:25 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:25 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:25 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[32m- avg_price(avg<Price>)[0m
17/03/27 22:25:25 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:25 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:25 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriver' on port 51887.
17/03/27 22:25:25 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:25 INFO Remoting: Starting remoting
17/03/27 22:25:25 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51900]
17/03/27 22:25:25 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51900.
17/03/27 22:25:25 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:25 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:25 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-c4c8c02e-b15e-468a-8ca2-0ea6b9529b71
17/03/27 22:25:25 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:25 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:25 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51917.
17/03/27 22:25:26 INFO NettyBlockTransferService: Server created on 51917
17/03/27 22:25:26 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51917 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51917)
17/03/27 22:25:26 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:26 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667925992
17/03/27 22:25:26 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:26 INFO BigDatalogContext: BigDatalog Query: "avg_price(ItemGroup, A)."
17/03/27 22:25:26 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:26 INFO BigDatalogContext: 
0: (ItemGroup, avg(Price) as A) <AGGREGATE>
 1: (Price, ItemGroup) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:26 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:26 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:26 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_avg_price
+- 'Aggregate ['price.ItemGroup], ['price.ItemGroup,unresolvedalias('avg('price.Price) AS A#154)]
   +- 'Project ['price.Price,'price.ItemGroup]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemGroup: string, A: double
Subquery aggregate_avg_price
+- Aggregate [ItemGroup#153], [ItemGroup#153,(avg(cast(Price#151 as bigint)),mode=Complete,isDistinct=false) AS A#154]
   +- Project [Price#151,ItemGroup#153]
      +- Subquery price
         +- LogicalRDD [Price#151,ItemName#152,ItemGroup#153], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemGroup#153], [ItemGroup#153,(avg(cast(Price#151 as bigint)),mode=Complete,isDistinct=false) AS A#154]
+- Project [Price#151,ItemGroup#153]
   +- LogicalRDD [Price#151,ItemName#152,ItemGroup#153], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemGroup#153], functions=[(avg(cast(Price#151 as bigint)),mode=Final,isDistinct=false)], output=[ItemGroup#153,A#154])
+- TungstenExchange hashpartitioning(ItemGroup#153,5), None
   +- TungstenAggregate(key=[ItemGroup#153], functions=[(avg(cast(Price#151 as bigint)),mode=Partial,isDistinct=false)], output=[ItemGroup#153,sum#158,count#159L])
      +- Project [Price#151,ItemGroup#153]
         +- Scan ExistingRDD[Price#151,ItemName#152,ItemGroup#153]
17/03/27 22:25:26 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:26 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:26 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:26 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.3 KB, free 2.0 GB)
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:25:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51917 (size: 4.7 KB, free: 2.0 GB)
17/03/27 22:25:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:26 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:26 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:26 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:26 INFO GenerateUnsafeRowJoiner: Code generated in 6.415532 ms
17/03/27 22:25:26 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:26 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 61 ms on localhost (1/5)
17/03/27 22:25:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 71 ms on localhost (2/5)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 71 ms on localhost (3/5)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 26 ms on localhost (4/5)
17/03/27 22:25:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 74 ms on localhost (5/5)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:26 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.076 s
17/03/27 22:25:26 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:26 INFO DAGScheduler: running: Set()
17/03/27 22:25:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:26 INFO DAGScheduler: failed: Set()
17/03/27 22:25:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.7 KB, free 2.0 GB)
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2.0 GB)
17/03/27 22:25:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51917 (size: 5.3 KB, free: 2.0 GB)
17/03/27 22:25:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:26 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:26 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:26 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:26 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1669 bytes result sent to driver
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:26 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:26 INFO GenerateMutableProjection: Code generated in 10.030881 ms
17/03/27 22:25:26 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:26 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 19 ms on localhost (1/5)
17/03/27 22:25:26 INFO GenerateUnsafeProjection: Code generated in 4.517713 ms
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:26 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2799 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2799 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2799 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 25 ms on localhost (2/5)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 12 ms on localhost (3/5)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 25 ms on localhost (4/5)
17/03/27 22:25:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2799 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 27 ms on localhost (5/5)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:26 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.027 s
17/03/27 22:25:26 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.115519 s
17/03/27 22:25:26 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:26 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:26 INFO BlockManager: BlockManager stopped
17/03/27 22:25:26 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:26 INFO SparkContext: Successfully stopped SparkContext
[32m- avg_price(ItemGroup, avg<Price>)[0m
17/03/27 22:25:26 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:26 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:26 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:26 INFO Utils: Successfully started service 'sparkDriver' on port 51934.
17/03/27 22:25:26 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:26 INFO Remoting: Starting remoting
17/03/27 22:25:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51947]
17/03/27 22:25:26 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51947.
17/03/27 22:25:26 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:26 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:26 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-d3f95c4c-add4-4b78-9b88-5c18ee987706
17/03/27 22:25:26 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:26 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:26 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51965.
17/03/27 22:25:26 INFO NettyBlockTransferService: Server created on 51965
17/03/27 22:25:26 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:51965 with 2.0 GB RAM, BlockManagerId(driver, localhost, 51965)
17/03/27 22:25:26 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:26 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667926396
17/03/27 22:25:26 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:26 INFO BigDatalogContext: BigDatalog Query: "avg_price_a(A)."
17/03/27 22:25:26 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:26 INFO BigDatalogContext: 
0: (avg(Price) as A) <AGGREGATE>
 1: (Price) <PROJECT>
  2: ItemGroup = 'a' <FILTER>
   3: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:26 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:26 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:26 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_avg_price
+- 'Aggregate [unresolvedalias('avg('price.Price) AS A#168)]
   +- 'Project ['price.Price]
      +- 'Filter ('price.ItemGroup = a)
         +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
A: double
Subquery aggregate_avg_price
+- Aggregate [(avg(cast(Price#165 as bigint)),mode=Complete,isDistinct=false) AS A#168]
   +- Project [Price#165]
      +- Filter (ItemGroup#167 = a)
         +- Subquery price
            +- LogicalRDD [Price#165,ItemName#166,ItemGroup#167], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(avg(cast(Price#165 as bigint)),mode=Complete,isDistinct=false) AS A#168]
+- Project [Price#165]
   +- Filter (ItemGroup#167 = a)
      +- LogicalRDD [Price#165,ItemName#166,ItemGroup#167], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(avg(cast(Price#165 as bigint)),mode=Final,isDistinct=false)], output=[A#168])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(avg(cast(Price#165 as bigint)),mode=Partial,isDistinct=false)], output=[sum#172,count#173L])
      +- Project [Price#165]
         +- Filter (ItemGroup#167 = a)
            +- Scan ExistingRDD[Price#165,ItemName#166,ItemGroup#167]
17/03/27 22:25:26 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:26 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:26 INFO DAGScheduler: Registering RDD 4 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:26 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KB, free 2.0 GB)
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:51965 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:26 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:26 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:26 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:26 INFO GeneratePredicate: Code generated in 16.240992 ms
17/03/27 22:25:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1568 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:26 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 88 ms on localhost (1/5)
17/03/27 22:25:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1568 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1568 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1577 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1577 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 107 ms on localhost (2/5)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 115 ms on localhost (3/5)
17/03/27 22:25:26 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 82 ms on localhost (4/5)
17/03/27 22:25:26 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.118 s
17/03/27 22:25:26 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:26 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 116 ms on localhost (5/5)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:26 INFO DAGScheduler: running: Set()
17/03/27 22:25:26 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:26 INFO DAGScheduler: failed: Set()
17/03/27 22:25:26 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.2 KB, free 2.0 GB)
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.5 KB, free 2.0 GB)
17/03/27 22:25:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:51965 (size: 5.5 KB, free: 2.0 GB)
17/03/27 22:25:26 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:26 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:26 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:26 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2796 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 6 ms on localhost (1/1)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:26 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.006 s
17/03/27 22:25:26 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.149708 s
17/03/27 22:25:26 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:26 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:26 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:26 INFO BlockManager: BlockManager stopped
17/03/27 22:25:26 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:26 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:26 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:26 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:26 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
[32m- avg_price_a(A)[0m
17/03/27 22:25:26 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:26 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:26 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:26 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:26 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:26 INFO Utils: Successfully started service 'sparkDriver' on port 51982.
17/03/27 22:25:26 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:26 INFO Remoting: Starting remoting
17/03/27 22:25:26 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:51995]
17/03/27 22:25:26 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 51995.
17/03/27 22:25:26 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:26 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:26 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-bf6f5c4f-3013-43ca-99a6-6cbb9b82f1de
17/03/27 22:25:26 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:26 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:26 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:26 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52012.
17/03/27 22:25:26 INFO NettyBlockTransferService: Server created on 52012
17/03/27 22:25:26 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:26 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52012 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52012)
17/03/27 22:25:26 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:26 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667926790
17/03/27 22:25:26 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:26 INFO BigDatalogContext: BigDatalog Query: "count_price(C)."
17/03/27 22:25:26 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:26 INFO BigDatalogContext: 
0: (count(Price) as C) <AGGREGATE>
 1: (Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:26 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:26 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:26 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_count_price
+- 'Aggregate [unresolvedalias('count('price.Price) AS C#182)]
   +- 'Project ['price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
C: bigint
Subquery aggregate_count_price
+- Aggregate [(count(Price#179),mode=Complete,isDistinct=false) AS C#182L]
   +- Project [Price#179]
      +- Subquery price
         +- LogicalRDD [Price#179,ItemName#180,ItemGroup#181], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(count(Price#179),mode=Complete,isDistinct=false) AS C#182L]
+- Project [Price#179]
   +- LogicalRDD [Price#179,ItemName#180,ItemGroup#181], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(count(Price#179),mode=Final,isDistinct=false)], output=[C#182L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(count(Price#179),mode=Partial,isDistinct=false)], output=[count#185L])
      +- Project [Price#179]
         +- Scan ExistingRDD[Price#179,ItemName#180,ItemGroup#181]
17/03/27 22:25:26 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:26 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:26 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:26 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:26 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.8 KB, free 2.0 GB)
17/03/27 22:25:26 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:26 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52012 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:26 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:26 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:26 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:26 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:26 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:26 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:26 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:26 INFO GenerateMutableProjection: Code generated in 6.08754 ms
17/03/27 22:25:26 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:26 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:26 INFO GenerateMutableProjection: Code generated in 3.355625 ms
17/03/27 22:25:26 INFO GenerateUnsafeProjection: Code generated in 4.069324 ms
17/03/27 22:25:26 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1491 bytes result sent to driver
17/03/27 22:25:26 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:26 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1491 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:26 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1491 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
17/03/27 22:25:26 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1491 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 76 ms on localhost (1/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 26 ms on localhost (2/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 77 ms on localhost (3/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 78 ms on localhost (4/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 80 ms on localhost (5/5)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:27 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.081 s
17/03/27 22:25:27 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:27 INFO DAGScheduler: running: Set()
17/03/27 22:25:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:27 INFO DAGScheduler: failed: Set()
17/03/27 22:25:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.2 KB, free 2.0 GB)
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:25:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52012 (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:25:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO GenerateMutableProjection: Code generated in 4.419657 ms
17/03/27 22:25:27 INFO GenerateMutableProjection: Code generated in 3.291393 ms
17/03/27 22:25:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2706 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 16 ms on localhost (1/1)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:27 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.017 s
17/03/27 22:25:27 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.116533 s
17/03/27 22:25:27 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:27 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:27 INFO BlockManager: BlockManager stopped
17/03/27 22:25:27 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:27 INFO SparkContext: Successfully stopped SparkContext
[32m- count_price(count<Price>)[0m
17/03/27 22:25:27 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:27 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:27 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:27 INFO Utils: Successfully started service 'sparkDriver' on port 52030.
17/03/27 22:25:27 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:27 INFO Remoting: Starting remoting
17/03/27 22:25:27 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52043.
17/03/27 22:25:27 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:27 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52043]
17/03/27 22:25:27 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-68adb15c-f502-42e3-a7b5-af3bafbd3efa
17/03/27 22:25:27 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:27 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52060.
17/03/27 22:25:27 INFO NettyBlockTransferService: Server created on 52060
17/03/27 22:25:27 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52060 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52060)
17/03/27 22:25:27 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:27 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667927153
17/03/27 22:25:27 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:27 INFO BigDatalogContext: BigDatalog Query: "count_price(ItemGroup, C)."
17/03/27 22:25:27 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:27 INFO BigDatalogContext: 
0: (ItemGroup, count(Price) as C) <AGGREGATE>
 1: (Price, ItemGroup) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:27 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:27 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:27 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_count_price
+- 'Aggregate ['price.ItemGroup], ['price.ItemGroup,unresolvedalias('count('price.Price) AS C#192)]
   +- 'Project ['price.Price,'price.ItemGroup]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemGroup: string, C: bigint
Subquery aggregate_count_price
+- Aggregate [ItemGroup#191], [ItemGroup#191,(count(Price#189),mode=Complete,isDistinct=false) AS C#192L]
   +- Project [Price#189,ItemGroup#191]
      +- Subquery price
         +- LogicalRDD [Price#189,ItemName#190,ItemGroup#191], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemGroup#191], [ItemGroup#191,(count(Price#189),mode=Complete,isDistinct=false) AS C#192L]
+- Project [Price#189,ItemGroup#191]
   +- LogicalRDD [Price#189,ItemName#190,ItemGroup#191], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemGroup#191], functions=[(count(Price#189),mode=Final,isDistinct=false)], output=[ItemGroup#191,C#192L])
+- TungstenExchange hashpartitioning(ItemGroup#191,5), None
   +- TungstenAggregate(key=[ItemGroup#191], functions=[(count(Price#189),mode=Partial,isDistinct=false)], output=[ItemGroup#191,count#195L])
      +- Project [Price#189,ItemGroup#191]
         +- Scan ExistingRDD[Price#189,ItemName#190,ItemGroup#191]
17/03/27 22:25:27 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:27 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:27 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:27 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.9 KB, free 2.0 GB)
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52060 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:27 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:27 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:27 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:27 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 106 ms on localhost (1/5)
17/03/27 22:25:27 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 118 ms on localhost (2/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 120 ms on localhost (3/5)
17/03/27 22:25:27 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:27 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 125 ms on localhost (4/5)
17/03/27 22:25:27 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.126 s
17/03/27 22:25:27 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:27 INFO DAGScheduler: running: Set()
17/03/27 22:25:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:27 INFO DAGScheduler: failed: Set()
17/03/27 22:25:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:27 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 88 ms on localhost (5/5)
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.4 KB, free 2.0 GB)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52060 (size: 5.2 KB, free: 2.0 GB)
17/03/27 22:25:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:27 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:27 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1669 bytes result sent to driver
17/03/27 22:25:27 INFO GenerateMutableProjection: Code generated in 8.751809 ms
17/03/27 22:25:27 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 16 ms on localhost (1/5)
17/03/27 22:25:27 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO GenerateUnsafeProjection: Code generated in 8.721089 ms
17/03/27 22:25:27 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2795 bytes result sent to driver
17/03/27 22:25:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2795 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 12 ms on localhost (2/5)
17/03/27 22:25:27 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2795 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 26 ms on localhost (3/5)
17/03/27 22:25:27 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2795 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 27 ms on localhost (4/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 28 ms on localhost (5/5)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:27 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.029 s
17/03/27 22:25:27 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.162786 s
17/03/27 22:25:27 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:27 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:27 INFO BlockManager: BlockManager stopped
17/03/27 22:25:27 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:27 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:27 INFO SparkContext: Running Spark version 1.6.3
[32m- count_price(ItemGroup, count<Price>)[0m
17/03/27 22:25:27 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:27 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:27 INFO Utils: Successfully started service 'sparkDriver' on port 52077.
17/03/27 22:25:27 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:27 INFO Remoting: Starting remoting
17/03/27 22:25:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52090]
17/03/27 22:25:27 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52090.
17/03/27 22:25:27 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:27 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:27 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-1aba23a7-1121-4b40-b01c-8b62e58d0c0b
17/03/27 22:25:27 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:27 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52108.
17/03/27 22:25:27 INFO NettyBlockTransferService: Server created on 52108
17/03/27 22:25:27 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52108 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52108)
17/03/27 22:25:27 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:27 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667927579
17/03/27 22:25:27 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:27 INFO BigDatalogContext: BigDatalog Query: "sum_price(S)."
17/03/27 22:25:27 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:27 INFO BigDatalogContext: 
0: (sum(Price) as S) <AGGREGATE>
 1: (Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:27 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:27 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:27 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_sum_price
+- 'Aggregate [unresolvedalias('sum('price.Price) AS S#202)]
   +- 'Project ['price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
S: bigint
Subquery aggregate_sum_price
+- Aggregate [(sum(cast(Price#199 as bigint)),mode=Complete,isDistinct=false) AS S#202L]
   +- Project [Price#199]
      +- Subquery price
         +- LogicalRDD [Price#199,ItemName#200,ItemGroup#201], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(sum(cast(Price#199 as bigint)),mode=Complete,isDistinct=false) AS S#202L]
+- Project [Price#199]
   +- LogicalRDD [Price#199,ItemName#200,ItemGroup#201], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(sum(cast(Price#199 as bigint)),mode=Final,isDistinct=false)], output=[S#202L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(sum(cast(Price#199 as bigint)),mode=Partial,isDistinct=false)], output=[sum#205L])
      +- Project [Price#199]
         +- Scan ExistingRDD[Price#199,ItemName#200,ItemGroup#201]
17/03/27 22:25:27 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:27 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:27 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:27 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.0 KB, free 2.0 GB)
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52108 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:27 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:27 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:27 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:27 INFO GenerateMutableProjection: Code generated in 4.381801 ms
17/03/27 22:25:27 INFO GenerateMutableProjection: Code generated in 4.212064 ms
17/03/27 22:25:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:27 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1491 bytes result sent to driver
17/03/27 22:25:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1491 bytes result sent to driver
17/03/27 22:25:27 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1491 bytes result sent to driver
17/03/27 22:25:27 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 40 ms on localhost (1/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 40 ms on localhost (2/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 40 ms on localhost (3/5)
17/03/27 22:25:27 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 41 ms on localhost (4/5)
17/03/27 22:25:27 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1491 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 12 ms on localhost (5/5)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:27 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.049 s
17/03/27 22:25:27 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:27 INFO DAGScheduler: running: Set()
17/03/27 22:25:27 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:27 INFO DAGScheduler: failed: Set()
17/03/27 22:25:27 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.4 KB, free 2.0 GB)
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:25:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52108 (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:25:27 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:27 INFO GenerateMutableProjection: Code generated in 4.513369 ms
17/03/27 22:25:27 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2706 bytes result sent to driver
17/03/27 22:25:27 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 11 ms on localhost (1/1)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:27 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.011 s
17/03/27 22:25:27 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.067222 s
17/03/27 22:25:27 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:27 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:27 INFO BlockManager: BlockManager stopped
17/03/27 22:25:27 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:27 INFO SparkContext: Successfully stopped SparkContext
[32m- sum_price(sum<Price>)[0m
17/03/27 22:25:27 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:27 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:27 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:27 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:27 INFO Utils: Successfully started service 'sparkDriver' on port 52125.
17/03/27 22:25:27 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:27 INFO Remoting: Starting remoting
17/03/27 22:25:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52138]
17/03/27 22:25:27 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52138.
17/03/27 22:25:27 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:27 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:27 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-2826c0fe-102b-4813-be95-ba85e3215419
17/03/27 22:25:27 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:27 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52155.
17/03/27 22:25:27 INFO NettyBlockTransferService: Server created on 52155
17/03/27 22:25:27 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52155 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52155)
17/03/27 22:25:27 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:27 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667927859
17/03/27 22:25:27 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:27 INFO BigDatalogContext: BigDatalog Query: "sum_price(ItemGroup, S)."
17/03/27 22:25:27 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:27 INFO BigDatalogContext: 
0: (ItemGroup, sum(Price) as S) <AGGREGATE>
 1: (Price, ItemGroup) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:27 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:27 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:27 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_sum_price
+- 'Aggregate ['price.ItemGroup], ['price.ItemGroup,unresolvedalias('sum('price.Price) AS S#212)]
   +- 'Project ['price.Price,'price.ItemGroup]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemGroup: string, S: bigint
Subquery aggregate_sum_price
+- Aggregate [ItemGroup#211], [ItemGroup#211,(sum(cast(Price#209 as bigint)),mode=Complete,isDistinct=false) AS S#212L]
   +- Project [Price#209,ItemGroup#211]
      +- Subquery price
         +- LogicalRDD [Price#209,ItemName#210,ItemGroup#211], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemGroup#211], [ItemGroup#211,(sum(cast(Price#209 as bigint)),mode=Complete,isDistinct=false) AS S#212L]
+- Project [Price#209,ItemGroup#211]
   +- LogicalRDD [Price#209,ItemName#210,ItemGroup#211], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemGroup#211], functions=[(sum(cast(Price#209 as bigint)),mode=Final,isDistinct=false)], output=[ItemGroup#211,S#212L])
+- TungstenExchange hashpartitioning(ItemGroup#211,5), None
   +- TungstenAggregate(key=[ItemGroup#211], functions=[(sum(cast(Price#209 as bigint)),mode=Partial,isDistinct=false)], output=[ItemGroup#211,sum#215L])
      +- Project [Price#209,ItemGroup#211]
         +- Scan ExistingRDD[Price#209,ItemName#210,ItemGroup#211]
17/03/27 22:25:27 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:27 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:27 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:27 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:27 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.1 KB, free 2.0 GB)
17/03/27 22:25:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 2.0 GB)
17/03/27 22:25:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52155 (size: 4.6 KB, free: 2.0 GB)
17/03/27 22:25:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:27 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:27 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:27 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:27 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:28 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:28 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 49 ms on localhost (1/5)
17/03/27 22:25:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 38 ms on localhost (2/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 69 ms on localhost (3/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 70 ms on localhost (4/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 72 ms on localhost (5/5)
17/03/27 22:25:28 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.073 s
17/03/27 22:25:28 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:28 INFO DAGScheduler: running: Set()
17/03/27 22:25:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:28 INFO DAGScheduler: failed: Set()
17/03/27 22:25:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.5 KB, free 2.0 GB)
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52155 (size: 5.2 KB, free: 2.0 GB)
17/03/27 22:25:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:28 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:28 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:28 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1669 bytes result sent to driver
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO GenerateMutableProjection: Code generated in 6.700701 ms
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2795 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2795 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2795 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 19 ms on localhost (1/5)
17/03/27 22:25:28 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 21 ms on localhost (2/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 20 ms on localhost (3/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 21 ms on localhost (4/5)
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2795 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 9 ms on localhost (5/5)
17/03/27 22:25:28 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.025 s
17/03/27 22:25:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:28 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.107175 s
17/03/27 22:25:28 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:28 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:28 INFO BlockManager: BlockManager stopped
17/03/27 22:25:28 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:28 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:28 INFO SparkContext: Running Spark version 1.6.3
[32m- sum_price(ItemGroup, sum<Price>)[0m
17/03/27 22:25:28 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:28 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:28 INFO Utils: Successfully started service 'sparkDriver' on port 52172.
17/03/27 22:25:28 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:28 INFO Remoting: Starting remoting
17/03/27 22:25:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52185]
17/03/27 22:25:28 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52185.
17/03/27 22:25:28 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:28 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:28 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-29a95289-2096-49e5-bdbc-232b4d3b7432
17/03/27 22:25:28 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:28 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:28 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52203.
17/03/27 22:25:28 INFO NettyBlockTransferService: Server created on 52203
17/03/27 22:25:28 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52203 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52203)
17/03/27 22:25:28 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:28 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667928190
17/03/27 22:25:28 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:28 INFO BigDatalogContext: BigDatalog Query: "sumcountavg_price(S, C, A)."
17/03/27 22:25:28 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:28 INFO BigDatalogContext: 
0: (sum(Price) as S, count(Price) as C, avg(Price) as A) <AGGREGATE>
 1: (Price) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:28 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:28 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:28 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_sumcountavg_price
+- 'Aggregate [unresolvedalias('sum('price.Price) AS S#222),unresolvedalias('count('price.Price) AS C#223),unresolvedalias('avg('price.Price) AS A#224)]
   +- 'Project ['price.Price]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
S: bigint, C: bigint, A: double
Subquery aggregate_sumcountavg_price
+- Aggregate [(sum(cast(Price#219 as bigint)),mode=Complete,isDistinct=false) AS S#222L,(count(Price#219),mode=Complete,isDistinct=false) AS C#223L,(avg(cast(Price#219 as bigint)),mode=Complete,isDistinct=false) AS A#224]
   +- Project [Price#219]
      +- Subquery price
         +- LogicalRDD [Price#219,ItemName#220,ItemGroup#221], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(sum(cast(Price#219 as bigint)),mode=Complete,isDistinct=false) AS S#222L,(count(Price#219),mode=Complete,isDistinct=false) AS C#223L,(avg(cast(Price#219 as bigint)),mode=Complete,isDistinct=false) AS A#224]
+- Project [Price#219]
   +- LogicalRDD [Price#219,ItemName#220,ItemGroup#221], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(sum(cast(Price#219 as bigint)),mode=Final,isDistinct=false),(count(Price#219),mode=Final,isDistinct=false),(avg(cast(Price#219 as bigint)),mode=Final,isDistinct=false)], output=[S#222L,C#223L,A#224])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(sum(cast(Price#219 as bigint)),mode=Partial,isDistinct=false),(count(Price#219),mode=Partial,isDistinct=false),(avg(cast(Price#219 as bigint)),mode=Partial,isDistinct=false)], output=[sum#232L,count#233L,sum#234,count#235L])
      +- Project [Price#219]
         +- Scan ExistingRDD[Price#219,ItemName#220,ItemGroup#221]
17/03/27 22:25:28 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:28 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:28 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:28 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KB, free 2.0 GB)
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52203 (size: 4.9 KB, free: 2.0 GB)
17/03/27 22:25:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:28 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:28 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:28 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:28 INFO GenerateMutableProjection: Code generated in 3.985853 ms
17/03/27 22:25:28 INFO GenerateMutableProjection: Code generated in 5.439936 ms
17/03/27 22:25:28 INFO GenerateUnsafeRowJoiner: Code generated in 3.435684 ms
17/03/27 22:25:28 INFO GenerateUnsafeProjection: Code generated in 3.363694 ms
17/03/27 22:25:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1491 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:28 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1491 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1491 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1491 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 64 ms on localhost (1/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 65 ms on localhost (2/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 65 ms on localhost (3/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 19 ms on localhost (4/5)
17/03/27 22:25:28 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1491 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 70 ms on localhost (5/5)
17/03/27 22:25:28 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.071 s
17/03/27 22:25:28 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:28 INFO DAGScheduler: running: Set()
17/03/27 22:25:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:28 INFO DAGScheduler: failed: Set()
17/03/27 22:25:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KB, free 2.0 GB)
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.7 KB, free 2.0 GB)
17/03/27 22:25:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52203 (size: 5.7 KB, free: 2.0 GB)
17/03/27 22:25:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
17/03/27 22:25:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO GenerateMutableProjection: Code generated in 6.928464 ms
17/03/27 22:25:28 INFO GenerateMutableProjection: Code generated in 4.346116 ms
17/03/27 22:25:28 INFO GenerateUnsafeProjection: Code generated in 6.534998 ms
17/03/27 22:25:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2877 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 31 ms on localhost (1/1)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:28 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.031 s
17/03/27 22:25:28 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.110877 s
17/03/27 22:25:28 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:28 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:28 INFO BlockManager: BlockManager stopped
17/03/27 22:25:28 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:28 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:28 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:28 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:28 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[32m- sumcountavg_price(sum<Price>, count<Price>, avg<Price>)[0m
17/03/27 22:25:28 INFO Utils: Successfully started service 'sparkDriver' on port 52220.
17/03/27 22:25:28 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:28 INFO Remoting: Starting remoting
17/03/27 22:25:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52233]
17/03/27 22:25:28 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52233.
17/03/27 22:25:28 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:28 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:28 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-7649132e-294b-42b2-9d45-f0fc19e5d314
17/03/27 22:25:28 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:28 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:28 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52250.
17/03/27 22:25:28 INFO NettyBlockTransferService: Server created on 52250
17/03/27 22:25:28 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52250 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52250)
17/03/27 22:25:28 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:28 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667928519
17/03/27 22:25:28 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:28 INFO BigDatalogContext: BigDatalog Query: "sumcountavg_price(ItemGroup, S, C, A)."
17/03/27 22:25:28 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:28 INFO BigDatalogContext: 
0: (ItemGroup, sum(Price) as S, count(Price) as C, avg(Price) as A) <AGGREGATE>
 1: (Price, ItemGroup) <PROJECT>
  2: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:28 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:28 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:28 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_sumcountavg_price
+- 'Aggregate ['price.ItemGroup], ['price.ItemGroup,unresolvedalias('sum('price.Price) AS S#250),unresolvedalias('count('price.Price) AS C#251),unresolvedalias('avg('price.Price) AS A#252)]
   +- 'Project ['price.Price,'price.ItemGroup]
      +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
ItemGroup: string, S: bigint, C: bigint, A: double
Subquery aggregate_sumcountavg_price
+- Aggregate [ItemGroup#249], [ItemGroup#249,(sum(cast(Price#247 as bigint)),mode=Complete,isDistinct=false) AS S#250L,(count(Price#247),mode=Complete,isDistinct=false) AS C#251L,(avg(cast(Price#247 as bigint)),mode=Complete,isDistinct=false) AS A#252]
   +- Project [Price#247,ItemGroup#249]
      +- Subquery price
         +- LogicalRDD [Price#247,ItemName#248,ItemGroup#249], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [ItemGroup#249], [ItemGroup#249,(sum(cast(Price#247 as bigint)),mode=Complete,isDistinct=false) AS S#250L,(count(Price#247),mode=Complete,isDistinct=false) AS C#251L,(avg(cast(Price#247 as bigint)),mode=Complete,isDistinct=false) AS A#252]
+- Project [Price#247,ItemGroup#249]
   +- LogicalRDD [Price#247,ItemName#248,ItemGroup#249], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[ItemGroup#249], functions=[(sum(cast(Price#247 as bigint)),mode=Final,isDistinct=false),(count(Price#247),mode=Final,isDistinct=false),(avg(cast(Price#247 as bigint)),mode=Final,isDistinct=false)], output=[ItemGroup#249,S#250L,C#251L,A#252])
+- TungstenExchange hashpartitioning(ItemGroup#249,5), None
   +- TungstenAggregate(key=[ItemGroup#249], functions=[(sum(cast(Price#247 as bigint)),mode=Partial,isDistinct=false),(count(Price#247),mode=Partial,isDistinct=false),(avg(cast(Price#247 as bigint)),mode=Partial,isDistinct=false)], output=[ItemGroup#249,sum#260L,count#261L,sum#262,count#263L])
      +- Project [Price#247,ItemGroup#249]
         +- Scan ExistingRDD[Price#247,ItemName#248,ItemGroup#249]
17/03/27 22:25:28 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:28 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:28 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:28 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:28 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.2 KB, free 2.0 GB)
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52250 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:28 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:28 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:28 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:28 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:28 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:28 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:28 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:28 INFO GenerateUnsafeRowJoiner: Code generated in 5.94449 ms
17/03/27 22:25:28 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:28 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:28 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 65 ms on localhost (1/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 31 ms on localhost (2/5)
17/03/27 22:25:28 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 72 ms on localhost (3/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 74 ms on localhost (4/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 75 ms on localhost (5/5)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:28 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.076 s
17/03/27 22:25:28 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:28 INFO DAGScheduler: running: Set()
17/03/27 22:25:28 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:28 INFO DAGScheduler: failed: Set()
17/03/27 22:25:28 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.9 KB, free 2.0 GB)
17/03/27 22:25:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.8 KB, free 2.0 GB)
17/03/27 22:25:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52250 (size: 5.8 KB, free: 2.0 GB)
17/03/27 22:25:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:28 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:28 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1669 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:28 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 5 ms on localhost (1/5)
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:28 INFO GenerateMutableProjection: Code generated in 7.199669 ms
17/03/27 22:25:28 INFO GenerateUnsafeProjection: Code generated in 5.059504 ms
17/03/27 22:25:28 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2969 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2969 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 2969 bytes result sent to driver
17/03/27 22:25:28 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2969 bytes result sent to driver
17/03/27 22:25:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 26 ms on localhost (2/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 21 ms on localhost (3/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 26 ms on localhost (4/5)
17/03/27 22:25:28 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 27 ms on localhost (5/5)
17/03/27 22:25:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:28 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.028 s
17/03/27 22:25:28 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.113454 s
17/03/27 22:25:28 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:28 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:28 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:28 INFO BlockManager: BlockManager stopped
17/03/27 22:25:28 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:28 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:28 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:28 INFO SparkContext: Running Spark version 1.6.3
[32m- sumcountavg_price(ItemGroup, sum<Price>, count<Price>, avg<Price>)[0m
17/03/27 22:25:28 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:28 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:28 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:28 INFO Utils: Successfully started service 'sparkDriver' on port 52268.
17/03/27 22:25:28 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:28 INFO Remoting: Starting remoting
17/03/27 22:25:28 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52281]
17/03/27 22:25:28 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52281.
17/03/27 22:25:28 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:28 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:28 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-b0ae0a09-42be-4de7-9148-353f7ebc251f
17/03/27 22:25:28 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:28 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:28 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52298.
17/03/27 22:25:28 INFO NettyBlockTransferService: Server created on 52298
17/03/27 22:25:28 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:28 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52298 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52298)
17/03/27 22:25:28 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:28 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667928824
17/03/27 22:25:28 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:28 INFO BigDatalogContext: BigDatalog Query: "avg_price_a_b_combined(N)."
17/03/27 22:25:28 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:28 INFO BigDatalogContext: 
0: (A + B as N) <DISTINCT PROJECT>
 1: () <JOIN>
  2: (avg(Price) as A) <AGGREGATE>
   3: (Price) <PROJECT>
    4: ItemGroup = 'a' <FILTER>
     5: price(Price, ItemName, ItemGroup) <BASE_RELATION>
  2: (avg(Price) as B) <AGGREGATE>
   3: (Price) <PROJECT>
    4: ItemGroup = 'b' <FILTER>
     5: price(Price, ItemName, ItemGroup) <BASE_RELATION>
17/03/27 22:25:28 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:28 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:28 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project [unresolvedalias(('aggregate_avg_price.A + 'aggregate_avg_price.B) AS N#280)]
   +- 'Join Inner, None
      :- 'Subquery aggregate_avg_price
      :  +- 'Aggregate [unresolvedalias('avg('price.Price) AS A#278)]
      :     +- 'Project ['price.Price]
      :        +- 'Filter ('price.ItemGroup = a)
      :           +- 'UnresolvedRelation `price`, None
      +- 'Subquery aggregate_avg_price
         +- 'Aggregate [unresolvedalias('avg('price1.Price) AS B#279)]
            +- 'Project ['price1.Price]
               +- 'Filter ('price1.ItemGroup = b)
                  +- 'Subquery price1
                     +- 'Project [*]
                        +- 'UnresolvedRelation `price`, None

== Analyzed Logical Plan ==
N: double
Distinct
+- Project [(A#278 + B#279) AS N#280]
   +- Join Inner, None
      :- Subquery aggregate_avg_price
      :  +- Aggregate [(avg(cast(Price#275 as bigint)),mode=Complete,isDistinct=false) AS A#278]
      :     +- Project [Price#275]
      :        +- Filter (ItemGroup#277 = a)
      :           +- Subquery price
      :              +- LogicalRDD [Price#275,ItemName#276,ItemGroup#277], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Subquery aggregate_avg_price
         +- Aggregate [(avg(cast(Price#275 as bigint)),mode=Complete,isDistinct=false) AS B#279]
            +- Project [Price#275]
               +- Filter (ItemGroup#277 = b)
                  +- Subquery price1
                     +- Project [Price#275,ItemName#276,ItemGroup#277]
                        +- Subquery price
                           +- LogicalRDD [Price#275,ItemName#276,ItemGroup#277], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [N#280], [N#280]
+- Project [(A#278 + B#279) AS N#280]
   +- Join Inner, None
      :- Aggregate [(avg(cast(Price#275 as bigint)),mode=Complete,isDistinct=false) AS A#278]
      :  +- Project [Price#275]
      :     +- Filter (ItemGroup#277 = a)
      :        +- LogicalRDD [Price#275,ItemName#276,ItemGroup#277], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Aggregate [(avg(cast(Price#275 as bigint)),mode=Complete,isDistinct=false) AS B#279]
         +- Project [Price#275]
            +- Filter (ItemGroup#277 = b)
               +- LogicalRDD [Price#275,ItemName#276,ItemGroup#277], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[N#280], functions=[], output=[N#280])
+- TungstenExchange hashpartitioning(N#280,5), None
   +- TungstenAggregate(key=[N#280], functions=[], output=[N#280])
      +- Project [(A#278 + B#279) AS N#280]
         +- CartesianProduct
            :- ConvertToSafe
            :  +- TungstenAggregate(key=[], functions=[(avg(cast(Price#275 as bigint)),mode=Final,isDistinct=false)], output=[A#278])
            :     +- TungstenExchange SinglePartition, None
            :        +- TungstenAggregate(key=[], functions=[(avg(cast(Price#275 as bigint)),mode=Partial,isDistinct=false)], output=[sum#284,count#285L])
            :           +- Project [Price#275]
            :              +- Filter (ItemGroup#277 = a)
            :                 +- Scan ExistingRDD[Price#275,ItemName#276,ItemGroup#277] 
            +- ConvertToSafe
               +- TungstenAggregate(key=[], functions=[(avg(cast(Price#275 as bigint)),mode=Final,isDistinct=false)], output=[B#279])
                  +- TungstenExchange SinglePartition, None
                     +- TungstenAggregate(key=[], functions=[(avg(cast(Price#275 as bigint)),mode=Partial,isDistinct=false)], output=[sum#289,count#290L])
                        +- Project [Price#275]
                           +- Filter (ItemGroup#277 = b)
                              +- Scan ExistingRDD[Price#275,ItemName#276,ItemGroup#277]
17/03/27 22:25:28 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:29 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:29 INFO DAGScheduler: Registering RDD 4 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO DAGScheduler: Registering RDD 12 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO DAGScheduler: Registering RDD 21 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:29 INFO DAGScheduler: Final stage: ResultStage 3 (collect at QuerySuite.scala:64)
17/03/27 22:25:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:25:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:25:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 10.1 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52298 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:29 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.1 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52298 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1568 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1577 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1577 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2556 bytes)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1568 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2555 bytes)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1568 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2558 bytes)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1568 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2554 bytes)
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1568 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1577 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1577 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 62 ms on localhost (1/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 37 ms on localhost (2/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 34 ms on localhost (1/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 28 ms on localhost (2/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 27 ms on localhost (3/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 22 ms on localhost (4/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 67 ms on localhost (3/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 68 ms on localhost (4/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 69 ms on localhost (5/5)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.070 s
17/03/27 22:25:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:29 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/03/27 22:25:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:29 INFO DAGScheduler: failed: Set()
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1568 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 44 ms on localhost (5/5)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.069 s
17/03/27 22:25:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:29 INFO DAGScheduler: running: Set()
17/03/27 22:25:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:29 INFO DAGScheduler: failed: Set()
17/03/27 22:25:29 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[21] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 16.5 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.2 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52298 (size: 7.2 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[21] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2178 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO GenerateSafeProjection: Code generated in 3.039116 ms
17/03/27 22:25:29 INFO GenerateUnsafeProjection: Code generated in 16.562467 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO GenerateMutableProjection: Code generated in 2.172127 ms
17/03/27 22:25:29 INFO GenerateMutableProjection: Code generated in 2.293455 ms
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2786 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 52 ms on localhost (1/1)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.052 s
17/03/27 22:25:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:29 INFO DAGScheduler: running: Set()
17/03/27 22:25:29 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/27 22:25:29 INFO DAGScheduler: failed: Set()
17/03/27 22:25:29 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[24] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 15.4 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.7 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52298 (size: 6.7 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[24] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 11, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 12, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 13, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 14, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 11)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 3.0 (TID 12)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 3.0 (TID 13)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 3.0 (TID 14)
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 3.0 (TID 14). 2744 bytes result sent to driver
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 15, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 14) in 6 ms on localhost (1/5)
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 3.0 (TID 15)
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 11). 2744 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 3.0 (TID 13). 2744 bytes result sent to driver
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 1 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 3.0 (TID 12). 3785 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 3.0 (TID 15). 2744 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 11) in 8 ms on localhost (2/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 13) in 8 ms on localhost (3/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 12) in 9 ms on localhost (4/5)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 15) in 4 ms on localhost (5/5)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ResultStage 3 (collect at QuerySuite.scala:64) finished in 0.009 s
17/03/27 22:25:29 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.148396 s
17/03/27 22:25:29 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:29 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:29 INFO BlockManager: BlockManager stopped
17/03/27 22:25:29 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:29 INFO SparkContext: Successfully stopped SparkContext
[32m- avg_price_a_b_combined(N)[0m
17/03/27 22:25:29 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:29 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:29 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:29 INFO Utils: Successfully started service 'sparkDriver' on port 52315.
17/03/27 22:25:29 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:29 INFO Remoting: Starting remoting
17/03/27 22:25:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52328]
17/03/27 22:25:29 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52328.
17/03/27 22:25:29 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:29 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:29 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-42c242d0-1854-4a6d-bf3c-bcaedad58317
17/03/27 22:25:29 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:29 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:29 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52345.
17/03/27 22:25:29 INFO NettyBlockTransferService: Server created on 52345
17/03/27 22:25:29 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:29 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52345 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52345)
17/03/27 22:25:29 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:29 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667929339
17/03/27 22:25:29 INFO NonMonotonicAggregateQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:29 INFO BigDatalogContext: BigDatalog Query: "nodeCount(A)"
17/03/27 22:25:29 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:29 INFO BigDatalogContext: 
0: (countd(From) as A) <AGGREGATE>
 1: node(From) <UNION>
  2: (From) <PROJECT>
   3: arc(From, To) <BASE_RELATION>
  2: (To) <PROJECT>
   3: arc(From, To) <BASE_RELATION>
17/03/27 22:25:29 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:29 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:29 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_nodeCount
+- 'Aggregate [unresolvedalias('count('node.From) AS A#303)]
   +- 'Distinct
      +- 'Subquery node
         +- 'Union
            :- 'Project ['arc.From]
            :  +- 'UnresolvedRelation `arc`, None
            +- 'Project ['arc1.To]
               +- 'Subquery arc1
                  +- 'Project [*]
                     +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: bigint
Subquery aggregate_nodeCount
+- Aggregate [(count(if ((gid#304 = 1)) From#305 else null),mode=Complete,isDistinct=false) AS A#303L]
   +- Aggregate [From#305,gid#304], [From#305,gid#304]
      +- Expand [List(From#301, 1)], [From#305,gid#304]
         +- Distinct
            +- Subquery node
               +- Union
                  :- Project [From#301]
                  :  +- Subquery arc
                  :     +- LogicalRDD [From#301,To#302], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
                  +- Project [To#302]
                     +- Subquery arc1
                        +- Project [From#301,To#302]
                           +- Subquery arc
                              +- LogicalRDD [From#301,To#302], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(count(if ((gid#304 = 1)) From#305 else null),mode=Complete,isDistinct=false) AS A#303L]
+- Aggregate [From#305,gid#304], [From#305,gid#304]
   +- Expand [List(From#301, 1)], [From#305,gid#304]
      +- Aggregate [From#301], [From#301]
         +- Union
            :- Project [From#301]
            :  +- LogicalRDD [From#301,To#302], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
            +- Project [To#302]
               +- LogicalRDD [From#301,To#302], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(count(if ((gid#304 = 1)) From#305 else null),mode=Final,isDistinct=false)], output=[A#303L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(count(if ((gid#304 = 1)) From#305 else null),mode=Partial,isDistinct=false)], output=[count#308L])
      +- TungstenAggregate(key=[From#305,gid#304], functions=[], output=[From#305,gid#304])
         +- TungstenExchange hashpartitioning(From#305,gid#304,5), None
            +- TungstenAggregate(key=[From#305,gid#304], functions=[], output=[From#305,gid#304])
               +- Expand [List(From#301, 1)], [From#305,gid#304]
                  +- TungstenAggregate(key=[From#301], functions=[], output=[From#301])
                     +- TungstenExchange hashpartitioning(From#301,5), None
                        +- TungstenAggregate(key=[From#301], functions=[], output=[From#301])
                           +- Union
                              :- Project [From#301]
                              :  +- Scan ExistingRDD[From#301,To#302] 
                              +- Project [To#302]
                                 +- Scan ExistingRDD[From#301,To#302]
17/03/27 22:25:29 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:29 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:29 INFO DAGScheduler: Registering RDD 5 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO DAGScheduler: Registering RDD 10 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO DAGScheduler: Registering RDD 14 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:29 INFO DAGScheduler: Final stage: ResultStage 3 (collect at QuerySuite.scala:64)
17/03/27 22:25:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:25:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:25:29 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.3 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52345 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2455 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, partition 5,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, partition 6,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, partition 7,PROCESS_LOCAL, 2455 bytes)
17/03/27 22:25:29 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, localhost, partition 8,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 50 ms on localhost (1/10)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 20 ms on localhost (2/10)
17/03/27 22:25:29 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, localhost, partition 9,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 14 ms on localhost (3/10)
17/03/27 22:25:29 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
17/03/27 22:25:29 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 14 ms on localhost (4/10)
17/03/27 22:25:29 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 14 ms on localhost (5/10)
17/03/27 22:25:29 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 12 ms on localhost (6/10)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 73 ms on localhost (7/10)
17/03/27 22:25:29 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1538 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 42 ms on localhost (8/10)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 75 ms on localhost (9/10)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 75 ms on localhost (10/10)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.077 s
17/03/27 22:25:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:29 INFO DAGScheduler: running: Set()
17/03/27 22:25:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:29 INFO DAGScheduler: failed: Set()
17/03/27 22:25:29 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 10.4 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52345 (size: 5.0 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 12, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 13, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 1.0 (TID 10)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 1.0 (TID 13)
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO GenerateUnsafeProjection: Code generated in 3.764917 ms
17/03/27 22:25:29 INFO GenerateMutableProjection: Code generated in 3.292013 ms
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 1.0 (TID 12). 2098 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 14, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 12) in 45 ms on localhost (1/5)
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 1.0 (TID 14)
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 1.0 (TID 11). 2098 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 11) in 47 ms on localhost (2/5)
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 1.0 (TID 13). 2098 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 13) in 48 ms on localhost (3/5)
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 1.0 (TID 10). 2098 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 10) in 52 ms on localhost (4/5)
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 1.0 (TID 14). 2098 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 14) in 14 ms on localhost (5/5)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.059 s
17/03/27 22:25:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:29 INFO DAGScheduler: running: Set()
17/03/27 22:25:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:29 INFO DAGScheduler: failed: Set()
17/03/27 22:25:29 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.5 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.7 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52345 (size: 5.7 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 17, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 18, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 2.0 (TID 15)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 2.0 (TID 16)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 2.0 (TID 17)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 2.0 (TID 18)
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO GenerateMutableProjection: Code generated in 9.756573 ms
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 2.0 (TID 17). 2438 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 19, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 17) in 24 ms on localhost (1/5)
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 2.0 (TID 19)
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 2.0 (TID 18). 2438 bytes result sent to driver
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 18) in 26 ms on localhost (2/5)
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 16). 2438 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 16) in 29 ms on localhost (3/5)
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 2.0 (TID 19). 2438 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 19) in 13 ms on localhost (4/5)
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 15). 2438 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 15) in 42 ms on localhost (5/5)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.042 s
17/03/27 22:25:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:29 INFO DAGScheduler: running: Set()
17/03/27 22:25:29 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/27 22:25:29 INFO DAGScheduler: failed: Set()
17/03/27 22:25:29 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.5 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52345 (size: 6.0 KB, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 20, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 20)
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 20). 3437 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 20) in 6 ms on localhost (1/1)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:29 INFO DAGScheduler: ResultStage 3 (collect at QuerySuite.scala:64) finished in 0.008 s
17/03/27 22:25:29 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.203453 s
17/03/27 22:25:29 INFO NonMonotonicAggregateQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:29 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:29 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:29 INFO BlockManager: BlockManager stopped
17/03/27 22:25:29 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:29 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:29 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:29 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:29 INFO SparkContext: Successfully stopped SparkContext
[32m- nodeCount(countd<A>)[0m
17/03/27 22:25:29 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:29 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:29 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[32mRelationalQuerySuite:[0m
17/03/27 22:25:29 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:29 INFO Utils: Successfully started service 'sparkDriver' on port 52363.
17/03/27 22:25:29 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:29 INFO Remoting: Starting remoting
17/03/27 22:25:29 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52376.
17/03/27 22:25:29 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52376]
17/03/27 22:25:29 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:29 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:29 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-388e839e-f263-4db6-931d-bddc75379bab
17/03/27 22:25:29 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:29 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:29 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52393.
17/03/27 22:25:29 INFO NettyBlockTransferService: Server created on 52393
17/03/27 22:25:29 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:29 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52393 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52393)
17/03/27 22:25:29 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:29 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667929867
17/03/27 22:25:29 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:29 INFO BigDatalogContext: BigDatalog Query: "employee(EmployeeId, DepartmentId, FirstName, LastName)."
17/03/27 22:25:29 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:29 INFO BigDatalogContext: 
0: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
17/03/27 22:25:29 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:29 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:29 INFO BigDatalogContext: == Parsed Logical Plan ==
'UnresolvedRelation `employee`, None

== Analyzed Logical Plan ==
EmployeeId: int, DepartmentId: int, FirstName: string, LastName: string
Subquery employee
+- LogicalRDD [EmployeeId#314,DepartmentId#315,FirstName#316,LastName#317], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
LogicalRDD [EmployeeId#314,DepartmentId#315,FirstName#316,LastName#317], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Scan ExistingRDD[EmployeeId#314,DepartmentId#315,FirstName#316,LastName#317]
17/03/27 22:25:29 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:29 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:29 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:29 INFO DAGScheduler: Final stage: ResultStage 0 (collect at QuerySuite.scala:64)
17/03/27 22:25:29 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:29 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:29 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 1605.0 B, free 2.0 GB)
17/03/27 22:25:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52393 (size: 1605.0 B, free: 2.0 GB)
17/03/27 22:25:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:29 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2401 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:29 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2407 bytes)
17/03/27 22:25:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:29 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:29 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 983 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 2207 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 983 bytes result sent to driver
17/03/27 22:25:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2198 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:29 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:29 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 2208 bytes result sent to driver
17/03/27 22:25:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 15 ms on localhost (1/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 3 ms on localhost (2/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 17 ms on localhost (3/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 17 ms on localhost (4/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 18 ms on localhost (5/5)
17/03/27 22:25:30 INFO DAGScheduler: ResultStage 0 (collect at QuerySuite.scala:64) finished in 0.020 s
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.038019 s
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:30 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:30 INFO BlockManager: BlockManager stopped
17/03/27 22:25:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:30 INFO SparkContext: Successfully stopped SparkContext
[32m- employee(EmployeeId, DepartmentId, FirstName, LastName).[0m
17/03/27 22:25:30 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:30 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriver' on port 52411.
17/03/27 22:25:30 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:30 INFO Remoting: Starting remoting
17/03/27 22:25:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52424]
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52424.
17/03/27 22:25:30 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:30 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:30 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-37bae73b-1f80-4f8a-8516-7ee0151ecad9
17/03/27 22:25:30 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:30 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:30 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52441.
17/03/27 22:25:30 INFO NettyBlockTransferService: Server created on 52441
17/03/27 22:25:30 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52441 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52441)
17/03/27 22:25:30 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:30 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667930094
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:30 INFO BigDatalogContext: BigDatalog Query: "employee(EmployeeId,DepartmentId,'Bob',LastName)."
17/03/27 22:25:30 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:30 INFO BigDatalogContext: 
0: FirstName = 'Bob' <FILTER>
 1: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
17/03/27 22:25:30 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:30 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:30 INFO BigDatalogContext: == Parsed Logical Plan ==
'Filter ('employee.FirstName = Bob)
+- 'UnresolvedRelation `employee`, None

== Analyzed Logical Plan ==
EmployeeId: int, DepartmentId: int, FirstName: string, LastName: string
Filter (FirstName#320 = Bob)
+- Subquery employee
   +- LogicalRDD [EmployeeId#318,DepartmentId#319,FirstName#320,LastName#321], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Filter (FirstName#320 = Bob)
+- LogicalRDD [EmployeeId#318,DepartmentId#319,FirstName#320,LastName#321], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Filter (FirstName#320 = Bob)
+- Scan ExistingRDD[EmployeeId#318,DepartmentId#319,FirstName#320,LastName#321]
17/03/27 22:25:30 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:30 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:30 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:30 INFO DAGScheduler: Final stage: ResultStage 0 (collect at QuerySuite.scala:64)
17/03/27 22:25:30 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:30 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[2] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.6 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.1 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52441 (size: 3.1 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2401 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2407 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2412 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 6 ms on localhost (1/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 2 ms on localhost (2/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 6 ms on localhost (3/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 6 ms on localhost (4/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 6 ms on localhost (5/5)
17/03/27 22:25:30 INFO DAGScheduler: ResultStage 0 (collect at QuerySuite.scala:64) finished in 0.007 s
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.011499 s
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:30 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:30 INFO BlockManager: BlockManager stopped
17/03/27 22:25:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:30 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:30 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:30 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[32m- employee(EmployeeId,DepartmentId,'Bob',LastName).[0m
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriver' on port 52458.
17/03/27 22:25:30 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:30 INFO Remoting: Starting remoting
17/03/27 22:25:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52471]
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52471.
17/03/27 22:25:30 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:30 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:30 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-7fd5fd8c-3da1-477c-9114-a3abc91b23fe
17/03/27 22:25:30 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:30 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:30 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52488.
17/03/27 22:25:30 INFO NettyBlockTransferService: Server created on 52488
17/03/27 22:25:30 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52488 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52488)
17/03/27 22:25:30 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:30 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667930266
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:30 INFO BigDatalogContext: BigDatalog Query: "employeeSalaryHistory(EmployeeID, Salary, Start, End)."
17/03/27 22:25:30 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:30 INFO BigDatalogContext: 
0: (Start <= '2010-12-01 12:00:00 AM') && (End >= '2014-01-01 12:00:00 AM') <FILTER>
 1: employee_salary(EmployeeId, Salary, Start, End) <BASE_RELATION>
17/03/27 22:25:30 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:30 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:30 INFO BigDatalogContext: == Parsed Logical Plan ==
'Filter (('employee_salary.Start <= 14944) && ('employee_salary.End >= 16071))
+- 'UnresolvedRelation `employee_salary`, None

== Analyzed Logical Plan ==
EmployeeId: int, Salary: double, Start: date, End: date
Filter ((Start#328 <= 14944) && (End#329 >= 16071))
+- Subquery employee_salary
   +- LogicalRDD [EmployeeId#326,Salary#327,Start#328,End#329], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Filter ((Start#328 <= 14944) && (End#329 >= 16071))
+- LogicalRDD [EmployeeId#326,Salary#327,Start#328,End#329], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
Filter ((Start#328 <= 14944) && (End#329 >= 16071))
+- Scan ExistingRDD[EmployeeId#326,Salary#327,Start#328,End#329]
17/03/27 22:25:30 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:30 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:30 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:30 INFO DAGScheduler: Final stage: ResultStage 0 (collect at QuerySuite.scala:64)
17/03/27 22:25:30 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:30 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:30 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52488 (size: 3.2 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2384 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:30 INFO GeneratePredicate: Code generated in 3.447165 ms
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2384 bytes)
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13 ms on localhost (1/5)
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 2569 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1197 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 14 ms on localhost (2/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 14 ms on localhost (3/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 2 ms on localhost (4/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 14 ms on localhost (5/5)
17/03/27 22:25:30 INFO DAGScheduler: ResultStage 0 (collect at QuerySuite.scala:64) finished in 0.015 s
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.019943 s
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:30 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:30 INFO BlockManager: BlockManager stopped
17/03/27 22:25:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:30 INFO SparkContext: Successfully stopped SparkContext
[32m- employeeSalaryHistory(EmployeeID, Salary, Start, End).[0m
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:30 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:30 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriver' on port 52505.
17/03/27 22:25:30 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:30 INFO Remoting: Starting remoting
17/03/27 22:25:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52518]
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52518.
17/03/27 22:25:30 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:30 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:30 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-2e3799f5-8bf9-4b10-959b-1d648f13e821
17/03/27 22:25:30 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:30 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:30 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52535.
17/03/27 22:25:30 INFO NettyBlockTransferService: Server created on 52535
17/03/27 22:25:30 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52535 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52535)
17/03/27 22:25:30 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:30 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667930468
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:30 INFO BigDatalogContext: BigDatalog Query: "employeeNames(FirstName, LastName)."
17/03/27 22:25:30 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:30 INFO BigDatalogContext: 
0: (FirstName, LastName) <DISTINCT PROJECT>
 1: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
17/03/27 22:25:30 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:30 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:30 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['employee.FirstName,'employee.LastName]
   +- 'UnresolvedRelation `employee`, None

== Analyzed Logical Plan ==
FirstName: string, LastName: string
Distinct
+- Project [FirstName#332,LastName#333]
   +- Subquery employee
      +- LogicalRDD [EmployeeId#330,DepartmentId#331,FirstName#332,LastName#333], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [FirstName#332,LastName#333], [FirstName#332,LastName#333]
+- Project [FirstName#332,LastName#333]
   +- LogicalRDD [EmployeeId#330,DepartmentId#331,FirstName#332,LastName#333], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[FirstName#332,LastName#333], functions=[], output=[FirstName#332,LastName#333])
+- TungstenExchange hashpartitioning(FirstName#332,LastName#333,5), None
   +- TungstenAggregate(key=[FirstName#332,LastName#333], functions=[], output=[FirstName#332,LastName#333])
      +- Project [FirstName#332,LastName#333]
         +- Scan ExistingRDD[EmployeeId#330,DepartmentId#331,FirstName#332,LastName#333]
17/03/27 22:25:30 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:30 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:30 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:30 INFO DAGScheduler: Final stage: ResultStage 1 (collect at QuerySuite.scala:64)
17/03/27 22:25:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 7.9 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.0 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52535 (size: 4.0 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:30 INFO GenerateUnsafeProjection: Code generated in 6.864541 ms
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1486 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 24 ms on localhost (1/5)
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1486 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 39 ms on localhost (2/5)
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 42 ms on localhost (3/5)
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 47 ms on localhost (4/5)
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 29 ms on localhost (5/5)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.050 s
17/03/27 22:25:30 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:30 INFO DAGScheduler: running: Set()
17/03/27 22:25:30 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:30 INFO DAGScheduler: failed: Set()
17/03/27 22:25:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.0 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52535 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1669 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1669 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 2687 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 5 ms on localhost (1/5)
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2723 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 5 ms on localhost (2/5)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 6 ms on localhost (3/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 6 ms on localhost (4/5)
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1669 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 4 ms on localhost (5/5)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: ResultStage 1 (collect at QuerySuite.scala:64) finished in 0.007 s
17/03/27 22:25:30 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.066568 s
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:30 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:30 INFO BlockManager: BlockManager stopped
17/03/27 22:25:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:30 INFO SparkContext: Successfully stopped SparkContext
[32m- employeeNames(FirstName, LastName).[0m
17/03/27 22:25:30 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:30 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:30 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriver' on port 52553.
17/03/27 22:25:30 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:30 INFO Remoting: Starting remoting
17/03/27 22:25:30 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52566]
17/03/27 22:25:30 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52566.
17/03/27 22:25:30 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:30 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:30 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-eb3c0f5d-289a-4f2d-ba6a-5fbda832b988
17/03/27 22:25:30 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:30 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:30 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52583.
17/03/27 22:25:30 INFO NettyBlockTransferService: Server created on 52583
17/03/27 22:25:30 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:30 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52583 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52583)
17/03/27 22:25:30 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:30 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667930711
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:30 INFO BigDatalogContext: BigDatalog Query: "employeeSalary(FirstName, Salary)."
17/03/27 22:25:30 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:30 INFO BigDatalogContext: 
0: (FirstName, Salary) <DISTINCT PROJECT>
 1: (0.EmployeeId = 1.EmployeeId) <JOIN>
  2: (EmployeeId, FirstName) <PROJECT>
   3: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
  2: (EmployeeId, Salary) <PROJECT>
   3: employee_salary(EmployeeId, Salary, Start, End) <BASE_RELATION>
17/03/27 22:25:30 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:30 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:30 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['employee.FirstName,'employee_salary.Salary]
   +- 'Join Inner, Some(('employee.EmployeeId = 'employee_salary.EmployeeId))
      :- 'Project ['employee.EmployeeId,'employee.FirstName]
      :  +- 'UnresolvedRelation `employee`, None
      +- 'Project ['employee_salary.EmployeeId,'employee_salary.Salary]
         +- 'UnresolvedRelation `employee_salary`, None

== Analyzed Logical Plan ==
FirstName: string, Salary: double
Distinct
+- Project [FirstName#336,Salary#339]
   +- Join Inner, Some((EmployeeId#334 = EmployeeId#338))
      :- Project [EmployeeId#334,FirstName#336]
      :  +- Subquery employee
      :     +- LogicalRDD [EmployeeId#334,DepartmentId#335,FirstName#336,LastName#337], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#338,Salary#339]
         +- Subquery employee_salary
            +- LogicalRDD [EmployeeId#338,Salary#339,Start#340,End#341], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [FirstName#336,Salary#339], [FirstName#336,Salary#339]
+- Project [FirstName#336,Salary#339]
   +- Join Inner, Some((EmployeeId#334 = EmployeeId#338))
      :- Project [EmployeeId#334,FirstName#336]
      :  +- LogicalRDD [EmployeeId#334,DepartmentId#335,FirstName#336,LastName#337], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#338,Salary#339]
         +- LogicalRDD [EmployeeId#338,Salary#339,Start#340,End#341], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[FirstName#336,Salary#339], functions=[], output=[FirstName#336,Salary#339])
+- TungstenExchange hashpartitioning(FirstName#336,Salary#339,5), None
   +- TungstenAggregate(key=[FirstName#336,Salary#339], functions=[], output=[FirstName#336,Salary#339])
      +- Project [FirstName#336,Salary#339]
         +- SortMergeJoin [EmployeeId#334], [EmployeeId#338]
            :- Sort [EmployeeId#334 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(EmployeeId#334,5), None
            :     +- Project [EmployeeId#334,FirstName#336]
            :        +- Scan ExistingRDD[EmployeeId#334,DepartmentId#335,FirstName#336,LastName#337] 
            +- Sort [EmployeeId#338 ASC], false, 0
               +- TungstenExchange hashpartitioning(EmployeeId#338,5), None
                  +- Project [EmployeeId#338,Salary#339]
                     +- Scan ExistingRDD[EmployeeId#338,Salary#339,Start#340,End#341]
17/03/27 22:25:30 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:30 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:30 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO DAGScheduler: Registering RDD 7 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:30 INFO DAGScheduler: Final stage: ResultStage 3 (collect at QuerySuite.scala:64)
17/03/27 22:25:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:25:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:25:30 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52583 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:30 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52583 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:30 INFO GenerateUnsafeProjection: Code generated in 6.498693 ms
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 28 ms on localhost (1/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 27 ms on localhost (2/5)
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2373 bytes)
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 5 ms on localhost (1/5)
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2373 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 23 ms on localhost (3/5)
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 8 ms on localhost (2/5)
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 48 ms on localhost (4/5)
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.052 s
17/03/27 22:25:30 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:30 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/03/27 22:25:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:30 INFO DAGScheduler: failed: Set()
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 50 ms on localhost (5/5)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 17 ms on localhost (3/5)
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1367 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 14 ms on localhost (4/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 41 ms on localhost (5/5)
17/03/27 22:25:30 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.056 s
17/03/27 22:25:30 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:30 INFO DAGScheduler: running: Set()
17/03/27 22:25:30 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:30 INFO DAGScheduler: failed: Set()
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 12.5 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52583 (size: 5.9 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:30 INFO GenerateUnsafeProjection: Code generated in 4.189412 ms
17/03/27 22:25:30 INFO GenerateUnsafeProjection: Code generated in 2.648443 ms
17/03/27 22:25:30 INFO GenerateMutableProjection: Code generated in 2.775667 ms
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2098 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 24 ms on localhost (1/5)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 2098 bytes result sent to driver
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 31 ms on localhost (2/5)
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2098 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 11 ms on localhost (3/5)
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2098 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 36 ms on localhost (4/5)
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2098 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 75 ms on localhost (5/5)
17/03/27 22:25:30 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.075 s
17/03/27 22:25:30 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:30 INFO DAGScheduler: running: Set()
17/03/27 22:25:30 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/27 22:25:30 INFO DAGScheduler: failed: Set()
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.4 KB, free 2.0 GB)
17/03/27 22:25:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2.0 GB)
17/03/27 22:25:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52583 (size: 5.3 KB, free: 2.0 GB)
17/03/27 22:25:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:30 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:30 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:30 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 2056 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:30 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 3194 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 2056 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:30 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 3193 bytes result sent to driver
17/03/27 22:25:30 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:30 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 2056 bytes result sent to driver
17/03/27 22:25:30 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 9 ms on localhost (1/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 10 ms on localhost (2/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 12 ms on localhost (3/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 11 ms on localhost (4/5)
17/03/27 22:25:30 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 6 ms on localhost (5/5)
17/03/27 22:25:30 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:30 INFO DAGScheduler: ResultStage 3 (collect at QuerySuite.scala:64) finished in 0.013 s
17/03/27 22:25:30 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.160745 s
17/03/27 22:25:30 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:31 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:31 INFO BlockManager: BlockManager stopped
17/03/27 22:25:31 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:31 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:31 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:31 INFO SecurityManager: Changing view acls to: Mike
[32m- employeeSalary(FirstName, Salary).[0m
17/03/27 22:25:31 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:31 INFO Utils: Successfully started service 'sparkDriver' on port 52600.
17/03/27 22:25:31 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:31 INFO Remoting: Starting remoting
17/03/27 22:25:31 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52613.
17/03/27 22:25:31 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:31 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:31 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-24709d3e-6627-4e97-bd33-08645f6e9a63
17/03/27 22:25:31 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52613]
17/03/27 22:25:31 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52630.
17/03/27 22:25:31 INFO NettyBlockTransferService: Server created on 52630
17/03/27 22:25:31 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52630 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52630)
17/03/27 22:25:31 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:31 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667931120
17/03/27 22:25:31 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:31 INFO BigDatalogContext: BigDatalog Query: "highEarners(FirstName, LastName, Salary)."
17/03/27 22:25:31 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:31 INFO BigDatalogContext: 
0: (FirstName, LastName, Salary) <DISTINCT PROJECT>
 1: (0.EmployeeId = 1.EmployeeId) <JOIN>
  2: (EmployeeId, FirstName, LastName) <PROJECT>
   3: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
  2: (EmployeeId, Salary) <PROJECT>
   3: Salary > 50000.0 <FILTER>
    4: employee_salary(EmployeeId, Salary, Start, End) <BASE_RELATION>
17/03/27 22:25:31 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:31 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:31 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['employee.FirstName,'employee.LastName,'employee_salary.Salary]
   +- 'Join Inner, Some(('employee.EmployeeId = 'employee_salary.EmployeeId))
      :- 'Project ['employee.EmployeeId,'employee.FirstName,'employee.LastName]
      :  +- 'UnresolvedRelation `employee`, None
      +- 'Project ['employee_salary.EmployeeId,'employee_salary.Salary]
         +- 'Filter ('employee_salary.Salary > 50000.0)
            +- 'UnresolvedRelation `employee_salary`, None

== Analyzed Logical Plan ==
FirstName: string, LastName: string, Salary: double
Distinct
+- Project [FirstName#344,LastName#345,Salary#347]
   +- Join Inner, Some((EmployeeId#342 = EmployeeId#346))
      :- Project [EmployeeId#342,FirstName#344,LastName#345]
      :  +- Subquery employee
      :     +- LogicalRDD [EmployeeId#342,DepartmentId#343,FirstName#344,LastName#345], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#346,Salary#347]
         +- Filter (Salary#347 > 50000.0)
            +- Subquery employee_salary
               +- LogicalRDD [EmployeeId#346,Salary#347,Start#348,End#349], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [FirstName#344,LastName#345,Salary#347], [FirstName#344,LastName#345,Salary#347]
+- Project [FirstName#344,LastName#345,Salary#347]
   +- Join Inner, Some((EmployeeId#342 = EmployeeId#346))
      :- Project [EmployeeId#342,FirstName#344,LastName#345]
      :  +- LogicalRDD [EmployeeId#342,DepartmentId#343,FirstName#344,LastName#345], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#346,Salary#347]
         +- Filter (Salary#347 > 50000.0)
            +- LogicalRDD [EmployeeId#346,Salary#347,Start#348,End#349], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[FirstName#344,LastName#345,Salary#347], functions=[], output=[FirstName#344,LastName#345,Salary#347])
+- TungstenExchange hashpartitioning(FirstName#344,LastName#345,Salary#347,5), None
   +- TungstenAggregate(key=[FirstName#344,LastName#345,Salary#347], functions=[], output=[FirstName#344,LastName#345,Salary#347])
      +- Project [FirstName#344,LastName#345,Salary#347]
         +- SortMergeJoin [EmployeeId#342], [EmployeeId#346]
            :- Sort [EmployeeId#342 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(EmployeeId#342,5), None
            :     +- Project [EmployeeId#342,FirstName#344,LastName#345]
            :        +- Scan ExistingRDD[EmployeeId#342,DepartmentId#343,FirstName#344,LastName#345] 
            +- Sort [EmployeeId#346 ASC], false, 0
               +- TungstenExchange hashpartitioning(EmployeeId#346,5), None
                  +- Project [EmployeeId#346,Salary#347]
                     +- Filter (Salary#347 > 50000.0)
                        +- Scan ExistingRDD[EmployeeId#346,Salary#347,Start#348,End#349]
17/03/27 22:25:31 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:31 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 14 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:31 INFO DAGScheduler: Final stage: ResultStage 3 (collect at QuerySuite.scala:64)
17/03/27 22:25:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:25:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52630 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.0 KB, free 2.0 GB)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.8 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52630 (size: 3.8 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 4.450377 ms
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 20 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 32 ms on localhost (2/5)
17/03/27 22:25:31 INFO GeneratePredicate: Code generated in 15.696098 ms
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1400 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1400 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2373 bytes)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 68 ms on localhost (3/5)
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2373 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 59 ms on localhost (4/5)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1400 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 15 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1400 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 9 ms on localhost (2/5)
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 78 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.079 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 60 ms on localhost (3/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 35 ms on localhost (4/5)
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1400 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 19 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.089 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set()
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.2 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.2 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52630 (size: 6.2 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.311252 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.045942 ms
17/03/27 22:25:31 INFO GenerateMutableProjection: Code generated in 3.203576 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.201094 ms
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 2184 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 20 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2184 bytes result sent to driver
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 22 ms on localhost (2/5)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2184 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 27 ms on localhost (3/5)
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2184 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 7 ms on localhost (4/5)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2184 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 44 ms on localhost (5/5)
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.045 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set()
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.1 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52630 (size: 5.6 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 2142 bytes result sent to driver
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 2142 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 2142 bytes result sent to driver
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 4 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 4 ms on localhost (2/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 4 ms on localhost (3/5)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 2142 bytes result sent to driver
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 3322 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 3 ms on localhost (4/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 6 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: ResultStage 3 (collect at QuerySuite.scala:64) finished in 0.006 s
17/03/27 22:25:31 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.152427 s
17/03/27 22:25:31 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:31 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:31 INFO BlockManager: BlockManager stopped
17/03/27 22:25:31 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:31 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:31 INFO SparkContext: Running Spark version 1.6.3
[32m- highEarners(FirstName, LastName, Salary).[0m
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:31 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:31 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:31 INFO Utils: Successfully started service 'sparkDriver' on port 52648.
17/03/27 22:25:31 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:31 INFO Remoting: Starting remoting
17/03/27 22:25:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52661]
17/03/27 22:25:31 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52661.
17/03/27 22:25:31 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:31 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:31 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-8862c580-c5dd-4380-9947-1cb2f2be84c4
17/03/27 22:25:31 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:31 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52678.
17/03/27 22:25:31 INFO NettyBlockTransferService: Server created on 52678
17/03/27 22:25:31 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52678 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52678)
17/03/27 22:25:31 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:31 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667931498
17/03/27 22:25:31 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:31 INFO BigDatalogContext: BigDatalog Query: "employeeAddressDepartment(EmployeeId, DepartmentId, FirstName, LastName, Street, City, State, Zip, DepartmentName)."
17/03/27 22:25:31 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:31 INFO BigDatalogContext: 
0: (EmployeeId, DepartmentId, FirstName, LastName, Street, City, State, Zip, DepartmentName) <DISTINCT PROJECT>
 1: (0.EmployeeId = 1.EmployeeId, 0.DepartmentId = 2.DepartmentId) <JOIN>
  2: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
  2: address(EmployeeId, Street, City, State, Zip) <BASE_RELATION>
  2: department(DepartmentId, DepartmentName) <BASE_RELATION>
17/03/27 22:25:31 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:31 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:31 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['employee.EmployeeId,'employee.DepartmentId,'employee.FirstName,'employee.LastName,'address.Street,'address.City,'address.State,'address.Zip,'department.DepartmentName]
   +- 'Join Inner, Some(('employee.DepartmentId = 'department.DepartmentId))
      :- 'Join Inner, Some(('employee.EmployeeId = 'address.EmployeeId))
      :  :- 'UnresolvedRelation `employee`, None
      :  +- 'UnresolvedRelation `address`, None
      +- 'UnresolvedRelation `department`, None

== Analyzed Logical Plan ==
EmployeeId: int, DepartmentId: int, FirstName: string, LastName: string, Street: string, City: string, State: string, Zip: int, DepartmentName: string
Distinct
+- Project [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355]
   +- Join Inner, Some((DepartmentId#351 = DepartmentId#354))
      :- Join Inner, Some((EmployeeId#350 = EmployeeId#356))
      :  :- Subquery employee
      :  :  +- LogicalRDD [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :  +- Subquery address
      :     +- LogicalRDD [EmployeeId#356,Street#357,City#358,State#359,Zip#360], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168
      +- Subquery department
         +- LogicalRDD [DepartmentId#354,DepartmentName#355], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355], [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355]
+- Project [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355]
   +- Join Inner, Some((DepartmentId#351 = DepartmentId#354))
      :- Project [City#358,FirstName#352,LastName#353,Zip#360,EmployeeId#350,Street#357,State#359,DepartmentId#351]
      :  +- Join Inner, Some((EmployeeId#350 = EmployeeId#356))
      :     :- LogicalRDD [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     +- LogicalRDD [EmployeeId#356,Street#357,City#358,State#359,Zip#360], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168
      +- LogicalRDD [DepartmentId#354,DepartmentName#355], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355], functions=[], output=[EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355])
+- TungstenAggregate(key=[EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355], functions=[], output=[EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355])
   +- Project [EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353,Street#357,City#358,State#359,Zip#360,DepartmentName#355]
      +- SortMergeJoin [DepartmentId#351], [DepartmentId#354]
         :- Sort [DepartmentId#351 ASC], false, 0
         :  +- TungstenExchange hashpartitioning(DepartmentId#351,5), None
         :     +- Project [City#358,FirstName#352,LastName#353,Zip#360,EmployeeId#350,Street#357,State#359,DepartmentId#351]
         :        +- SortMergeJoin [EmployeeId#350], [EmployeeId#356]
         :           :- Sort [EmployeeId#350 ASC], false, 0
         :           :  +- TungstenExchange hashpartitioning(EmployeeId#350,5), None
         :           :     +- ConvertToUnsafe
         :           :        +- Scan ExistingRDD[EmployeeId#350,DepartmentId#351,FirstName#352,LastName#353] 
         :           +- Sort [EmployeeId#356 ASC], false, 0
         :              +- TungstenExchange hashpartitioning(EmployeeId#356,5), None
         :                 +- ConvertToUnsafe
         :                    +- Scan ExistingRDD[EmployeeId#356,Street#357,City#358,State#359,Zip#360] 
         +- Sort [DepartmentId#354 ASC], false, 0
            +- TungstenExchange hashpartitioning(DepartmentId#354,5), None
               +- ConvertToUnsafe
                  +- Scan ExistingRDD[DepartmentId#354,DepartmentName#355]
17/03/27 22:25:31 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:31 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 4 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:31 INFO DAGScheduler: Final stage: ResultStage 4 (collect at QuerySuite.scala:64)
17/03/27 22:25:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 3)
17/03/27 22:25:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 3)
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52678 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2371 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2374 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52678 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52678 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.815186 ms
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2366 bytes)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 37 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 6.831028 ms
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 49 ms on localhost (2/5)
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 37 ms on localhost (3/5)
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 5 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 14 ms on localhost (2/5)
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 18 ms on localhost (3/5)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2428 bytes)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 20 ms on localhost (4/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 82 ms on localhost (4/5)
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 13.825277 ms
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 84 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.086 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 2)
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 46 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.084 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2427 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 6 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 18 ms on localhost (2/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 22 ms on localhost (3/5)
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 12 ms on localhost (4/5)
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1222 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 38 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.099 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set()
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, ResultStage 4)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.8 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.4 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52678 (size: 5.4 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.661275 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.261294 ms
17/03/27 22:25:31 INFO GenerateMutableProjection: Code generated in 2.256219 ms
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1840 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 22 ms on localhost (1/5)
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1840 bytes result sent to driver
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 22 ms on localhost (2/5)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 1840 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 7 ms on localhost (3/5)
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1840 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 39 ms on localhost (4/5)
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1840 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 41 ms on localhost (5/5)
17/03/27 22:25:31 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.041 s
17/03/27 22:25:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:31 INFO DAGScheduler: running: Set()
17/03/27 22:25:31 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/03/27 22:25:31 INFO DAGScheduler: failed: Set()
17/03/27 22:25:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.2 KB, free 2.0 GB)
17/03/27 22:25:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.6 KB, free 2.0 GB)
17/03/27 22:25:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:52678 (size: 6.6 KB, free: 2.0 GB)
17/03/27 22:25:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:31 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:31 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:31 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:31 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:31 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO GenerateOrdering: Code generated in 3.590836 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 2.27763 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 2.234808 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 4.403521 ms
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.528155 ms
17/03/27 22:25:31 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 2323 bytes result sent to driver
17/03/27 22:25:31 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2323 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:31 INFO GenerateUnsafeProjection: Code generated in 3.782914 ms
17/03/27 22:25:31 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2323 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 35 ms on localhost (1/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 36 ms on localhost (2/5)
17/03/27 22:25:31 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:31 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 2323 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 36 ms on localhost (3/5)
17/03/27 22:25:31 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 10 ms on localhost (4/5)
17/03/27 22:25:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 3867 bytes result sent to driver
17/03/27 22:25:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 49 ms on localhost (5/5)
17/03/27 22:25:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:31 INFO DAGScheduler: ResultStage 4 (collect at QuerySuite.scala:64) finished in 0.049 s
17/03/27 22:25:31 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.208717 s
17/03/27 22:25:31 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:31 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:31 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:31 INFO BlockManager: BlockManager stopped
17/03/27 22:25:31 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:31 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:31 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:31 INFO SparkContext: Running Spark version 1.6.3
[32m- employeeAddressDepartment(EmployeeId, DepartmentId, FirstName, LastName, Street, City, State, Zip, DepartmentName).[0m
17/03/27 22:25:31 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:31 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:31 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:31 INFO Utils: Successfully started service 'sparkDriver' on port 52696.
17/03/27 22:25:31 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:31 INFO Remoting: Starting remoting
17/03/27 22:25:31 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52709]
17/03/27 22:25:31 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52709.
17/03/27 22:25:31 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:31 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:31 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-8e0395a0-f73b-40b6-9d6c-f769bb59de4e
17/03/27 22:25:31 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:31 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:31 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:31 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52726.
17/03/27 22:25:31 INFO NettyBlockTransferService: Server created on 52726
17/03/27 22:25:31 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:31 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52726 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52726)
17/03/27 22:25:31 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:32 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667931966
17/03/27 22:25:32 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:32 INFO BigDatalogContext: BigDatalog Query: "employeeSalaryAddition(FirstName, LastName, AdjustedSalary)."
17/03/27 22:25:32 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:32 INFO BigDatalogContext: 
0: (FirstName, LastName, Salary + 5000.0 as AdjustedSalary) <DISTINCT PROJECT>
 1: (0.EmployeeId = 1.EmployeeId) <JOIN>
  2: (EmployeeId, FirstName, LastName) <PROJECT>
   3: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
  2: (EmployeeId, Salary) <PROJECT>
   3: employee_salary(EmployeeId, Salary, Start, End) <BASE_RELATION>
17/03/27 22:25:32 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:32 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:32 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['employee.FirstName,'employee.LastName,unresolvedalias(('employee_salary.Salary + 5000.0) AS AdjustedSalary#369)]
   +- 'Join Inner, Some(('employee.EmployeeId = 'employee_salary.EmployeeId))
      :- 'Project ['employee.EmployeeId,'employee.FirstName,'employee.LastName]
      :  +- 'UnresolvedRelation `employee`, None
      +- 'Project ['employee_salary.EmployeeId,'employee_salary.Salary]
         +- 'UnresolvedRelation `employee_salary`, None

== Analyzed Logical Plan ==
FirstName: string, LastName: string, AdjustedSalary: double
Distinct
+- Project [FirstName#363,LastName#364,(Salary#366 + 5000.0) AS AdjustedSalary#369]
   +- Join Inner, Some((EmployeeId#361 = EmployeeId#365))
      :- Project [EmployeeId#361,FirstName#363,LastName#364]
      :  +- Subquery employee
      :     +- LogicalRDD [EmployeeId#361,DepartmentId#362,FirstName#363,LastName#364], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#365,Salary#366]
         +- Subquery employee_salary
            +- LogicalRDD [EmployeeId#365,Salary#366,Start#367,End#368], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [FirstName#363,LastName#364,AdjustedSalary#369], [FirstName#363,LastName#364,AdjustedSalary#369]
+- Project [FirstName#363,LastName#364,(Salary#366 + 5000.0) AS AdjustedSalary#369]
   +- Join Inner, Some((EmployeeId#361 = EmployeeId#365))
      :- Project [EmployeeId#361,FirstName#363,LastName#364]
      :  +- LogicalRDD [EmployeeId#361,DepartmentId#362,FirstName#363,LastName#364], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#365,Salary#366]
         +- LogicalRDD [EmployeeId#365,Salary#366,Start#367,End#368], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[FirstName#363,LastName#364,AdjustedSalary#369], functions=[], output=[FirstName#363,LastName#364,AdjustedSalary#369])
+- TungstenExchange hashpartitioning(FirstName#363,LastName#364,AdjustedSalary#369,5), None
   +- TungstenAggregate(key=[FirstName#363,LastName#364,AdjustedSalary#369], functions=[], output=[FirstName#363,LastName#364,AdjustedSalary#369])
      +- Project [FirstName#363,LastName#364,(Salary#366 + 5000.0) AS AdjustedSalary#369]
         +- SortMergeJoin [EmployeeId#361], [EmployeeId#365]
            :- Sort [EmployeeId#361 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(EmployeeId#361,5), None
            :     +- Project [EmployeeId#361,FirstName#363,LastName#364]
            :        +- Scan ExistingRDD[EmployeeId#361,DepartmentId#362,FirstName#363,LastName#364] 
            +- Sort [EmployeeId#365 ASC], false, 0
               +- TungstenExchange hashpartitioning(EmployeeId#365,5), None
                  +- Project [EmployeeId#365,Salary#366]
                     +- Scan ExistingRDD[EmployeeId#365,Salary#366,Start#367,End#368]
17/03/27 22:25:32 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:32 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 7 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:32 INFO DAGScheduler: Final stage: ResultStage 3 (collect at QuerySuite.scala:64)
17/03/27 22:25:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:25:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52726 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52726 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2373 bytes)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2373 bytes)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 59 ms on localhost (1/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 60 ms on localhost (2/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 60 ms on localhost (3/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 52 ms on localhost (4/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 31 ms on localhost (1/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 26 ms on localhost (2/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 38 ms on localhost (3/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 69 ms on localhost (5/5)
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.070 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 59 ms on localhost (4/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 54 ms on localhost (5/5)
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.070 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set()
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.2 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52726 (size: 6.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO GenerateUnsafeProjection: Code generated in 8.849865 ms
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 2098 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 23 ms on localhost (1/5)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2098 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 8 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2098 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 41 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2098 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 46 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2098 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 51 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.051 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set()
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[16] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.1 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.7 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52726 (size: 5.7 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[16] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 3243 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 2056 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 2056 bytes result sent to driver
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 8 ms on localhost (1/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 8 ms on localhost (2/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 9 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 3244 bytes result sent to driver
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 11 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 2056 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 5 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO DAGScheduler: ResultStage 3 (collect at QuerySuite.scala:64) finished in 0.012 s
17/03/27 22:25:32 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.146694 s
17/03/27 22:25:32 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:32 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:32 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:32 INFO BlockManager: BlockManager stopped
17/03/27 22:25:32 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:32 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:32 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:32 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:32 INFO SparkContext: Successfully stopped SparkContext
[32m- employeeSalaryAddition(FirstName, LastName, AdjustedSalary).[0m
17/03/27 22:25:32 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:32 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:32 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:32 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:32 INFO Utils: Successfully started service 'sparkDriver' on port 52743.
17/03/27 22:25:32 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:32 INFO Remoting: Starting remoting
17/03/27 22:25:32 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52756]
17/03/27 22:25:32 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52756.
17/03/27 22:25:32 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:32 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:32 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-042d51b9-ca31-4e94-986e-5f4cfe630977
17/03/27 22:25:32 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:32 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:32 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:32 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52774.
17/03/27 22:25:32 INFO NettyBlockTransferService: Server created on 52774
17/03/27 22:25:32 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:32 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52774 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52774)
17/03/27 22:25:32 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:32 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667932391
17/03/27 22:25:32 INFO RelationalQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:32 INFO BigDatalogContext: BigDatalog Query: "westCoastEmployees(EmployeeID, FirstName, LastName)."
17/03/27 22:25:32 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:32 INFO BigDatalogContext: 
0: westCoastEmployees(EmployeeId, FirstName, LastName) <UNION>
 1: (EmployeeId, FirstName, LastName) <PROJECT>
  2: (0.EmployeeId = 1.EmployeeId) <JOIN>
   3: (EmployeeId, FirstName, LastName) <PROJECT>
    4: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
   3: (EmployeeId) <PROJECT>
    4: State = 'AZ' <FILTER>
     5: address(EmployeeId, Street, City, State, Zip) <BASE_RELATION>
 1: (EmployeeId, FirstName, LastName) <PROJECT>
  2: (0.EmployeeId = 1.EmployeeId) <JOIN>
   3: (EmployeeId, FirstName, LastName) <PROJECT>
    4: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
   3: (EmployeeId) <PROJECT>
    4: State = 'CA' <FILTER>
     5: address(EmployeeId, Street, City, State, Zip) <BASE_RELATION>
 1: (EmployeeId, FirstName, LastName) <PROJECT>
  2: (0.EmployeeId = 1.EmployeeId) <JOIN>
   3: (EmployeeId, FirstName, LastName) <PROJECT>
    4: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
   3: (EmployeeId) <PROJECT>
    4: State = 'ID' <FILTER>
     5: address(EmployeeId, Street, City, State, Zip) <BASE_RELATION>
 1: (EmployeeId, FirstName, LastName) <PROJECT>
  2: (0.EmployeeId = 1.EmployeeId) <JOIN>
   3: (EmployeeId, FirstName, LastName) <PROJECT>
    4: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
   3: (EmployeeId) <PROJECT>
    4: State = 'NV' <FILTER>
     5: address(EmployeeId, Street, City, State, Zip) <BASE_RELATION>
17/03/27 22:25:32 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:32 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:32 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Subquery westCoastEmployees7
   +- 'Union
      :- 'Subquery westCoastEmployees7
      :  +- 'Union
      :     :- 'Subquery westCoastEmployees
      :     :  +- 'Union
      :     :     :- 'Project ['employee.EmployeeId,'employee.FirstName,'employee.LastName]
      :     :     :  +- 'Join Inner, Some(('employee.EmployeeId = 'address.EmployeeId))
      :     :     :     :- 'Project ['employee.EmployeeId,'employee.FirstName,'employee.LastName]
      :     :     :     :  +- 'UnresolvedRelation `employee`, None
      :     :     :     +- 'Project ['address.EmployeeId]
      :     :     :        +- 'Filter ('address.State = AZ)
      :     :     :           +- 'UnresolvedRelation `address`, None
      :     :     +- 'Project ['employee1.EmployeeId,'employee1.FirstName,'employee1.LastName]
      :     :        +- 'Join Inner, Some(('employee1.EmployeeId = 'address2.EmployeeId))
      :     :           :- 'Project ['employee1.EmployeeId,'employee1.FirstName,'employee1.LastName]
      :     :           :  +- 'Subquery employee1
      :     :           :     +- 'Project [*]
      :     :           :        +- 'UnresolvedRelation `employee`, None
      :     :           +- 'Project ['address2.EmployeeId]
      :     :              +- 'Filter ('address2.State = CA)
      :     :                 +- 'Subquery address2
      :     :                    +- 'Project [*]
      :     :                       +- 'UnresolvedRelation `address`, None
      :     +- 'Project ['employee3.EmployeeId,'employee3.FirstName,'employee3.LastName]
      :        +- 'Join Inner, Some(('employee3.EmployeeId = 'address4.EmployeeId))
      :           :- 'Project ['employee3.EmployeeId,'employee3.FirstName,'employee3.LastName]
      :           :  +- 'Subquery employee3
      :           :     +- 'Project [*]
      :           :        +- 'UnresolvedRelation `employee`, None
      :           +- 'Project ['address4.EmployeeId]
      :              +- 'Filter ('address4.State = ID)
      :                 +- 'Subquery address4
      :                    +- 'Project [*]
      :                       +- 'UnresolvedRelation `address`, None
      +- 'Project ['employee5.EmployeeId,'employee5.FirstName,'employee5.LastName]
         +- 'Join Inner, Some(('employee5.EmployeeId = 'address6.EmployeeId))
            :- 'Project ['employee5.EmployeeId,'employee5.FirstName,'employee5.LastName]
            :  +- 'Subquery employee5
            :     +- 'Project [*]
            :        +- 'UnresolvedRelation `employee`, None
            +- 'Project ['address6.EmployeeId]
               +- 'Filter ('address6.State = NV)
                  +- 'Subquery address6
                     +- 'Project [*]
                        +- 'UnresolvedRelation `address`, None

== Analyzed Logical Plan ==
EmployeeId: int, FirstName: string, LastName: string
Distinct
+- Subquery westCoastEmployees7
   +- Union
      :- Subquery westCoastEmployees7
      :  +- Union
      :     :- Subquery westCoastEmployees
      :     :  +- Union
      :     :     :- Project [EmployeeId#370,FirstName#372,LastName#373]
      :     :     :  +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
      :     :     :     :- Project [EmployeeId#370,FirstName#372,LastName#373]
      :     :     :     :  +- Subquery employee
      :     :     :     :     +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     :     :     +- Project [EmployeeId#374]
      :     :     :        +- Filter (State#377 = AZ)
      :     :     :           +- Subquery address
      :     :     :              +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
      :     :     +- Project [EmployeeId#370,FirstName#372,LastName#373]
      :     :        +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
      :     :           :- Project [EmployeeId#370,FirstName#372,LastName#373]
      :     :           :  +- Subquery employee1
      :     :           :     +- Project [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373]
      :     :           :        +- Subquery employee
      :     :           :           +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     :           +- Project [EmployeeId#374]
      :     :              +- Filter (State#377 = CA)
      :     :                 +- Subquery address2
      :     :                    +- Project [EmployeeId#374,Street#375,City#376,State#377,Zip#378]
      :     :                       +- Subquery address
      :     :                          +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
      :     +- Project [EmployeeId#370,FirstName#372,LastName#373]
      :        +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
      :           :- Project [EmployeeId#370,FirstName#372,LastName#373]
      :           :  +- Subquery employee3
      :           :     +- Project [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373]
      :           :        +- Subquery employee
      :           :           +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :           +- Project [EmployeeId#374]
      :              +- Filter (State#377 = ID)
      :                 +- Subquery address4
      :                    +- Project [EmployeeId#374,Street#375,City#376,State#377,Zip#378]
      :                       +- Subquery address
      :                          +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
      +- Project [EmployeeId#370,FirstName#372,LastName#373]
         +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
            :- Project [EmployeeId#370,FirstName#372,LastName#373]
            :  +- Subquery employee5
            :     +- Project [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373]
            :        +- Subquery employee
            :           +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
            +- Project [EmployeeId#374]
               +- Filter (State#377 = NV)
                  +- Subquery address6
                     +- Project [EmployeeId#374,Street#375,City#376,State#377,Zip#378]
                        +- Subquery address
                           +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [EmployeeId#370,FirstName#372,LastName#373], [EmployeeId#370,FirstName#372,LastName#373]
+- Union
   :- Union
   :  :- Union
   :  :  :- Project [EmployeeId#370,FirstName#372,LastName#373]
   :  :  :  +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
   :  :  :     :- Project [EmployeeId#370,FirstName#372,LastName#373]
   :  :  :     :  +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :  :  :     +- Project [EmployeeId#374]
   :  :  :        +- Filter (State#377 = AZ)
   :  :  :           +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
   :  :  +- Project [EmployeeId#370,FirstName#372,LastName#373]
   :  :     +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
   :  :        :- Project [EmployeeId#370,FirstName#372,LastName#373]
   :  :        :  +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :  :        +- Project [EmployeeId#374]
   :  :           +- Filter (State#377 = CA)
   :  :              +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
   :  +- Project [EmployeeId#370,FirstName#372,LastName#373]
   :     +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
   :        :- Project [EmployeeId#370,FirstName#372,LastName#373]
   :        :  +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :        +- Project [EmployeeId#374]
   :           +- Filter (State#377 = ID)
   :              +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
   +- Project [EmployeeId#370,FirstName#372,LastName#373]
      +- Join Inner, Some((EmployeeId#370 = EmployeeId#374))
         :- Project [EmployeeId#370,FirstName#372,LastName#373]
         :  +- LogicalRDD [EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [EmployeeId#374]
            +- Filter (State#377 = NV)
               +- LogicalRDD [EmployeeId#374,Street#375,City#376,State#377,Zip#378], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[EmployeeId#370,FirstName#372,LastName#373], functions=[], output=[EmployeeId#370,FirstName#372,LastName#373])
+- TungstenExchange hashpartitioning(EmployeeId#370,FirstName#372,LastName#373,5), None
   +- TungstenAggregate(key=[EmployeeId#370,FirstName#372,LastName#373], functions=[], output=[EmployeeId#370,FirstName#372,LastName#373])
      +- Union
         :- Project [EmployeeId#370,FirstName#372,LastName#373]
         :  +- SortMergeJoin [EmployeeId#370], [EmployeeId#374]
         :     :- Sort [EmployeeId#370 ASC], false, 0
         :     :  +- TungstenExchange hashpartitioning(EmployeeId#370,5), None
         :     :     +- Project [EmployeeId#370,FirstName#372,LastName#373]
         :     :        +- Scan ExistingRDD[EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373] 
         :     +- Sort [EmployeeId#374 ASC], false, 0
         :        +- TungstenExchange hashpartitioning(EmployeeId#374,5), None
         :           +- Project [EmployeeId#374]
         :              +- Filter (State#377 = AZ)
         :                 +- Scan ExistingRDD[EmployeeId#374,Street#375,City#376,State#377,Zip#378] 
         :- Project [EmployeeId#370,FirstName#372,LastName#373]
         :  +- SortMergeJoin [EmployeeId#370], [EmployeeId#374]
         :     :- Sort [EmployeeId#370 ASC], false, 0
         :     :  +- TungstenExchange hashpartitioning(EmployeeId#370,5), None
         :     :     +- Project [EmployeeId#370,FirstName#372,LastName#373]
         :     :        +- Scan ExistingRDD[EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373] 
         :     +- Sort [EmployeeId#374 ASC], false, 0
         :        +- TungstenExchange hashpartitioning(EmployeeId#374,5), None
         :           +- Project [EmployeeId#374]
         :              +- Filter (State#377 = CA)
         :                 +- Scan ExistingRDD[EmployeeId#374,Street#375,City#376,State#377,Zip#378] 
         :- Project [EmployeeId#370,FirstName#372,LastName#373]
         :  +- SortMergeJoin [EmployeeId#370], [EmployeeId#374]
         :     :- Sort [EmployeeId#370 ASC], false, 0
         :     :  +- TungstenExchange hashpartitioning(EmployeeId#370,5), None
         :     :     +- Project [EmployeeId#370,FirstName#372,LastName#373]
         :     :        +- Scan ExistingRDD[EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373] 
         :     +- Sort [EmployeeId#374 ASC], false, 0
         :        +- TungstenExchange hashpartitioning(EmployeeId#374,5), None
         :           +- Project [EmployeeId#374]
         :              +- Filter (State#377 = ID)
         :                 +- Scan ExistingRDD[EmployeeId#374,Street#375,City#376,State#377,Zip#378] 
         +- Project [EmployeeId#370,FirstName#372,LastName#373]
            +- SortMergeJoin [EmployeeId#370], [EmployeeId#374]
               :- Sort [EmployeeId#370 ASC], false, 0
               :  +- TungstenExchange hashpartitioning(EmployeeId#370,5), None
               :     +- Project [EmployeeId#370,FirstName#372,LastName#373]
               :        +- Scan ExistingRDD[EmployeeId#370,DepartmentId#371,FirstName#372,LastName#373] 
               +- Sort [EmployeeId#374 ASC], false, 0
                  +- TungstenExchange hashpartitioning(EmployeeId#374,5), None
                     +- Project [EmployeeId#374]
                        +- Filter (State#377 = NV)
                           +- Scan ExistingRDD[EmployeeId#374,Street#375,City#376,State#377,Zip#378]
17/03/27 22:25:32 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:32 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 14 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 19 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 25 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 30 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 36 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 41 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Registering RDD 48 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:32 INFO DAGScheduler: Final stage: ResultStage 9 (collect at QuerySuite.scala:64)
17/03/27 22:25:32 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52774 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52774 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[14] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52774 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[14] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52774 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[25] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:52774 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[25] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 6.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:52774 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[36] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:52774 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[36] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[41] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 6.9 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:52774 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[41] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 21 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:32 INFO GeneratePredicate: Code generated in 9.162651 ms
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 40 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2428 bytes)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 10 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2427 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 66 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 69 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 16 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 21 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 16 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 65 ms on localhost (4/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 82 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.096 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 7, ShuffleMapStage 4)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 30 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 44 ms on localhost (5/5)
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.108 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 3, ShuffleMapStage 7, ShuffleMapStage 4)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 16 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2428 bytes)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 57 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 10 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2427 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 9 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 45 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 11 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 8 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 45 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 21 ms on localhost (2/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 23 ms on localhost (3/5)
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.170 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 26, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 25 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 27, localhost, partition 2,PROCESS_LOCAL, 2428 bytes)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 5.0 (TID 26)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 5.0 (TID 26). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 40 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 28, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, localhost, partition 4,PROCESS_LOCAL, 2427 bytes)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 5.0 (TID 27)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 26) in 24 ms on localhost (1/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 43 ms on localhost (2/5)
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.207 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 7)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 5.0 (TID 28)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 5.0 (TID 29)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 5.0 (TID 28). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 28) in 34 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 5.0 (TID 27). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 32, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 27) in 42 ms on localhost (4/5)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 163 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 6.0 (TID 32)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 6.0 (TID 31)
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.244 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 6, ShuffleMapStage 7)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 5.0 (TID 29). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 33, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 29) in 47 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 5 (rdd at BigDatalogProgram.scala:41) finished in 0.248 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 6, ShuffleMapStage 7)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 6.0 (TID 33)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 6.0 (TID 31). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 34, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 31) in 18 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 6.0 (TID 34)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 6.0 (TID 33). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 35, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 7.0 (TID 35)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 33) in 11 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 6.0 (TID 32). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 36, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 32) in 24 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 7.0 (TID 36)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 7.0 (TID 35). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 37, localhost, partition 2,PROCESS_LOCAL, 2428 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 35) in 4 ms on localhost (1/5)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 7.0 (TID 37)
17/03/27 22:25:32 INFO Executor: Finished task 1.0 in stage 7.0 (TID 36). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 38, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 36) in 4 ms on localhost (2/5)
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 7.0 (TID 38)
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 7.0 (TID 37). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 39, localhost, partition 4,PROCESS_LOCAL, 2427 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 37) in 4 ms on localhost (3/5)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 7.0 (TID 39)
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 7.0 (TID 38). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 38) in 4 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 7.0 (TID 39). 1400 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 39) in 4 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 7 (rdd at BigDatalogProgram.scala:41) finished in 0.266 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set(ShuffleMapStage 6)
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 6.0 (TID 30)
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 6.0 (TID 34). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 34) in 29 ms on localhost (4/5)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 6.0 (TID 30). 1367 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 30) in 49 ms on localhost (5/5)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:32 INFO DAGScheduler: ShuffleMapStage 6 (rdd at BigDatalogProgram.scala:41) finished in 0.280 s
17/03/27 22:25:32 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:32 INFO DAGScheduler: running: Set()
17/03/27 22:25:32 INFO DAGScheduler: waiting: Set(ResultStage 9, ShuffleMapStage 8)
17/03/27 22:25:32 INFO DAGScheduler: failed: Set()
17/03/27 22:25:32 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[48] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 21.7 KB, free 2.0 GB)
17/03/27 22:25:32 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.4 KB, free 2.0 GB)
17/03/27 22:25:32 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:52774 (size: 8.4 KB, free: 2.0 GB)
17/03/27 22:25:32 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:32 INFO DAGScheduler: Submitting 20 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[48] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:32 INFO TaskSchedulerImpl: Adding task set 8.0 with 20 tasks
17/03/27 22:25:32 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 42, localhost, partition 2,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 43, localhost, partition 3,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO Executor: Running task 0.0 in stage 8.0 (TID 40)
17/03/27 22:25:32 INFO Executor: Running task 1.0 in stage 8.0 (TID 41)
17/03/27 22:25:32 INFO Executor: Running task 2.0 in stage 8.0 (TID 42)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO GenerateUnsafeProjection: Code generated in 5.457313 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Running task 3.0 in stage 8.0 (TID 43)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO GenerateUnsafeProjection: Code generated in 9.674032 ms
17/03/27 22:25:32 INFO GenerateMutableProjection: Code generated in 3.947685 ms
17/03/27 22:25:32 INFO Executor: Finished task 3.0 in stage 8.0 (TID 43). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 44, localhost, partition 4,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 43) in 55 ms on localhost (1/20)
17/03/27 22:25:32 INFO Executor: Running task 4.0 in stage 8.0 (TID 44)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Finished task 2.0 in stage 8.0 (TID 42). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 5.0 in stage 8.0 (TID 45, localhost, partition 5,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 42) in 66 ms on localhost (2/20)
17/03/27 22:25:32 INFO Executor: Running task 5.0 in stage 8.0 (TID 45)
17/03/27 22:25:32 INFO Executor: Finished task 0.0 in stage 8.0 (TID 40). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO TaskSetManager: Starting task 6.0 in stage 8.0 (TID 46, localhost, partition 6,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO Executor: Running task 6.0 in stage 8.0 (TID 46)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 40) in 70 ms on localhost (3/20)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Finished task 4.0 in stage 8.0 (TID 44). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 7.0 in stage 8.0 (TID 47, localhost, partition 7,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 44) in 25 ms on localhost (4/20)
17/03/27 22:25:32 INFO Executor: Running task 7.0 in stage 8.0 (TID 47)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO Executor: Finished task 6.0 in stage 8.0 (TID 46). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 8.0 in stage 8.0 (TID 48, localhost, partition 8,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 6.0 in stage 8.0 (TID 46) in 12 ms on localhost (5/20)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Running task 8.0 in stage 8.0 (TID 48)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO Executor: Finished task 7.0 in stage 8.0 (TID 47). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 9.0 in stage 8.0 (TID 49, localhost, partition 9,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 7.0 in stage 8.0 (TID 47) in 10 ms on localhost (6/20)
17/03/27 22:25:32 INFO Executor: Running task 9.0 in stage 8.0 (TID 49)
17/03/27 22:25:32 INFO Executor: Finished task 8.0 in stage 8.0 (TID 48). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO TaskSetManager: Starting task 10.0 in stage 8.0 (TID 50, localhost, partition 10,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:32 INFO TaskSetManager: Finished task 8.0 in stage 8.0 (TID 48) in 10 ms on localhost (7/20)
17/03/27 22:25:32 INFO Executor: Running task 10.0 in stage 8.0 (TID 50)
17/03/27 22:25:32 INFO Executor: Finished task 5.0 in stage 8.0 (TID 45). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO TaskSetManager: Starting task 11.0 in stage 8.0 (TID 51, localhost, partition 11,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:32 INFO TaskSetManager: Finished task 5.0 in stage 8.0 (TID 45) in 29 ms on localhost (8/20)
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:32 INFO Executor: Finished task 9.0 in stage 8.0 (TID 49). 3732 bytes result sent to driver
17/03/27 22:25:32 INFO Executor: Running task 11.0 in stage 8.0 (TID 51)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 12.0 in stage 8.0 (TID 52, localhost, partition 12,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO TaskSetManager: Finished task 9.0 in stage 8.0 (TID 49) in 10 ms on localhost (9/20)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 10.0 in stage 8.0 (TID 50). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Running task 12.0 in stage 8.0 (TID 52)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 11.0 in stage 8.0 (TID 51). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 13.0 in stage 8.0 (TID 53, localhost, partition 13,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 14.0 in stage 8.0 (TID 54, localhost, partition 14,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO Executor: Finished task 12.0 in stage 8.0 (TID 52). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 15.0 in stage 8.0 (TID 55, localhost, partition 15,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 10.0 in stage 8.0 (TID 50) in 17 ms on localhost (10/20)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 11.0 in stage 8.0 (TID 51) in 12 ms on localhost (11/20)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 12.0 in stage 8.0 (TID 52) in 12 ms on localhost (12/20)
17/03/27 22:25:33 INFO Executor: Running task 13.0 in stage 8.0 (TID 53)
17/03/27 22:25:33 INFO Executor: Running task 14.0 in stage 8.0 (TID 54)
17/03/27 22:25:33 INFO Executor: Running task 15.0 in stage 8.0 (TID 55)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 13.0 in stage 8.0 (TID 53). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 16.0 in stage 8.0 (TID 56, localhost, partition 16,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 13.0 in stage 8.0 (TID 53) in 9 ms on localhost (13/20)
17/03/27 22:25:33 INFO Executor: Running task 16.0 in stage 8.0 (TID 56)
17/03/27 22:25:33 INFO Executor: Finished task 14.0 in stage 8.0 (TID 54). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 17.0 in stage 8.0 (TID 57, localhost, partition 17,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO Executor: Running task 17.0 in stage 8.0 (TID 57)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 14.0 in stage 8.0 (TID 54) in 12 ms on localhost (14/20)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO Executor: Finished task 16.0 in stage 8.0 (TID 56). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Finished task 17.0 in stage 8.0 (TID 57). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 18.0 in stage 8.0 (TID 58, localhost, partition 18,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 19.0 in stage 8.0 (TID 59, localhost, partition 19,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:33 INFO Executor: Finished task 15.0 in stage 8.0 (TID 55). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 16.0 in stage 8.0 (TID 56) in 24 ms on localhost (15/20)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 17.0 in stage 8.0 (TID 57) in 21 ms on localhost (16/20)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 15.0 in stage 8.0 (TID 55) in 31 ms on localhost (17/20)
17/03/27 22:25:33 INFO Executor: Running task 18.0 in stage 8.0 (TID 58)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Running task 19.0 in stage 8.0 (TID 59)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 18.0 in stage 8.0 (TID 58). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Finished task 19.0 in stage 8.0 (TID 59). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 18.0 in stage 8.0 (TID 58) in 11 ms on localhost (18/20)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 19.0 in stage 8.0 (TID 59) in 12 ms on localhost (19/20)
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 8.0 (TID 41). 3732 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 41) in 147 ms on localhost (20/20)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 8 (rdd at BigDatalogProgram.scala:41) finished in 0.148 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set()
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[51] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 17.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 6.6 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:52774 (size: 6.6 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 9 (MapPartitionsRDD[51] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 9.0 with 5 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 60, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 9.0 (TID 61, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 9.0 (TID 62, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 9.0 (TID 63, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 9.0 (TID 60)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 20 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 9.0 (TID 60). 3690 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 9.0 (TID 61)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 20 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 9.0 (TID 61). 3690 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 9.0 (TID 62)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 20 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 9.0 (TID 62). 4872 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 9.0 (TID 63)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 20 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 9.0 (TID 64, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 9.0 (TID 63). 3690 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 60) in 11 ms on localhost (1/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 9.0 (TID 61) in 11 ms on localhost (2/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 9.0 (TID 62) in 12 ms on localhost (3/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 9.0 (TID 63) in 12 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 9.0 (TID 64)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 20 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 9.0 (TID 64). 4871 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 9.0 (TID 64) in 7 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ResultStage 9 (collect at QuerySuite.scala:64) finished in 0.019 s
17/03/27 22:25:33 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.478114 s
17/03/27 22:25:33 INFO RelationalQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:33 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:33 INFO BlockManager: BlockManager stopped
17/03/27 22:25:33 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:33 INFO SparkContext: Successfully stopped SparkContext
[32m- westCoastEmployees(EmployeeID, FirstName, LastName).[0m
17/03/27 22:25:33 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:33 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:33 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[32mTriangleQuerySuite:[0m
17/03/27 22:25:33 INFO Utils: Successfully started service 'sparkDriver' on port 52792.
17/03/27 22:25:33 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:33 INFO Remoting: Starting remoting
17/03/27 22:25:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52805]
17/03/27 22:25:33 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52805.
17/03/27 22:25:33 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:33 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:33 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-2a576c54-b7bf-4533-92ab-4a6a71ab1305
17/03/27 22:25:33 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:33 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:33 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52822.
17/03/27 22:25:33 INFO NettyBlockTransferService: Server created on 52822
17/03/27 22:25:33 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52822 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52822)
17/03/27 22:25:33 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:33 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667933204
17/03/27 22:25:33 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:33 INFO BigDatalogContext: BigDatalog Query: "triangle_count(A)"
17/03/27 22:25:33 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:33 INFO BigDatalogContext: 
0: (count(1) as A) <AGGREGATE>
 1: (X, Y, Y) <PROJECT>
  2: (0.Y = 1.X, 1.Y = 2.X, 0.X = 2.Y) <JOIN>
   3: X < Y <FILTER>
    4: arc(X, Y) <BASE_RELATION>
   3: X < Y <FILTER>
    4: arc(X, Y) <BASE_RELATION>
   3: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:33 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:33 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:33 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_triangle_count
+- 'Aggregate [unresolvedalias('count(1) AS A#381)]
   +- 'Project ['arc.X,'arc.Y,'arc1.Y]
      +- 'Join Inner, Some((('arc1.Y = 'arc2.X) && ('arc.X = 'arc2.Y)))
         :- 'Join Inner, Some(('arc.Y = 'arc1.X))
         :  :- 'Filter ('arc.X < 'arc.Y)
         :  :  +- 'UnresolvedRelation `arc`, None
         :  +- 'Filter ('arc1.X < 'arc1.Y)
         :     +- 'Subquery arc1
         :        +- 'Project [*]
         :           +- 'UnresolvedRelation `arc`, None
         +- 'Subquery arc2
            +- 'Project [*]
               +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: bigint
Subquery aggregate_triangle_count
+- Aggregate [(count(1),mode=Complete,isDistinct=false) AS A#381L]
   +- Project [X#379,Y#380,Y#383]
      +- Join Inner, Some(((Y#383 = X#384) && (X#379 = Y#385)))
         :- Join Inner, Some((Y#380 = X#382))
         :  :- Filter (X#379 < Y#380)
         :  :  +- Subquery arc
         :  :     +- LogicalRDD [X#379,Y#380], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Filter (X#382 < Y#383)
         :     +- Subquery arc1
         :        +- Project [X#382,Y#383]
         :           +- Subquery arc
         :              +- LogicalRDD [X#382,Y#383], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Subquery arc2
            +- Project [X#384,Y#385]
               +- Subquery arc
                  +- LogicalRDD [X#384,Y#385], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(count(1),mode=Complete,isDistinct=false) AS A#381L]
+- Project
   +- Join Inner, Some(((Y#383 = X#384) && (X#379 = Y#385)))
      :- Project [Y#383,X#379]
      :  +- Join Inner, Some((Y#380 = X#382))
      :     :- Filter (X#379 < Y#380)
      :     :  +- LogicalRDD [X#379,Y#380], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     +- Filter (X#382 < Y#383)
      :        +- LogicalRDD [X#382,Y#383], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- LogicalRDD [X#384,Y#385], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(count(1),mode=Final,isDistinct=false)], output=[A#381L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(count(1),mode=Partial,isDistinct=false)], output=[count#388L])
      +- Project
         +- SortMergeJoin [Y#383,X#379], [X#384,Y#385]
            :- Sort [Y#383 ASC,X#379 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(Y#383,X#379,5), None
            :     +- Project [Y#383,X#379]
            :        +- SortMergeJoin [Y#380], [X#382]
            :           :- Sort [Y#380 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(Y#380,5), None
            :           :     +- ConvertToUnsafe
            :           :        +- Filter (X#379 < Y#380)
            :           :           +- Scan ExistingRDD[X#379,Y#380] 
            :           +- Sort [X#382 ASC], false, 0
            :              +- TungstenExchange hashpartitioning(X#382,5), None
            :                 +- ConvertToUnsafe
            :                    +- Filter (X#382 < Y#383)
            :                       +- Scan ExistingRDD[X#382,Y#383] 
            +- Sort [X#384 ASC,Y#385 ASC], false, 0
               +- TungstenExchange hashpartitioning(X#384,Y#385,5), None
                  +- ConvertToUnsafe
                     +- Scan ExistingRDD[X#384,Y#385]
17/03/27 22:25:33 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:33 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:33 INFO DAGScheduler: Final stage: ResultStage 5 (collect at QuerySuite.scala:64)
17/03/27 22:25:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52822 (size: 3.4 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52822 (size: 3.4 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52822 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:33 INFO GeneratePredicate: Code generated in 4.006022 ms
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 30 ms on localhost (1/5)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 16 ms on localhost (2/5)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 3.0 (TID 12)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 26 ms on localhost (1/5)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 3.0 (TID 13)
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 3.0 (TID 14)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 3.0 (TID 12). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 22 ms on localhost (2/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 20 ms on localhost (3/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 17 ms on localhost (1/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 19 ms on localhost (4/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 17 ms on localhost (2/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 15 ms on localhost (3/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 53 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 53 ms on localhost (4/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 54 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.055 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 3)
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 3.0 (TID 13). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 17 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 3.0 (TID 14). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 19 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.061 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 48 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.064 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set()
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.7 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52822 (size: 5.3 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 15, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 16, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 17, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 18, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 16)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 2.0 (TID 17)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 15)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 2.0 (TID 18)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO GenerateUnsafeProjection: Code generated in 2.703367 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO GenerateUnsafeProjection: Code generated in 2.169955 ms
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 2.0 (TID 16). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 19, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 2.0 (TID 19)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 16) in 16 ms on localhost (1/5)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 2.0 (TID 18). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 18) in 21 ms on localhost (2/5)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 2.0 (TID 17). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 17) in 23 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 2.0 (TID 19). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 19) in 9 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 15). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 15) in 30 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.030 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set()
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.1 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:52822 (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO GenerateOrdering: Code generated in 3.109554 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO GenerateMutableProjection: Code generated in 2.965884 ms
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 22 ms on localhost (1/5)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 23 ms on localhost (2/5)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 25 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 29 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 9 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.031 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set()
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:52822 (size: 6.4 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 3523 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 5 ms on localhost (1/1)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ResultStage 5 (collect at QuerySuite.scala:64) finished in 0.005 s
17/03/27 22:25:33 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.143956 s
17/03/27 22:25:33 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:33 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:33 INFO BlockManager: BlockManager stopped
17/03/27 22:25:33 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:33 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:33 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:33 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:33 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:33 INFO Utils: Successfully started service 'sparkDriver' on port 52839.
17/03/27 22:25:33 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:33 INFO Remoting: Starting remoting
17/03/27 22:25:33 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52853]
17/03/27 22:25:33 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52853.
17/03/27 22:25:33 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:33 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:33 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-d9f1d8c2-4344-4fab-a594-41d350bdf9b3
17/03/27 22:25:33 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:33 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:33 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52870.
17/03/27 22:25:33 INFO NettyBlockTransferService: Server created on 52870
17/03/27 22:25:33 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:33 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52870 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52870)
17/03/27 22:25:33 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:33 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667933619
17/03/27 22:25:33 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:33 INFO BigDatalogContext: BigDatalog Query: "triangle_count(A)"
17/03/27 22:25:33 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:33 INFO BigDatalogContext: 
0: (count(1) as A) <AGGREGATE>
 1: (X, Y, Y) <PROJECT>
  2: (0.Y = 1.X, 1.Y = 2.X, 0.X = 2.Y) <JOIN>
   3: X < Y <FILTER>
    4: arc(X, Y) <BASE_RELATION>
   3: X < Y <FILTER>
    4: arc(X, Y) <BASE_RELATION>
   3: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:33 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:33 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:33 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_triangle_count
+- 'Aggregate [unresolvedalias('count(1) AS A#398)]
   +- 'Project ['arc.X,'arc.Y,'arc1.Y]
      +- 'Join Inner, Some((('arc1.Y = 'arc2.X) && ('arc.X = 'arc2.Y)))
         :- 'Join Inner, Some(('arc.Y = 'arc1.X))
         :  :- 'Filter ('arc.X < 'arc.Y)
         :  :  +- 'UnresolvedRelation `arc`, None
         :  +- 'Filter ('arc1.X < 'arc1.Y)
         :     +- 'Subquery arc1
         :        +- 'Project [*]
         :           +- 'UnresolvedRelation `arc`, None
         +- 'Subquery arc2
            +- 'Project [*]
               +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: bigint
Subquery aggregate_triangle_count
+- Aggregate [(count(1),mode=Complete,isDistinct=false) AS A#398L]
   +- Project [X#396,Y#397,Y#400]
      +- Join Inner, Some(((Y#400 = X#401) && (X#396 = Y#402)))
         :- Join Inner, Some((Y#397 = X#399))
         :  :- Filter (X#396 < Y#397)
         :  :  +- Subquery arc
         :  :     +- LogicalRDD [X#396,Y#397], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Filter (X#399 < Y#400)
         :     +- Subquery arc1
         :        +- Project [X#399,Y#400]
         :           +- Subquery arc
         :              +- LogicalRDD [X#399,Y#400], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Subquery arc2
            +- Project [X#401,Y#402]
               +- Subquery arc
                  +- LogicalRDD [X#401,Y#402], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(count(1),mode=Complete,isDistinct=false) AS A#398L]
+- Project
   +- Join Inner, Some(((Y#400 = X#401) && (X#396 = Y#402)))
      :- Project [Y#400,X#396]
      :  +- Join Inner, Some((Y#397 = X#399))
      :     :- Filter (X#396 < Y#397)
      :     :  +- LogicalRDD [X#396,Y#397], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     +- Filter (X#399 < Y#400)
      :        +- LogicalRDD [X#399,Y#400], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- LogicalRDD [X#401,Y#402], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(count(1),mode=Final,isDistinct=false)], output=[A#398L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(count(1),mode=Partial,isDistinct=false)], output=[count#405L])
      +- Project
         +- SortMergeJoin [Y#400,X#396], [X#401,Y#402]
            :- Sort [Y#400 ASC,X#396 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(Y#400,X#396,5), None
            :     +- Project [Y#400,X#396]
            :        +- SortMergeJoin [Y#397], [X#399]
            :           :- Sort [Y#397 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(Y#397,5), None
            :           :     +- ConvertToUnsafe
            :           :        +- Filter (X#396 < Y#397)
            :           :           +- Scan ExistingRDD[X#396,Y#397] 
            :           +- Sort [X#399 ASC], false, 0
            :              +- TungstenExchange hashpartitioning(X#399,5), None
            :                 +- ConvertToUnsafe
            :                    +- Filter (X#399 < Y#400)
            :                       +- Scan ExistingRDD[X#399,Y#400] 
            +- Sort [X#401 ASC,Y#402 ASC], false, 0
               +- TungstenExchange hashpartitioning(X#401,Y#402,5), None
                  +- ConvertToUnsafe
                     +- Scan ExistingRDD[X#401,Y#402]
17/03/27 22:25:33 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:33 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:33 INFO DAGScheduler: Final stage: ResultStage 5 (collect at QuerySuite.scala:64)
17/03/27 22:25:33 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52870 (size: 3.4 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52870 (size: 3.4 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52870 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 46 ms on localhost (1/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 24 ms on localhost (1/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 34 ms on localhost (2/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 21 ms on localhost (3/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 21 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 3.0 (TID 12)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 27 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.056 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 3)
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1436 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 60 ms on localhost (2/5)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 3.0 (TID 13)
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 25 ms on localhost (1/5)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 3.0 (TID 14)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 75 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 3.0 (TID 14). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 18 ms on localhost (2/5)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 3.0 (TID 12). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 32 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 3.0 (TID 13). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 28 ms on localhost (4/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 89 ms on localhost (4/5)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 78 ms on localhost (5/5)
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.090 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.7 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52870 (size: 5.3 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 15, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 16, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 17, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 2.0 (TID 15)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 2.0 (TID 16)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 2.0 (TID 17)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 2.0 (TID 16). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 18, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 16) in 11 ms on localhost (1/5)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 2.0 (TID 18)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 2.0 (TID 17). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 19, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 17) in 12 ms on localhost (2/5)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 2.0 (TID 19)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 2.0 (TID 19). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 19) in 8 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 1222 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 79 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.110 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 2.0 (TID 18). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 18) in 13 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 2.0 (TID 15). 2012 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 15) in 26 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.026 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set()
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.1 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:52870 (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:33 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:33 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:33 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 11 ms on localhost (1/5)
17/03/27 22:25:33 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:33 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 13 ms on localhost (2/5)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 17 ms on localhost (3/5)
17/03/27 22:25:33 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 18 ms on localhost (4/5)
17/03/27 22:25:33 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2524 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 31 ms on localhost (5/5)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.033 s
17/03/27 22:25:33 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:33 INFO DAGScheduler: running: Set()
17/03/27 22:25:33 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/03/27 22:25:33 INFO DAGScheduler: failed: Set()
17/03/27 22:25:33 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.3 KB, free 2.0 GB)
17/03/27 22:25:33 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 2.0 GB)
17/03/27 22:25:33 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:52870 (size: 6.4 KB, free: 2.0 GB)
17/03/27 22:25:33 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:33 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/27 22:25:33 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:33 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 3523 bytes result sent to driver
17/03/27 22:25:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 5 ms on localhost (1/1)
17/03/27 22:25:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:33 INFO DAGScheduler: ResultStage 5 (collect at QuerySuite.scala:64) finished in 0.005 s
17/03/27 22:25:33 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.173718 s
17/03/27 22:25:33 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:33 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:33 INFO BlockManager: BlockManager stopped
17/03/27 22:25:33 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:33 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:33 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:33 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:33 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:33 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:33 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:34 INFO Utils: Successfully started service 'sparkDriver' on port 52887.
17/03/27 22:25:34 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:34 INFO Remoting: Starting remoting
17/03/27 22:25:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52900]
17/03/27 22:25:34 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52900.
17/03/27 22:25:34 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:34 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:34 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-9713c72e-43f8-408e-ab8d-679b863d283c
17/03/27 22:25:34 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:34 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:34 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52917.
17/03/27 22:25:34 INFO NettyBlockTransferService: Server created on 52917
17/03/27 22:25:34 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52917 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52917)
17/03/27 22:25:34 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:34 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667934057
17/03/27 22:25:34 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:34 INFO BigDatalogContext: BigDatalog Query: "triangle_count(A)"
17/03/27 22:25:34 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:34 INFO BigDatalogContext: 
0: (count(1) as A) <AGGREGATE>
 1: (X, Y, Y) <PROJECT>
  2: (0.Y = 1.X, 1.Y = 2.X, 0.X = 2.Y) <JOIN>
   3: X < Y <FILTER>
    4: arc(X, Y) <BASE_RELATION>
   3: X < Y <FILTER>
    4: arc(X, Y) <BASE_RELATION>
   3: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:34 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:34 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:34 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_triangle_count
+- 'Aggregate [unresolvedalias('count(1) AS A#415)]
   +- 'Project ['arc.X,'arc.Y,'arc1.Y]
      +- 'Join Inner, Some((('arc1.Y = 'arc2.X) && ('arc.X = 'arc2.Y)))
         :- 'Join Inner, Some(('arc.Y = 'arc1.X))
         :  :- 'Filter ('arc.X < 'arc.Y)
         :  :  +- 'UnresolvedRelation `arc`, None
         :  +- 'Filter ('arc1.X < 'arc1.Y)
         :     +- 'Subquery arc1
         :        +- 'Project [*]
         :           +- 'UnresolvedRelation `arc`, None
         +- 'Subquery arc2
            +- 'Project [*]
               +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: bigint
Subquery aggregate_triangle_count
+- Aggregate [(count(1),mode=Complete,isDistinct=false) AS A#415L]
   +- Project [X#413,Y#414,Y#417]
      +- Join Inner, Some(((Y#417 = X#418) && (X#413 = Y#419)))
         :- Join Inner, Some((Y#414 = X#416))
         :  :- Filter (X#413 < Y#414)
         :  :  +- Subquery arc
         :  :     +- LogicalRDD [X#413,Y#414], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Filter (X#416 < Y#417)
         :     +- Subquery arc1
         :        +- Project [X#416,Y#417]
         :           +- Subquery arc
         :              +- LogicalRDD [X#416,Y#417], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Subquery arc2
            +- Project [X#418,Y#419]
               +- Subquery arc
                  +- LogicalRDD [X#418,Y#419], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(count(1),mode=Complete,isDistinct=false) AS A#415L]
+- Project
   +- Join Inner, Some(((Y#417 = X#418) && (X#413 = Y#419)))
      :- Project [Y#417,X#413]
      :  +- Join Inner, Some((Y#414 = X#416))
      :     :- Filter (X#413 < Y#414)
      :     :  +- LogicalRDD [X#413,Y#414], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     +- Filter (X#416 < Y#417)
      :        +- LogicalRDD [X#416,Y#417], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- LogicalRDD [X#418,Y#419], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(count(1),mode=Final,isDistinct=false)], output=[A#415L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(count(1),mode=Partial,isDistinct=false)], output=[count#422L])
      +- Project
         +- SortMergeJoin [Y#417,X#413], [X#418,Y#419]
            :- Sort [Y#417 ASC,X#413 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(Y#417,X#413,5), None
            :     +- Project [Y#417,X#413]
            :        +- SortMergeJoin [Y#414], [X#416]
            :           :- Sort [Y#414 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(Y#414,5), None
            :           :     +- ConvertToUnsafe
            :           :        +- Filter (X#413 < Y#414)
            :           :           +- Scan ExistingRDD[X#413,Y#414] 
            :           +- Sort [X#416 ASC], false, 0
            :              +- TungstenExchange hashpartitioning(X#416,5), None
            :                 +- ConvertToUnsafe
            :                    +- Filter (X#416 < Y#417)
            :                       +- Scan ExistingRDD[X#416,Y#417] 
            +- Sort [X#418 ASC,Y#419 ASC], false, 0
               +- TungstenExchange hashpartitioning(X#418,Y#419,5), None
                  +- ConvertToUnsafe
                     +- Scan ExistingRDD[X#418,Y#419]
17/03/27 22:25:34 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:34 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:34 INFO DAGScheduler: Final stage: ResultStage 5 (collect at QuerySuite.scala:64)
17/03/27 22:25:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52917 (size: 3.4 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.4 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52917 (size: 3.4 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52917 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 37 ms on localhost (1/5)
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 14 ms on localhost (1/5)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 13 ms on localhost (2/5)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 4 ms on localhost (3/5)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 10)
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2336 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 12 ms on localhost (4/5)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 3.0 (TID 11)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 13 ms on localhost (5/5)
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.067 s
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 3)
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 3.0 (TID 12)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 3.0 (TID 11). 1222 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 11) in 11 ms on localhost (1/5)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 3.0 (TID 13)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1436 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 3.0 (TID 14)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 78 ms on localhost (2/5)
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 3.0 (TID 12). 1222 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 12) in 13 ms on localhost (2/5)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 3.0 (TID 14). 1222 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 14) in 14 ms on localhost (3/5)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 3.0 (TID 13). 1222 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 13) in 27 ms on localhost (4/5)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 100 ms on localhost (3/5)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 10). 1222 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 10) in 45 ms on localhost (5/5)
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.098 s
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set(ShuffleMapStage 0)
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 79 ms on localhost (4/5)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 104 ms on localhost (5/5)
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.106 s
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set()
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 2, ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 10.7 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.3 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52917 (size: 5.3 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 15, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 16, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 17, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 18, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 15)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 2.0 (TID 17)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 2.0 (TID 18)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 2.0 (TID 16)
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 2.0 (TID 17). 2012 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 19, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 17) in 12 ms on localhost (1/5)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 2.0 (TID 19)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 2.0 (TID 18). 2012 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 18) in 13 ms on localhost (2/5)
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 2.0 (TID 19). 2012 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 19) in 7 ms on localhost (3/5)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 2.0 (TID 15). 2012 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 15) in 20 ms on localhost (4/5)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 2.0 (TID 16). 2012 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 16) in 22 ms on localhost (5/5)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.022 s
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set()
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 15.1 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:52917 (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 2524 bytes result sent to driver
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 16 ms on localhost (1/5)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 2524 bytes result sent to driver
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 19 ms on localhost (2/5)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2524 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 24 ms on localhost (3/5)
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2524 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 26 ms on localhost (4/5)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 2524 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 15 ms on localhost (5/5)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.030 s
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set()
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[26] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.3 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:52917 (size: 6.4 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[26] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 3523 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 5 ms on localhost (1/1)
17/03/27 22:25:34 INFO DAGScheduler: ResultStage 5 (collect at QuerySuite.scala:64) finished in 0.005 s
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.174059 s
17/03/27 22:25:34 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:34 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:34 INFO BlockManager: BlockManager stopped
17/03/27 22:25:34 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:34 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:34 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:34 INFO SparkContext: Successfully stopped SparkContext
[32m- Triangle Counting - f[0m
17/03/27 22:25:34 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:34 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:34 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:34 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:34 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:34 INFO Utils: Successfully started service 'sparkDriver' on port 52935.
17/03/27 22:25:34 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:34 INFO Remoting: Starting remoting
17/03/27 22:25:34 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52948]
17/03/27 22:25:34 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52948.
17/03/27 22:25:34 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:34 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:34 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-e13c912b-127d-4ba1-918a-054e5ba8a338
17/03/27 22:25:34 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:34 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:34 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:34 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52965.
17/03/27 22:25:34 INFO NettyBlockTransferService: Server created on 52965
17/03/27 22:25:34 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:34 INFO BlockManagerMasterEndpoint: Registering block manager localhost:52965 with 2.0 GB RAM, BlockManagerId(driver, localhost, 52965)
17/03/27 22:25:34 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:34 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667934509
17/03/27 22:25:34 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:34 INFO BigDatalogContext: BigDatalog Query: "triangle_closing(A,B,C)"
17/03/27 22:25:34 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:34 INFO BigDatalogContext: 
0: (Y, Y, count(X) as C) <AGGREGATE>
 1: (Y, Y, X) <PROJECT>
  2: Y ~= Y <FILTER>
   3: (0.X = 1.X, 0.Y = 2.X, 1.Y = 2.Y) <JOIN>
    4: uarc(X, Y) <UNION>
     5: arc(X, Y) <BASE_RELATION>
     5: (Y, X) <PROJECT>
      6: arc(X, Y) <BASE_RELATION>
    4: uarc(X, Y) <UNION>
     5: arc(X, Y) <BASE_RELATION>
     5: (Y, X) <PROJECT>
      6: arc(X, Y) <BASE_RELATION>
    4: (0.Y = 0.X, 1.Y = 0.Y) <NEGATION>
     5: uarc(X, Y) <UNION>
      6: arc(X, Y) <BASE_RELATION>
      6: (Y, X) <PROJECT>
       7: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:34 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:34 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:34 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_triangle_closing
+- 'Aggregate ['uarc.Y,'uarc4.Y], ['uarc.Y,'uarc4.Y,unresolvedalias('count('uarc.X) AS C#432)]
   +- 'Project ['uarc.Y,'uarc4.Y,'uarc.X]
      +- 'Filter NOT ('uarc.Y = 'uarc4.Y)
         +- 'Filter (isnull('uarc7.X) && isnull('uarc7.Y))
            +- 'Join LeftOuter, Some((('uarc.Y = 'uarc7.X) && ('uarc4.Y = 'uarc7.Y)))
               :- 'Join Inner, Some(('uarc.X = 'uarc4.X))
               :  :- 'Distinct
               :  :  +- 'Subquery uarc
               :  :     +- 'Union
               :  :        :- 'UnresolvedRelation `arc`, None
               :  :        +- 'Project ['arc1.Y,'arc1.X]
               :  :           +- 'Subquery arc1
               :  :              +- 'Project [*]
               :  :                 +- 'UnresolvedRelation `arc`, None
               :  +- 'Distinct
               :     +- 'Subquery uarc4
               :        +- 'Union
               :           :- 'Subquery arc2
               :           :  +- 'Project [*]
               :           :     +- 'UnresolvedRelation `arc`, None
               :           +- 'Project ['arc3.Y,'arc3.X]
               :              +- 'Subquery arc3
               :                 +- 'Project [*]
               :                    +- 'UnresolvedRelation `arc`, None
               +- 'Distinct
                  +- 'Subquery uarc7
                     +- 'Union
                        :- 'Subquery arc5
                        :  +- 'Project [*]
                        :     +- 'UnresolvedRelation `arc`, None
                        +- 'Project ['arc6.Y,'arc6.X]
                           +- 'Subquery arc6
                              +- 'Project [*]
                                 +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
Y: int, Y: int, C: bigint
Subquery aggregate_triangle_closing
+- Aggregate [Y#431,Y#434], [Y#431,Y#434,(count(X#430),mode=Complete,isDistinct=false) AS C#432L]
   +- Project [Y#431,Y#434,X#430]
      +- Filter NOT (Y#431 = Y#434)
         +- Filter (isnull(X#437) && isnull(Y#438))
            +- Join LeftOuter, Some(((Y#431 = X#437) && (Y#434 = Y#438)))
               :- Join Inner, Some((X#430 = X#433))
               :  :- Distinct
               :  :  +- Subquery uarc
               :  :     +- Union
               :  :        :- Subquery arc
               :  :        :  +- LogicalRDD [X#430,Y#431], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :  :        +- Project [Y#431,X#430]
               :  :           +- Subquery arc1
               :  :              +- Project [X#430,Y#431]
               :  :                 +- Subquery arc
               :  :                    +- LogicalRDD [X#430,Y#431], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :  +- Distinct
               :     +- Subquery uarc4
               :        +- Union
               :           :- Subquery arc2
               :           :  +- Project [X#433,Y#434]
               :           :     +- Subquery arc
               :           :        +- LogicalRDD [X#433,Y#434], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           +- Project [Y#434,X#433]
               :              +- Subquery arc3
               :                 +- Project [X#433,Y#434]
               :                    +- Subquery arc
               :                       +- LogicalRDD [X#433,Y#434], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Distinct
                  +- Subquery uarc7
                     +- Union
                        :- Subquery arc5
                        :  +- Project [X#437,Y#438]
                        :     +- Subquery arc
                        :        +- LogicalRDD [X#437,Y#438], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
                        +- Project [Y#438,X#437]
                           +- Subquery arc6
                              +- Project [X#437,Y#438]
                                 +- Subquery arc
                                    +- LogicalRDD [X#437,Y#438], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [Y#431,Y#434], [Y#431,Y#434,(count(X#430),mode=Complete,isDistinct=false) AS C#432L]
+- Project [Y#431,Y#434,X#430]
   +- Filter (isnull(X#437) && isnull(Y#438))
      +- Join LeftOuter, Some(((Y#431 = X#437) && (Y#434 = Y#438)))
         :- Join Inner, Some((NOT (Y#431 = Y#434) && (X#430 = X#433)))
         :  :- Aggregate [X#430,Y#431], [X#430,Y#431]
         :  :  +- Union
         :  :     :- LogicalRDD [X#430,Y#431], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  :     +- Project [Y#431,X#430]
         :  :        +- LogicalRDD [X#430,Y#431], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Aggregate [X#433,Y#434], [X#433,Y#434]
         :     +- Union
         :        :- LogicalRDD [X#433,Y#434], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :        +- Project [Y#434,X#433]
         :           +- LogicalRDD [X#433,Y#434], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Aggregate [X#437,Y#438], [X#437,Y#438]
            +- Union
               :- LogicalRDD [X#437,Y#438], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Project [Y#438,X#437]
                  +- LogicalRDD [X#437,Y#438], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[Y#431,Y#434], functions=[(count(X#430),mode=Final,isDistinct=false)], output=[Y#431,Y#434,C#432L])
+- TungstenAggregate(key=[Y#431,Y#434], functions=[(count(X#430),mode=Partial,isDistinct=false)], output=[Y#431,Y#434,count#443L])
   +- Project [Y#431,Y#434,X#430]
      +- Filter (isnull(X#437) && isnull(Y#438))
         +- SortMergeOuterJoin [Y#431,Y#434], [X#437,Y#438], LeftOuter, None
            :- Sort [Y#431 ASC,Y#434 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(Y#431,Y#434,5), None
            :     +- Filter NOT (Y#431 = Y#434)
            :        +- SortMergeJoin [X#430], [X#433]
            :           :- Sort [X#430 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(X#430,5), None
            :           :     +- TungstenAggregate(key=[X#430,Y#431], functions=[], output=[X#430,Y#431])
            :           :        +- TungstenExchange hashpartitioning(X#430,Y#431,5), None
            :           :           +- TungstenAggregate(key=[X#430,Y#431], functions=[], output=[X#430,Y#431])
            :           :              +- Union
            :           :                 :- ConvertToUnsafe
            :           :                 :  +- Scan ExistingRDD[X#430,Y#431] 
            :           :                 +- Project [Y#431,X#430]
            :           :                    +- Scan ExistingRDD[X#430,Y#431] 
            :           +- Sort [X#433 ASC], false, 0
            :              +- TungstenExchange hashpartitioning(X#433,5), None
            :                 +- TungstenAggregate(key=[X#433,Y#434], functions=[], output=[X#433,Y#434])
            :                    +- TungstenExchange hashpartitioning(X#433,Y#434,5), None
            :                       +- TungstenAggregate(key=[X#433,Y#434], functions=[], output=[X#433,Y#434])
            :                          +- Union
            :                             :- ConvertToUnsafe
            :                             :  +- Scan ExistingRDD[X#433,Y#434] 
            :                             +- Project [Y#434,X#433]
            :                                +- Scan ExistingRDD[X#433,Y#434] 
            +- Sort [X#437 ASC,Y#438 ASC], false, 0
               +- TungstenAggregate(key=[X#437,Y#438], functions=[], output=[X#437,Y#438])
                  +- TungstenExchange hashpartitioning(X#437,Y#438,5), None
                     +- TungstenAggregate(key=[X#437,Y#438], functions=[], output=[X#437,Y#438])
                        +- Union
                           :- ConvertToUnsafe
                           :  +- Scan ExistingRDD[X#437,Y#438] 
                           +- Project [Y#438,X#437]
                              +- Scan ExistingRDD[X#437,Y#438]
17/03/27 22:25:34 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:34 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 30 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 5 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 15 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 18 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:34 INFO DAGScheduler: Final stage: ResultStage 6 (collect at QuerySuite.scala:64)
17/03/27 22:25:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:34 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:52965 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.3 KB, free 2.0 GB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:52965 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:52965 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 10 tasks
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1486 bytes result sent to driver
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 40 ms on localhost (1/10)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:34 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
17/03/27 22:25:34 INFO GenerateUnsafeProjection: Code generated in 13.105683 ms
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 45 ms on localhost (2/10)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 59 ms on localhost (3/10)
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
17/03/27 22:25:34 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1486 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 25 ms on localhost (4/10)
17/03/27 22:25:34 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 82 ms on localhost (5/10)
17/03/27 22:25:34 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 10)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 16 ms on localhost (6/10)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 10). 1486 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 10) in 4 ms on localhost (1/10)
17/03/27 22:25:34 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 90 ms on localhost (7/10)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 25 ms on localhost (8/10)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:34 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 1.0 (TID 13)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 56 ms on localhost (9/10)
17/03/27 22:25:34 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 1.0 (TID 11). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 11) in 20 ms on localhost (2/10)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 1.0 (TID 14)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 1.0 (TID 13). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 15, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:34 INFO Executor: Running task 5.0 in stage 1.0 (TID 15)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 13) in 13 ms on localhost (3/10)
17/03/27 22:25:34 INFO Executor: Finished task 5.0 in stage 1.0 (TID 15). 1486 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 16, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 6.0 in stage 1.0 (TID 16)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 15) in 5 ms on localhost (4/10)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 1.0 (TID 14). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 17, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 14) in 14 ms on localhost (5/10)
17/03/27 22:25:34 INFO Executor: Running task 7.0 in stage 1.0 (TID 17)
17/03/27 22:25:34 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 18, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 8.0 in stage 1.0 (TID 18)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 43 ms on localhost (10/10)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.125 s
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 3)
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO Executor: Finished task 2.0 in stage 1.0 (TID 12). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 19, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 12) in 43 ms on localhost (6/10)
17/03/27 22:25:34 INFO Executor: Running task 9.0 in stage 1.0 (TID 19)
17/03/27 22:25:34 INFO Executor: Finished task 7.0 in stage 1.0 (TID 17). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 17) in 15 ms on localhost (7/10)
17/03/27 22:25:34 INFO Executor: Finished task 8.0 in stage 1.0 (TID 18). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 20)
17/03/27 22:25:34 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 1.0 in stage 3.0 (TID 21)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 18) in 15 ms on localhost (8/10)
17/03/27 22:25:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 20). 1486 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 22, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 20) in 10 ms on localhost (1/10)
17/03/27 22:25:34 INFO Executor: Running task 2.0 in stage 3.0 (TID 22)
17/03/27 22:25:34 INFO Executor: Finished task 9.0 in stage 1.0 (TID 19). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 23, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 3.0 in stage 3.0 (TID 23)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 19) in 24 ms on localhost (9/10)
17/03/27 22:25:34 INFO Executor: Finished task 1.0 in stage 3.0 (TID 21). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 24, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 21) in 21 ms on localhost (2/10)
17/03/27 22:25:34 INFO Executor: Running task 4.0 in stage 3.0 (TID 24)
17/03/27 22:25:34 INFO Executor: Finished task 3.0 in stage 3.0 (TID 23). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 25, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 23) in 11 ms on localhost (3/10)
17/03/27 22:25:34 INFO Executor: Running task 5.0 in stage 3.0 (TID 25)
17/03/27 22:25:34 INFO Executor: Finished task 4.0 in stage 3.0 (TID 24). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 26, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 6.0 in stage 3.0 (TID 26)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 24) in 12 ms on localhost (4/10)
17/03/27 22:25:34 INFO Executor: Finished task 5.0 in stage 3.0 (TID 25). 1486 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 27, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 7.0 in stage 3.0 (TID 27)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 25) in 4 ms on localhost (5/10)
17/03/27 22:25:34 INFO Executor: Finished task 7.0 in stage 3.0 (TID 27). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 28, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO Executor: Running task 8.0 in stage 3.0 (TID 28)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 27) in 15 ms on localhost (6/10)
17/03/27 22:25:34 INFO Executor: Finished task 6.0 in stage 1.0 (TID 16). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 29, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 16) in 68 ms on localhost (10/10)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:34 INFO Executor: Running task 9.0 in stage 3.0 (TID 29)
17/03/27 22:25:34 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.184 s
17/03/27 22:25:34 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:34 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:34 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:34 INFO DAGScheduler: failed: Set()
17/03/27 22:25:34 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.6 KB, free 1983.7 MB)
17/03/27 22:25:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 1951.5 MB)
17/03/27 22:25:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:52965 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:34 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:34 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:34 INFO Executor: Finished task 9.0 in stage 3.0 (TID 29). 1495 bytes result sent to driver
17/03/27 22:25:34 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 30, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:34 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 29) in 13 ms on localhost (7/10)
17/03/27 22:25:34 INFO Executor: Running task 0.0 in stage 2.0 (TID 30)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 8.0 in stage 3.0 (TID 28). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 31, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 28) in 17 ms on localhost (8/10)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 31)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 31). 1874 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 32, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 31) in 5 ms on localhost (1/5)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 2.0 (TID 32)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 6.0 in stage 3.0 (TID 26). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 33, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 26) in 40 ms on localhost (9/10)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 2.0 (TID 33)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 2.0 (TID 32). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 34, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 32) in 14 ms on localhost (2/5)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 2.0 (TID 34)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 2.0 (TID 33). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 33) in 14 ms on localhost (3/5)
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 30). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 30) in 25 ms on localhost (4/5)
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 3.0 (TID 22). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 22) in 84 ms on localhost (10/10)
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.222 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:52965 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 35, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 36, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 37, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 4.0 (TID 35)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 4.0 (TID 36)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 4.0 (TID 37)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 2.0 (TID 34). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 4.0 (TID 36). 1874 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 38, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 39, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 34) in 19 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 36) in 8 ms on localhost (1/5)
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.047 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set(ShuffleMapStage 4)
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 4.0 (TID 38)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 4.0 (TID 39)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 4.0 (TID 37). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 37) in 20 ms on localhost (2/5)
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 4.0 (TID 35). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 35) in 27 ms on localhost (3/5)
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 4.0 (TID 39). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 39) in 22 ms on localhost (4/5)
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 4.0 (TID 38). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 38) in 24 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.030 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set()
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:52965 (size: 6.1 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 42, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 43, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 5.0 (TID 40)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 5.0 (TID 41)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 5.0 (TID 42)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 5.0 (TID 43)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO GeneratePredicate: Code generated in 3.885314 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO GenerateMutableProjection: Code generated in 7.029003 ms
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 5.0 (TID 41). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 44, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 41) in 23 ms on localhost (1/5)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 5.0 (TID 44)
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 5.0 (TID 42). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 42) in 24 ms on localhost (2/5)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 5.0 (TID 43). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 43) in 25 ms on localhost (3/5)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 5.0 (TID 44). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 44) in 10 ms on localhost (4/5)
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 40). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 40) in 38 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 5 (rdd at BigDatalogProgram.scala:41) finished in 0.038 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set()
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 20.5 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:52965 (size: 8.2 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 45, localhost, partition 0,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 46, localhost, partition 1,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 47, localhost, partition 2,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 48, localhost, partition 3,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 45)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 6.0 (TID 46)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 6.0 (TID 47)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 6.0 (TID 48)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO GenerateOrdering: Code generated in 3.327078 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO GenerateUnsafeProjection: Code generated in 9.233401 ms
17/03/27 22:25:35 INFO GeneratePredicate: Code generated in 2.068795 ms
17/03/27 22:25:35 INFO GenerateUnsafeProjection: Code generated in 9.584665 ms
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 6.0 (TID 48). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 6.0 (TID 46). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 49, localhost, partition 4,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 48) in 43 ms on localhost (1/5)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 46) in 43 ms on localhost (2/5)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 6.0 (TID 49)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO GenerateMutableProjection: Code generated in 2.769462 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO GenerateMutableProjection: Code generated in 7.795142 ms
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 6.0 (TID 49). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 49) in 83 ms on localhost (3/5)
17/03/27 22:25:35 INFO GenerateUnsafeProjection: Code generated in 2.72633 ms
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 6.0 (TID 47). 4801 bytes result sent to driver
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 6.0 (TID 45). 4801 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 47) in 127 ms on localhost (4/5)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 45) in 128 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ResultStage 6 (collect at QuerySuite.scala:64) finished in 0.128 s
17/03/27 22:25:35 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.442753 s
17/03/27 22:25:35 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:35 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:52965 in memory (size: 6.1 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:35 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:35 INFO BlockManager: BlockManager stopped
17/03/27 22:25:35 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:35 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:35 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:35 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:35 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:35 INFO Utils: Successfully started service 'sparkDriver' on port 52983.
17/03/27 22:25:35 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:35 INFO Remoting: Starting remoting
17/03/27 22:25:35 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:52996]
17/03/27 22:25:35 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 52996.
17/03/27 22:25:35 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:35 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:35 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-f93e7819-50da-4dbf-8d37-d5b428a52d07
17/03/27 22:25:35 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:35 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:35 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:35 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53014.
17/03/27 22:25:35 INFO NettyBlockTransferService: Server created on 53014
17/03/27 22:25:35 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:35 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53014 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53014)
17/03/27 22:25:35 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:35 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667935376
17/03/27 22:25:35 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:35 INFO BigDatalogContext: BigDatalog Query: "triangle_closing(A,B,C)"
17/03/27 22:25:35 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:35 INFO BigDatalogContext: 
0: (Y, Y, count(X) as C) <AGGREGATE>
 1: (Y, Y, X) <PROJECT>
  2: Y ~= Y <FILTER>
   3: (0.X = 1.X, 0.Y = 2.X, 1.Y = 2.Y) <JOIN>
    4: uarc(X, Y) <UNION>
     5: arc(X, Y) <BASE_RELATION>
     5: (Y, X) <PROJECT>
      6: arc(X, Y) <BASE_RELATION>
    4: uarc(X, Y) <UNION>
     5: arc(X, Y) <BASE_RELATION>
     5: (Y, X) <PROJECT>
      6: arc(X, Y) <BASE_RELATION>
    4: (0.Y = 0.X, 1.Y = 0.Y) <NEGATION>
     5: uarc(X, Y) <UNION>
      6: arc(X, Y) <BASE_RELATION>
      6: (Y, X) <PROJECT>
       7: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:35 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:35 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:35 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_triangle_closing
+- 'Aggregate ['uarc.Y,'uarc4.Y], ['uarc.Y,'uarc4.Y,unresolvedalias('count('uarc.X) AS C#457)]
   +- 'Project ['uarc.Y,'uarc4.Y,'uarc.X]
      +- 'Filter NOT ('uarc.Y = 'uarc4.Y)
         +- 'Filter (isnull('uarc7.X) && isnull('uarc7.Y))
            +- 'Join LeftOuter, Some((('uarc.Y = 'uarc7.X) && ('uarc4.Y = 'uarc7.Y)))
               :- 'Join Inner, Some(('uarc.X = 'uarc4.X))
               :  :- 'Distinct
               :  :  +- 'Subquery uarc
               :  :     +- 'Union
               :  :        :- 'UnresolvedRelation `arc`, None
               :  :        +- 'Project ['arc1.Y,'arc1.X]
               :  :           +- 'Subquery arc1
               :  :              +- 'Project [*]
               :  :                 +- 'UnresolvedRelation `arc`, None
               :  +- 'Distinct
               :     +- 'Subquery uarc4
               :        +- 'Union
               :           :- 'Subquery arc2
               :           :  +- 'Project [*]
               :           :     +- 'UnresolvedRelation `arc`, None
               :           +- 'Project ['arc3.Y,'arc3.X]
               :              +- 'Subquery arc3
               :                 +- 'Project [*]
               :                    +- 'UnresolvedRelation `arc`, None
               +- 'Distinct
                  +- 'Subquery uarc7
                     +- 'Union
                        :- 'Subquery arc5
                        :  +- 'Project [*]
                        :     +- 'UnresolvedRelation `arc`, None
                        +- 'Project ['arc6.Y,'arc6.X]
                           +- 'Subquery arc6
                              +- 'Project [*]
                                 +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
Y: int, Y: int, C: bigint
Subquery aggregate_triangle_closing
+- Aggregate [Y#456,Y#459], [Y#456,Y#459,(count(X#455),mode=Complete,isDistinct=false) AS C#457L]
   +- Project [Y#456,Y#459,X#455]
      +- Filter NOT (Y#456 = Y#459)
         +- Filter (isnull(X#462) && isnull(Y#463))
            +- Join LeftOuter, Some(((Y#456 = X#462) && (Y#459 = Y#463)))
               :- Join Inner, Some((X#455 = X#458))
               :  :- Distinct
               :  :  +- Subquery uarc
               :  :     +- Union
               :  :        :- Subquery arc
               :  :        :  +- LogicalRDD [X#455,Y#456], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :  :        +- Project [Y#456,X#455]
               :  :           +- Subquery arc1
               :  :              +- Project [X#455,Y#456]
               :  :                 +- Subquery arc
               :  :                    +- LogicalRDD [X#455,Y#456], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :  +- Distinct
               :     +- Subquery uarc4
               :        +- Union
               :           :- Subquery arc2
               :           :  +- Project [X#458,Y#459]
               :           :     +- Subquery arc
               :           :        +- LogicalRDD [X#458,Y#459], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           +- Project [Y#459,X#458]
               :              +- Subquery arc3
               :                 +- Project [X#458,Y#459]
               :                    +- Subquery arc
               :                       +- LogicalRDD [X#458,Y#459], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Distinct
                  +- Subquery uarc7
                     +- Union
                        :- Subquery arc5
                        :  +- Project [X#462,Y#463]
                        :     +- Subquery arc
                        :        +- LogicalRDD [X#462,Y#463], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
                        +- Project [Y#463,X#462]
                           +- Subquery arc6
                              +- Project [X#462,Y#463]
                                 +- Subquery arc
                                    +- LogicalRDD [X#462,Y#463], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [Y#456,Y#459], [Y#456,Y#459,(count(X#455),mode=Complete,isDistinct=false) AS C#457L]
+- Project [Y#456,Y#459,X#455]
   +- Filter (isnull(X#462) && isnull(Y#463))
      +- Join LeftOuter, Some(((Y#456 = X#462) && (Y#459 = Y#463)))
         :- Join Inner, Some((NOT (Y#456 = Y#459) && (X#455 = X#458)))
         :  :- Aggregate [X#455,Y#456], [X#455,Y#456]
         :  :  +- Union
         :  :     :- LogicalRDD [X#455,Y#456], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  :     +- Project [Y#456,X#455]
         :  :        +- LogicalRDD [X#455,Y#456], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Aggregate [X#458,Y#459], [X#458,Y#459]
         :     +- Union
         :        :- LogicalRDD [X#458,Y#459], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :        +- Project [Y#459,X#458]
         :           +- LogicalRDD [X#458,Y#459], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Aggregate [X#462,Y#463], [X#462,Y#463]
            +- Union
               :- LogicalRDD [X#462,Y#463], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Project [Y#463,X#462]
                  +- LogicalRDD [X#462,Y#463], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[Y#456,Y#459], functions=[(count(X#455),mode=Final,isDistinct=false)], output=[Y#456,Y#459,C#457L])
+- TungstenAggregate(key=[Y#456,Y#459], functions=[(count(X#455),mode=Partial,isDistinct=false)], output=[Y#456,Y#459,count#468L])
   +- Project [Y#456,Y#459,X#455]
      +- Filter (isnull(X#462) && isnull(Y#463))
         +- SortMergeOuterJoin [Y#456,Y#459], [X#462,Y#463], LeftOuter, None
            :- Sort [Y#456 ASC,Y#459 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(Y#456,Y#459,5), None
            :     +- Filter NOT (Y#456 = Y#459)
            :        +- SortMergeJoin [X#455], [X#458]
            :           :- Sort [X#455 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(X#455,5), None
            :           :     +- TungstenAggregate(key=[X#455,Y#456], functions=[], output=[X#455,Y#456])
            :           :        +- TungstenExchange hashpartitioning(X#455,Y#456,5), None
            :           :           +- TungstenAggregate(key=[X#455,Y#456], functions=[], output=[X#455,Y#456])
            :           :              +- Union
            :           :                 :- ConvertToUnsafe
            :           :                 :  +- Scan ExistingRDD[X#455,Y#456] 
            :           :                 +- Project [Y#456,X#455]
            :           :                    +- Scan ExistingRDD[X#455,Y#456] 
            :           +- Sort [X#458 ASC], false, 0
            :              +- TungstenExchange hashpartitioning(X#458,5), None
            :                 +- TungstenAggregate(key=[X#458,Y#459], functions=[], output=[X#458,Y#459])
            :                    +- TungstenExchange hashpartitioning(X#458,Y#459,5), None
            :                       +- TungstenAggregate(key=[X#458,Y#459], functions=[], output=[X#458,Y#459])
            :                          +- Union
            :                             :- ConvertToUnsafe
            :                             :  +- Scan ExistingRDD[X#458,Y#459] 
            :                             +- Project [Y#459,X#458]
            :                                +- Scan ExistingRDD[X#458,Y#459] 
            +- Sort [X#462 ASC,Y#463 ASC], false, 0
               +- TungstenAggregate(key=[X#462,Y#463], functions=[], output=[X#462,Y#463])
                  +- TungstenExchange hashpartitioning(X#462,Y#463,5), None
                     +- TungstenAggregate(key=[X#462,Y#463], functions=[], output=[X#462,Y#463])
                        +- Union
                           :- ConvertToUnsafe
                           :  +- Scan ExistingRDD[X#462,Y#463] 
                           +- Project [Y#463,X#462]
                              +- Scan ExistingRDD[X#462,Y#463]
17/03/27 22:25:35 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:35 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:35 INFO DAGScheduler: Registering RDD 30 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO DAGScheduler: Registering RDD 5 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO DAGScheduler: Registering RDD 15 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO DAGScheduler: Registering RDD 18 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:35 INFO DAGScheduler: Final stage: ResultStage 6 (collect at QuerySuite.scala:64)
17/03/27 22:25:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53014 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.3 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53014 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53014 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 3.0 with 10 tasks
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2445 bytes)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, partition 5,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
17/03/27 22:25:35 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, localhost, partition 9,PROCESS_LOCAL, 2445 bytes)
17/03/27 22:25:35 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
17/03/27 22:25:35 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 1.0 (TID 10)
17/03/27 22:25:35 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:35 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:35 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 1.0 (TID 11). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2445 bytes)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 1.0 (TID 14)
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 1.0 (TID 12). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 15, localhost, partition 5,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 5.0 in stage 1.0 (TID 15)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 81 ms on localhost (1/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 58 ms on localhost (2/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 56 ms on localhost (3/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 54 ms on localhost (4/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 44 ms on localhost (5/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 42 ms on localhost (6/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 37 ms on localhost (7/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 11) in 29 ms on localhost (1/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 12) in 27 ms on localhost (2/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 85 ms on localhost (8/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 85 ms on localhost (9/10)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 85 ms on localhost (10/10)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 1.0 (TID 13)
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.086 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 3)
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 1.0 (TID 10). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 16, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 10) in 43 ms on localhost (3/10)
17/03/27 22:25:35 INFO Executor: Running task 6.0 in stage 1.0 (TID 16)
17/03/27 22:25:35 INFO Executor: Finished task 5.0 in stage 1.0 (TID 15). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 17, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 1.0 (TID 14). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 15) in 29 ms on localhost (4/10)
17/03/27 22:25:35 INFO Executor: Running task 7.0 in stage 1.0 (TID 17)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 18, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 14) in 33 ms on localhost (5/10)
17/03/27 22:25:35 INFO Executor: Running task 8.0 in stage 1.0 (TID 18)
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 1.0 (TID 13). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 19, localhost, partition 9,PROCESS_LOCAL, 2445 bytes)
17/03/27 22:25:35 INFO Executor: Running task 9.0 in stage 1.0 (TID 19)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 13) in 41 ms on localhost (6/10)
17/03/27 22:25:35 INFO Executor: Finished task 6.0 in stage 1.0 (TID 16). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 3.0 (TID 20)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 16) in 15 ms on localhost (7/10)
17/03/27 22:25:35 INFO Executor: Finished task 8.0 in stage 1.0 (TID 18). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 18) in 13 ms on localhost (8/10)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 3.0 (TID 21)
17/03/27 22:25:35 INFO Executor: Finished task 9.0 in stage 1.0 (TID 19). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 22, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 19) in 13 ms on localhost (9/10)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 3.0 (TID 22)
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 3.0 (TID 20). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 23, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 20) in 13 ms on localhost (1/10)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 3.0 (TID 23)
17/03/27 22:25:35 INFO Executor: Finished task 7.0 in stage 1.0 (TID 17). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 24, localhost, partition 4,PROCESS_LOCAL, 2445 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 17) in 24 ms on localhost (10/10)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 3.0 (TID 24)
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.123 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2048.0 MB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53014 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 3.0 (TID 21). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 25, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 2.0 (TID 25)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 21) in 17 ms on localhost (2/10)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 3.0 (TID 23). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 26, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 2.0 (TID 26)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 23) in 17 ms on localhost (3/10)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 3.0 (TID 22). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 27, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 22) in 20 ms on localhost (4/10)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 2.0 (TID 27)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 3.0 (TID 24). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 28, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 24) in 14 ms on localhost (5/10)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 2.0 (TID 28)
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 2.0 (TID 26). 1874 bytes result sent to driver
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 29, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 26) in 7 ms on localhost (1/5)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 2.0 (TID 29)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 2.0 (TID 25). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 30, localhost, partition 5,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 25) in 20 ms on localhost (2/5)
17/03/27 22:25:35 INFO Executor: Running task 5.0 in stage 3.0 (TID 30)
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 2.0 (TID 28). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 31, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO Executor: Running task 6.0 in stage 3.0 (TID 31)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 28) in 19 ms on localhost (3/5)
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 2.0 (TID 29). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 32, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 29) in 21 ms on localhost (4/5)
17/03/27 22:25:35 INFO Executor: Running task 7.0 in stage 3.0 (TID 32)
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 2.0 (TID 27). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 33, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 27) in 28 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.037 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO Executor: Running task 8.0 in stage 3.0 (TID 33)
17/03/27 22:25:35 INFO Executor: Finished task 5.0 in stage 3.0 (TID 30). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 34, localhost, partition 9,PROCESS_LOCAL, 2445 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 30) in 19 ms on localhost (6/10)
17/03/27 22:25:35 INFO Executor: Running task 9.0 in stage 3.0 (TID 34)
17/03/27 22:25:35 INFO Executor: Finished task 6.0 in stage 3.0 (TID 31). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 31) in 18 ms on localhost (7/10)
17/03/27 22:25:35 INFO Executor: Finished task 7.0 in stage 3.0 (TID 32). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 32) in 16 ms on localhost (8/10)
17/03/27 22:25:35 INFO Executor: Finished task 8.0 in stage 3.0 (TID 33). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 33) in 16 ms on localhost (9/10)
17/03/27 22:25:35 INFO Executor: Finished task 9.0 in stage 3.0 (TID 34). 1495 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 34) in 12 ms on localhost (10/10)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.177 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set()
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53014 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 35, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 36, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 37, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 38, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 4.0 (TID 35)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 4.0 (TID 36)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 4.0 (TID 37)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 4.0 (TID 38)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 4.0 (TID 36). 1874 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 39, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 36) in 12 ms on localhost (1/5)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 4.0 (TID 39)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 4.0 (TID 35). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 35) in 21 ms on localhost (2/5)
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 4.0 (TID 37). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 37) in 23 ms on localhost (3/5)
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 4.0 (TID 38). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 38) in 24 ms on localhost (4/5)
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 4.0 (TID 39). 1883 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 39) in 15 ms on localhost (5/5)
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.026 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set()
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53014 (size: 6.1 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 42, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 43, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 5.0 (TID 40)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 5.0 (TID 41)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 5.0 (TID 42)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 5.0 (TID 43)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 5.0 (TID 42). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 44, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 42) in 14 ms on localhost (1/5)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 5.0 (TID 44)
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 5.0 (TID 43). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 43) in 16 ms on localhost (2/5)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 5.0 (TID 40). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 40) in 18 ms on localhost (3/5)
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 5.0 (TID 41). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 41) in 21 ms on localhost (4/5)
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 5.0 (TID 44). 2657 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 44) in 13 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ShuffleMapStage 5 (rdd at BigDatalogProgram.scala:41) finished in 0.027 s
17/03/27 22:25:35 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:35 INFO DAGScheduler: running: Set()
17/03/27 22:25:35 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/03/27 22:25:35 INFO DAGScheduler: failed: Set()
17/03/27 22:25:35 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 20.5 KB, free 2.0 GB)
17/03/27 22:25:35 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:35 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53014 (size: 8.2 KB, free: 2.0 GB)
17/03/27 22:25:35 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:35 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 45, localhost, partition 0,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 46, localhost, partition 1,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 47, localhost, partition 2,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 48, localhost, partition 3,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 45)
17/03/27 22:25:35 INFO Executor: Running task 2.0 in stage 6.0 (TID 47)
17/03/27 22:25:35 INFO Executor: Running task 3.0 in stage 6.0 (TID 48)
17/03/27 22:25:35 INFO Executor: Running task 1.0 in stage 6.0 (TID 46)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 1.0 in stage 6.0 (TID 46). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO Executor: Finished task 2.0 in stage 6.0 (TID 47). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO Executor: Finished task 3.0 in stage 6.0 (TID 48). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 49, localhost, partition 4,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:35 INFO Executor: Running task 4.0 in stage 6.0 (TID 49)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 46) in 8 ms on localhost (1/5)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 47) in 8 ms on localhost (2/5)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 48) in 8 ms on localhost (3/5)
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Getting 10 non-empty blocks out of 10 blocks
17/03/27 22:25:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:35 INFO Executor: Finished task 0.0 in stage 6.0 (TID 45). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO Executor: Finished task 4.0 in stage 6.0 (TID 49). 3613 bytes result sent to driver
17/03/27 22:25:35 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 45) in 16 ms on localhost (4/5)
17/03/27 22:25:35 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 49) in 8 ms on localhost (5/5)
17/03/27 22:25:35 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:35 INFO DAGScheduler: ResultStage 6 (collect at QuerySuite.scala:64) finished in 0.017 s
17/03/27 22:25:35 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.269589 s
17/03/27 22:25:35 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:35 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:35 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:35 INFO BlockManager: BlockManager stopped
17/03/27 22:25:35 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:35 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:35 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:35 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:35 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:35 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:35 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:35 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:35 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:35 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:36 INFO Utils: Successfully started service 'sparkDriver' on port 53032.
17/03/27 22:25:36 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:36 INFO Remoting: Starting remoting
17/03/27 22:25:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53045]
17/03/27 22:25:36 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53045.
17/03/27 22:25:36 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:36 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:36 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-cfee2747-1cba-4fdc-82f3-11f205bd5bb9
17/03/27 22:25:36 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:36 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:36 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53062.
17/03/27 22:25:36 INFO NettyBlockTransferService: Server created on 53062
17/03/27 22:25:36 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53062 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53062)
17/03/27 22:25:36 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:36 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667936049
17/03/27 22:25:36 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:36 INFO BigDatalogContext: BigDatalog Query: "triangle_closing(A,B,C)"
17/03/27 22:25:36 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:36 INFO BigDatalogContext: 
0: (Y, Y, count(X) as C) <AGGREGATE>
 1: (Y, Y, X) <PROJECT>
  2: Y ~= Y <FILTER>
   3: (0.X = 1.X, 0.Y = 2.X, 1.Y = 2.Y) <JOIN>
    4: uarc(X, Y) <UNION>
     5: arc(X, Y) <BASE_RELATION>
     5: (Y, X) <PROJECT>
      6: arc(X, Y) <BASE_RELATION>
    4: uarc(X, Y) <UNION>
     5: arc(X, Y) <BASE_RELATION>
     5: (Y, X) <PROJECT>
      6: arc(X, Y) <BASE_RELATION>
    4: (0.Y = 0.X, 1.Y = 0.Y) <NEGATION>
     5: uarc(X, Y) <UNION>
      6: arc(X, Y) <BASE_RELATION>
      6: (Y, X) <PROJECT>
       7: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:36 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:36 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:36 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_triangle_closing
+- 'Aggregate ['uarc.Y,'uarc4.Y], ['uarc.Y,'uarc4.Y,unresolvedalias('count('uarc.X) AS C#482)]
   +- 'Project ['uarc.Y,'uarc4.Y,'uarc.X]
      +- 'Filter NOT ('uarc.Y = 'uarc4.Y)
         +- 'Filter (isnull('uarc7.X) && isnull('uarc7.Y))
            +- 'Join LeftOuter, Some((('uarc.Y = 'uarc7.X) && ('uarc4.Y = 'uarc7.Y)))
               :- 'Join Inner, Some(('uarc.X = 'uarc4.X))
               :  :- 'Distinct
               :  :  +- 'Subquery uarc
               :  :     +- 'Union
               :  :        :- 'UnresolvedRelation `arc`, None
               :  :        +- 'Project ['arc1.Y,'arc1.X]
               :  :           +- 'Subquery arc1
               :  :              +- 'Project [*]
               :  :                 +- 'UnresolvedRelation `arc`, None
               :  +- 'Distinct
               :     +- 'Subquery uarc4
               :        +- 'Union
               :           :- 'Subquery arc2
               :           :  +- 'Project [*]
               :           :     +- 'UnresolvedRelation `arc`, None
               :           +- 'Project ['arc3.Y,'arc3.X]
               :              +- 'Subquery arc3
               :                 +- 'Project [*]
               :                    +- 'UnresolvedRelation `arc`, None
               +- 'Distinct
                  +- 'Subquery uarc7
                     +- 'Union
                        :- 'Subquery arc5
                        :  +- 'Project [*]
                        :     +- 'UnresolvedRelation `arc`, None
                        +- 'Project ['arc6.Y,'arc6.X]
                           +- 'Subquery arc6
                              +- 'Project [*]
                                 +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
Y: int, Y: int, C: bigint
Subquery aggregate_triangle_closing
+- Aggregate [Y#481,Y#484], [Y#481,Y#484,(count(X#480),mode=Complete,isDistinct=false) AS C#482L]
   +- Project [Y#481,Y#484,X#480]
      +- Filter NOT (Y#481 = Y#484)
         +- Filter (isnull(X#487) && isnull(Y#488))
            +- Join LeftOuter, Some(((Y#481 = X#487) && (Y#484 = Y#488)))
               :- Join Inner, Some((X#480 = X#483))
               :  :- Distinct
               :  :  +- Subquery uarc
               :  :     +- Union
               :  :        :- Subquery arc
               :  :        :  +- LogicalRDD [X#480,Y#481], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :  :        +- Project [Y#481,X#480]
               :  :           +- Subquery arc1
               :  :              +- Project [X#480,Y#481]
               :  :                 +- Subquery arc
               :  :                    +- LogicalRDD [X#480,Y#481], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :  +- Distinct
               :     +- Subquery uarc4
               :        +- Union
               :           :- Subquery arc2
               :           :  +- Project [X#483,Y#484]
               :           :     +- Subquery arc
               :           :        +- LogicalRDD [X#483,Y#484], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           +- Project [Y#484,X#483]
               :              +- Subquery arc3
               :                 +- Project [X#483,Y#484]
               :                    +- Subquery arc
               :                       +- LogicalRDD [X#483,Y#484], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Distinct
                  +- Subquery uarc7
                     +- Union
                        :- Subquery arc5
                        :  +- Project [X#487,Y#488]
                        :     +- Subquery arc
                        :        +- LogicalRDD [X#487,Y#488], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
                        +- Project [Y#488,X#487]
                           +- Subquery arc6
                              +- Project [X#487,Y#488]
                                 +- Subquery arc
                                    +- LogicalRDD [X#487,Y#488], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [Y#481,Y#484], [Y#481,Y#484,(count(X#480),mode=Complete,isDistinct=false) AS C#482L]
+- Project [Y#481,Y#484,X#480]
   +- Filter (isnull(X#487) && isnull(Y#488))
      +- Join LeftOuter, Some(((Y#481 = X#487) && (Y#484 = Y#488)))
         :- Join Inner, Some((NOT (Y#481 = Y#484) && (X#480 = X#483)))
         :  :- Aggregate [X#480,Y#481], [X#480,Y#481]
         :  :  +- Union
         :  :     :- LogicalRDD [X#480,Y#481], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  :     +- Project [Y#481,X#480]
         :  :        +- LogicalRDD [X#480,Y#481], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Aggregate [X#483,Y#484], [X#483,Y#484]
         :     +- Union
         :        :- LogicalRDD [X#483,Y#484], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :        +- Project [Y#484,X#483]
         :           +- LogicalRDD [X#483,Y#484], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Aggregate [X#487,Y#488], [X#487,Y#488]
            +- Union
               :- LogicalRDD [X#487,Y#488], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Project [Y#488,X#487]
                  +- LogicalRDD [X#487,Y#488], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[Y#481,Y#484], functions=[(count(X#480),mode=Final,isDistinct=false)], output=[Y#481,Y#484,C#482L])
+- TungstenAggregate(key=[Y#481,Y#484], functions=[(count(X#480),mode=Partial,isDistinct=false)], output=[Y#481,Y#484,count#493L])
   +- Project [Y#481,Y#484,X#480]
      +- Filter (isnull(X#487) && isnull(Y#488))
         +- SortMergeOuterJoin [Y#481,Y#484], [X#487,Y#488], LeftOuter, None
            :- Sort [Y#481 ASC,Y#484 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(Y#481,Y#484,5), None
            :     +- Filter NOT (Y#481 = Y#484)
            :        +- SortMergeJoin [X#480], [X#483]
            :           :- Sort [X#480 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(X#480,5), None
            :           :     +- TungstenAggregate(key=[X#480,Y#481], functions=[], output=[X#480,Y#481])
            :           :        +- TungstenExchange hashpartitioning(X#480,Y#481,5), None
            :           :           +- TungstenAggregate(key=[X#480,Y#481], functions=[], output=[X#480,Y#481])
            :           :              +- Union
            :           :                 :- ConvertToUnsafe
            :           :                 :  +- Scan ExistingRDD[X#480,Y#481] 
            :           :                 +- Project [Y#481,X#480]
            :           :                    +- Scan ExistingRDD[X#480,Y#481] 
            :           +- Sort [X#483 ASC], false, 0
            :              +- TungstenExchange hashpartitioning(X#483,5), None
            :                 +- TungstenAggregate(key=[X#483,Y#484], functions=[], output=[X#483,Y#484])
            :                    +- TungstenExchange hashpartitioning(X#483,Y#484,5), None
            :                       +- TungstenAggregate(key=[X#483,Y#484], functions=[], output=[X#483,Y#484])
            :                          +- Union
            :                             :- ConvertToUnsafe
            :                             :  +- Scan ExistingRDD[X#483,Y#484] 
            :                             +- Project [Y#484,X#483]
            :                                +- Scan ExistingRDD[X#483,Y#484] 
            +- Sort [X#487 ASC,Y#488 ASC], false, 0
               +- TungstenAggregate(key=[X#487,Y#488], functions=[], output=[X#487,Y#488])
                  +- TungstenExchange hashpartitioning(X#487,Y#488,5), None
                     +- TungstenAggregate(key=[X#487,Y#488], functions=[], output=[X#487,Y#488])
                        +- Union
                           :- ConvertToUnsafe
                           :  +- Scan ExistingRDD[X#487,Y#488] 
                           +- Project [Y#488,X#487]
                              +- Scan ExistingRDD[X#487,Y#488]
17/03/27 22:25:36 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:36 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:36 INFO DAGScheduler: Registering RDD 30 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO DAGScheduler: Registering RDD 5 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO DAGScheduler: Registering RDD 15 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO DAGScheduler: Registering RDD 18 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:36 INFO DAGScheduler: Final stage: ResultStage 6 (collect at QuerySuite.scala:64)
17/03/27 22:25:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:36 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53062 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks
17/03/27 22:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.3 KB, free 2.0 GB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53062 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks
17/03/27 22:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.2 KB, free 2.0 GB)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53062 (size: 4.2 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 3.0 with 10 tasks
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1486 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:36 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
17/03/27 22:25:36 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 1486 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
17/03/27 22:25:36 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 26 ms on localhost (1/10)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 30 ms on localhost (2/10)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 82 ms on localhost (3/10)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 45 ms on localhost (4/10)
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 110 ms on localhost (5/10)
17/03/27 22:25:36 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 111 ms on localhost (6/10)
17/03/27 22:25:36 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 114 ms on localhost (7/10)
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 1.0 (TID 10)
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 1.0 (TID 10). 1486 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 10) in 6 ms on localhost (1/10)
17/03/27 22:25:36 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 12 ms on localhost (8/10)
17/03/27 22:25:36 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 63 ms on localhost (9/10)
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 1.0 (TID 13)
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 1.0 (TID 12). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 12) in 12 ms on localhost (2/10)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 1.0 (TID 14)
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 1.0 (TID 13). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 15, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 13) in 13 ms on localhost (3/10)
17/03/27 22:25:36 INFO Executor: Running task 5.0 in stage 1.0 (TID 15)
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 1.0 (TID 14). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 16, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO Executor: Running task 6.0 in stage 1.0 (TID 16)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 14) in 11 ms on localhost (4/10)
17/03/27 22:25:36 INFO Executor: Finished task 5.0 in stage 1.0 (TID 15). 1486 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 17, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO Executor: Running task 7.0 in stage 1.0 (TID 17)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 15) in 15 ms on localhost (5/10)
17/03/27 22:25:36 INFO Executor: Finished task 6.0 in stage 1.0 (TID 16). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 18, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 16) in 14 ms on localhost (6/10)
17/03/27 22:25:36 INFO Executor: Running task 8.0 in stage 1.0 (TID 18)
17/03/27 22:25:36 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 19, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 54 ms on localhost (10/10)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO Executor: Running task 9.0 in stage 1.0 (TID 19)
17/03/27 22:25:36 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.168 s
17/03/27 22:25:36 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:36 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 3)
17/03/27 22:25:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:36 INFO DAGScheduler: failed: Set()
17/03/27 22:25:36 INFO Executor: Finished task 7.0 in stage 1.0 (TID 17). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 20, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 17) in 18 ms on localhost (7/10)
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 3.0 (TID 20)
17/03/27 22:25:36 INFO Executor: Finished task 8.0 in stage 1.0 (TID 18). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 21, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 18) in 32 ms on localhost (8/10)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 3.0 (TID 21)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:36 INFO Executor: Finished task 9.0 in stage 1.0 (TID 19). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 22, localhost, partition 2,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 19) in 43 ms on localhost (9/10)
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 3.0 (TID 22)
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 1.0 (TID 11). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 23, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 11) in 87 ms on localhost (10/10)
17/03/27 22:25:36 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.203 s
17/03/27 22:25:36 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:36 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 2, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:36 INFO DAGScheduler: failed: Set()
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 3.0 (TID 23)
17/03/27 22:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.6 KB, free 1983.7 MB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2016.0 MB)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53062 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 3.0 (TID 22). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 24, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 22) in 11 ms on localhost (1/10)
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 2.0 (TID 24)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 3.0 (TID 23). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 25, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 23) in 12 ms on localhost (2/10)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 2.0 (TID 25)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 3.0 (TID 21). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 26, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 21) in 42 ms on localhost (3/10)
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 3.0 (TID 20). 1486 bytes result sent to driver
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 2.0 (TID 26)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 27, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 20) in 61 ms on localhost (4/10)
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 2.0 (TID 27)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 2.0 (TID 25). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 28, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 25) in 20 ms on localhost (1/5)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 2.0 (TID 28)
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 2.0 (TID 24). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 29, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 24) in 27 ms on localhost (2/5)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 3.0 (TID 29)
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 2.0 (TID 26). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 30, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 26) in 20 ms on localhost (3/5)
17/03/27 22:25:36 INFO Executor: Running task 5.0 in stage 3.0 (TID 30)
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 2.0 (TID 27). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 31, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 27) in 20 ms on localhost (4/5)
17/03/27 22:25:36 INFO Executor: Running task 6.0 in stage 3.0 (TID 31)
17/03/27 22:25:36 INFO Executor: Finished task 5.0 in stage 3.0 (TID 30). 1486 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 32, localhost, partition 7,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 30) in 4 ms on localhost (5/10)
17/03/27 22:25:36 INFO Executor: Running task 7.0 in stage 3.0 (TID 32)
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 3.0 (TID 29). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 33, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 29) in 16 ms on localhost (6/10)
17/03/27 22:25:36 INFO Executor: Running task 8.0 in stage 3.0 (TID 33)
17/03/27 22:25:36 INFO Executor: Finished task 6.0 in stage 3.0 (TID 31). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 34, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 31) in 15 ms on localhost (7/10)
17/03/27 22:25:36 INFO Executor: Running task 9.0 in stage 3.0 (TID 34)
17/03/27 22:25:36 INFO Executor: Finished task 7.0 in stage 3.0 (TID 32). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 32) in 16 ms on localhost (8/10)
17/03/27 22:25:36 INFO Executor: Finished task 8.0 in stage 3.0 (TID 33). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 33) in 14 ms on localhost (9/10)
17/03/27 22:25:36 INFO Executor: Finished task 9.0 in stage 3.0 (TID 34). 1495 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 34) in 10 ms on localhost (10/10)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.273 s
17/03/27 22:25:36 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:36 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
17/03/27 22:25:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:36 INFO DAGScheduler: failed: Set()
17/03/27 22:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[18] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53062 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[18] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 35, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 36, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 37, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 4.0 (TID 35)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 4.0 (TID 36)
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 4.0 (TID 37)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 4.0 (TID 37). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 38, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 37) in 19 ms on localhost (1/5)
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 4.0 (TID 38)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 4.0 (TID 36). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 39, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 36) in 24 ms on localhost (2/5)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 4.0 (TID 39)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 4.0 (TID 38). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 38) in 15 ms on localhost (3/5)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 2.0 (TID 28). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 28) in 94 ms on localhost (5/5)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.121 s
17/03/27 22:25:36 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:36 INFO DAGScheduler: running: Set(ShuffleMapStage 4)
17/03/27 22:25:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/27 22:25:36 INFO DAGScheduler: failed: Set()
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 4.0 (TID 35). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 35) in 54 ms on localhost (4/5)
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 4.0 (TID 39). 1883 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 39) in 35 ms on localhost (5/5)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.059 s
17/03/27 22:25:36 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:36 INFO DAGScheduler: running: Set()
17/03/27 22:25:36 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/27 22:25:36 INFO DAGScheduler: failed: Set()
17/03/27 22:25:36 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.5 KB, free 2.0 GB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2.0 GB)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53062 (size: 6.1 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 42, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 43, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 40)
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 5.0 (TID 42)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 5.0 (TID 41)
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 5.0 (TID 43)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 5.0 (TID 40). 2657 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 44, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 40) in 18 ms on localhost (1/5)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 5.0 (TID 44)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 5.0 (TID 41). 2657 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 41) in 20 ms on localhost (2/5)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 5.0 (TID 42). 2657 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 42) in 22 ms on localhost (3/5)
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 5.0 (TID 43). 2657 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 43) in 30 ms on localhost (4/5)
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 5.0 (TID 44). 2657 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 44) in 13 ms on localhost (5/5)
17/03/27 22:25:36 INFO DAGScheduler: ShuffleMapStage 5 (rdd at BigDatalogProgram.scala:41) finished in 0.031 s
17/03/27 22:25:36 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:36 INFO DAGScheduler: running: Set()
17/03/27 22:25:36 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/03/27 22:25:36 INFO DAGScheduler: failed: Set()
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 20.5 KB, free 2.0 GB)
17/03/27 22:25:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53062 (size: 8.2 KB, free: 2.0 GB)
17/03/27 22:25:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:36 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:36 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 45, localhost, partition 0,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 46, localhost, partition 1,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 47, localhost, partition 2,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:36 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 48, localhost, partition 3,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:36 INFO Executor: Running task 0.0 in stage 6.0 (TID 45)
17/03/27 22:25:36 INFO Executor: Running task 1.0 in stage 6.0 (TID 46)
17/03/27 22:25:36 INFO Executor: Running task 2.0 in stage 6.0 (TID 47)
17/03/27 22:25:36 INFO Executor: Running task 3.0 in stage 6.0 (TID 48)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 1.0 in stage 6.0 (TID 46). 4801 bytes result sent to driver
17/03/27 22:25:36 INFO Executor: Finished task 3.0 in stage 6.0 (TID 48). 4801 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 49, localhost, partition 4,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:36 INFO Executor: Running task 4.0 in stage 6.0 (TID 49)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 46) in 11 ms on localhost (1/5)
17/03/27 22:25:36 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 48) in 12 ms on localhost (2/5)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 2.0 in stage 6.0 (TID 47). 4801 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 47) in 16 ms on localhost (3/5)
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:36 INFO Executor: Finished task 0.0 in stage 6.0 (TID 45). 3613 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 45) in 24 ms on localhost (4/5)
17/03/27 22:25:36 INFO Executor: Finished task 4.0 in stage 6.0 (TID 49). 4801 bytes result sent to driver
17/03/27 22:25:36 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 49) in 17 ms on localhost (5/5)
17/03/27 22:25:36 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:36 INFO DAGScheduler: ResultStage 6 (collect at QuerySuite.scala:64) finished in 0.028 s
17/03/27 22:25:36 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.418169 s
17/03/27 22:25:36 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:36 INFO BlockManager: BlockManager stopped
17/03/27 22:25:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:36 INFO SparkContext: Successfully stopped SparkContext
[32m- Triangle Closing - fff[0m
17/03/27 22:25:36 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:36 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:36 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:36 INFO Utils: Successfully started service 'sparkDriver' on port 53080.
17/03/27 22:25:36 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:36 INFO Remoting: Starting remoting
17/03/27 22:25:36 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53093]
17/03/27 22:25:36 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53093.
17/03/27 22:25:36 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:36 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:36 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-28797a21-dca7-43a5-a796-3c81c3a5c0bc
17/03/27 22:25:36 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:36 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:36 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:36 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53110.
17/03/27 22:25:36 INFO NettyBlockTransferService: Server created on 53110
17/03/27 22:25:36 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:36 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53110 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53110)
17/03/27 22:25:36 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:36 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667936930
17/03/27 22:25:37 INFO TriangleQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:37 INFO BigDatalogContext: BigDatalog Query: "pymk(A,B)"
17/03/27 22:25:37 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:37 INFO BigDatalogContext: 
0: (Y, W9) <DISTINCT PROJECT>
 1: topK_pymk4(10) <LIMIT>
  2: topK_pymk4(Y, W9, Z)[[2,DESC]] <SORT>
   3: (Y, W9, Z) <PROJECT>
    4: (0.Y = 1.W1) <JOIN>
     5: (Y, count(X) as Z) <AGGREGATE>
      6: (Y, X) <PROJECT>
       7: (0.X = 1.X, 0.Y = 2.X) <JOIN>
        8: Y ~= 0 <FILTER>
         9: uarc(X, Y) <UNION>
          10: arc(X, Y) <BASE_RELATION>
          10: (Y, X) <PROJECT>
           11: arc(X, Y) <BASE_RELATION>
        8: uarc(X, 0) <UNION>
         9: (X) <PROJECT>
          10: Y = 0 <FILTER>
           11: arc(X, Y) <BASE_RELATION>
         9: (Y, Y) <PROJECT>
          10: X = 0 <FILTER>
           11: arc(X, Y) <BASE_RELATION>
        8: (0.Y = 0.X) <NEGATION>
         9: uarc(X, 0) <UNION>
          10: (X) <PROJECT>
           11: Y = 0 <FILTER>
            12: arc(X, Y) <BASE_RELATION>
          10: (Y, Y) <PROJECT>
           11: X = 0 <FILTER>
            12: arc(X, Y) <BASE_RELATION>
     5: pages(W1, W2, W3, W4, W5, W6, W7, W8, W9) <BASE_RELATION>
17/03/27 22:25:37 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:37 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:37 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['aggregate_triangle_closing.Y,'pages.W9]
   +- 'Limit 10
      +- 'Sort ['aggregate_triangle_closing.Z DESC], true
         +- 'Project ['aggregate_triangle_closing.Y,'pages.W9,'aggregate_triangle_closing.Z]
            +- 'Join Inner, Some(('aggregate_triangle_closing.Y = 'pages.W1))
               :- 'Subquery aggregate_triangle_closing
               :  +- 'Aggregate ['uarc.Y], ['uarc.Y,unresolvedalias('count('uarc.X) AS Z#518)]
               :     +- 'Project ['uarc.Y,'uarc.X]
               :        +- 'Filter isnull('uarc7.X)
               :           +- 'Join LeftOuter, Some(('uarc.Y = 'uarc7.X))
               :              :- 'Join Inner, Some(('uarc.X = 'uarc4.X))
               :              :  :- 'Filter NOT ('uarc.Y = 0)
               :              :  :  +- 'Distinct
               :              :  :     +- 'Subquery uarc
               :              :  :        +- 'Union
               :              :  :           :- 'UnresolvedRelation `arc`, None
               :              :  :           +- 'Project ['arc1.Y,'arc1.X]
               :              :  :              +- 'Subquery arc1
               :              :  :                 +- 'Project [*]
               :              :  :                    +- 'UnresolvedRelation `arc`, None
               :              :  +- 'Distinct
               :              :     +- 'Subquery uarc4
               :              :        +- 'Union
               :              :           :- 'Project ['arc2.X,unresolvedalias(0 AS c_0#516)]
               :              :           :  +- 'Filter ('arc2.Y = 0)
               :              :           :     +- 'Subquery arc2
               :              :           :        +- 'Project [*]
               :              :           :           +- 'UnresolvedRelation `arc`, None
               :              :           +- 'Project ['arc3.Y,'arc3.Y]
               :              :              +- 'Filter ('arc3.X = 0)
               :              :                 +- 'Subquery arc3
               :              :                    +- 'Project [*]
               :              :                       +- 'UnresolvedRelation `arc`, None
               :              +- 'Distinct
               :                 +- 'Subquery uarc7
               :                    +- 'Union
               :                       :- 'Project ['arc5.X,unresolvedalias(0 AS c_0#517)]
               :                       :  +- 'Filter ('arc5.Y = 0)
               :                       :     +- 'Subquery arc5
               :                       :        +- 'Project [*]
               :                       :           +- 'UnresolvedRelation `arc`, None
               :                       +- 'Project ['arc6.Y,'arc6.Y]
               :                          +- 'Filter ('arc6.X = 0)
               :                             +- 'Subquery arc6
               :                                +- 'Project [*]
               :                                   +- 'UnresolvedRelation `arc`, None
               +- 'UnresolvedRelation `pages`, None

== Analyzed Logical Plan ==
Y: int, W9: int
Distinct
+- Project [Y#506,W9#515]
   +- Limit 10
      +- Sort [Z#518L DESC], true
         +- Project [Y#506,W9#515,Z#518L]
            +- Join Inner, Some((Y#506 = W1#507))
               :- Subquery aggregate_triangle_closing
               :  +- Aggregate [Y#506], [Y#506,(count(X#505),mode=Complete,isDistinct=false) AS Z#518L]
               :     +- Project [Y#506,X#505]
               :        +- Filter isnull(X#523)
               :           +- Join LeftOuter, Some((Y#506 = X#523))
               :              :- Join Inner, Some((X#505 = X#519))
               :              :  :- Filter NOT (Y#506 = 0)
               :              :  :  +- Distinct
               :              :  :     +- Subquery uarc
               :              :  :        +- Union
               :              :  :           :- Subquery arc
               :              :  :           :  +- LogicalRDD [X#505,Y#506], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :              :  :           +- Project [Y#506,X#505]
               :              :  :              +- Subquery arc1
               :              :  :                 +- Project [X#505,Y#506]
               :              :  :                    +- Subquery arc
               :              :  :                       +- LogicalRDD [X#505,Y#506], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :              :  +- Distinct
               :              :     +- Subquery uarc4
               :              :        +- Union
               :              :           :- Project [X#519,0 AS c_0#516]
               :              :           :  +- Filter (Y#520 = 0)
               :              :           :     +- Subquery arc2
               :              :           :        +- Project [X#519,Y#520]
               :              :           :           +- Subquery arc
               :              :           :              +- LogicalRDD [X#519,Y#520], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :              :           +- Project [Y#520,Y#520]
               :              :              +- Filter (X#519 = 0)
               :              :                 +- Subquery arc3
               :              :                    +- Project [X#519,Y#520]
               :              :                       +- Subquery arc
               :              :                          +- LogicalRDD [X#519,Y#520], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :              +- Distinct
               :                 +- Subquery uarc7
               :                    +- Union
               :                       :- Project [X#523,0 AS c_0#517]
               :                       :  +- Filter (Y#524 = 0)
               :                       :     +- Subquery arc5
               :                       :        +- Project [X#523,Y#524]
               :                       :           +- Subquery arc
               :                       :              +- LogicalRDD [X#523,Y#524], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :                       +- Project [Y#524,Y#524]
               :                          +- Filter (X#523 = 0)
               :                             +- Subquery arc6
               :                                +- Project [X#523,Y#524]
               :                                   +- Subquery arc
               :                                      +- LogicalRDD [X#523,Y#524], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Subquery pages
                  +- LogicalRDD [W1#507,W2#508,W3#509,W4#510,W5#511,W6#512,W7#513,W8#514,W9#515], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [Y#506,W9#515], [Y#506,W9#515]
+- Limit 10
   +- Project [Y#506,W9#515]
      +- Sort [Z#518L DESC], true
         +- Project [Y#506,W9#515,Z#518L]
            +- Join Inner, Some((Y#506 = W1#507))
               :- Aggregate [Y#506], [Y#506,(count(X#505),mode=Complete,isDistinct=false) AS Z#518L]
               :  +- Project [Y#506,X#505]
               :     +- Filter isnull(X#523)
               :        +- Join LeftOuter, Some((Y#506 = X#523))
               :           :- Join Inner, Some((X#505 = X#519))
               :           :  :- Aggregate [X#505,Y#506], [X#505,Y#506]
               :           :  :  +- Union
               :           :  :     :- Filter NOT (Y#506 = 0)
               :           :  :     :  +- LogicalRDD [X#505,Y#506], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           :  :     +- Project [Y#506,X#505]
               :           :  :        +- Filter NOT (X#505 = 0)
               :           :  :           +- LogicalRDD [X#505,Y#506], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           :  +- Aggregate [X#519,c_0#516], [X#519,c_0#516]
               :           :     +- Union
               :           :        :- Project [X#519,0 AS c_0#516]
               :           :        :  +- Filter (Y#520 = 0)
               :           :        :     +- LogicalRDD [X#519,Y#520], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           :        +- Project [Y#520,Y#520]
               :           :           +- Filter (X#519 = 0)
               :           :              +- LogicalRDD [X#519,Y#520], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :           +- Aggregate [X#523,c_0#517], [X#523,c_0#517]
               :              +- Union
               :                 :- Project [X#523,0 AS c_0#517]
               :                 :  +- Filter (Y#524 = 0)
               :                 :     +- LogicalRDD [X#523,Y#524], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               :                 +- Project [Y#524,Y#524]
               :                    +- Filter (X#523 = 0)
               :                       +- LogicalRDD [X#523,Y#524], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Project [W9#515,W1#507]
                  +- LogicalRDD [W1#507,W2#508,W3#509,W4#510,W5#511,W6#512,W7#513,W8#514,W9#515], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[Y#506,W9#515], functions=[], output=[Y#506,W9#515])
+- TungstenAggregate(key=[Y#506,W9#515], functions=[], output=[Y#506,W9#515])
   +- TakeOrderedAndProject(limit=10, orderBy=[Z#518L DESC], output=[Y#506,W9#515])
      +- ConvertToSafe
         +- Project [Y#506,W9#515,Z#518L]
            +- SortMergeJoin [Y#506], [W1#507]
               :- Sort [Y#506 ASC], false, 0
               :  +- TungstenAggregate(key=[Y#506], functions=[(count(X#505),mode=Final,isDistinct=false)], output=[Y#506,Z#518L])
               :     +- TungstenAggregate(key=[Y#506], functions=[(count(X#505),mode=Partial,isDistinct=false)], output=[Y#506,count#529L])
               :        +- Project [Y#506,X#505]
               :           +- Filter isnull(X#523)
               :              +- SortMergeOuterJoin [Y#506], [X#523], LeftOuter, None
               :                 :- Sort [Y#506 ASC], false, 0
               :                 :  +- TungstenExchange hashpartitioning(Y#506,5), None
               :                 :     +- SortMergeJoin [X#505], [X#519]
               :                 :        :- Sort [X#505 ASC], false, 0
               :                 :        :  +- TungstenExchange hashpartitioning(X#505,5), None
               :                 :        :     +- TungstenAggregate(key=[X#505,Y#506], functions=[], output=[X#505,Y#506])
               :                 :        :        +- TungstenExchange hashpartitioning(X#505,Y#506,5), None
               :                 :        :           +- TungstenAggregate(key=[X#505,Y#506], functions=[], output=[X#505,Y#506])
               :                 :        :              +- Union
               :                 :        :                 :- ConvertToUnsafe
               :                 :        :                 :  +- Filter NOT (Y#506 = 0)
               :                 :        :                 :     +- Scan ExistingRDD[X#505,Y#506] 
               :                 :        :                 +- Project [Y#506,X#505]
               :                 :        :                    +- Filter NOT (X#505 = 0)
               :                 :        :                       +- Scan ExistingRDD[X#505,Y#506] 
               :                 :        +- Sort [X#519 ASC], false, 0
               :                 :           +- TungstenExchange hashpartitioning(X#519,5), None
               :                 :              +- TungstenAggregate(key=[X#519,c_0#516], functions=[], output=[X#519,c_0#516])
               :                 :                 +- TungstenExchange hashpartitioning(X#519,c_0#516,5), None
               :                 :                    +- TungstenAggregate(key=[X#519,c_0#516], functions=[], output=[X#519,c_0#516])
               :                 :                       +- Union
               :                 :                          :- Project [X#519,0 AS c_0#516]
               :                 :                          :  +- Filter (Y#520 = 0)
               :                 :                          :     +- Scan ExistingRDD[X#519,Y#520] 
               :                 :                          +- Project [Y#520,Y#520]
               :                 :                             +- Filter (X#519 = 0)
               :                 :                                +- Scan ExistingRDD[X#519,Y#520] 
               :                 +- Sort [X#523 ASC], false, 0
               :                    +- TungstenExchange hashpartitioning(X#523,5), None
               :                       +- TungstenAggregate(key=[X#523,c_0#517], functions=[], output=[X#523,c_0#517])
               :                          +- TungstenExchange hashpartitioning(X#523,c_0#517,5), None
               :                             +- TungstenAggregate(key=[X#523,c_0#517], functions=[], output=[X#523,c_0#517])
               :                                +- Union
               :                                   :- Project [X#523,0 AS c_0#517]
               :                                   :  +- Filter (Y#524 = 0)
               :                                   :     +- Scan ExistingRDD[X#523,Y#524] 
               :                                   +- Project [Y#524,Y#524]
               :                                      +- Filter (X#523 = 0)
               :                                         +- Scan ExistingRDD[X#523,Y#524] 
               +- Sort [W1#507 ASC], false, 0
                  +- TungstenExchange hashpartitioning(W1#507,5), None
                     +- Project [W9#515,W1#507]
                        +- Scan ExistingRDD[W1#507,W2#508,W3#509,W4#510,W5#511,W6#512,W7#513,W8#514,W9#515]
17/03/27 22:25:37 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:37 INFO SparkContext: Starting job: rdd at BigDatalogProgram.scala:41
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 49 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 36 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 39 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 11 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 20 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 23 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 27 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Got job 0 (rdd at BigDatalogProgram.scala:41) with 5 output partitions
17/03/27 22:25:37 INFO DAGScheduler: Final stage: ResultStage 8 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 2, ShuffleMapStage 7)
17/03/27 22:25:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 2, ShuffleMapStage 7)
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[49] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 6.1 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53110 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[49] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[36] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2340 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2345 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2345 bytes)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 9.8 KB, free 2.0 GB)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53110 (size: 4.8 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[36] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 9.6 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53110 (size: 4.7 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[8] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 3.0 with 10 tasks
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 9.8 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53110 (size: 4.8 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO GenerateUnsafeProjection: Code generated in 3.332973 ms
17/03/27 22:25:37 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 5.0 with 10 tasks
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2345 bytes)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 13 ms on localhost (1/5)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO GeneratePredicate: Code generated in 2.531458 ms
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 30 ms on localhost (2/5)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:37 INFO GenerateUnsafeProjection: Code generated in 3.013671 ms
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 14 ms on localhost (1/10)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 10, localhost, partition 5,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 11, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 10 ms on localhost (2/10)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 13 ms on localhost (3/10)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Running task 5.0 in stage 1.0 (TID 10)
17/03/27 22:25:37 INFO Executor: Running task 6.0 in stage 1.0 (TID 11)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 12, localhost, partition 7,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO GenerateUnsafeProjection: Code generated in 14.538355 ms
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 46 ms on localhost (3/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 32 ms on localhost (4/10)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 57 ms on localhost (4/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 57 ms on localhost (5/5)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO Executor: Running task 7.0 in stage 1.0 (TID 12)
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.059 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 5, ShuffleMapStage 3)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 13, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 22 ms on localhost (5/10)
17/03/27 22:25:37 INFO Executor: Running task 8.0 in stage 1.0 (TID 13)
17/03/27 22:25:37 INFO Executor: Finished task 8.0 in stage 1.0 (TID 13). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 14, localhost, partition 9,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO Executor: Finished task 7.0 in stage 1.0 (TID 12). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Running task 9.0 in stage 1.0 (TID 14)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 13) in 10 ms on localhost (6/10)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 12) in 28 ms on localhost (7/10)
17/03/27 22:25:37 INFO GeneratePredicate: Code generated in 2.146992 ms
17/03/27 22:25:37 INFO Executor: Finished task 9.0 in stage 1.0 (TID 14). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 14) in 6 ms on localhost (8/10)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:37 INFO Executor: Finished task 5.0 in stage 1.0 (TID 10). 1710 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 10) in 37 ms on localhost (9/10)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:37 INFO Executor: Finished task 6.0 in stage 1.0 (TID 11). 1710 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 11) in 49 ms on localhost (10/10)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.087 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 3)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 10.0 KB, free 2047.9 MB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.9 KB, free 2047.9 MB)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 18 ms on localhost (1/10)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53110 (size: 4.9 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 20, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 25 ms on localhost (2/10)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 20)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 20). 2089 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 21, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 20) in 4 ms on localhost (1/5)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 21)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 22, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 12 ms on localhost (3/10)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 2.0 (TID 22)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 23, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 31 ms on localhost (4/10)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 2.0 (TID 23)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 2.0 (TID 22). 2089 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 24, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 22) in 9 ms on localhost (2/5)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 2.0 (TID 23). 2089 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 5.0 in stage 3.0 (TID 25, localhost, partition 5,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 23) in 5 ms on localhost (3/5)
17/03/27 22:25:37 INFO Executor: Running task 5.0 in stage 3.0 (TID 25)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 21). 2098 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 6.0 in stage 3.0 (TID 26, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 21) in 17 ms on localhost (4/5)
17/03/27 22:25:37 INFO Executor: Running task 6.0 in stage 3.0 (TID 26)
17/03/27 22:25:37 INFO GeneratePredicate: Code generated in 1.925435 ms
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 2.0 (TID 24)
17/03/27 22:25:37 INFO Executor: Finished task 5.0 in stage 3.0 (TID 25). 1658 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 7.0 in stage 3.0 (TID 27, localhost, partition 7,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 5.0 in stage 3.0 (TID 25) in 7 ms on localhost (5/10)
17/03/27 22:25:37 INFO Executor: Running task 7.0 in stage 3.0 (TID 27)
17/03/27 22:25:37 INFO Executor: Finished task 6.0 in stage 3.0 (TID 26). 1658 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 8.0 in stage 3.0 (TID 28, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 6.0 in stage 3.0 (TID 26) in 6 ms on localhost (6/10)
17/03/27 22:25:37 INFO Executor: Running task 8.0 in stage 3.0 (TID 28)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 9.0 in stage 3.0 (TID 29, localhost, partition 9,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 35 ms on localhost (7/10)
17/03/27 22:25:37 INFO Executor: Running task 9.0 in stage 3.0 (TID 29)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:37 INFO Executor: Finished task 8.0 in stage 3.0 (TID 28). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 8.0 in stage 3.0 (TID 28) in 21 ms on localhost (8/10)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 5.0 (TID 30)
17/03/27 22:25:37 INFO Executor: Finished task 7.0 in stage 3.0 (TID 27). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 7.0 in stage 3.0 (TID 27) in 26 ms on localhost (9/10)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 5.0 (TID 31)
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 5.0 (TID 30). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 32, localhost, partition 2,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 30) in 5 ms on localhost (1/10)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 5.0 (TID 32)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 5.0 (TID 31). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 33, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 31) in 8 ms on localhost (2/10)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 5.0 (TID 33)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 5.0 (TID 32). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 34, localhost, partition 4,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 32) in 11 ms on localhost (3/10)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 5.0 (TID 33). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 5.0 (TID 34)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 5.0 in stage 5.0 (TID 35, localhost, partition 5,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 33) in 7 ms on localhost (4/10)
17/03/27 22:25:37 INFO Executor: Running task 5.0 in stage 5.0 (TID 35)
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 5.0 (TID 34). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 6.0 in stage 5.0 (TID 36, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 34) in 6 ms on localhost (5/10)
17/03/27 22:25:37 INFO Executor: Running task 6.0 in stage 5.0 (TID 36)
17/03/27 22:25:37 INFO Executor: Finished task 5.0 in stage 5.0 (TID 35). 1710 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 7.0 in stage 5.0 (TID 37, localhost, partition 7,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 5.0 in stage 5.0 (TID 35) in 13 ms on localhost (6/10)
17/03/27 22:25:37 INFO Executor: Running task 7.0 in stage 5.0 (TID 37)
17/03/27 22:25:37 INFO Executor: Finished task 9.0 in stage 3.0 (TID 29). 1667 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 8.0 in stage 5.0 (TID 38, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 9.0 in stage 3.0 (TID 29) in 49 ms on localhost (10/10)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO Executor: Running task 8.0 in stage 5.0 (TID 38)
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.166 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 2)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 4, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[11] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 9.6 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53110 (size: 4.8 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[11] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:37 INFO Executor: Finished task 7.0 in stage 5.0 (TID 37). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 39, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 7.0 in stage 5.0 (TID 37) in 6 ms on localhost (7/10)
17/03/27 22:25:37 INFO Executor: Finished task 8.0 in stage 5.0 (TID 38). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 4.0 (TID 39)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 40, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 8.0 in stage 5.0 (TID 38) in 7 ms on localhost (8/10)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 4.0 (TID 40)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 6.0 in stage 5.0 (TID 36). 1710 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 41, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 6.0 in stage 5.0 (TID 36) in 20 ms on localhost (9/10)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 4.0 (TID 41)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 2.0 (TID 24). 2098 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 42, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 4.0 (TID 42)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 24) in 81 ms on localhost (5/5)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.100 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 5, ShuffleMapStage 4)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 4.0 (TID 39). 2055 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 43, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 39) in 19 ms on localhost (1/5)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 4.0 (TID 43)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 4.0 (TID 40). 2055 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 9.0 in stage 5.0 (TID 44, localhost, partition 9,PROCESS_LOCAL, 2450 bytes)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 8 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 40) in 26 ms on localhost (2/5)
17/03/27 22:25:37 INFO Executor: Running task 9.0 in stage 5.0 (TID 44)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 4.0 (TID 42). 2055 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 42) in 15 ms on localhost (3/5)
17/03/27 22:25:37 INFO Executor: Finished task 9.0 in stage 5.0 (TID 44). 1701 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 9.0 in stage 5.0 (TID 44) in 13 ms on localhost (10/10)
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 5 (rdd at BigDatalogProgram.scala:41) finished in 0.200 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 4)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, ShuffleMapStage 7, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.0 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.9 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53110 (size: 4.9 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[23] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 45, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 46, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 6.0 (TID 45)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 6.0 (TID 46)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 4.0 (TID 43). 2055 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 6.0 (TID 45). 2089 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 47, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 48, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 43) in 22 ms on localhost (4/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 45) in 4 ms on localhost (1/5)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 6.0 (TID 47)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 6.0 (TID 48)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 6.0 (TID 48). 2089 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 49, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 48) in 6 ms on localhost (2/5)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 6.0 (TID 49)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 6.0 (TID 47). 2089 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 47) in 7 ms on localhost (3/5)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 10 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 6.0 (TID 46). 2098 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 46) in 13 ms on localhost (4/5)
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 6.0 (TID 49). 2098 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 49) in 14 ms on localhost (5/5)
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 6 (rdd at BigDatalogProgram.scala:41) finished in 0.023 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 4)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 4.0 (TID 41). 2055 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 41) in 55 ms on localhost (5/5)
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.062 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set()
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ShuffleMapStage 7, ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[27] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 14.6 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:53110 (size: 6.4 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[27] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 52, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 53, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 7.0 (TID 50)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 7.0 (TID 51)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 7.0 (TID 52)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 7.0 (TID 53)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 7.0 (TID 53). 2958 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 54, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 7.0 (TID 52). 2958 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 7.0 (TID 54)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 53) in 12 ms on localhost (1/5)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 52) in 14 ms on localhost (2/5)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 7.0 (TID 54). 2958 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 54) in 8 ms on localhost (3/5)
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 7.0 (TID 50). 2958 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 50) in 25 ms on localhost (4/5)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 7.0 (TID 51). 2958 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 51) in 25 ms on localhost (5/5)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 7 (rdd at BigDatalogProgram.scala:41) finished in 0.026 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set()
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ResultStage 8)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[56] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 26.1 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.9 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:53110 (size: 9.9 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 8 (MapPartitionsRDD[56] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 8.0 with 5 tasks
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 55, localhost, partition 0,NODE_LOCAL, 2208 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 56, localhost, partition 1,NODE_LOCAL, 2208 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 57, localhost, partition 2,NODE_LOCAL, 2208 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 58, localhost, partition 3,NODE_LOCAL, 2208 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 8.0 (TID 55)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 8.0 (TID 56)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 8.0 (TID 57)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 8.0 (TID 58)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO GeneratePredicate: Code generated in 1.619476 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:37 INFO GenerateUnsafeProjection: Code generated in 2.416026 ms
17/03/27 22:25:37 INFO GenerateMutableProjection: Code generated in 6.155807 ms
17/03/27 22:25:37 INFO GenerateUnsafeProjection: Code generated in 2.714228 ms
17/03/27 22:25:37 INFO GenerateUnsafeRowJoiner: Code generated in 3.278359 ms
17/03/27 22:25:37 INFO GenerateSafeProjection: Code generated in 7.329376 ms
17/03/27 22:25:37 INFO GenerateUnsafeProjection: Code generated in 9.008741 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 8.0 (TID 57). 5893 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 8.0 (TID 58). 5893 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 59, localhost, partition 4,NODE_LOCAL, 2208 bytes)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 8.0 (TID 59)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 57) in 41 ms on localhost (1/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 58) in 41 ms on localhost (2/5)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 8.0 (TID 59). 5600 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 8.0 (TID 56). 5600 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 8.0 (TID 55). 5600 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 8.0 (TID 59) in 16 ms on localhost (3/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 55) in 56 ms on localhost (4/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 56) in 56 ms on localhost (5/5)
17/03/27 22:25:37 INFO DAGScheduler: ResultStage 8 (rdd at BigDatalogProgram.scala:41) finished in 0.056 s
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: Job 0 finished: rdd at BigDatalogProgram.scala:41, took 0.328518 s
17/03/27 22:25:37 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:37 INFO DAGScheduler: Got job 1 (collect at QuerySuite.scala:64) with 1 output partitions
17/03/27 22:25:37 INFO DAGScheduler: Final stage: ResultStage 9 (collect at QuerySuite.scala:64)
17/03/27 22:25:37 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:37 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:37 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[60] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 22.7 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:53110 (size: 8.0 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[60] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 60, localhost, partition 0,PROCESS_LOCAL, 2347 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 9.0 (TID 60)
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 9.0 (TID 60). 5693 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 60) in 4 ms on localhost (1/1)
17/03/27 22:25:37 INFO DAGScheduler: ResultStage 9 (collect at QuerySuite.scala:64) finished in 0.004 s
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: Job 1 finished: collect at QuerySuite.scala:64, took 0.006315 s
17/03/27 22:25:37 INFO TriangleQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:37 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:37 INFO BlockManager: BlockManager stopped
17/03/27 22:25:37 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:37 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
[32m- PYMK - ff[0m
17/03/27 22:25:37 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:37 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:37 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[32mNegationQuerySuite:[0m
17/03/27 22:25:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:37 INFO Utils: Successfully started service 'sparkDriver' on port 53128.
17/03/27 22:25:37 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:37 INFO Remoting: Starting remoting
17/03/27 22:25:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53141]
17/03/27 22:25:37 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53141.
17/03/27 22:25:37 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:37 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:37 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-4f66b4fe-7f4c-4b41-89b8-3884511f7be0
17/03/27 22:25:37 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:37 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:37 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53158.
17/03/27 22:25:37 INFO NettyBlockTransferService: Server created on 53158
17/03/27 22:25:37 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:37 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53158 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53158)
17/03/27 22:25:37 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:37 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667937749
17/03/27 22:25:37 INFO NegationQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:37 INFO BigDatalogContext: BigDatalog Query: "employee_missing_address(EmployeeId)."
17/03/27 22:25:37 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:37 INFO BigDatalogContext: 
0: (EmployeeId) <DISTINCT PROJECT>
 1: (0.EmployeeId = 1.EmployeeId) <JOIN>
  2: (EmployeeId) <PROJECT>
   3: employee(EmployeeId, DepartmentId, FirstName, LastName) <BASE_RELATION>
  2: (0.EmployeeId = 0.EmployeeId) <NEGATION>
   3: (EmployeeId) <PROJECT>
    4: address(EmployeeId, Street, City, State, Zip) <BASE_RELATION>
17/03/27 22:25:37 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:37 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:37 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['employee.EmployeeId]
   +- 'Filter isnull('address.EmployeeId)
      +- 'Join LeftOuter, Some(('employee.EmployeeId = 'address.EmployeeId))
         :- 'Project ['employee.EmployeeId]
         :  +- 'UnresolvedRelation `employee`, None
         +- 'Project ['address.EmployeeId]
            +- 'UnresolvedRelation `address`, None

== Analyzed Logical Plan ==
EmployeeId: int
Distinct
+- Project [EmployeeId#541]
   +- Filter isnull(EmployeeId#545)
      +- Join LeftOuter, Some((EmployeeId#541 = EmployeeId#545))
         :- Project [EmployeeId#541]
         :  +- Subquery employee
         :     +- LogicalRDD [EmployeeId#541,DepartmentId#542,FirstName#543,LastName#544], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [EmployeeId#545]
            +- Subquery address
               +- LogicalRDD [EmployeeId#545,Street#546,City#547,State#548,Zip#549], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [EmployeeId#541], [EmployeeId#541]
+- Project [EmployeeId#541]
   +- Filter isnull(EmployeeId#545)
      +- Join LeftOuter, Some((EmployeeId#541 = EmployeeId#545))
         :- Project [EmployeeId#541]
         :  +- LogicalRDD [EmployeeId#541,DepartmentId#542,FirstName#543,LastName#544], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [EmployeeId#545]
            +- LogicalRDD [EmployeeId#545,Street#546,City#547,State#548,Zip#549], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[EmployeeId#541], functions=[], output=[EmployeeId#541])
+- TungstenAggregate(key=[EmployeeId#541], functions=[], output=[EmployeeId#541])
   +- Project [EmployeeId#541]
      +- Filter isnull(EmployeeId#545)
         +- SortMergeOuterJoin [EmployeeId#541], [EmployeeId#545], LeftOuter, None
            :- Sort [EmployeeId#541 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(EmployeeId#541,5), None
            :     +- Project [EmployeeId#541]
            :        +- Scan ExistingRDD[EmployeeId#541,DepartmentId#542,FirstName#543,LastName#544] 
            +- Sort [EmployeeId#545 ASC], false, 0
               +- TungstenExchange hashpartitioning(EmployeeId#545,5), None
                  +- Project [EmployeeId#545]
                     +- Scan ExistingRDD[EmployeeId#545,Street#546,City#547,State#548,Zip#549]
17/03/27 22:25:37 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:37 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 7 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Registering RDD 3 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:37 INFO DAGScheduler: Final stage: ResultStage 2 (collect at QuerySuite.scala:64)
17/03/27 22:25:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 1)
17/03/27 22:25:37 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 1)
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53158 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[7] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:37 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2428 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53158 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2427 bytes)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2390 bytes)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2396 bytes)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 25 ms on localhost (1/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 11 ms on localhost (1/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 16 ms on localhost (2/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 14 ms on localhost (2/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 29 ms on localhost (3/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 28 ms on localhost (4/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 18 ms on localhost (3/5)
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 13 ms on localhost (4/5)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 32 ms on localhost (5/5)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.033 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set(ShuffleMapStage 1)
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1367 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 12 ms on localhost (5/5)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.032 s
17/03/27 22:25:37 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:37 INFO DAGScheduler: running: Set()
17/03/27 22:25:37 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/03/27 22:25:37 INFO DAGScheduler: failed: Set()
17/03/27 22:25:37 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.8 KB, free 2.0 GB)
17/03/27 22:25:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53158 (size: 6.3 KB, free: 2.0 GB)
17/03/27 22:25:37 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:37 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:37 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:37 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:37 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:37 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:37 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:37 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO GeneratePredicate: Code generated in 2.5538 ms
17/03/27 22:25:37 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2151 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2151 bytes result sent to driver
17/03/27 22:25:37 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2151 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:37 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 10 ms on localhost (1/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 10 ms on localhost (2/5)
17/03/27 22:25:37 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 10 ms on localhost (3/5)
17/03/27 22:25:37 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3190 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 11 ms on localhost (4/5)
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:37 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2151 bytes result sent to driver
17/03/27 22:25:37 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 3 ms on localhost (5/5)
17/03/27 22:25:37 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:37 INFO DAGScheduler: ResultStage 2 (collect at QuerySuite.scala:64) finished in 0.013 s
17/03/27 22:25:37 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.055136 s
17/03/27 22:25:37 INFO NegationQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:37 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:37 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:37 INFO BlockManager: BlockManager stopped
17/03/27 22:25:37 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:37 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:37 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:37 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:37 INFO SparkContext: Successfully stopped SparkContext
[32m- employee_missing_address(EmployeeID)[0m
17/03/27 22:25:37 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:37 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:37 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:37 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:37 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:37 INFO Utils: Successfully started service 'sparkDriver' on port 53176.
17/03/27 22:25:37 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:37 INFO Remoting: Starting remoting
17/03/27 22:25:37 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53189]
17/03/27 22:25:37 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53189.
17/03/27 22:25:37 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:37 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:37 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-e8afe258-797c-49fb-a202-c9d62a2adeb1
17/03/27 22:25:37 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:38 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:38 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53206.
17/03/27 22:25:38 INFO NettyBlockTransferService: Server created on 53206
17/03/27 22:25:38 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53206 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53206)
17/03/27 22:25:38 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:38 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667938014
17/03/27 22:25:38 INFO NegationQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:38 INFO BigDatalogContext: BigDatalog Query: "cannot_graduate(FirstName,LastName)."
17/03/27 22:25:38 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:38 INFO BigDatalogContext: 
0: (FirstName, LastName) <DISTINCT PROJECT>
 1: (0.StudentId = 1.StudentId) <JOIN>
  2: (StudentId, FirstName, LastName) <PROJECT>
   3: student(StudentId, FirstName, LastName, GradeYear) <BASE_RELATION>
  2: (0.StudentId = 0.StudentId) <NEGATION>
   3: (StudentId) <PROJECT>
    4: CourseId = 100 <FILTER>
     5: taken(StudentId, CourseId, Grade) <BASE_RELATION>
17/03/27 22:25:38 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:38 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:38 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['student.FirstName,'student.LastName]
   +- 'Filter isnull('taken.StudentId)
      +- 'Join LeftOuter, Some(('student.StudentId = 'taken.StudentId))
         :- 'Project ['student.StudentId,'student.FirstName,'student.LastName]
         :  +- 'UnresolvedRelation `student`, None
         +- 'Project ['taken.StudentId]
            +- 'Filter ('taken.CourseId = 100)
               +- 'UnresolvedRelation `taken`, None

== Analyzed Logical Plan ==
FirstName: string, LastName: string
Distinct
+- Project [FirstName#551,LastName#552]
   +- Filter isnull(StudentId#557)
      +- Join LeftOuter, Some((StudentId#550 = StudentId#557))
         :- Project [StudentId#550,FirstName#551,LastName#552]
         :  +- Subquery student
         :     +- LogicalRDD [StudentId#550,FirstName#551,LastName#552,GradeYear#553], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [StudentId#557]
            +- Filter (CourseId#558 = 100)
               +- Subquery taken
                  +- LogicalRDD [StudentId#557,CourseId#558,Grade#559], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [FirstName#551,LastName#552], [FirstName#551,LastName#552]
+- Project [FirstName#551,LastName#552]
   +- Filter isnull(StudentId#557)
      +- Join LeftOuter, Some((StudentId#550 = StudentId#557))
         :- Project [StudentId#550,FirstName#551,LastName#552]
         :  +- LogicalRDD [StudentId#550,FirstName#551,LastName#552,GradeYear#553], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Project [StudentId#557]
            +- Filter (CourseId#558 = 100)
               +- LogicalRDD [StudentId#557,CourseId#558,Grade#559], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[FirstName#551,LastName#552], functions=[], output=[FirstName#551,LastName#552])
+- TungstenExchange hashpartitioning(FirstName#551,LastName#552,5), None
   +- TungstenAggregate(key=[FirstName#551,LastName#552], functions=[], output=[FirstName#551,LastName#552])
      +- Project [FirstName#551,LastName#552]
         +- Filter isnull(StudentId#557)
            +- SortMergeOuterJoin [StudentId#550], [StudentId#557], LeftOuter, None
               :- Sort [StudentId#550 ASC], false, 0
               :  +- TungstenExchange hashpartitioning(StudentId#550,5), None
               :     +- Project [StudentId#550,FirstName#551,LastName#552]
               :        +- Scan ExistingRDD[StudentId#550,FirstName#551,LastName#552,GradeYear#553] 
               +- Sort [StudentId#557 ASC], false, 0
                  +- TungstenExchange hashpartitioning(StudentId#557,5), None
                     +- Project [StudentId#557]
                        +- Filter (CourseId#558 = 100)
                           +- Scan ExistingRDD[StudentId#557,CourseId#558,Grade#559]
17/03/27 22:25:38 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:38 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 5 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 10 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:38 INFO DAGScheduler: Final stage: ResultStage 3 (collect at QuerySuite.scala:64)
17/03/27 22:25:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:25:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53206 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2401 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2399 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2402 bytes)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53206 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2400 bytes)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 52 ms on localhost (1/5)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2420 bytes)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 62 ms on localhost (2/5)
17/03/27 22:25:38 INFO GeneratePredicate: Code generated in 2.837108 ms
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2473 bytes)
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2466 bytes)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2465 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 4 ms on localhost (1/5)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2477 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 70 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 4 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 4 ms on localhost (3/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 26 ms on localhost (4/5)
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 16 ms on localhost (4/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 4 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.032 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set(ShuffleMapStage 0)
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 77 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.078 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set()
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ResultStage 3)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 13.6 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.3 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53206 (size: 6.3 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:38 INFO GeneratePredicate: Code generated in 2.435575 ms
17/03/27 22:25:38 INFO GenerateUnsafeProjection: Code generated in 2.878688 ms
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 2270 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 16 ms on localhost (1/5)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2270 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 29 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2270 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 32 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2270 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 35 ms on localhost (4/5)
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2270 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 27 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.042 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set()
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ResultStage 3)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[20] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.2 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53206 (size: 5.6 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 3 (MapPartitionsRDD[20] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 2228 bytes result sent to driver
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 2228 bytes result sent to driver
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 3 ms on localhost (1/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 3 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 3249 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 6 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 3292 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 7 ms on localhost (4/5)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 3251 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 6 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ResultStage 3 (collect at QuerySuite.scala:64) finished in 0.009 s
17/03/27 22:25:38 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.143127 s
17/03/27 22:25:38 INFO NegationQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:38 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:38 INFO BlockManager: BlockManager stopped
17/03/27 22:25:38 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:38 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
[32m- cannot_graduate(FirstName, LastName)[0m
17/03/27 22:25:38 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:38 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:38 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:38 INFO Utils: Successfully started service 'sparkDriver' on port 53223.
17/03/27 22:25:38 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:38 INFO Remoting: Starting remoting
17/03/27 22:25:38 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53237.
17/03/27 22:25:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53237]
17/03/27 22:25:38 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:38 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:38 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-6c96ca8e-88ee-4f81-8280-16f6bef1757e
17/03/27 22:25:38 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:38 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:38 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53254.
17/03/27 22:25:38 INFO NettyBlockTransferService: Server created on 53254
17/03/27 22:25:38 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53254 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53254)
17/03/27 22:25:38 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:38 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667938414
17/03/27 22:25:38 INFO NegationQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:38 INFO BigDatalogContext: BigDatalog Query: "can_take_course_50(StudentId)"
17/03/27 22:25:38 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:38 INFO BigDatalogContext: 
0: can_take_course_50(StudentId) <UNION>
 1: (StudentId) <PROJECT>
  2: (0.StudentId = 1.StudentId) <JOIN>
   3: (StudentId) <PROJECT>
    4: student(StudentId, FirstName, LastName, GradeYear) <BASE_RELATION>
   3: (0.StudentId = 0.StudentId) <NEGATION>
    4: (StudentId) <PROJECT>
     5: CourseId = 100 <FILTER>
      6: taken(StudentId, CourseId, Grade) <BASE_RELATION>
 1: (StudentId) <PROJECT>
  2: (0.StudentId = 1.StudentId) <JOIN>
   3: (StudentId) <PROJECT>
    4: student(StudentId, FirstName, LastName, GradeYear) <BASE_RELATION>
   3: (0.StudentId = 0.StudentId) <NEGATION>
    4: (StudentId) <PROJECT>
     5: CourseId = 50 <FILTER>
      6: taken(StudentId, CourseId, Grade) <BASE_RELATION>
17/03/27 22:25:38 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:38 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:38 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Subquery can_take_course_50
   +- 'Union
      :- 'Project ['student.StudentId]
      :  +- 'Filter isnull('taken.StudentId)
      :     +- 'Join LeftOuter, Some(('student.StudentId = 'taken.StudentId))
      :        :- 'Project ['student.StudentId]
      :        :  +- 'UnresolvedRelation `student`, None
      :        +- 'Project ['taken.StudentId]
      :           +- 'Filter ('taken.CourseId = 100)
      :              +- 'UnresolvedRelation `taken`, None
      +- 'Project ['student1.StudentId]
         +- 'Filter isnull('taken2.StudentId)
            +- 'Join LeftOuter, Some(('student1.StudentId = 'taken2.StudentId))
               :- 'Project ['student1.StudentId]
               :  +- 'Subquery student1
               :     +- 'Project [*]
               :        +- 'UnresolvedRelation `student`, None
               +- 'Project ['taken2.StudentId]
                  +- 'Filter ('taken2.CourseId = 50)
                     +- 'Subquery taken2
                        +- 'Project [*]
                           +- 'UnresolvedRelation `taken`, None

== Analyzed Logical Plan ==
StudentId: int
Distinct
+- Subquery can_take_course_50
   +- Union
      :- Project [StudentId#562]
      :  +- Filter isnull(StudentId#569)
      :     +- Join LeftOuter, Some((StudentId#562 = StudentId#569))
      :        :- Project [StudentId#562]
      :        :  +- Subquery student
      :        :     +- LogicalRDD [StudentId#562,FirstName#563,LastName#564,GradeYear#565], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :        +- Project [StudentId#569]
      :           +- Filter (CourseId#570 = 100)
      :              +- Subquery taken
      :                 +- LogicalRDD [StudentId#569,CourseId#570,Grade#571], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168
      +- Project [StudentId#562]
         +- Filter isnull(StudentId#569)
            +- Join LeftOuter, Some((StudentId#562 = StudentId#569))
               :- Project [StudentId#562]
               :  +- Subquery student1
               :     +- Project [StudentId#562,FirstName#563,LastName#564,GradeYear#565]
               :        +- Subquery student
               :           +- LogicalRDD [StudentId#562,FirstName#563,LastName#564,GradeYear#565], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
               +- Project [StudentId#569]
                  +- Filter (CourseId#570 = 50)
                     +- Subquery taken2
                        +- Project [StudentId#569,CourseId#570,Grade#571]
                           +- Subquery taken
                              +- LogicalRDD [StudentId#569,CourseId#570,Grade#571], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [StudentId#562], [StudentId#562]
+- Union
   :- Project [StudentId#562]
   :  +- Filter isnull(StudentId#569)
   :     +- Join LeftOuter, Some((StudentId#562 = StudentId#569))
   :        :- Project [StudentId#562]
   :        :  +- LogicalRDD [StudentId#562,FirstName#563,LastName#564,GradeYear#565], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :        +- Project [StudentId#569]
   :           +- Filter (CourseId#570 = 100)
   :              +- LogicalRDD [StudentId#569,CourseId#570,Grade#571], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168
   +- Project [StudentId#562]
      +- Filter isnull(StudentId#569)
         +- Join LeftOuter, Some((StudentId#562 = StudentId#569))
            :- Project [StudentId#562]
            :  +- LogicalRDD [StudentId#562,FirstName#563,LastName#564,GradeYear#565], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
            +- Project [StudentId#569]
               +- Filter (CourseId#570 = 50)
                  +- LogicalRDD [StudentId#569,CourseId#570,Grade#571], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[StudentId#562], functions=[], output=[StudentId#562])
+- TungstenExchange hashpartitioning(StudentId#562,5), None
   +- TungstenAggregate(key=[StudentId#562], functions=[], output=[StudentId#562])
      +- Union
         :- Project [StudentId#562]
         :  +- Filter isnull(StudentId#569)
         :     +- SortMergeOuterJoin [StudentId#562], [StudentId#569], LeftOuter, None
         :        :- Sort [StudentId#562 ASC], false, 0
         :        :  +- TungstenExchange hashpartitioning(StudentId#562,5), None
         :        :     +- Project [StudentId#562]
         :        :        +- Scan ExistingRDD[StudentId#562,FirstName#563,LastName#564,GradeYear#565] 
         :        +- Sort [StudentId#569 ASC], false, 0
         :           +- TungstenExchange hashpartitioning(StudentId#569,5), None
         :              +- Project [StudentId#569]
         :                 +- Filter (CourseId#570 = 100)
         :                    +- Scan ExistingRDD[StudentId#569,CourseId#570,Grade#571] 
         +- Project [StudentId#562]
            +- Filter isnull(StudentId#569)
               +- SortMergeOuterJoin [StudentId#562], [StudentId#569], LeftOuter, None
                  :- Sort [StudentId#562 ASC], false, 0
                  :  +- TungstenExchange hashpartitioning(StudentId#562,5), None
                  :     +- Project [StudentId#562]
                  :        +- Scan ExistingRDD[StudentId#562,FirstName#563,LastName#564,GradeYear#565] 
                  +- Sort [StudentId#569 ASC], false, 0
                     +- TungstenExchange hashpartitioning(StudentId#569,5), None
                        +- Project [StudentId#569]
                           +- Filter (CourseId#570 = 50)
                              +- Scan ExistingRDD[StudentId#569,CourseId#570,Grade#571]
17/03/27 22:25:38 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:38 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 5 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 10 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 22 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Registering RDD 30 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:38 INFO DAGScheduler: Final stage: ResultStage 5 (collect at QuerySuite.scala:64)
17/03/27 22:25:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/03/27 22:25:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53254 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[10] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2401 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2399 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2402 bytes)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53254 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[10] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53254 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[22] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53254 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[22] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2400 bytes)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 43 ms on localhost (1/5)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2420 bytes)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2473 bytes)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2466 bytes)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2465 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 52 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2477 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 35 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 5 ms on localhost (1/5)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2401 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 7 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2399 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 7 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2402 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 5 ms on localhost (4/5)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2400 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 7 ms on localhost (1/5)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2420 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 16 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2473 bytes)
17/03/27 22:25:38 INFO GeneratePredicate: Code generated in 3.640175 ms
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 20 ms on localhost (3/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 33 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.076 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set(ShuffleMapStage 0, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 78 ms on localhost (4/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 79 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.080 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set(ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2466 bytes)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 18 ms on localhost (4/5)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1367 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2465 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 22 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.077 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2477 bytes)
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 8 ms on localhost (1/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 11 ms on localhost (2/5)
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 5 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 6 ms on localhost (4/5)
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 1400 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 14 ms on localhost (5/5)
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.090 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set()
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ResultStage 5, ShuffleMapStage 4)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.7 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.3 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53254 (size: 7.3 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[30] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 4.0 with 10 tasks
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 5 ms
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 17 ms on localhost (1/10)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 5.0 in stage 4.0 (TID 25, localhost, partition 5,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO Executor: Running task 5.0 in stage 4.0 (TID 25)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 23 ms on localhost (2/10)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 6.0 in stage 4.0 (TID 26, localhost, partition 6,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 34 ms on localhost (3/10)
17/03/27 22:25:38 INFO Executor: Running task 6.0 in stage 4.0 (TID 26)
17/03/27 22:25:38 INFO Executor: Finished task 5.0 in stage 4.0 (TID 25). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 7.0 in stage 4.0 (TID 27, localhost, partition 7,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 5.0 in stage 4.0 (TID 25) in 13 ms on localhost (4/10)
17/03/27 22:25:38 INFO Executor: Running task 7.0 in stage 4.0 (TID 27)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 6.0 in stage 4.0 (TID 26). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 8.0 in stage 4.0 (TID 28, localhost, partition 8,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 6.0 in stage 4.0 (TID 26) in 6 ms on localhost (5/10)
17/03/27 22:25:38 INFO Executor: Running task 8.0 in stage 4.0 (TID 28)
17/03/27 22:25:38 INFO Executor: Finished task 7.0 in stage 4.0 (TID 27). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 9.0 in stage 4.0 (TID 29, localhost, partition 9,NODE_LOCAL, 2257 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 7.0 in stage 4.0 (TID 27) in 6 ms on localhost (6/10)
17/03/27 22:25:38 INFO Executor: Running task 9.0 in stage 4.0 (TID 29)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 8.0 in stage 4.0 (TID 28). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 8.0 in stage 4.0 (TID 28) in 18 ms on localhost (7/10)
17/03/27 22:25:38 INFO Executor: Finished task 9.0 in stage 4.0 (TID 29). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 9.0 in stage 4.0 (TID 29) in 25 ms on localhost (8/10)
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 52 ms on localhost (9/10)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2872 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 75 ms on localhost (10/10)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.077 s
17/03/27 22:25:38 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:38 INFO DAGScheduler: running: Set()
17/03/27 22:25:38 INFO DAGScheduler: waiting: Set(ResultStage 5)
17/03/27 22:25:38 INFO DAGScheduler: failed: Set()
17/03/27 22:25:38 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[33] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 14.0 KB, free 2.0 GB)
17/03/27 22:25:38 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.0 KB, free 2.0 GB)
17/03/27 22:25:38 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53254 (size: 6.0 KB, free: 2.0 GB)
17/03/27 22:25:38 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:38 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:38 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 30, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 31, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 32, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 33, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO Executor: Running task 1.0 in stage 5.0 (TID 31)
17/03/27 22:25:38 INFO Executor: Running task 3.0 in stage 5.0 (TID 33)
17/03/27 22:25:38 INFO Executor: Running task 0.0 in stage 5.0 (TID 30)
17/03/27 22:25:38 INFO Executor: Running task 2.0 in stage 5.0 (TID 32)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:38 INFO Executor: Finished task 1.0 in stage 5.0 (TID 31). 2830 bytes result sent to driver
17/03/27 22:25:38 INFO Executor: Finished task 0.0 in stage 5.0 (TID 30). 3877 bytes result sent to driver
17/03/27 22:25:38 INFO Executor: Finished task 2.0 in stage 5.0 (TID 32). 2830 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 34, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:38 INFO Executor: Running task 4.0 in stage 5.0 (TID 34)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 31) in 4 ms on localhost (1/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 32) in 4 ms on localhost (2/5)
17/03/27 22:25:38 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 30) in 4 ms on localhost (3/5)
17/03/27 22:25:38 INFO Executor: Finished task 3.0 in stage 5.0 (TID 33). 3877 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 33) in 5 ms on localhost (4/5)
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:25:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:38 INFO Executor: Finished task 4.0 in stage 5.0 (TID 34). 3908 bytes result sent to driver
17/03/27 22:25:38 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 34) in 3 ms on localhost (5/5)
17/03/27 22:25:38 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:38 INFO DAGScheduler: ResultStage 5 (collect at QuerySuite.scala:64) finished in 0.007 s
17/03/27 22:25:38 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.191903 s
17/03/27 22:25:38 INFO NegationQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:38 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:38 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:38 INFO BlockManager: BlockManager stopped
17/03/27 22:25:38 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:38 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:38 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:25:38 INFO SparkContext: Running Spark version 1.6.3
[32m- can_take_course_50(StudentId)[0m
17/03/27 22:25:38 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:25:38 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:38 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:38 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:38 INFO Utils: Successfully started service 'sparkDriver' on port 53271.
17/03/27 22:25:38 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:38 INFO Remoting: Starting remoting
17/03/27 22:25:38 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53284]
17/03/27 22:25:38 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53284.
17/03/27 22:25:38 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:38 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:38 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-943eb193-dc29-490b-90e6-8a9ce633563b
17/03/27 22:25:38 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:38 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:38 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:38 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53301.
17/03/27 22:25:38 INFO NettyBlockTransferService: Server created on 53301
17/03/27 22:25:38 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:38 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53301 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53301)
17/03/27 22:25:38 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:38 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667938911
17/03/27 22:25:38 INFO NegationQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:38 INFO BigDatalogContext: BigDatalog Query: "can_enroll(StudentId, CourseId)"
17/03/27 22:25:38 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:38 INFO BigDatalogContext: 
0: (StudentId, CourseId) <DISTINCT PROJECT>
 1: (0.StudentId = 2.StudentId, 0.StudentId = 3.StudentId, 1.CourseId = 3.CourseId) <JOIN>
  2: (StudentId) <PROJECT>
   3: student(StudentId, FirstName, LastName, GradeYear) <BASE_RELATION>
  2: (CourseId) <PROJECT>
   3: course(Name, CourseId, Units) <BASE_RELATION>
  2: (0.StudentId = 0.StudentId) <NEGATION>
   3: (StudentId) <PROJECT>
    4: N > 12 <FILTER>
     5: (StudentId, sum(Units) as N) <AGGREGATE>
      6: (StudentId, Units) <PROJECT>
       7: (0.CourseId = 1.CourseId) <JOIN>
        8: enrolled(StudentId, CourseId) <BASE_RELATION>
        8: (CourseId, Units) <PROJECT>
         9: course(Name, CourseId, Units) <BASE_RELATION>
  2: (0.StudentId = 0.StudentId, 1.CourseId = 0.CourseId) <NEGATION>
   3: (StudentId, CourseId) <PROJECT>
    4: taken(StudentId, CourseId, Grade) <BASE_RELATION>
17/03/27 22:25:38 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:38 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:39 INFO BigDatalogContext: == Parsed Logical Plan ==
'Distinct
+- 'Project ['student.StudentId,'course.CourseId]
   +- 'Filter (isnull('taken.StudentId) && isnull('taken.CourseId))
      +- 'Join LeftOuter, Some((('student.StudentId = 'taken.StudentId) && ('course.CourseId = 'taken.CourseId)))
         :- 'Filter isnull('aggregate_enrolled_units.StudentId)
         :  +- 'Join LeftOuter, Some(('student.StudentId = 'aggregate_enrolled_units.StudentId))
         :     :- 'Join Inner, None
         :     :  :- 'Project ['student.StudentId]
         :     :  :  +- 'UnresolvedRelation `student`, None
         :     :  +- 'Project ['course.CourseId]
         :     :     +- 'UnresolvedRelation `course`, None
         :     +- 'Project ['aggregate_enrolled_units.StudentId]
         :        +- 'Filter ('aggregate_enrolled_units.N > 12)
         :           +- 'Subquery aggregate_enrolled_units
         :              +- 'Aggregate ['enrolled.StudentId], ['enrolled.StudentId,unresolvedalias('sum('course1.Units) AS N#586)]
         :                 +- 'Project ['enrolled.StudentId,'course1.Units]
         :                    +- 'Join Inner, Some(('enrolled.CourseId = 'course1.CourseId))
         :                       :- 'UnresolvedRelation `enrolled`, None
         :                       +- 'Project ['course1.CourseId,'course1.Units]
         :                          +- 'Subquery course1
         :                             +- 'Project [*]
         :                                +- 'UnresolvedRelation `course`, None
         +- 'Project ['taken.StudentId,'taken.CourseId]
            +- 'UnresolvedRelation `taken`, None

== Analyzed Logical Plan ==
StudentId: int, CourseId: int
Distinct
+- Project [StudentId#574,CourseId#579]
   +- Filter (isnull(StudentId#581) && isnull(CourseId#582))
      +- Join LeftOuter, Some(((StudentId#574 = StudentId#581) && (CourseId#579 = CourseId#582)))
         :- Filter isnull(StudentId#584)
         :  +- Join LeftOuter, Some((StudentId#574 = StudentId#584))
         :     :- Join Inner, None
         :     :  :- Project [StudentId#574]
         :     :  :  +- Subquery student
         :     :  :     +- LogicalRDD [StudentId#574,FirstName#575,LastName#576,GradeYear#577], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :     :  +- Project [CourseId#579]
         :     :     +- Subquery course
         :     :        +- LogicalRDD [Name#578,CourseId#579,Units#580], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
         :     +- Project [StudentId#584]
         :        +- Filter (N#586L > cast(12 as bigint))
         :           +- Subquery aggregate_enrolled_units
         :              +- Aggregate [StudentId#584], [StudentId#584,(sum(cast(Units#580 as bigint)),mode=Complete,isDistinct=false) AS N#586L]
         :                 +- Project [StudentId#584,Units#580]
         :                    +- Join Inner, Some((CourseId#585 = CourseId#579))
         :                       :- Subquery enrolled
         :                       :  +- LogicalRDD [StudentId#584,CourseId#585], ParallelCollectionRDD[3] at parallelize at Utilities.scala:168
         :                       +- Project [CourseId#579,Units#580]
         :                          +- Subquery course1
         :                             +- Project [Name#578,CourseId#579,Units#580]
         :                                +- Subquery course
         :                                   +- LogicalRDD [Name#578,CourseId#579,Units#580], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
         +- Project [StudentId#581,CourseId#582]
            +- Subquery taken
               +- LogicalRDD [StudentId#581,CourseId#582,Grade#583], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [StudentId#574,CourseId#579], [StudentId#574,CourseId#579]
+- Project [StudentId#574,CourseId#579]
   +- Filter (isnull(StudentId#581) && isnull(CourseId#582))
      +- Join LeftOuter, Some(((StudentId#574 = StudentId#581) && (CourseId#579 = CourseId#582)))
         :- Filter isnull(StudentId#584)
         :  +- Join LeftOuter, Some((StudentId#574 = StudentId#584))
         :     :- Join Inner, None
         :     :  :- Project [StudentId#574]
         :     :  :  +- LogicalRDD [StudentId#574,FirstName#575,LastName#576,GradeYear#577], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :     :  +- Project [CourseId#579]
         :     :     +- LogicalRDD [Name#578,CourseId#579,Units#580], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
         :     +- Project [StudentId#584]
         :        +- Filter (N#586L > 12)
         :           +- Aggregate [StudentId#584], [StudentId#584,(sum(cast(Units#580 as bigint)),mode=Complete,isDistinct=false) AS N#586L]
         :              +- Project [StudentId#584,Units#580]
         :                 +- Join Inner, Some((CourseId#585 = CourseId#579))
         :                    :- LogicalRDD [StudentId#584,CourseId#585], ParallelCollectionRDD[3] at parallelize at Utilities.scala:168
         :                    +- Project [CourseId#579,Units#580]
         :                       +- LogicalRDD [Name#578,CourseId#579,Units#580], ParallelCollectionRDD[1] at parallelize at Utilities.scala:168
         +- Project [StudentId#581,CourseId#582]
            +- LogicalRDD [StudentId#581,CourseId#582,Grade#583], ParallelCollectionRDD[2] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[StudentId#574,CourseId#579], functions=[], output=[StudentId#574,CourseId#579])
+- TungstenAggregate(key=[StudentId#574,CourseId#579], functions=[], output=[StudentId#574,CourseId#579])
   +- Project [StudentId#574,CourseId#579]
      +- Filter (isnull(StudentId#581) && isnull(CourseId#582))
         +- SortMergeOuterJoin [StudentId#574,CourseId#579], [StudentId#581,CourseId#582], LeftOuter, None
            :- Sort [StudentId#574 ASC,CourseId#579 ASC], false, 0
            :  +- TungstenExchange hashpartitioning(StudentId#574,CourseId#579,5), None
            :     +- Filter isnull(StudentId#584)
            :        +- SortMergeOuterJoin [StudentId#574], [StudentId#584], LeftOuter, None
            :           :- Sort [StudentId#574 ASC], false, 0
            :           :  +- TungstenExchange hashpartitioning(StudentId#574,5), None
            :           :     +- ConvertToUnsafe
            :           :        +- CartesianProduct
            :           :           :- ConvertToSafe
            :           :           :  +- Project [StudentId#574]
            :           :           :     +- Scan ExistingRDD[StudentId#574,FirstName#575,LastName#576,GradeYear#577] 
            :           :           +- ConvertToSafe
            :           :              +- Project [CourseId#579]
            :           :                 +- Scan ExistingRDD[Name#578,CourseId#579,Units#580] 
            :           +- Sort [StudentId#584 ASC], false, 0
            :              +- Project [StudentId#584]
            :                 +- Filter (N#586L > 12)
            :                    +- TungstenAggregate(key=[StudentId#584], functions=[(sum(cast(Units#580 as bigint)),mode=Final,isDistinct=false)], output=[StudentId#584,N#586L])
            :                       +- TungstenExchange hashpartitioning(StudentId#584,5), None
            :                          +- TungstenAggregate(key=[StudentId#584], functions=[(sum(cast(Units#580 as bigint)),mode=Partial,isDistinct=false)], output=[StudentId#584,sum#589L])
            :                             +- Project [StudentId#584,Units#580]
            :                                +- SortMergeJoin [CourseId#585], [CourseId#579]
            :                                   :- Sort [CourseId#585 ASC], false, 0
            :                                   :  +- TungstenExchange hashpartitioning(CourseId#585,5), None
            :                                   :     +- ConvertToUnsafe
            :                                   :        +- Scan ExistingRDD[StudentId#584,CourseId#585] 
            :                                   +- Sort [CourseId#579 ASC], false, 0
            :                                      +- TungstenExchange hashpartitioning(CourseId#579,5), None
            :                                         +- Project [CourseId#579,Units#580]
            :                                            +- Scan ExistingRDD[Name#578,CourseId#579,Units#580] 
            +- Sort [StudentId#581 ASC,CourseId#582 ASC], false, 0
               +- TungstenExchange hashpartitioning(StudentId#581,CourseId#582,5), None
                  +- Project [StudentId#581,CourseId#582]
                     +- Scan ExistingRDD[StudentId#581,CourseId#582,Grade#583]
17/03/27 22:25:39 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:39 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 39 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 13 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 17 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 21 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 27 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 35 (rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO DAGScheduler: Got job 0 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:25:39 INFO DAGScheduler: Final stage: ResultStage 6 (collect at QuerySuite.scala:64)
17/03/27 22:25:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0, ShuffleMapStage 5)
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.8 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53301 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[39] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2420 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2473 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2466 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2465 bytes)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.3 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53301 (size: 4.3 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 25 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 25 tasks
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53301 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[17] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 5.8 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53301 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2477 bytes)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2620 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2674 bytes)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 44 ms on localhost (1/5)
17/03/27 22:25:39 INFO GenerateSafeProjection: Code generated in 10.775921 ms
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 43 ms on localhost (2/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 44 ms on localhost (3/5)
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2620 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2672 bytes)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 15 ms on localhost (1/25)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2672 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 51 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 10, localhost, partition 5,PROCESS_LOCAL, 2696 bytes)
17/03/27 22:25:39 INFO Executor: Running task 5.0 in stage 1.0 (TID 10)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 4 ms on localhost (2/25)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 32 ms on localhost (3/25)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 11, localhost, partition 6,PROCESS_LOCAL, 2750 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 36 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 0 (rdd at BigDatalogProgram.scala:41) finished in 0.067 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO Executor: Finished task 5.0 in stage 1.0 (TID 10). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 12, localhost, partition 7,PROCESS_LOCAL, 2696 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 10) in 14 ms on localhost (4/25)
17/03/27 22:25:39 INFO Executor: Running task 7.0 in stage 1.0 (TID 12)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 13, localhost, partition 8,PROCESS_LOCAL, 2748 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 14, localhost, partition 9,PROCESS_LOCAL, 2748 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 18 ms on localhost (5/25)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 21 ms on localhost (6/25)
17/03/27 22:25:39 INFO Executor: Running task 8.0 in stage 1.0 (TID 13)
17/03/27 22:25:39 INFO Executor: Running task 9.0 in stage 1.0 (TID 14)
17/03/27 22:25:39 INFO Executor: Finished task 7.0 in stage 1.0 (TID 12). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 10.0 in stage 1.0 (TID 15, localhost, partition 10,PROCESS_LOCAL, 2694 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 12) in 15 ms on localhost (7/25)
17/03/27 22:25:39 INFO Executor: Running task 10.0 in stage 1.0 (TID 15)
17/03/27 22:25:39 INFO Executor: Finished task 9.0 in stage 1.0 (TID 14). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 11.0 in stage 1.0 (TID 16, localhost, partition 11,PROCESS_LOCAL, 2743 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 14) in 15 ms on localhost (8/25)
17/03/27 22:25:39 INFO Executor: Running task 11.0 in stage 1.0 (TID 16)
17/03/27 22:25:39 INFO Executor: Running task 6.0 in stage 1.0 (TID 11)
17/03/27 22:25:39 INFO Executor: Finished task 10.0 in stage 1.0 (TID 15). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 12.0 in stage 1.0 (TID 17, localhost, partition 12,PROCESS_LOCAL, 2694 bytes)
17/03/27 22:25:39 INFO Executor: Running task 12.0 in stage 1.0 (TID 17)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 10.0 in stage 1.0 (TID 15) in 12 ms on localhost (9/25)
17/03/27 22:25:39 INFO Executor: Finished task 11.0 in stage 1.0 (TID 16). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 13.0 in stage 1.0 (TID 18, localhost, partition 13,PROCESS_LOCAL, 2746 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 11.0 in stage 1.0 (TID 16) in 11 ms on localhost (10/25)
17/03/27 22:25:39 INFO Executor: Running task 13.0 in stage 1.0 (TID 18)
17/03/27 22:25:39 INFO Executor: Finished task 8.0 in stage 1.0 (TID 13). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 14.0 in stage 1.0 (TID 19, localhost, partition 14,PROCESS_LOCAL, 2746 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 13) in 36 ms on localhost (11/25)
17/03/27 22:25:39 INFO Executor: Finished task 12.0 in stage 1.0 (TID 17). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Running task 14.0 in stage 1.0 (TID 19)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 15.0 in stage 1.0 (TID 20, localhost, partition 15,PROCESS_LOCAL, 2697 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 12.0 in stage 1.0 (TID 17) in 12 ms on localhost (12/25)
17/03/27 22:25:39 INFO Executor: Running task 15.0 in stage 1.0 (TID 20)
17/03/27 22:25:39 INFO Executor: Finished task 6.0 in stage 1.0 (TID 11). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 16.0 in stage 1.0 (TID 21, localhost, partition 16,PROCESS_LOCAL, 2751 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 11) in 46 ms on localhost (13/25)
17/03/27 22:25:39 INFO Executor: Running task 16.0 in stage 1.0 (TID 21)
17/03/27 22:25:39 INFO Executor: Finished task 15.0 in stage 1.0 (TID 20). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 17.0 in stage 1.0 (TID 22, localhost, partition 17,PROCESS_LOCAL, 2697 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 15.0 in stage 1.0 (TID 20) in 12 ms on localhost (14/25)
17/03/27 22:25:39 INFO Executor: Running task 17.0 in stage 1.0 (TID 22)
17/03/27 22:25:39 INFO Executor: Finished task 16.0 in stage 1.0 (TID 21). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 18.0 in stage 1.0 (TID 23, localhost, partition 18,PROCESS_LOCAL, 2749 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 16.0 in stage 1.0 (TID 21) in 10 ms on localhost (15/25)
17/03/27 22:25:39 INFO Executor: Running task 18.0 in stage 1.0 (TID 23)
17/03/27 22:25:39 INFO Executor: Finished task 17.0 in stage 1.0 (TID 22). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 19.0 in stage 1.0 (TID 24, localhost, partition 19,PROCESS_LOCAL, 2749 bytes)
17/03/27 22:25:39 INFO Executor: Running task 19.0 in stage 1.0 (TID 24)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 17.0 in stage 1.0 (TID 22) in 11 ms on localhost (16/25)
17/03/27 22:25:39 INFO Executor: Finished task 18.0 in stage 1.0 (TID 23). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 20.0 in stage 1.0 (TID 25, localhost, partition 20,PROCESS_LOCAL, 2695 bytes)
17/03/27 22:25:39 INFO Executor: Running task 20.0 in stage 1.0 (TID 25)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 18.0 in stage 1.0 (TID 23) in 11 ms on localhost (17/25)
17/03/27 22:25:39 INFO Executor: Finished task 13.0 in stage 1.0 (TID 18). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 21.0 in stage 1.0 (TID 26, localhost, partition 21,PROCESS_LOCAL, 2749 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 13.0 in stage 1.0 (TID 18) in 42 ms on localhost (18/25)
17/03/27 22:25:39 INFO Executor: Running task 21.0 in stage 1.0 (TID 26)
17/03/27 22:25:39 INFO Executor: Finished task 14.0 in stage 1.0 (TID 19). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 22.0 in stage 1.0 (TID 27, localhost, partition 22,PROCESS_LOCAL, 2695 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 14.0 in stage 1.0 (TID 19) in 37 ms on localhost (19/25)
17/03/27 22:25:39 INFO Executor: Running task 22.0 in stage 1.0 (TID 27)
17/03/27 22:25:39 INFO Executor: Finished task 19.0 in stage 1.0 (TID 24). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 23.0 in stage 1.0 (TID 28, localhost, partition 23,PROCESS_LOCAL, 2747 bytes)
17/03/27 22:25:39 INFO Executor: Running task 23.0 in stage 1.0 (TID 28)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 19.0 in stage 1.0 (TID 24) in 18 ms on localhost (20/25)
17/03/27 22:25:39 INFO Executor: Finished task 20.0 in stage 1.0 (TID 25). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 24.0 in stage 1.0 (TID 29, localhost, partition 24,PROCESS_LOCAL, 2747 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 20.0 in stage 1.0 (TID 25) in 17 ms on localhost (21/25)
17/03/27 22:25:39 INFO Executor: Running task 24.0 in stage 1.0 (TID 29)
17/03/27 22:25:39 INFO Executor: Finished task 21.0 in stage 1.0 (TID 26). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 21.0 in stage 1.0 (TID 26) in 15 ms on localhost (22/25)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 30)
17/03/27 22:25:39 INFO Executor: Finished task 22.0 in stage 1.0 (TID 27). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 31, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 31)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 22.0 in stage 1.0 (TID 27) in 19 ms on localhost (23/25)
17/03/27 22:25:39 INFO Executor: Finished task 23.0 in stage 1.0 (TID 28). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 32, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 23.0 in stage 1.0 (TID 28) in 20 ms on localhost (24/25)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 2.0 (TID 32)
17/03/27 22:25:39 INFO Executor: Finished task 24.0 in stage 1.0 (TID 29). 1486 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 33, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 2.0 (TID 33)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 24.0 in stage 1.0 (TID 29) in 27 ms on localhost (25/25)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 1 (rdd at BigDatalogProgram.scala:41) finished in 0.173 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set(ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 2.0 (TID 31). 1222 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 34, localhost, partition 4,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 31) in 18 ms on localhost (1/5)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 2.0 (TID 34)
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 2.0 (TID 30). 1222 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 2.0 (TID 34). 1222 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 35, localhost, partition 0,PROCESS_LOCAL, 2384 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 3.0 (TID 35)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 36, localhost, partition 1,PROCESS_LOCAL, 2438 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 34) in 11 ms on localhost (2/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 30) in 36 ms on localhost (3/5)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 3.0 (TID 36)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 2.0 (TID 32). 1222 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 37, localhost, partition 2,PROCESS_LOCAL, 2384 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 32) in 25 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 3.0 (TID 37)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 2.0 (TID 33). 1222 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 38, localhost, partition 3,PROCESS_LOCAL, 2436 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 33) in 18 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 2 (rdd at BigDatalogProgram.scala:41) finished in 0.187 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 3.0 (TID 38)
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 3.0 (TID 35). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 39, localhost, partition 4,PROCESS_LOCAL, 2436 bytes)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 3.0 (TID 39)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 35) in 13 ms on localhost (1/5)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 3.0 (TID 37). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 37) in 13 ms on localhost (2/5)
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 3.0 (TID 36). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 36) in 17 ms on localhost (3/5)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 3.0 (TID 38). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 38) in 16 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 3.0 (TID 39). 1367 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 39) in 11 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 3 (rdd at BigDatalogProgram.scala:41) finished in 0.203 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set()
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6, ShuffleMapStage 4)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[27] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 13.5 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.4 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53301 (size: 6.4 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[27] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 40, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 41, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 42, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 43, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 4.0 (TID 40)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 4.0 (TID 42)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 4.0 (TID 43)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 4.0 (TID 41)
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO GenerateUnsafeProjection: Code generated in 3.741953 ms
17/03/27 22:25:39 INFO GenerateMutableProjection: Code generated in 2.9212 ms
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 4.0 (TID 41). 2055 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 44, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 41) in 21 ms on localhost (1/5)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 4.0 (TID 44)
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 4.0 (TID 42). 2055 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 42) in 29 ms on localhost (2/5)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 4.0 (TID 43). 2055 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 43) in 35 ms on localhost (3/5)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 4.0 (TID 44). 2055 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 44) in 21 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 4.0 (TID 40). 2055 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 40) in 42 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 4 (rdd at BigDatalogProgram.scala:41) finished in 0.042 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set()
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ResultStage 6)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[35] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.1 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53301 (size: 7.9 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[35] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 45, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 46, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 47, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 48, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 5.0 (TID 45)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 5.0 (TID 47)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 5.0 (TID 48)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 5.0 (TID 46)
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 20 non-empty blocks out of 25 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 20 non-empty blocks out of 25 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 20 non-empty blocks out of 25 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 20 non-empty blocks out of 25 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO GeneratePredicate: Code generated in 2.27794 ms
17/03/27 22:25:39 INFO GeneratePredicate: Code generated in 1.508697 ms
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 5.0 (TID 46). 2958 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 49, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 46) in 16 ms on localhost (1/5)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 5.0 (TID 49)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 5.0 (TID 47). 2958 bytes result sent to driver
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 20 non-empty blocks out of 25 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 47) in 18 ms on localhost (2/5)
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 5.0 (TID 45). 2958 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 45) in 25 ms on localhost (3/5)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 5.0 (TID 48). 2958 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 48) in 27 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 5.0 (TID 49). 2958 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 49) in 20 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 5 (rdd at BigDatalogProgram.scala:41) finished in 0.035 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set()
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ResultStage 6)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[47] at rdd at BigDatalogProgram.scala:41), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 21.1 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53301 (size: 8.6 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 6 (MapPartitionsRDD[47] at rdd at BigDatalogProgram.scala:41)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 50, localhost, partition 0,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 51, localhost, partition 1,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 52, localhost, partition 2,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 53, localhost, partition 3,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 6.0 (TID 50)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 6.0 (TID 51)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 6.0 (TID 52)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 6.0 (TID 53)
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO GeneratePredicate: Code generated in 3.544911 ms
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 6.0 (TID 52). 4688 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 6.0 (TID 50). 4734 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 54, localhost, partition 4,NODE_LOCAL, 2159 bytes)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 6.0 (TID 54)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 52) in 12 ms on localhost (1/5)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 6.0 (TID 53). 4770 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 50) in 13 ms on localhost (2/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 53) in 12 ms on localhost (3/5)
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 3 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 6.0 (TID 54). 4770 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 54) in 8 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 6.0 (TID 51). 4814 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 51) in 21 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ResultStage 6 (collect at QuerySuite.scala:64) finished in 0.023 s
17/03/27 22:25:39 INFO DAGScheduler: Job 0 finished: collect at QuerySuite.scala:64, took 0.322582 s
17/03/27 22:25:39 INFO NegationQuerySuite: ========== END BigDatalog Query 1 END ==========

17/03/27 22:25:39 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:25:39 INFO MemoryStore: MemoryStore cleared
17/03/27 22:25:39 INFO BlockManager: BlockManager stopped
17/03/27 22:25:39 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:25:39 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:25:39 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:25:39 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:25:39 INFO SparkContext: Successfully stopped SparkContext
[32m- can_enroll(StudentId, CourseId)[0m
17/03/27 22:25:39 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:39 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:39 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:39 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[32mAggregatesInRecursionQuerySuite:[0m
17/03/27 22:25:39 INFO Utils: Successfully started service 'sparkDriver' on port 53319.
17/03/27 22:25:39 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:39 INFO Remoting: Starting remoting
17/03/27 22:25:39 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53332]
17/03/27 22:25:39 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53332.
17/03/27 22:25:39 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:39 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:39 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-024bcf67-a4db-43ea-afcf-5504c2aa9c72
17/03/27 22:25:39 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:39 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:39 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:39 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53350.
17/03/27 22:25:39 INFO NettyBlockTransferService: Server created on 53350
17/03/27 22:25:39 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:39 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53350 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53350)
17/03/27 22:25:39 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:39 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667939576
17/03/27 22:25:39 INFO AggregatesInRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:39 INFO BigDatalogContext: BigDatalog Query: "shortestpaths(A,B,C)"
17/03/27 22:25:39 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:39 INFO BigDatalogContext: 
0: mminpath(X as A, Y as B, FSAggr_1 as C) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: MonotonicSemiNaive)
Exit Rules: 
 1: (X, Y, mmin(D) as FSAggr_1) <AGGREGATE_FS>
  2: arc(X, Y, D) <BASE_RELATION>
Recursive Rules: 
 1: (X, Y, mmin(D) as FSAggr_1) <AGGREGATE_FS>
  2: (X, Y, D1 + D as D) <PROJECT>
   3: (0.Y = 1.X) <JOIN>
    4: mminpath(X, Y, D1) <RECURSIVE_RELATION>
    4: arc(X, Y, D) <BASE_RELATION>
17/03/27 22:25:39 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:39 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:39 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery mminpath
+- 'Project [unresolvedalias('X AS A#599),unresolvedalias('Y AS B#600),unresolvedalias('FSAggr_1 AS C#601)]
   +- 'AggregateRecursion mminpath, true, [1,0,0]
      :- 'Subquery fs_aggregate_mminpath_1
      :  +- 'MonotonicAggregate ['arc.X,'arc.Y], ['arc.X,'arc.Y,unresolvedalias('mmin('arc.D) AS FSAggr_1#602)], [1,0,0]
      :     +- 'UnresolvedRelation `arc`, None
      +- 'Subquery fs_aggregate_mminpath_2
         +- 'MonotonicAggregate ['mminpath1.X,'arc2.Y], ['mminpath1.X,'arc2.Y,unresolvedalias('mmin('D) AS FSAggr_1#607)], [1,0,0]
            +- 'Project ['mminpath1.X,'arc2.Y,unresolvedalias(('mminpath1.D1 + 'arc2.D) AS D#606)]
               +- 'Join Inner, Some(('mminpath1.Y = 'arc2.X))
                  :- Subquery mminpath1
                  :  +- AggregateRelation mminpath, [X#603,Y#604,D1#605], [1,0,0]
                  +- 'BroadcastHint
                     +- 'Subquery arc2
                        +- 'Project [*]
                           +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: int, B: int, C: int
Subquery mminpath
+- Project [X#603 AS A#599,Y#594 AS B#600,FSAggr_1#607 AS C#601]
   +- AggregateRecursion mminpath, true, [1,0,0]
      :- Subquery fs_aggregate_mminpath_1
      :  +- MonotonicAggregate [X#593,Y#594], [X#593,Y#594,(mmin(D#595),mode=Complete,isDistinct=false) AS FSAggr_1#602], [1,0,0]
      :     +- Subquery arc
      :        +- LogicalRDD [X#593,Y#594,D#595], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Subquery fs_aggregate_mminpath_2
         +- MonotonicAggregate [X#603,Y#594], [X#603,Y#594,(mmin(D#606),mode=Complete,isDistinct=false) AS FSAggr_1#607], [1,0,0]
            +- Project [X#603,Y#594,(D1#605 + D#595) AS D#606]
               +- Join Inner, Some((Y#604 = X#593))
                  :- Subquery mminpath1
                  :  +- AggregateRelation mminpath, [X#603,Y#604,D1#605], [1,0,0]
                  +- BroadcastHint
                     +- Subquery arc2
                        +- Project [X#593,Y#594,D#595]
                           +- Subquery arc
                              +- LogicalRDD [X#593,Y#594,D#595], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Project [X#603 AS A#599,Y#594 AS B#600,FSAggr_1#607 AS C#601]
+- AggregateRecursion mminpath, true, [1,0,0]
   :- MonotonicAggregate [X#593,Y#594], [X#593,Y#594,(mmin(D#595),mode=Complete,isDistinct=false) AS FSAggr_1#602], [1,0,0]
   :  +- LogicalRDD [X#593,Y#594,D#595], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- MonotonicAggregate [X#603,Y#594], [X#603,Y#594,(mmin(D#606),mode=Complete,isDistinct=false) AS FSAggr_1#607], [1,0,0]
      +- Project [X#603,Y#594,(D1#605 + D#595) AS D#606]
         +- Join Inner, Some((Y#604 = X#593))
            :- AggregateRelation mminpath, [X#603,Y#604,D1#605], [1,0,0]
            +- BroadcastHint
               +- Project [X#593,Y#594,D#595]
                  +- LogicalRDD [X#593,Y#594,D#595], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Project [X#603 AS A#599,Y#594 AS B#600,FSAggr_1#607 AS C#601]
+- AggregateRecursion [X#603,Y#594,FSAggr_1#607] (Linear) [mminpath][1,0,0]
   :- MonotonicAggregate(key=[X#593,Y#594], functions=[(mmin(D#595),mode=Final,isDistinct=false)], output=[X#593,Y#594,FSAggr_1#602])
   :  +- TungstenExchange hashpartitioning(X#593,5), None
   :     +- MonotonicAggregatePartial(key=[X#593,Y#594], functions=[(mmin(D#595),mode=Partial,isDistinct=false)], output=[X#593,Y#594,mmin#610])
   :        +- Scan ExistingRDD[X#593,Y#594,D#595] 
   +- MonotonicAggregate(key=[X#603,Y#594], functions=[(mmin(D#606),mode=Final,isDistinct=false)], output=[X#603,Y#594,FSAggr_1#607])
      +- MonotonicAggregatePartial(key=[X#603,Y#594], functions=[(mmin(D#606),mode=Partial,isDistinct=false)], output=[X#603,Y#594,mmin#613])
         +- Project [X#603,Y#594,(D1#605 + D#595) AS D#606]
            +- BroadcastHashJoin [Y#604], [X#593], BuildRight
               :- AggregateRelation [X#603,Y#604,D1#605](mminpath)
               +- Project [X#593,Y#594,D#595]
                  +- Scan ExistingRDD[X#593,Y#594,D#595]
17/03/27 22:25:39 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:39 INFO AggregateRecursion: Recursion operator configuration settings:
17/03/27 22:25:39 INFO AggregateRecursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:39 INFO AggregateRecursion: Aggregate recursion version: Single-Job PSN w/ AggregateSetRDD
17/03/27 22:25:39 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:39 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:39 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:39 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:39 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:39 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at run at null:-1), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53350 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at run at null:-1)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2362 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:39 INFO SparkContext: Starting job: reduce at AggregateSetRDD.scala:110
17/03/27 22:25:39 INFO DAGScheduler: Registering RDD 5 (execute at MonotonicAggregate.scala:151)
17/03/27 22:25:39 INFO DAGScheduler: Got job 1 (reduce at AggregateSetRDD.scala:110) with 5 output partitions
17/03/27 22:25:39 INFO DAGScheduler: Final stage: ResultStage 2 (reduce at AggregateSetRDD.scala:110)
17/03/27 22:25:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:39 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at execute at MonotonicAggregate.scala:151), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53350 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at execute at MonotonicAggregate.scala:151)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1500 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1500 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1500 bytes result sent to driver
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1549 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2361 bytes)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1500 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 21 ms on localhost (1/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 28 ms on localhost (2/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 29 ms on localhost (3/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 28 ms on localhost (4/5)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 28 ms on localhost (5/5)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.029 s
17/03/27 22:25:39 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1495 bytes result sent to driver
17/03/27 22:25:39 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.033669 s
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.5 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 300.0 B, free 2.0 GB)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 23 ms on localhost (1/5)
17/03/27 22:25:39 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:39 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1495 bytes result sent to driver
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53350 (size: 300.0 B, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 2 from run at null:-1
17/03/27 22:25:39 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 25 ms on localhost (2/5)
17/03/27 22:25:39 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1495 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 24 ms on localhost (3/5)
17/03/27 22:25:39 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1495 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 29 ms on localhost (4/5)
17/03/27 22:25:39 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1495 bytes result sent to driver
17/03/27 22:25:39 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 12 ms on localhost (5/5)
17/03/27 22:25:39 INFO DAGScheduler: ShuffleMapStage 1 (execute at MonotonicAggregate.scala:151) finished in 0.038 s
17/03/27 22:25:39 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:39 INFO DAGScheduler: running: Set()
17/03/27 22:25:39 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/03/27 22:25:39 INFO DAGScheduler: failed: Set()
17/03/27 22:25:39 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:39 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[9] at map at AggregateSetRDD.scala:110), which has no missing parents
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 17.3 KB, free 2.0 GB)
17/03/27 22:25:39 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:39 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53350 (size: 8.2 KB, free: 2.0 GB)
17/03/27 22:25:39 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:39 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[9] at map at AggregateSetRDD.scala:110)
17/03/27 22:25:39 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:39 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:39 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:39 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:39 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:39 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:39 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:39 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:25:39 INFO CacheManager: Partition rdd_7_1 not found, computing it
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO CacheManager: Partition rdd_7_0 not found, computing it
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:40 INFO MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 326.2 MB, free 1722.0 MB)
17/03/27 22:25:40 INFO BlockManagerInfo: Added rdd_7_2 in memory on localhost:53350 (size: 326.2 MB, free: 1722.1 MB)
17/03/27 22:25:40 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 2491 bytes result sent to driver
17/03/27 22:25:40 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:40 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 628 ms on localhost (1/5)
17/03/27 22:25:40 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:40 INFO CacheManager: Partition rdd_7_4 not found, computing it
17/03/27 22:25:40 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:40 INFO MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 326.2 MB, free 1395.9 MB)
17/03/27 22:25:40 INFO BlockManagerInfo: Added rdd_7_3 in memory on localhost:53350 (size: 326.2 MB, free: 1395.9 MB)
17/03/27 22:25:41 INFO MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 326.2 MB, free 1069.7 MB)
17/03/27 22:25:41 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2491 bytes result sent to driver
17/03/27 22:25:41 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 325.3 MB, free 744.5 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added rdd_7_0 in memory on localhost:53350 (size: 326.2 MB, free: 1069.8 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added rdd_7_1 in memory on localhost:53350 (size: 325.3 MB, free: 744.5 MB)
17/03/27 22:25:41 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2491 bytes result sent to driver
17/03/27 22:25:41 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 1261 ms on localhost (2/5)
17/03/27 22:25:41 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2491 bytes result sent to driver
17/03/27 22:25:41 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 1261 ms on localhost (3/5)
17/03/27 22:25:41 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 1262 ms on localhost (4/5)
17/03/27 22:25:41 INFO MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 454.5 MB, free 290.0 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added rdd_7_4 in memory on localhost:53350 (size: 454.5 MB, free: 290.0 MB)
17/03/27 22:25:41 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2491 bytes result sent to driver
17/03/27 22:25:41 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 993 ms on localhost (5/5)
17/03/27 22:25:41 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:41 INFO DAGScheduler: ResultStage 2 (reduce at AggregateSetRDD.scala:110) finished in 1.622 s
17/03/27 22:25:41 INFO DAGScheduler: Job 1 finished: reduce at AggregateSetRDD.scala:110, took 1.673682 s
17/03/27 22:25:41 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:41 INFO AggregateRecursion: Fixed Point Iteration # 1, time: 14ms
17/03/27 22:25:41 INFO DAGScheduler: Got job 2 (runFixedPointJob at AggregateRecursion.scala:159) with 5 output partitions
17/03/27 22:25:41 INFO DAGScheduler: Final stage: FixedPointResultStage 3 (runFixedPointJob at AggregateRecursion.scala:159)
17/03/27 22:25:41 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:41 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:41 INFO DAGScheduler: Submitting FixedPointResultStage 3 (SetRDD - deltaSPrime SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:41 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 20.8 KB, free 290.0 MB)
17/03/27 22:25:41 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.2 KB, free 290.0 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53350 (size: 9.2 KB, free: 290.0 MB)
17/03/27 22:25:41 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:41 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 3 (SetRDD - deltaSPrime SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:41 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:41 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2197 bytes)
17/03/27 22:25:41 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2197 bytes)
17/03/27 22:25:41 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2197 bytes)
17/03/27 22:25:41 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2197 bytes)
17/03/27 22:25:41 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:41 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:41 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:41 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:41 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:25:41 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:25:41 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:25:41 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:25:41 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:25:41 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:25:41 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_2 locally
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_2 locally
17/03/27 22:25:41 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_3 locally
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_3 locally
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_0 locally
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_0 locally
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:25:41 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:25:41 INFO AggregateSetRDDMinMaxPartition: Update deltaSPrime set size before 2 after 2, delta set size 0 took 1 ms
17/03/27 22:25:41 INFO AggregateSetRDDMinMaxPartition: Update deltaSPrime set size before 2 after 4, delta set size 2 took 0 ms
17/03/27 22:25:41 INFO AggregateSetRDDMinMaxPartition: Update deltaSPrime set size before 2 after 4, delta set size 2 took 1 ms
17/03/27 22:25:41 INFO AggregateSetRDDMinMaxPartition: Update deltaSPrime set size before 2 after 4, delta set size 2 took 0 ms
17/03/27 22:25:41 INFO MemoryStore: 8 blocks selected for dropping
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:25:41 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:53350 (size: 2.7 KB)
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:41 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53350 (size: 4.4 KB)
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:25:41 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53350 (size: 300.0 B)
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:25:41 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53350 (size: 8.2 KB)
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:25:41 INFO BlockManager: Dropping block rdd_7_4 from memory
17/03/27 22:25:41 INFO BlockManagerInfo: Removed rdd_7_4 on localhost:53350 in memory (size: 454.5 MB, free: 744.5 MB)
17/03/27 22:25:41 INFO MemoryStore: 4 blocks selected for dropping
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:25:41 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:53350 (size: 9.2 KB)
17/03/27 22:25:41 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:25:41 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:25:41 INFO BlockManager: Dropping block rdd_7_2 from memory
17/03/27 22:25:41 INFO BlockManagerInfo: Removed rdd_7_2 on localhost:53350 in memory (size: 326.2 MB, free: 1070.7 MB)
17/03/27 22:25:41 INFO BlockManager: Dropping block rdd_7_3 from memory
17/03/27 22:25:41 INFO BlockManagerInfo: Removed rdd_7_3 on localhost:53350 in memory (size: 326.2 MB, free: 1396.8 MB)
17/03/27 22:25:41 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:41 INFO BlockManager: Dropping block rdd_7_0 from memory
17/03/27 22:25:41 INFO BlockManagerInfo: Removed rdd_7_0 on localhost:53350 in memory (size: 326.2 MB, free: 1723.0 MB)
17/03/27 22:25:41 INFO BlockManager: Dropping block rdd_7_1 from memory
17/03/27 22:25:41 INFO BlockManagerInfo: Removed rdd_7_1 on localhost:53350 in memory (size: 325.3 MB, free: 2.0 GB)
17/03/27 22:25:41 INFO MemoryStore: Will not store rdd_14_1 as it would require dropping another block from the same RDD
17/03/27 22:25:41 WARN MemoryStore: Not enough space to cache rdd_14_1 in memory! (computed 325.4 MB so far)
17/03/27 22:25:41 INFO MemoryStore: Memory use = 2.5 KB (blocks) + 2047.1 MB (scratch space shared across 5 tasks(s)) = 2047.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:41 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 325.4 MB, free 1722.8 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added rdd_14_0 in memory on localhost:53350 (size: 325.4 MB, free: 1722.8 MB)
17/03/27 22:25:41 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 325.4 MB, free 1397.4 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added rdd_14_2 in memory on localhost:53350 (size: 325.4 MB, free: 1397.4 MB)
17/03/27 22:25:41 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 325.4 MB, free 1072.0 MB)
17/03/27 22:25:41 INFO BlockManagerInfo: Added rdd_14_3 in memory on localhost:53350 (size: 325.4 MB, free: 1072.0 MB)
17/03/27 22:25:42 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:42 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:25:42 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:25:42 INFO BlockManager: Dropping block rdd_14_0 from memory
17/03/27 22:25:42 INFO BlockManagerInfo: Removed rdd_14_0 on localhost:53350 in memory (size: 325.4 MB, free: 1397.4 MB)
17/03/27 22:25:42 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:42 INFO BlockManager: Dropping block rdd_14_2 from memory
17/03/27 22:25:42 INFO BlockManagerInfo: Removed rdd_14_2 on localhost:53350 in memory (size: 325.4 MB, free: 1722.8 MB)
17/03/27 22:25:42 INFO MemoryStore: Will not store rdd_16_3 as it would require dropping another block from the same RDD
17/03/27 22:25:42 WARN MemoryStore: Not enough space to cache rdd_16_3 in memory! (computed 356.6 MB so far)
17/03/27 22:25:42 INFO MemoryStore: Memory use = 325.4 MB (blocks) + 1705.3 MB (scratch space shared across 5 tasks(s)) = 2030.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:42 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 3922 bytes result sent to driver
17/03/27 22:25:42 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2197 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 738 ms on localhost (1/5)
17/03/27 22:25:42 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:25:42 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 20.8 KB, free 1722.8 MB)
17/03/27 22:25:42 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:42 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:25:42 INFO CacheManager: Partition rdd_7_4 not found, computing it
17/03/27 22:25:42 ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 19)
org.apache.spark.SparkException: Checkpoint block rdd_7_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:42 WARN TaskSetManager: Lost task 4.0 in stage 3.0 (TID 19, localhost): org.apache.spark.SparkException: Checkpoint block rdd_7_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:42 ERROR TaskSetManager: Task 4 in stage 3.0 failed 1 times; aborting job
17/03/27 22:25:42 INFO TaskSchedulerImpl: Cancelling stage 3
17/03/27 22:25:42 INFO TaskSchedulerImpl: Stage 3 was cancelled
17/03/27 22:25:42 INFO DAGScheduler: FixedPointResultStage 3 (runFixedPointJob at AggregateRecursion.scala:159) failed in 0.747 s
17/03/27 22:25:42 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 324.3 MB, free 1398.5 MB)
17/03/27 22:25:42 INFO DAGScheduler: Fixed Point Job 2 failed: runFixedPointJob at AggregateRecursion.scala:159, took 0.769099 s
17/03/27 22:25:42 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:42 INFO Executor: Executor is trying to kill task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:42 INFO Executor: Executor is trying to kill task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:42 INFO Executor: Executor is trying to kill task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:42 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:53350 (size: 324.3 MB, free: 1398.5 MB)
17/03/27 22:25:42 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:42 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:42 INFO Executor: Executor killed task 1.0 in stage 3.0 (TID 16)
17/03/27 22:25:42 WARN TaskSetManager: Lost task 1.0 in stage 3.0 (TID 16, localhost): TaskKilled (killed intentionally)
[31m- ShortestPaths with Monotonic Aggregate - LL - fff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 3.0 failed 1 times, most recent failure: Lost task 4.0 in stage 3.0 (TID 19, localhost): org.apache.spark.SparkException: Checkpoint block rdd_7_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_7_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  ...[0m
17/03/27 22:25:42 INFO Utils: Successfully started service 'sparkDriver' on port 53371.
17/03/27 22:25:42 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:42 INFO Remoting: Starting remoting
17/03/27 22:25:42 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53384]
17/03/27 22:25:42 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53384.
17/03/27 22:25:42 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:42 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:42 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-3ae007cf-3bd8-4152-a015-17ccd9faa4f0
17/03/27 22:25:42 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:42 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:42 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:42 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53401.
17/03/27 22:25:42 INFO NettyBlockTransferService: Server created on 53401
17/03/27 22:25:42 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:42 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53401 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53401)
17/03/27 22:25:42 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:42 INFO MemoryStore: Block rdd_16_2 stored as values in memory (estimated size 325.8 MB, free 1072.7 MB)
17/03/27 22:25:42 INFO BlockManagerInfo: Added rdd_16_2 in memory on localhost:53350 (size: 325.8 MB, free: 1072.7 MB)
17/03/27 22:25:42 INFO Executor: Executor killed task 2.0 in stage 3.0 (TID 17)
17/03/27 22:25:42 WARN TaskSetManager: Lost task 2.0 in stage 3.0 (TID 17, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:42 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667942269
17/03/27 22:25:42 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$1.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:40)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$1.apply(AggregatesInRecursionQuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$1.apply(AggregatesInRecursionQuerySuite.scala:33)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$2.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:56)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$2.apply(AggregatesInRecursionQuerySuite.scala:49)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$2.apply(AggregatesInRecursionQuerySuite.scala:49)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:42 INFO AggregatesInRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:42 INFO BigDatalogContext: BigDatalog Query: "shortestpaths(A,B,C)"
17/03/27 22:25:42 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:42 INFO BigDatalogContext: 
0: mminpath(X as A, Z as B, FSAggr_1 as C) <RECURSIVE_CLIQUE>(Recursion: NONLINEAR, Evaluation Type: MonotonicSemiNaive)
Exit Rules: 
 1: (X, Y, mmin(D) as FSAggr_1) <AGGREGATE_FS>
  2: arc(X, Y, D) <BASE_RELATION>
Recursive Rules: 
 1: (X, Z, mmin(D) as FSAggr_1) <AGGREGATE_FS>
  2: (X, Z, D1 + D2 as D) <PROJECT>
   3: (0.Y = 1.Y) <JOIN>
    4: mminpath(X, Y, D1) <RECURSIVE_RELATION>
    4: mminpath(Y, Z, D2) <RECURSIVE_RELATION>
17/03/27 22:25:42 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:42 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:42 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery mminpath
+- 'Project [unresolvedalias('X AS A#626),unresolvedalias('Z AS B#627),unresolvedalias('FSAggr_1 AS C#628)]
   +- 'AggregateRecursion mminpath, false, [1,0,0]
      :- 'Subquery fs_aggregate_mminpath_1
      :  +- 'MonotonicAggregate ['arc.X,'arc.Y], ['arc.X,'arc.Y,unresolvedalias('mmin('arc.D) AS FSAggr_1#629)], [1,0,0]
      :     +- 'UnresolvedRelation `arc`, None
      +- 'Subquery fs_aggregate_mminpath_2
         +- 'MonotonicAggregate ['mminpath1.X,'mminpath2.Z], ['mminpath1.X,'mminpath2.Z,unresolvedalias('mmin('D) AS FSAggr_1#637)], [1,0,0]
            +- 'Project ['mminpath1.X,'mminpath2.Z,unresolvedalias(('mminpath1.D1 + 'mminpath2.D2) AS D#636)]
               +- 'Join Inner, Some(('mminpath1.Y = 'mminpath2.Y))
                  :- Subquery mminpath1
                  :  +- AggregateRelation mminpath, [X#630,Y#631,D1#632], [1,0,0]
                  +- Subquery mminpath2
                     +- NonLinearRecursiveRelation mminpath, [Y#633,Z#634,D2#635], [1,0,0]

== Analyzed Logical Plan ==
A: int, B: int, C: int
Subquery mminpath
+- Project [X#630 AS A#626,Z#634 AS B#627,FSAggr_1#637 AS C#628]
   +- AggregateRecursion mminpath, false, [1,0,0]
      :- Subquery fs_aggregate_mminpath_1
      :  +- MonotonicAggregate [X#620,Y#621], [X#620,Y#621,(mmin(D#622),mode=Complete,isDistinct=false) AS FSAggr_1#629], [1,0,0]
      :     +- Subquery arc
      :        +- LogicalRDD [X#620,Y#621,D#622], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Subquery fs_aggregate_mminpath_2
         +- MonotonicAggregate [X#630,Z#634], [X#630,Z#634,(mmin(D#636),mode=Complete,isDistinct=false) AS FSAggr_1#637], [1,0,0]
            +- Project [X#630,Z#634,(D1#632 + D2#635) AS D#636]
               +- Join Inner, Some((Y#631 = Y#633))
                  :- Subquery mminpath1
                  :  +- AggregateRelation mminpath, [X#630,Y#631,D1#632], [1,0,0]
                  +- Subquery mminpath2
                     +- NonLinearRecursiveRelation mminpath, [Y#633,Z#634,D2#635], [1,0,0]

== Optimized Logical Plan ==
Project [X#630 AS A#626,Z#634 AS B#627,FSAggr_1#637 AS C#628]
+- AggregateRecursion mminpath, false, [1,0,0]
   :- MonotonicAggregate [X#620,Y#621], [X#620,Y#621,(mmin(D#622),mode=Complete,isDistinct=false) AS FSAggr_1#629], [1,0,0]
   :  +- LogicalRDD [X#620,Y#621,D#622], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- MonotonicAggregate [X#630,Z#634], [X#630,Z#634,(mmin(D#636),mode=Complete,isDistinct=false) AS FSAggr_1#637], [1,0,0]
      +- Project [X#630,Z#634,(D1#632 + D2#635) AS D#636]
         +- Join Inner, Some((Y#631 = Y#633))
            :- AggregateRelation mminpath, [X#630,Y#631,D1#632], [1,0,0]
            +- NonLinearRecursiveRelation mminpath, [Y#633,Z#634,D2#635], [1,0,0]

== Physical Plan ==
Project [X#630 AS A#626,Z#634 AS B#627,FSAggr_1#637 AS C#628]
+- AggregateRecursion [X#630,Z#634,FSAggr_1#637] (NonLinear) [mminpath][1,0,0]
   :- MonotonicAggregate(key=[X#620,Y#621], functions=[(mmin(D#622),mode=Final,isDistinct=false)], output=[X#620,Y#621,FSAggr_1#629])
   :  +- TungstenExchange hashpartitioning(X#620,5), None
   :     +- MonotonicAggregatePartial(key=[X#620,Y#621], functions=[(mmin(D#622),mode=Partial,isDistinct=false)], output=[X#620,Y#621,mmin#640])
   :        +- Scan ExistingRDD[X#620,Y#621,D#622] 
   +- MonotonicAggregate(key=[X#630,Z#634], functions=[(mmin(D#636),mode=Final,isDistinct=false)], output=[X#630,Z#634,FSAggr_1#637])
      +- TungstenExchange hashpartitioning(X#630,5), None
         +- MonotonicAggregatePartial(key=[X#630,Z#634], functions=[(mmin(D#636),mode=Partial,isDistinct=false)], output=[X#630,Z#634,mmin#643])
            +- Project [X#630,Z#634,(D1#632 + D2#635) AS D#636]
               +- SortMergeJoin [Y#631], [Y#633]
                  :- Sort [Y#631 ASC], false, 0
                  :  +- TungstenExchange hashpartitioning(Y#631,5), None
                  :     +- AggregateRelation [X#630,Y#631,D1#632](mminpath)
                  +- Sort [Y#633 ASC], false, 0
                     +- NonLinearRecursiveRelation [Y#633,Z#634,D2#635](all_mminpath)
17/03/27 22:25:42 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:42 INFO AggregateRecursion: Recursion operator configuration settings:
17/03/27 22:25:42 INFO AggregateRecursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:42 INFO AggregateRecursion: Aggregate recursion version: Single-Job PSN w/ AggregateSetRDD
17/03/27 22:25:42 INFO SparkContext: Starting job: reduce at AggregateSetRDD.scala:110
17/03/27 22:25:42 INFO DAGScheduler: Registering RDD 4 (execute at MonotonicAggregate.scala:151)
17/03/27 22:25:42 INFO DAGScheduler: Got job 0 (reduce at AggregateSetRDD.scala:110) with 5 output partitions
17/03/27 22:25:42 INFO DAGScheduler: Final stage: ResultStage 1 (reduce at AggregateSetRDD.scala:110)
17/03/27 22:25:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:42 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at execute at MonotonicAggregate.scala:151), which has no missing parents
17/03/27 22:25:42 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.6 KB, free 2.0 GB)
17/03/27 22:25:42 INFO MemoryStore: Block rdd_16_0 stored as values in memory (estimated size 325.9 MB, free 746.8 MB)
17/03/27 22:25:42 INFO BlockManagerInfo: Added rdd_16_0 in memory on localhost:53350 (size: 325.9 MB, free: 746.8 MB)
17/03/27 22:25:42 INFO Executor: Executor killed task 0.0 in stage 3.0 (TID 15)
17/03/27 22:25:42 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 15, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:42 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:42 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.4 KB, free 2.0 GB)
17/03/27 22:25:42 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53401 (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:42 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:42 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at execute at MonotonicAggregate.scala:151)
17/03/27 22:25:42 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:42 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2351 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2361 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2356 bytes)
17/03/27 22:25:42 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:42 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:42 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:42 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:42 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:42 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2397 bytes)
17/03/27 22:25:42 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:42 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 109 ms on localhost (1/5)
17/03/27 22:25:42 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1495 bytes result sent to driver
17/03/27 22:25:42 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1495 bytes result sent to driver
17/03/27 22:25:42 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1495 bytes result sent to driver
17/03/27 22:25:42 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1495 bytes result sent to driver
17/03/27 22:25:42 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 111 ms on localhost (2/5)
17/03/27 22:25:42 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 162 ms on localhost (3/5)
17/03/27 22:25:42 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 164 ms on localhost (4/5)
17/03/27 22:25:42 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 164 ms on localhost (5/5)
17/03/27 22:25:42 INFO DAGScheduler: ShuffleMapStage 0 (execute at MonotonicAggregate.scala:151) finished in 0.164 s
17/03/27 22:25:42 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:42 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:42 INFO DAGScheduler: running: Set()
17/03/27 22:25:42 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:42 INFO DAGScheduler: failed: Set()
17/03/27 22:25:42 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at map at AggregateSetRDD.scala:110), which has no missing parents
17/03/27 22:25:42 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.9 KB, free 2.0 GB)
17/03/27 22:25:42 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.9 KB, free 2.0 GB)
17/03/27 22:25:42 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53401 (size: 7.9 KB, free: 2.0 GB)
17/03/27 22:25:42 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:42 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at map at AggregateSetRDD.scala:110)
17/03/27 22:25:42 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:42 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:42 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:42 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:42 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:42 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:42 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:42 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:42 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:42 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:42 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:25:42 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 358.5 MB so far)
17/03/27 22:25:42 INFO MemoryStore: Memory use = 37.7 KB (blocks) + 1614.1 MB (scratch space shared across 5 tasks(s)) = 1614.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:42 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1950 bytes result sent to driver
17/03/27 22:25:42 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:42 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 278 ms on localhost (1/5)
17/03/27 22:25:42 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:42 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:43 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53401 in memory (size: 4.4 KB, free: 2.0 GB)
17/03/27 22:25:43 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 358.2 MB, free 1690.0 MB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:53401 (size: 358.2 MB, free: 1690.1 MB)
17/03/27 22:25:43 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 2319 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 762 ms on localhost (2/5)
17/03/27 22:25:43 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 390.4 MB, free 1299.6 MB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:53401 (size: 390.4 MB, free: 1299.6 MB)
17/03/27 22:25:43 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 2319 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 776 ms on localhost (3/5)
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1233
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1232
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1225
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1224
17/03/27 22:25:43 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:53401 in memory (size: 7.9 KB, free: 1299.6 MB)
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1223
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1222
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1221
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1220
17/03/27 22:25:43 INFO ContextCleaner: Cleaned accumulator 1208
17/03/27 22:25:43 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 422.7 MB, free 876.9 MB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:53401 (size: 422.7 MB, free: 876.9 MB)
17/03/27 22:25:43 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 2319 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 785 ms on localhost (4/5)
17/03/27 22:25:43 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 455.0 MB, free 422.0 MB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:53401 (size: 455.0 MB, free: 422.0 MB)
17/03/27 22:25:43 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 2319 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 682 ms on localhost (5/5)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:43 INFO DAGScheduler: ResultStage 1 (reduce at AggregateSetRDD.scala:110) finished in 0.960 s
17/03/27 22:25:43 INFO DAGScheduler: Job 0 finished: reduce at AggregateSetRDD.scala:110, took 1.163920 s
17/03/27 22:25:43 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:43 INFO AggregateRecursion: Fixed Point Iteration # 1, time: 17ms
17/03/27 22:25:43 INFO DAGScheduler: Registering RDD 10 (mapPartitionsInternal at AggregateSetRDD.scala:98)
17/03/27 22:25:43 INFO DAGScheduler: Registering RDD 17 (execute at MonotonicAggregate.scala:154)
17/03/27 22:25:43 INFO DAGScheduler: Got job 1 (runFixedPointJob at AggregateRecursion.scala:159) with 5 output partitions
17/03/27 22:25:43 INFO DAGScheduler: Final stage: FixedPointResultStage 4 (runFixedPointJob at AggregateRecursion.scala:159)
17/03/27 22:25:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/03/27 22:25:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/03/27 22:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[10] at mapPartitionsInternal at AggregateSetRDD.scala:98), which has no missing parents
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 19.8 KB, free 422.0 MB)
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.8 KB, free 421.9 MB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53401 (size: 8.8 KB, free: 422.0 MB)
17/03/27 22:25:43 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:43 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[10] at mapPartitionsInternal at AggregateSetRDD.scala:98)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:43 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:43 INFO Executor: Running task 4.0 in stage 2.0 (TID 13)
17/03/27 22:25:43 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:43 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:43 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:25:43 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:43 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3410 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 14, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 17 ms on localhost (1/5)
17/03/27 22:25:43 INFO Executor: Running task 3.0 in stage 2.0 (TID 14)
17/03/27 22:25:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 3410 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 19 ms on localhost (2/5)
17/03/27 22:25:43 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 3410 bytes result sent to driver
17/03/27 22:25:43 ERROR Executor: Exception in task 3.0 in stage 2.0 (TID 14)
org.apache.spark.SparkException: Checkpoint block rdd_6_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 20 ms on localhost (3/5)
17/03/27 22:25:43 WARN TaskSetManager: Lost task 3.0 in stage 2.0 (TID 14, localhost): org.apache.spark.SparkException: Checkpoint block rdd_6_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:43 ERROR TaskSetManager: Task 3 in stage 2.0 failed 1 times; aborting job
17/03/27 22:25:43 INFO TaskSchedulerImpl: Cancelling stage 2
17/03/27 22:25:43 INFO TaskSchedulerImpl: Stage 2 was cancelled
17/03/27 22:25:43 INFO DAGScheduler: ShuffleMapStage 2 (mapPartitionsInternal at AggregateSetRDD.scala:98) failed in 0.021 s
17/03/27 22:25:43 INFO Executor: Executor is trying to kill task 4.0 in stage 2.0 (TID 13)
17/03/27 22:25:43 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at AggregateRecursion.scala:159, took 0.043105 s
[31m- ShortestPaths with Monotonic Aggregate - NL - fff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 2.0 failed 1 times, most recent failure: Lost task 3.0 in stage 2.0 (TID 14, localhost): org.apache.spark.SparkException: Checkpoint block rdd_6_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_6_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)[0m
[31m  ...[0m
17/03/27 22:25:43 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:43 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:43 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:43 INFO Executor: Executor killed task 4.0 in stage 2.0 (TID 13)
17/03/27 22:25:43 WARN TaskSetManager: Lost task 4.0 in stage 2.0 (TID 13, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:43 INFO Utils: Successfully started service 'sparkDriver' on port 53421.
17/03/27 22:25:43 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:43 INFO Remoting: Starting remoting
17/03/27 22:25:43 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53434]
17/03/27 22:25:43 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53434.
17/03/27 22:25:43 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:43 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:43 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-235c7d13-5010-41c5-a7d9-4417abc0a5e5
17/03/27 22:25:43 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:43 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:43 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53451.
17/03/27 22:25:43 INFO NettyBlockTransferService: Server created on 53451
17/03/27 22:25:43 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:43 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53451 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53451)
17/03/27 22:25:43 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:43 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667943733
17/03/27 22:25:43 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$2.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:56)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$2.apply(AggregatesInRecursionQuerySuite.scala:49)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$2.apply(AggregatesInRecursionQuerySuite.scala:49)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$3.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:75)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$3.apply(AggregatesInRecursionQuerySuite.scala:65)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$3.apply(AggregatesInRecursionQuerySuite.scala:65)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:43 INFO AggregatesInRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:43 INFO BigDatalogContext: BigDatalog Query: "sssp(A,B)"
17/03/27 22:25:43 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:43 INFO BigDatalogContext: 
0: mminpath(Y as A, FSAggr_1 as B) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: MonotonicSemiNaive)
Exit Rules: 
 1: (X, mmin(D) as FSAggr_1) <AGGREGATE_FS>
  2: TUPLE(0 as X, 0 as D) <TUPLE>
Recursive Rules: 
 1: (Y, mmin(D) as FSAggr_1) <AGGREGATE_FS>
  2: (Y, D1 + D as D) <PROJECT>
   3: (0.X = 1.X) <JOIN>
    4: mminpath(X, D1) <RECURSIVE_RELATION>
    4: arc(X, Y, D) <BASE_RELATION>
17/03/27 22:25:43 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:43 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:43 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery mminpath
+- 'Project [unresolvedalias('Y AS A#655),unresolvedalias('FSAggr_1 AS B#656)]
   +- 'AggregateRecursion mminpath, true, [1,0]
      :- 'Subquery fs_aggregate_mminpath_1
      :  +- 'MonotonicAggregate ['TUPLE.X], ['TUPLE.X,unresolvedalias('mmin('TUPLE.D) AS FSAggr_1#659)], [1,0]
      :     +- Subquery TUPLE
      :        +- LocalRelation [X#657,D#658], [[0,0]]
      +- 'Subquery fs_aggregate_mminpath_2
         +- 'MonotonicAggregate ['arc.Y], ['arc.Y,unresolvedalias('mmin('D) AS FSAggr_1#663)], [1,0]
            +- 'Project ['arc.Y,unresolvedalias(('mminpath1.D1 + 'arc.D) AS D#662)]
               +- 'Join Inner, Some(('mminpath1.X = 'arc.X))
                  :- Subquery mminpath1
                  :  +- AggregateRelation mminpath, [X#660,D1#661], [1,0]
                  +- 'BroadcastHint
                     +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: int, B: int
Subquery mminpath
+- Project [Y#651 AS A#655,FSAggr_1#663 AS B#656]
   +- AggregateRecursion mminpath, true, [1,0]
      :- Subquery fs_aggregate_mminpath_1
      :  +- MonotonicAggregate [X#657], [X#657,(mmin(D#658),mode=Complete,isDistinct=false) AS FSAggr_1#659], [1,0]
      :     +- Subquery TUPLE
      :        +- LocalRelation [X#657,D#658], [[0,0]]
      +- Subquery fs_aggregate_mminpath_2
         +- MonotonicAggregate [Y#651], [Y#651,(mmin(D#662),mode=Complete,isDistinct=false) AS FSAggr_1#663], [1,0]
            +- Project [Y#651,(D1#661 + D#652) AS D#662]
               +- Join Inner, Some((X#660 = X#650))
                  :- Subquery mminpath1
                  :  +- AggregateRelation mminpath, [X#660,D1#661], [1,0]
                  +- BroadcastHint
                     +- Subquery arc
                        +- LogicalRDD [X#650,Y#651,D#652], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Project [Y#651 AS A#655,FSAggr_1#663 AS B#656]
+- AggregateRecursion mminpath, true, [1,0]
   :- MonotonicAggregate [X#657], [X#657,(mmin(D#658),mode=Complete,isDistinct=false) AS FSAggr_1#659], [1,0]
   :  +- LocalRelation [X#657,D#658], [[0,0]]
   +- MonotonicAggregate [Y#651], [Y#651,(mmin(D#662),mode=Complete,isDistinct=false) AS FSAggr_1#663], [1,0]
      +- Project [Y#651,(D1#661 + D#652) AS D#662]
         +- Join Inner, Some((X#660 = X#650))
            :- AggregateRelation mminpath, [X#660,D1#661], [1,0]
            +- BroadcastHint
               +- LogicalRDD [X#650,Y#651,D#652], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Project [Y#651 AS A#655,FSAggr_1#663 AS B#656]
+- AggregateRecursion [Y#651,FSAggr_1#663] (Linear) [mminpath][1,0]
   :- MonotonicAggregate(key=[X#657], functions=[(mmin(D#658),mode=Final,isDistinct=false)], output=[X#657,FSAggr_1#659])
   :  +- TungstenExchange hashpartitioning(X#657,5), None
   :     +- MonotonicAggregatePartial(key=[X#657], functions=[(mmin(D#658),mode=Partial,isDistinct=false)], output=[X#657,mmin#666])
   :        +- LocalTableScan [X#657,D#658], [[0,0]]
   +- MonotonicAggregate(key=[Y#651], functions=[(mmin(D#662),mode=Final,isDistinct=false)], output=[Y#651,FSAggr_1#663])
      +- TungstenExchange hashpartitioning(Y#651,5), None
         +- MonotonicAggregatePartial(key=[Y#651], functions=[(mmin(D#662),mode=Partial,isDistinct=false)], output=[Y#651,mmin#669])
            +- Project [Y#651,(D1#661 + D#652) AS D#662]
               +- BroadcastHashJoin [X#660], [X#650], BuildRight
                  :- AggregateRelation [X#660,D1#661](mminpath)
                  +- ConvertToUnsafe
                     +- Scan ExistingRDD[X#650,Y#651,D#652]
17/03/27 22:25:43 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:43 INFO AggregateRecursion: Recursion operator configuration settings:
17/03/27 22:25:43 INFO AggregateRecursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:43 INFO AggregateRecursion: Aggregate recursion version: Single-Job PSN w/ AggregateSetRDD
17/03/27 22:25:43 INFO SparkContext: Starting job: reduce at AggregateSetRDD.scala:110
17/03/27 22:25:43 INFO DAGScheduler: Registering RDD 5 (execute at MonotonicAggregate.scala:151)
17/03/27 22:25:43 INFO DAGScheduler: Got job 0 (reduce at AggregateSetRDD.scala:110) with 5 output partitions
17/03/27 22:25:43 INFO DAGScheduler: Final stage: ResultStage 1 (reduce at AggregateSetRDD.scala:110)
17/03/27 22:25:43 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:43 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:43 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[5] at execute at MonotonicAggregate.scala:151), which has no missing parents
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 2.0 GB)
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53451 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:43 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[5] at execute at MonotonicAggregate.scala:151)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 4 tasks
17/03/27 22:25:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2305 bytes)
17/03/27 22:25:43 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:43 INFO DAGScheduler: Got job 1 (run at null:-1) with 5 output partitions
17/03/27 22:25:43 INFO DAGScheduler: Final stage: ResultStage 2 (run at null:-1)
17/03/27 22:25:43 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:43 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:43 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at run at null:-1), which has no missing parents
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:25:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.5 KB, free 2.0 GB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53451 (size: 2.5 KB, free: 2.0 GB)
17/03/27 22:25:43 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:43 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at run at null:-1)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:43 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:43 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:43 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:43 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1486 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 4, localhost, partition 0,PROCESS_LOCAL, 2362 bytes)
17/03/27 22:25:43 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1486 bytes result sent to driver
17/03/27 22:25:43 INFO Executor: Running task 0.0 in stage 2.0 (TID 4)
17/03/27 22:25:43 INFO Executor: Finished task 0.0 in stage 2.0 (TID 4). 1431 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 5, localhost, partition 1,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:43 INFO Executor: Running task 1.0 in stage 2.0 (TID 5)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 6, localhost, partition 2,PROCESS_LOCAL, 2372 bytes)
17/03/27 22:25:43 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1486 bytes result sent to driver
17/03/27 22:25:43 INFO Executor: Finished task 1.0 in stage 2.0 (TID 5). 1431 bytes result sent to driver
17/03/27 22:25:43 INFO Executor: Running task 2.0 in stage 2.0 (TID 6)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 7, localhost, partition 3,PROCESS_LOCAL, 2367 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 8, localhost, partition 4,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:25:43 INFO Executor: Finished task 2.0 in stage 2.0 (TID 6). 1431 bytes result sent to driver
17/03/27 22:25:43 INFO Executor: Running task 3.0 in stage 2.0 (TID 7)
17/03/27 22:25:43 INFO Executor: Finished task 3.0 in stage 2.0 (TID 7). 1431 bytes result sent to driver
17/03/27 22:25:43 INFO Executor: Running task 4.0 in stage 2.0 (TID 8)
17/03/27 22:25:43 INFO Executor: Finished task 4.0 in stage 2.0 (TID 8). 1480 bytes result sent to driver
17/03/27 22:25:43 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1495 bytes result sent to driver
17/03/27 22:25:43 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 24 ms on localhost (1/4)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 5) in 11 ms on localhost (1/5)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 25 ms on localhost (2/4)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 6) in 10 ms on localhost (2/5)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 7) in 9 ms on localhost (3/5)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 25 ms on localhost (3/4)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 4) in 13 ms on localhost (4/5)
17/03/27 22:25:43 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 8) in 10 ms on localhost (5/5)
17/03/27 22:25:43 INFO DAGScheduler: ResultStage 2 (run at null:-1) finished in 0.021 s
17/03/27 22:25:43 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:43 INFO DAGScheduler: Job 1 finished: run at null:-1, took 0.022860 s
17/03/27 22:25:43 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 26 ms on localhost (4/4)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:43 INFO DAGScheduler: ShuffleMapStage 0 (execute at MonotonicAggregate.scala:151) finished in 0.026 s
17/03/27 22:25:43 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:43 INFO DAGScheduler: running: Set()
17/03/27 22:25:43 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:43 INFO DAGScheduler: failed: Set()
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.5 KB, free 2.0 GB)
17/03/27 22:25:43 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at map at AggregateSetRDD.scala:110), which has no missing parents
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 300.0 B, free 2.0 GB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53451 (size: 300.0 B, free: 2.0 GB)
17/03/27 22:25:43 INFO SparkContext: Created broadcast 2 from run at null:-1
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 17.3 KB, free 2.0 GB)
17/03/27 22:25:43 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 8.2 KB, free 2.0 GB)
17/03/27 22:25:43 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53451 (size: 8.2 KB, free: 2.0 GB)
17/03/27 22:25:43 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:43 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at map at AggregateSetRDD.scala:110)
17/03/27 22:25:43 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:43 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 9, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 10, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 11, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:43 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 12, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:43 INFO Executor: Running task 0.0 in stage 1.0 (TID 9)
17/03/27 22:25:43 INFO Executor: Running task 1.0 in stage 1.0 (TID 10)
17/03/27 22:25:43 INFO Executor: Running task 2.0 in stage 1.0 (TID 11)
17/03/27 22:25:43 INFO Executor: Running task 3.0 in stage 1.0 (TID 12)
17/03/27 22:25:43 INFO CacheManager: Partition rdd_7_1 not found, computing it
17/03/27 22:25:43 INFO CacheManager: Partition rdd_7_0 not found, computing it
17/03/27 22:25:43 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:43 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:25:43 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:44 INFO MemoryStore: Will not store rdd_7_0 as it would require dropping another block from the same RDD
17/03/27 22:25:44 WARN MemoryStore: Not enough space to cache rdd_7_0 in memory! (computed 457.1 MB so far)
17/03/27 22:25:44 INFO MemoryStore: Memory use = 48.6 KB (blocks) + 1373.3 MB (scratch space shared across 5 tasks(s)) = 1373.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 9). 2079 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 13, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 9) in 263 ms on localhost (1/5)
17/03/27 22:25:44 INFO Executor: Running task 4.0 in stage 1.0 (TID 13)
17/03/27 22:25:44 INFO CacheManager: Partition rdd_7_4 not found, computing it
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:44 INFO MemoryStore: Will not store rdd_7_3 as it would require dropping another block from the same RDD
17/03/27 22:25:44 WARN MemoryStore: Not enough space to cache rdd_7_3 in memory! (computed 457.1 MB so far)
17/03/27 22:25:44 INFO MemoryStore: Memory use = 48.6 KB (blocks) + 1373.3 MB (scratch space shared across 5 tasks(s)) = 1373.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:44 INFO Executor: Finished task 3.0 in stage 1.0 (TID 12). 2079 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 12) in 292 ms on localhost (2/5)
17/03/27 22:25:44 INFO MemoryStore: Block rdd_7_2 stored as values in memory (estimated size 457.1 MB, free 1591.1 MB)
17/03/27 22:25:44 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 457.1 MB, free 1134.1 MB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added rdd_7_1 in memory on localhost:53451 (size: 457.1 MB, free: 1591.2 MB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added rdd_7_2 in memory on localhost:53451 (size: 457.1 MB, free: 1134.1 MB)
17/03/27 22:25:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 10). 2448 bytes result sent to driver
17/03/27 22:25:44 INFO Executor: Finished task 2.0 in stage 1.0 (TID 11). 2448 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 10) in 458 ms on localhost (3/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 11) in 458 ms on localhost (4/5)
17/03/27 22:25:44 INFO MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 489.6 MB, free 644.5 MB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added rdd_7_4 in memory on localhost:53451 (size: 489.6 MB, free: 644.5 MB)
17/03/27 22:25:44 INFO Executor: Finished task 4.0 in stage 1.0 (TID 13). 2448 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 13) in 398 ms on localhost (5/5)
17/03/27 22:25:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:44 INFO DAGScheduler: ResultStage 1 (reduce at AggregateSetRDD.scala:110) finished in 0.660 s
17/03/27 22:25:44 INFO DAGScheduler: Job 0 finished: reduce at AggregateSetRDD.scala:110, took 0.697423 s
17/03/27 22:25:44 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:44 INFO AggregateRecursion: Fixed Point Iteration # 1, time: 12ms
17/03/27 22:25:44 INFO DAGScheduler: Registering RDD 15 (execute at MonotonicAggregate.scala:154)
17/03/27 22:25:44 INFO DAGScheduler: Got job 2 (runFixedPointJob at AggregateRecursion.scala:159) with 5 output partitions
17/03/27 22:25:44 INFO DAGScheduler: Final stage: FixedPointResultStage 4 (runFixedPointJob at AggregateRecursion.scala:159)
17/03/27 22:25:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/03/27 22:25:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/03/27 22:25:44 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[15] at execute at MonotonicAggregate.scala:154), which has no missing parents
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 21.1 KB, free 644.4 MB)
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 9.5 KB, free 644.4 MB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53451 (size: 9.5 KB, free: 644.5 MB)
17/03/27 22:25:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:44 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[15] at execute at MonotonicAggregate.scala:154)
17/03/27 22:25:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:44 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 14, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 15, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 16, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 17, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:44 INFO Executor: Running task 1.0 in stage 3.0 (TID 14)
17/03/27 22:25:44 INFO Executor: Running task 2.0 in stage 3.0 (TID 15)
17/03/27 22:25:44 INFO Executor: Running task 4.0 in stage 3.0 (TID 16)
17/03/27 22:25:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 17)
17/03/27 22:25:44 INFO BlockManager: Found block rdd_7_4 locally
17/03/27 22:25:44 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:25:44 INFO BlockManager: Found block rdd_7_2 locally
17/03/27 22:25:44 INFO CacheManager: Partition rdd_7_0 not found, computing it
17/03/27 22:25:44 INFO Executor: Finished task 1.0 in stage 3.0 (TID 14). 3247 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:25:44 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 17)
org.apache.spark.SparkException: Checkpoint block rdd_7_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 14) in 6 ms on localhost (1/5)
17/03/27 22:25:44 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:44 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 17, localhost): org.apache.spark.SparkException: Checkpoint block rdd_7_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:44 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job
17/03/27 22:25:44 INFO TaskSchedulerImpl: Cancelling stage 3
17/03/27 22:25:44 INFO TaskSchedulerImpl: Stage 3 was cancelled
17/03/27 22:25:44 INFO DAGScheduler: ShuffleMapStage 3 (execute at MonotonicAggregate.scala:154) failed in 0.009 s
17/03/27 22:25:44 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:25:44 INFO Executor: Executor is trying to kill task 2.0 in stage 3.0 (TID 15)
17/03/27 22:25:44 INFO Executor: Executor is trying to kill task 4.0 in stage 3.0 (TID 16)
17/03/27 22:25:44 INFO Executor: Executor is trying to kill task 3.0 in stage 3.0 (TID 18)
17/03/27 22:25:44 INFO DAGScheduler: Fixed Point Job 2 failed: runFixedPointJob at AggregateRecursion.scala:159, took 0.023377 s
17/03/27 22:25:44 INFO Executor: Executor killed task 2.0 in stage 3.0 (TID 15)
[31m- Single Source ShortestPaths with Monotonic Aggregate - LL - ff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 17, localhost): org.apache.spark.SparkException: Checkpoint block rdd_7_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_7_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  ...[0m
17/03/27 22:25:44 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:44 ERROR Executor: Exception in task 3.0 in stage 3.0 (TID 18)
org.apache.spark.SparkException: Checkpoint block rdd_7_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:44 WARN TaskSetManager: Lost task 2.0 in stage 3.0 (TID 15, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:44 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:44 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:44 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:44 WARN TaskSetManager: Lost task 3.0 in stage 3.0 (TID 18, localhost): org.apache.spark.SparkException: Checkpoint block rdd_7_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:44 INFO Executor: Executor killed task 4.0 in stage 3.0 (TID 16)
17/03/27 22:25:44 WARN TaskSetManager: Lost task 4.0 in stage 3.0 (TID 16, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:44 INFO Utils: Successfully started service 'sparkDriver' on port 53471.
17/03/27 22:25:44 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:44 INFO Remoting: Starting remoting
17/03/27 22:25:44 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53484]
17/03/27 22:25:44 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53484.
17/03/27 22:25:44 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:44 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:44 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-35b58d54-8861-4f83-8f87-8c065226847a
17/03/27 22:25:44 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:44 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:44 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53501.
17/03/27 22:25:44 INFO NettyBlockTransferService: Server created on 53501
17/03/27 22:25:44 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:44 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53501 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53501)
17/03/27 22:25:44 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:44 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667944655
17/03/27 22:25:44 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$3.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:75)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$3.apply(AggregatesInRecursionQuerySuite.scala:65)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$3.apply(AggregatesInRecursionQuerySuite.scala:65)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$4.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:92)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$4.apply(AggregatesInRecursionQuerySuite.scala:84)
	at edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$4.apply(AggregatesInRecursionQuerySuite.scala:84)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:44 INFO AggregatesInRecursionQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:44 INFO BigDatalogContext: BigDatalog Query: "cc(A)"
17/03/27 22:25:44 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:44 INFO BigDatalogContext: 
0: (countd(Aggr_1) as A) <AGGREGATE>
 1: (Aggr_1) <PROJECT>
  2: cc3(Y, FSAggr_1 as Aggr_1) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: MonotonicSemiNaive)
  Exit Rules: 
   3: (X, mmin(X) as FSAggr_1) <AGGREGATE_FS>
    4: (X) <PROJECT>
     5: arc(X, Y) <BASE_RELATION>
  Recursive Rules: 
   3: (Y, mmin(V) as FSAggr_1) <AGGREGATE_FS>
    4: (Y, V) <PROJECT>
     5: (0.X = 1.X) <JOIN>
      6: cc3(X, V) <RECURSIVE_RELATION>
      6: arc(X, Y) <BASE_RELATION>
17/03/27 22:25:44 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:44 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:44 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery aggregate_cc
+- 'Aggregate [unresolvedalias('count('cc3.Aggr_1) AS A#685)]
   +- 'Project ['cc3.Aggr_1]
      +- 'Subquery cc3
         +- 'Project ['Y,unresolvedalias('FSAggr_1 AS Aggr_1#680)]
            +- 'AggregateRecursion cc3, true, [1,0]
               :- 'Subquery fs_aggregate_cc3_1
               :  +- 'MonotonicAggregate ['arc.X], ['arc.X,unresolvedalias('mmin('arc.X) AS FSAggr_1#681)], [1,0]
               :     +- 'Project ['arc.X]
               :        +- 'UnresolvedRelation `arc`, None
               +- 'Subquery fs_aggregate_cc3_2
                  +- 'MonotonicAggregate ['arc2.Y], ['arc2.Y,unresolvedalias('mmin('cc31.V) AS FSAggr_1#684)], [1,0]
                     +- 'Project ['arc2.Y,'cc31.V]
                        +- 'Join Inner, Some(('cc31.X = 'arc2.X))
                           :- Subquery cc31
                           :  +- AggregateRelation cc3, [X#682,V#683], [1,0]
                           +- 'BroadcastHint
                              +- 'Subquery arc2
                                 +- 'Project [*]
                                    +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: bigint
Subquery aggregate_cc
+- Aggregate [(count(if ((gid#686 = 1)) Aggr_1#687 else null),mode=Complete,isDistinct=false) AS A#685L]
   +- Aggregate [Aggr_1#687,gid#686], [Aggr_1#687,gid#686]
      +- Expand [List(Aggr_1#680, 1)], [Aggr_1#687,gid#686]
         +- Project [Aggr_1#680]
            +- Subquery cc3
               +- Project [Y#677,FSAggr_1#684 AS Aggr_1#680]
                  +- AggregateRecursion cc3, true, [1,0]
                     :- Subquery fs_aggregate_cc3_1
                     :  +- MonotonicAggregate [X#676], [X#676,(mmin(X#676),mode=Complete,isDistinct=false) AS FSAggr_1#681], [1,0]
                     :     +- Project [X#676]
                     :        +- Subquery arc
                     :           +- LogicalRDD [X#676,Y#677], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
                     +- Subquery fs_aggregate_cc3_2
                        +- MonotonicAggregate [Y#677], [Y#677,(mmin(V#683),mode=Complete,isDistinct=false) AS FSAggr_1#684], [1,0]
                           +- Project [Y#677,V#683]
                              +- Join Inner, Some((X#682 = X#676))
                                 :- Subquery cc31
                                 :  +- AggregateRelation cc3, [X#682,V#683], [1,0]
                                 +- BroadcastHint
                                    +- Subquery arc2
                                       +- Project [X#676,Y#677]
                                          +- Subquery arc
                                             +- LogicalRDD [X#676,Y#677], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Aggregate [(count(if ((gid#686 = 1)) Aggr_1#687 else null),mode=Complete,isDistinct=false) AS A#685L]
+- Aggregate [Aggr_1#687,gid#686], [Aggr_1#687,gid#686]
   +- Expand [List(Aggr_1#680, 1)], [Aggr_1#687,gid#686]
      +- Project [FSAggr_1#684 AS Aggr_1#680]
         +- AggregateRecursion cc3, true, [1,0]
            :- MonotonicAggregate [X#676], [X#676,(mmin(X#676),mode=Complete,isDistinct=false) AS FSAggr_1#681], [1,0]
            :  +- Project [X#676]
            :     +- LogicalRDD [X#676,Y#677], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
            +- MonotonicAggregate [Y#677], [Y#677,(mmin(V#683),mode=Complete,isDistinct=false) AS FSAggr_1#684], [1,0]
               +- Project [Y#677,V#683]
                  +- Join Inner, Some((X#682 = X#676))
                     :- AggregateRelation cc3, [X#682,V#683], [1,0]
                     +- BroadcastHint
                        +- Project [X#676,Y#677]
                           +- LogicalRDD [X#676,Y#677], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
TungstenAggregate(key=[], functions=[(count(if ((gid#686 = 1)) Aggr_1#687 else null),mode=Final,isDistinct=false)], output=[A#685L])
+- TungstenExchange SinglePartition, None
   +- TungstenAggregate(key=[], functions=[(count(if ((gid#686 = 1)) Aggr_1#687 else null),mode=Partial,isDistinct=false)], output=[count#696L])
      +- TungstenAggregate(key=[Aggr_1#687,gid#686], functions=[], output=[Aggr_1#687,gid#686])
         +- TungstenExchange hashpartitioning(Aggr_1#687,gid#686,5), None
            +- TungstenAggregate(key=[Aggr_1#687,gid#686], functions=[], output=[Aggr_1#687,gid#686])
               +- Expand [List(Aggr_1#680, 1)], [Aggr_1#687,gid#686]
                  +- Project [FSAggr_1#684 AS Aggr_1#680]
                     +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0]
                        :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])
                        :  +- TungstenExchange hashpartitioning(X#676,5), None
                        :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#691])
                        :        +- Project [X#676]
                        :           +- Scan ExistingRDD[X#676,Y#677] 
                        +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])
                           +- TungstenExchange hashpartitioning(Y#677,5), None
                              +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#694])
                                 +- Project [Y#677,V#683]
                                    +- BroadcastHashJoin [X#682], [X#676], BuildRight
                                       :- AggregateRelation [X#682,V#683](cc3)
                                       +- Project [X#676,Y#677]
                                          +- Scan ExistingRDD[X#676,Y#677]
17/03/27 22:25:44 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:44 INFO AggregateRecursion: Recursion operator configuration settings:
17/03/27 22:25:44 INFO AggregateRecursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:44 INFO AggregateRecursion: Aggregate recursion version: Single-Job PSN w/ AggregateSetRDD
17/03/27 22:25:44 INFO SparkContext: Starting job: reduce at AggregateSetRDD.scala:110
17/03/27 22:25:44 INFO DAGScheduler: Registering RDD 4 (execute at MonotonicAggregate.scala:151)
17/03/27 22:25:44 INFO DAGScheduler: Got job 0 (reduce at AggregateSetRDD.scala:110) with 5 output partitions
17/03/27 22:25:44 INFO DAGScheduler: Final stage: ResultStage 1 (reduce at AggregateSetRDD.scala:110)
17/03/27 22:25:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 0)
17/03/27 22:25:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 0)
17/03/27 22:25:44 INFO DAGScheduler: Submitting ShuffleMapStage 0 (MapPartitionsRDD[4] at execute at MonotonicAggregate.scala:151), which has no missing parents
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 9.0 KB, free 2.0 GB)
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53501 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:44 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:44 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[4] at execute at MonotonicAggregate.scala:151)
17/03/27 22:25:44 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:44 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:44 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:44 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:44 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:44 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:44 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:44 INFO DAGScheduler: Got job 1 (run at null:-1) with 5 output partitions
17/03/27 22:25:44 INFO DAGScheduler: Final stage: ResultStage 2 (run at null:-1)
17/03/27 22:25:44 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:44 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[10] at run at null:-1), which has no missing parents
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.1 KB, free 1983.7 MB)
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 1951.5 MB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53501 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:44 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:44 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 2 (MapPartitionsRDD[10] at run at null:-1)
17/03/27 22:25:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:44 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1538 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2377 bytes)
17/03/27 22:25:44 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:44 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1538 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:44 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1538 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:44 INFO Executor: Running task 1.0 in stage 2.0 (TID 6)
17/03/27 22:25:44 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1538 bytes result sent to driver
17/03/27 22:25:44 INFO Executor: Finished task 1.0 in stage 2.0 (TID 6). 1484 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:44 INFO Executor: Running task 2.0 in stage 2.0 (TID 7)
17/03/27 22:25:44 INFO Executor: Running task 3.0 in stage 2.0 (TID 8)
17/03/27 22:25:44 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1538 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2388 bytes)
17/03/27 22:25:44 INFO Executor: Running task 4.0 in stage 2.0 (TID 9)
17/03/27 22:25:44 INFO Executor: Finished task 3.0 in stage 2.0 (TID 8). 1484 bytes result sent to driver
17/03/27 22:25:44 INFO Executor: Finished task 2.0 in stage 2.0 (TID 7). 1484 bytes result sent to driver
17/03/27 22:25:44 INFO Executor: Finished task 4.0 in stage 2.0 (TID 9). 1525 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 71 ms on localhost (1/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 6) in 4 ms on localhost (1/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 71 ms on localhost (2/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 8) in 2 ms on localhost (2/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 7) in 2 ms on localhost (3/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 9) in 1 ms on localhost (4/5)
17/03/27 22:25:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 72 ms on localhost (3/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 25 ms on localhost (4/5)
17/03/27 22:25:44 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 72 ms on localhost (5/5)
17/03/27 22:25:44 INFO DAGScheduler: ShuffleMapStage 0 (execute at MonotonicAggregate.scala:151) finished in 0.072 s
17/03/27 22:25:44 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:44 INFO DAGScheduler: running: Set(ResultStage 2)
17/03/27 22:25:44 INFO DAGScheduler: waiting: Set(ResultStage 1)
17/03/27 22:25:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1484 bytes result sent to driver
17/03/27 22:25:44 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:44 INFO DAGScheduler: failed: Set()
17/03/27 22:25:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 8 ms on localhost (5/5)
17/03/27 22:25:44 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[8] at map at AggregateSetRDD.scala:110), which has no missing parents
17/03/27 22:25:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 16.8 KB, free 2.0 GB)
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KB, free 2.0 GB)
17/03/27 22:25:44 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53501 (size: 8.0 KB, free: 2.0 GB)
17/03/27 22:25:44 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:44 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[8] at map at AggregateSetRDD.scala:110)
17/03/27 22:25:44 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:44 INFO DAGScheduler: ResultStage 2 (run at null:-1) finished in 0.042 s
17/03/27 22:25:44 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:44 INFO DAGScheduler: Job 1 finished: run at null:-1, took 0.059388 s
17/03/27 22:25:44 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 12, localhost, partition 2,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:44 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 13, localhost, partition 3,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:44 INFO Executor: Running task 0.0 in stage 1.0 (TID 10)
17/03/27 22:25:44 INFO Executor: Running task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.4 KB, free 2.0 GB)
17/03/27 22:25:44 INFO Executor: Running task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 303.0 B, free 2.0 GB)
17/03/27 22:25:44 INFO Executor: Running task 3.0 in stage 1.0 (TID 13)
17/03/27 22:25:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53501 (size: 303.0 B, free: 2.0 GB)
17/03/27 22:25:44 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:44 INFO SparkContext: Created broadcast 3 from run at null:-1
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:44 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:44 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:44 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1291
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1290
17/03/27 22:25:45 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53501 in memory (size: 8.0 KB, free: 2.0 GB)
17/03/27 22:25:45 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:53501 in memory (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1327
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1326
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1263
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1262
17/03/27 22:25:45 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53501 in memory (size: 303.0 B, free: 2.0 GB)
17/03/27 22:25:45 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53501 in memory (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1283
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1282
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1281
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1280
17/03/27 22:25:45 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:45 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 524.1 MB so far)
17/03/27 22:25:45 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1574.4 MB (scratch space shared across 5 tasks(s)) = 1574.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 10). 2165 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 14, localhost, partition 4,NODE_LOCAL, 1968 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 10) in 326 ms on localhost (1/5)
17/03/27 22:25:45 INFO Executor: Running task 4.0 in stage 1.0 (TID 14)
17/03/27 22:25:45 INFO TorrentBroadcast: Started reading broadcast variable 2
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1279
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1278
17/03/27 22:25:45 INFO ContextCleaner: Cleaned accumulator 1267
17/03/27 22:25:45 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:25:45 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 524.1 MB so far)
17/03/27 22:25:45 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1573.4 MB (scratch space shared across 4 tasks(s)) = 1573.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:45 INFO Executor: Finished task 3.0 in stage 1.0 (TID 13). 2165 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 13) in 336 ms on localhost (2/5)
17/03/27 22:25:45 ERROR Utils: Exception encountered
org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:45 ERROR Executor: Exception in task 4.0 in stage 1.0 (TID 14)
java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 11 more
17/03/27 22:25:45 WARN TaskSetManager: Lost task 4.0 in stage 1.0 (TID 14, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 11 more

17/03/27 22:25:45 ERROR TaskSetManager: Task 4 in stage 1.0 failed 1 times; aborting job
17/03/27 22:25:45 INFO TaskSchedulerImpl: Cancelling stage 1
17/03/27 22:25:45 INFO TaskSchedulerImpl: Stage 1 was cancelled
17/03/27 22:25:45 INFO DAGScheduler: ResultStage 1 (reduce at AggregateSetRDD.scala:110) failed in 0.339 s
17/03/27 22:25:45 INFO Executor: Executor is trying to kill task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:45 INFO Executor: Executor is trying to kill task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:45 INFO DAGScheduler: Job 0 failed: reduce at AggregateSetRDD.scala:110, took 0.421418 s
17/03/27 22:25:45 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:45 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:45 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:45 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[31m- Connected Components with Monotonic Aggregate - ff *** FAILED ***[0m
[31m  org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[], functions=[(count(if ((gid#697 = 1)) Aggr_1#698 else null),mode=Final,isDistinct=false)], output=[A#685L])[0m
[31m+- TungstenExchange SinglePartition, None[0m
[31m   +- TungstenAggregate(key=[], functions=[(count(if ((gid#697 = 1)) Aggr_1#698 else null),mode=Partial,isDistinct=false)], output=[count#707L])[0m
[31m      +- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m         +- TungstenExchange hashpartitioning(Aggr_1#698,gid#697,5), None[0m
[31m            +- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m               +- Expand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m                  +- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m                     +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m                        :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m                        :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m                        :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m                        :        +- Project [X#676][0m
[31m                        :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m                        +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m                           +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m                              +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m                                 +- Project [Y#677,V#683][0m
[31m                                    +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                                       :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                                       +- Project [X#676,Y#677][0m
[31m                                          +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:55)[0m
[31m  at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:55)[0m
[31m  at org.apache.spark.sql.DataFrame.rdd$lzycompute(DataFrame.scala:1638)[0m
[31m  at org.apache.spark.sql.DataFrame.rdd(DataFrame.scala:1635)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenExchange SinglePartition, None[0m
[31m+- TungstenAggregate(key=[], functions=[(count(if ((gid#697 = 1)) Aggr_1#698 else null),mode=Partial,isDistinct=false)], output=[count#707L])[0m
[31m   +- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m      +- TungstenExchange hashpartitioning(Aggr_1#698,gid#697,5), None[0m
[31m         +- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m            +- Expand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m               +- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m                  +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m                     :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m                     :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m                     :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m                     :        +- Project [X#676][0m
[31m                     :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m                     +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m                        +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m                           +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m                              +- Project [Y#677,V#683][0m
[31m                                 +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                                    :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                                    +- Project [X#676,Y#677][0m
[31m                                       +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.Exchange.doExecute(Exchange.scala:247)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[], functions=[(count(if ((gid#697 = 1)) Aggr_1#698 else null),mode=Partial,isDistinct=false)], output=[count#707L])[0m
[31m+- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m   +- TungstenExchange hashpartitioning(Aggr_1#698,gid#697,5), None[0m
[31m      +- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m         +- Expand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m            +- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m               +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m                  :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m                  :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m                  :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m                  :        +- Project [X#676][0m
[31m                  :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m                  +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m                     +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m                        +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m                           +- Project [Y#677,V#683][0m
[31m                              +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                                 :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                                 +- Project [X#676,Y#677][0m
[31m                                    +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.Exchange.prepareShuffleDependency(Exchange.scala:164)[0m
[31m  at org.apache.spark.sql.execution.Exchange$$anonfun$doExecute$1.apply(Exchange.scala:254)[0m
[31m  at org.apache.spark.sql.execution.Exchange$$anonfun$doExecute$1.apply(Exchange.scala:248)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m+- TungstenExchange hashpartitioning(Aggr_1#698,gid#697,5), None[0m
[31m   +- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m      +- Expand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m         +- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m            +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m               :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m               :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m               :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m               :        +- Project [X#676][0m
[31m               :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m               +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m                  +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m                     +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m                        +- Project [Y#677,V#683][0m
[31m                           +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                              :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                              +- Project [X#676,Y#677][0m
[31m                                 +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenExchange hashpartitioning(Aggr_1#698,gid#697,5), None[0m
[31m+- TungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m   +- Expand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m      +- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m         +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m            :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m            :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m            :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m            :        +- Project [X#676][0m
[31m            :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m            +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m               +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m                  +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m                     +- Project [Y#677,V#683][0m
[31m                        +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                           :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                           +- Project [X#676,Y#677][0m
[31m                              +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.Exchange.doExecute(Exchange.scala:247)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mTungstenAggregate(key=[Aggr_1#698,gid#697], functions=[], output=[Aggr_1#698,gid#697])[0m
[31m+- Expand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m   +- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m      +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m         :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m         :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m         :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m         :        +- Project [X#676][0m
[31m         :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m         +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m            +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m               +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m                  +- Project [Y#677,V#683][0m
[31m                     +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                        :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                        +- Project [X#676,Y#677][0m
[31m                           +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.Exchange.prepareShuffleDependency(Exchange.scala:164)[0m
[31m  at org.apache.spark.sql.execution.Exchange$$anonfun$doExecute$1.apply(Exchange.scala:254)[0m
[31m  at org.apache.spark.sql.execution.Exchange$$anonfun$doExecute$1.apply(Exchange.scala:248)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.sql.catalyst.errors.package$TreeNodeException: execute, tree:[0m
[31mExpand [List(Aggr_1#680, 1)], [Aggr_1#698,gid#697][0m
[31m+- Project [FSAggr_1#684 AS Aggr_1#680][0m
[31m   +- AggregateRecursion [Y#677,FSAggr_1#684] (Linear) [cc3][1,0][0m
[31m      :- MonotonicAggregate(key=[X#676], functions=[(mmin(X#676),mode=Final,isDistinct=false)], output=[X#676,FSAggr_1#681])[0m
[31m      :  +- TungstenExchange hashpartitioning(X#676,5), None[0m
[31m      :     +- MonotonicAggregatePartial(key=[X#676], functions=[(mmin(X#676),mode=Partial,isDistinct=false)], output=[X#676,mmin#702])[0m
[31m      :        +- Project [X#676][0m
[31m      :           +- Scan ExistingRDD[X#676,Y#677] [0m
[31m      +- MonotonicAggregate(key=[Y#677], functions=[(mmin(V#683),mode=Final,isDistinct=false)], output=[Y#677,FSAggr_1#684])[0m
[31m         +- TungstenExchange hashpartitioning(Y#677,5), None[0m
[31m            +- MonotonicAggregatePartial(key=[Y#677], functions=[(mmin(V#683),mode=Partial,isDistinct=false)], output=[Y#677,mmin#705])[0m
[31m               +- Project [Y#677,V#683][0m
[31m                  +- BroadcastHashJoin [X#682], [X#676], BuildRight[0m
[31m                     :- AggregateRelation [X#682,V#683](cc3)[0m
[31m                     +- Project [X#676,Y#677][0m
[31m                        +- Scan ExistingRDD[X#676,Y#677][0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:49)[0m
[31m  at org.apache.spark.sql.execution.Expand.doExecute(Expand.scala:59)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:133)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$5.apply(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:150)[0m
[31m  at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:131)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:86)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate$$anonfun$doExecute$1.apply(TungstenAggregate.scala:80)[0m
[31m  at org.apache.spark.sql.catalyst.errors.package$.attachTree(package.scala:48)[0m
[31m  at org.apache.spark.sql.execution.aggregate.TungstenAggregate.doExecute(TungstenAggregate.scala:80)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 1.0 failed 1 times, most recent failure: Lost task 4.0 in stage 1.0 (TID 14, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
[0m
[31m	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
[0m
[31m	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31mCaused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at scala.Option.getOrElse(Option.scala:121)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at scala.collection.immutable.List.foreach(List.scala:381)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
[0m
[31m	... 11 more
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)[0m
[31m  at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)[0m
[31m  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:62)[0m
[31m  at org.apache.spark.scheduler.Task.run(Task.scala:89)[0m
[31m  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)[0m
[31m  at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at scala.Option.getOrElse(Option.scala:121)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at scala.collection.immutable.List.foreach(List.scala:381)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)[0m
[31m  ...[0m
[32mRecursiveQuerySuite:[0m
17/03/27 22:25:45 INFO Utils: Successfully started service 'sparkDriver' on port 53519.
17/03/27 22:25:45 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:45 INFO Remoting: Starting remoting
17/03/27 22:25:45 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 525.9 MB, free 1522.3 MB)
17/03/27 22:25:45 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:53501 (size: 525.9 MB, free: 1522.3 MB)
17/03/27 22:25:45 INFO Executor: Executor killed task 2.0 in stage 1.0 (TID 12)
17/03/27 22:25:45 WARN TaskSetManager: Lost task 2.0 in stage 1.0 (TID 12, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:45 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 558.2 MB, free 964.2 MB)
17/03/27 22:25:45 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:53501 (size: 558.2 MB, free: 964.2 MB)
17/03/27 22:25:45 INFO Executor: Executor killed task 1.0 in stage 1.0 (TID 11)
17/03/27 22:25:45 WARN TaskSetManager: Lost task 1.0 in stage 1.0 (TID 11, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:45 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53533]
17/03/27 22:25:45 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53533.
17/03/27 22:25:45 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:45 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:45 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-b2e72113-4e93-431a-9edc-c33ddb6f7464
17/03/27 22:25:45 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:45 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:45 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:45 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53550.
17/03/27 22:25:45 INFO NettyBlockTransferService: Server created on 53550
17/03/27 22:25:45 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:45 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53550 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53550)
17/03/27 22:25:45 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:45 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667945608
17/03/27 22:25:45 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$4.apply$mcV$sp(AggregatesInRecursionQuerySuite.scala:92)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$4.apply(AggregatesInRecursionQuerySuite.scala:84)
edu.ucla.cs.wis.bigdatalog.spark.AggregatesInRecursionQuerySuite$$anonfun$4.apply(AggregatesInRecursionQuerySuite.scala:84)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$1.apply$mcV$sp(RecursiveQuerySuites.scala:37)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$1.apply(RecursiveQuerySuites.scala:32)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$1.apply(RecursiveQuerySuites.scala:32)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:45 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:45 INFO BigDatalogContext: BigDatalog Query: "leftLinearPaths(A,B)."
17/03/27 22:25:45 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:45 INFO BigDatalogContext: 
0: leftLinearPaths(A, To) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: arc(From, To) <BASE_RELATION>
Recursive Rules: 
 1: (A, To) <DISTINCT PROJECT>
  2: (0.C = 1.From) <JOIN>
   3: leftLinearPaths(A, C) <RECURSIVE_RELATION>
   3: arc(From, To) <BASE_RELATION>
17/03/27 22:25:45 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:45 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:45 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery leftLinearPaths
+- 'Recursion leftLinearPaths, true, [1,0]
   :- 'UnresolvedRelation `arc`, None
   +- 'Project ['leftLinearPaths1.A,'arc2.To]
      +- 'Join Inner, Some(('leftLinearPaths1.C = 'arc2.From))
         :- Subquery leftLinearPaths1
         :  +- LinearRecursiveRelation leftLinearPaths, [A#712,C#713], [1,0]
         +- 'BroadcastHint
            +- 'Subquery arc2
               +- 'Project [*]
                  +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: int, To: int
Subquery leftLinearPaths
+- Recursion leftLinearPaths, true, [1,0]
   :- Subquery arc
   :  +- LogicalRDD [From#708,To#709], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [A#712,To#709]
      +- Join Inner, Some((C#713 = From#708))
         :- Subquery leftLinearPaths1
         :  +- LinearRecursiveRelation leftLinearPaths, [A#712,C#713], [1,0]
         +- BroadcastHint
            +- Subquery arc2
               +- Project [From#708,To#709]
                  +- Subquery arc
                     +- LogicalRDD [From#708,To#709], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion leftLinearPaths, true, [1,0]
:- LogicalRDD [From#708,To#709], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [A#712,To#709]
   +- Join Inner, Some((C#713 = From#708))
      :- LinearRecursiveRelation leftLinearPaths, [A#712,C#713], [1,0]
      +- BroadcastHint
         +- Project [From#708,To#709]
            +- LogicalRDD [From#708,To#709], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [A#712,To#709] (Linear) [leftLinearPaths][1,0]
:- TungstenExchange hashpartitioning(From#708,5), None
:  +- ConvertToUnsafe
:     +- Scan ExistingRDD[From#708,To#709] 
+- Project [A#712,To#709]
   +- BroadcastHashJoin [C#713], [From#708], BuildRight
      :- LinearRecursiveRelation [A#712,C#713](leftLinearPaths)
      +- Project [From#708,To#709]
         +- Scan ExistingRDD[From#708,To#709]
17/03/27 22:25:45 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:45 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:45 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:45 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:45 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:45 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:45 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:45 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:45 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:45 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[8] at run at null:-1), which has no missing parents
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:45 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53550 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:45 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:45 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at run at null:-1)
17/03/27 22:25:45 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:45 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:45 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:45 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:45 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:45 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1484 bytes result sent to driver
17/03/27 22:25:45 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1484 bytes result sent to driver
17/03/27 22:25:45 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:45 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1484 bytes result sent to driver
17/03/27 22:25:45 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:45 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1484 bytes result sent to driver
17/03/27 22:25:45 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1484 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7 ms on localhost (1/5)
17/03/27 22:25:45 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 7 ms on localhost (2/5)
17/03/27 22:25:45 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7 ms on localhost (3/5)
17/03/27 22:25:45 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 7 ms on localhost (4/5)
17/03/27 22:25:45 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 4 ms on localhost (5/5)
17/03/27 22:25:45 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.008 s
17/03/27 22:25:45 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:45 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.010318 s
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.3 KB, free 2.0 GB)
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 296.0 B, free 2.0 GB)
17/03/27 22:25:45 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53550 (size: 296.0 B, free: 2.0 GB)
17/03/27 22:25:45 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:45 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:45 INFO Recursion: Fixed Point Iteration # 1, time: 25ms
17/03/27 22:25:45 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:25:45 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:45 INFO DAGScheduler: Final stage: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:45 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:45 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53550 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:45 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:45 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:25:45 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:45 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:45 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:45 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:45 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:45 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:45 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 22 ms on localhost (1/5)
17/03/27 22:25:45 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:45 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 23 ms on localhost (2/5)
17/03/27 22:25:45 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 30 ms on localhost (3/5)
17/03/27 22:25:45 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 37 ms on localhost (4/5)
17/03/27 22:25:45 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1222 bytes result sent to driver
17/03/27 22:25:45 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 23 ms on localhost (5/5)
17/03/27 22:25:45 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:45 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.046 s
17/03/27 22:25:45 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:45 INFO DAGScheduler: running: Set()
17/03/27 22:25:45 INFO DAGScheduler: waiting: Set(FixedPointResultStage 2)
17/03/27 22:25:45 INFO DAGScheduler: failed: Set()
17/03/27 22:25:45 INFO DAGScheduler: Submitting FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.9 KB, free 2.0 GB)
17/03/27 22:25:45 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:45 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53550 (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:45 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:45 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:45 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:45 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:45 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:45 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:45 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:45 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:45 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:45 INFO CacheManager: Partition rdd_17_2 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_17_3 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:45 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:45 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 10 ms
17/03/27 22:25:45 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:45 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:46 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:25:46 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 558.5 MB so far)
17/03/27 22:25:46 INFO MemoryStore: Memory use = 38.7 KB (blocks) + 1677.4 MB (scratch space shared across 5 tasks(s)) = 1677.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:46 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:46 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:46 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:46 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:46 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:46 INFO MemoryStore: Memory use = 38.7 KB (blocks) + 1678.4 MB (scratch space shared across 5 tasks(s)) = 1678.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:46 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:46 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:46 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:46 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:46 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:46 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:46 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:46 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:46 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:46 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 558.5 MB, free 931.3 MB)
17/03/27 22:25:46 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:53550 (size: 558.5 MB, free: 931.3 MB)
17/03/27 22:25:46 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:46 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:46 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:46 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:46 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:46 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:46 INFO MemoryStore: Memory use = 1116.9 MB (blocks) + 842.7 MB (scratch space shared across 5 tasks(s)) = 1959.6 MB. Storage limit = 2.0 GB.
17/03/27 22:25:46 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:46 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:46 INFO MemoryStore: 9 blocks selected for dropping
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:25:46 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:53550 (size: 2.7 KB)
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:46 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53550 (size: 296.0 B)
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:25:46 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53550 (size: 2.8 KB)
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:25:46 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53550 (size: 6.8 KB)
17/03/27 22:25:46 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:46 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:25:46 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:46 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:53550 in memory (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:46 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:46 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:53550 in memory (size: 558.5 MB, free: 2.0 GB)
17/03/27 22:25:46 INFO MemoryStore: Will not store rdd_11_2 as it would require dropping another block from the same RDD
17/03/27 22:25:46 WARN MemoryStore: Not enough space to cache rdd_11_2 in memory! (computed 558.5 MB so far)
17/03/27 22:25:46 INFO MemoryStore: Memory use = 2.3 KB (blocks) + 1680.4 MB (scratch space shared across 5 tasks(s)) = 1680.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:46 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:46 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 558.4 MB, free 1489.8 MB)
17/03/27 22:25:46 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:53550 (size: 558.4 MB, free: 1489.8 MB)
17/03/27 22:25:46 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:46 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:46 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:46 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 558.4 MB so far)
17/03/27 22:25:46 INFO MemoryStore: Memory use = 558.4 MB (blocks) + 844.7 MB (scratch space shared across 5 tasks(s)) = 1403.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:46 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:46 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 558.4 MB, free 931.4 MB)
17/03/27 22:25:46 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:53550 (size: 558.4 MB, free: 931.4 MB)
17/03/27 22:25:46 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:47 INFO MemoryStore: Will not store rdd_11_3 as it would require dropping another block from the same RDD
17/03/27 22:25:47 WARN MemoryStore: Not enough space to cache rdd_11_3 in memory! (computed 558.4 MB so far)
17/03/27 22:25:47 INFO MemoryStore: Memory use = 1116.9 MB (blocks) + 845.7 MB (scratch space shared across 5 tasks(s)) = 1962.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:47 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:25:47 INFO MemoryStore: Will not store rdd_11_0 as it would require dropping another block from the same RDD
17/03/27 22:25:47 WARN MemoryStore: Not enough space to cache rdd_11_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:47 INFO MemoryStore: Memory use = 1116.9 MB (blocks) + 846.7 MB (scratch space shared across 5 tasks(s)) = 1963.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:47 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:47 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53550 on disk (size: 2.8 KB)
17/03/27 22:25:47 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53550 on disk (size: 2.7 KB)
17/03/27 22:25:47 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:47 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:25:47 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:53550 in memory (size: 558.4 MB, free: 1489.8 MB)
17/03/27 22:25:47 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:47 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:47 INFO BlockManager: Dropping block rdd_11_1 from memory
17/03/27 22:25:47 INFO BlockManagerInfo: Removed rdd_11_1 on localhost:53550 in memory (size: 558.4 MB, free: 2.0 GB)
17/03/27 22:25:47 INFO ContextCleaner: Cleaned accumulator 1336
17/03/27 22:25:47 INFO ContextCleaner: Cleaned accumulator 1335
17/03/27 22:25:47 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:47 INFO BlockManagerInfo: Added rdd_13_2 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:47 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:47 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:47 INFO MemoryStore: Will not store rdd_13_3 as it would require dropping another block from the same RDD
17/03/27 22:25:47 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 558.5 MB so far)
17/03/27 22:25:47 INFO MemoryStore: Memory use = 558.5 MB (blocks) + 847.7 MB (scratch space shared across 5 tasks(s)) = 1406.2 MB. Storage limit = 2.0 GB.
17/03/27 22:25:47 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:47 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:47 INFO MemoryStore: Will not store rdd_13_0 as it would require dropping another block from the same RDD
17/03/27 22:25:47 WARN MemoryStore: Not enough space to cache rdd_13_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:47 INFO MemoryStore: Memory use = 558.5 MB (blocks) + 848.7 MB (scratch space shared across 5 tasks(s)) = 1407.2 MB. Storage limit = 2.0 GB.
17/03/27 22:25:47 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:47 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:47 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 558.5 MB, free 931.3 MB)
17/03/27 22:25:47 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:53550 (size: 558.5 MB, free: 931.3 MB)
17/03/27 22:25:47 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:47 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:47 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:47 INFO BlockManager: Dropping block rdd_13_2 from memory
17/03/27 22:25:47 INFO BlockManagerInfo: Removed rdd_13_2 on localhost:53550 in memory (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:47 INFO BlockManager: Dropping block rdd_13_1 from memory
17/03/27 22:25:47 INFO BlockManagerInfo: Removed rdd_13_1 on localhost:53550 in memory (size: 558.5 MB, free: 2.0 GB)
17/03/27 22:25:47 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:47 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:47 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1686.4 MB (scratch space shared across 5 tasks(s)) = 1686.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:47 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:47 INFO MemoryStore: Will not store rdd_6_1 as it would require dropping another block from the same RDD
17/03/27 22:25:47 WARN MemoryStore: Not enough space to cache rdd_6_1 in memory! (computed 558.5 MB so far)
17/03/27 22:25:47 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1687.4 MB (scratch space shared across 5 tasks(s)) = 1687.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:47 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:47 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:47 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:47 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:47 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:47 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:47 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 558.5 MB, free 931.3 MB)
17/03/27 22:25:47 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:53550 (size: 558.5 MB, free: 931.3 MB)
17/03/27 22:25:47 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:25:47 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: Will not store rdd_6_1 as it would require dropping another block from the same RDD
17/03/27 22:25:48 WARN MemoryStore: Not enough space to cache rdd_6_1 in memory! (computed 558.5 MB so far)
17/03/27 22:25:48 INFO MemoryStore: Memory use = 1116.9 MB (blocks) + 851.7 MB (scratch space shared across 5 tasks(s)) = 1968.6 MB. Storage limit = 2.0 GB.
17/03/27 22:25:48 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:48 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:48 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:53550 in memory (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:48 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:25:48 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:53550 in memory (size: 558.5 MB, free: 2.0 GB)
17/03/27 22:25:48 INFO MemoryStore: Will not store rdd_11_3 as it would require dropping another block from the same RDD
17/03/27 22:25:48 WARN MemoryStore: Not enough space to cache rdd_11_3 in memory! (computed 558.5 MB so far)
17/03/27 22:25:48 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1689.4 MB (scratch space shared across 5 tasks(s)) = 1689.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:48 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:48 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:48 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:48 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:25:48 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:53550 in memory (size: 558.5 MB, free: 2.0 GB)
17/03/27 22:25:48 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:48 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:48 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:48 INFO BlockManager: Dropping block rdd_11_2 from memory
17/03/27 22:25:48 INFO BlockManagerInfo: Removed rdd_11_2 on localhost:53550 in memory (size: 558.5 MB, free: 2.0 GB)
17/03/27 22:25:48 INFO MemoryStore: Will not store rdd_11_0 as it would require dropping another block from the same RDD
17/03/27 22:25:48 WARN MemoryStore: Not enough space to cache rdd_11_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:48 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1690.4 MB (scratch space shared across 5 tasks(s)) = 1690.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:48 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:48 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:48 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:48 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:48 INFO BlockManager: Dropping block rdd_11_1 from memory
17/03/27 22:25:48 INFO BlockManagerInfo: Removed rdd_11_1 on localhost:53550 in memory (size: 558.5 MB, free: 2.0 GB)
17/03/27 22:25:48 INFO MemoryStore: Block rdd_17_3 stored as values in memory (estimated size 558.5 MB, free 1489.8 MB)
17/03/27 22:25:48 INFO BlockManagerInfo: Added rdd_17_3 in memory on localhost:53550 (size: 558.5 MB, free: 1489.8 MB)
17/03/27 22:25:48 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 3446 bytes result sent to driver
17/03/27 22:25:48 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:48 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:48 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 2966 ms on localhost (1/5)
17/03/27 22:25:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.9 KB, free 1489.8 MB)
17/03/27 22:25:48 INFO CacheManager: Partition rdd_17_4 not found, computing it
17/03/27 22:25:48 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:25:48 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:48 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:48 INFO MemoryStore: Will not store rdd_17_0 as it would require dropping another block from the same RDD
17/03/27 22:25:48 WARN MemoryStore: Not enough space to cache rdd_17_0 in memory! (computed 558.5 MB so far)
17/03/27 22:25:48 INFO MemoryStore: Memory use = 558.5 MB (blocks) + 850.7 MB (scratch space shared across 5 tasks(s)) = 1409.2 MB. Storage limit = 2.0 GB.
17/03/27 22:25:48 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2000 bytes result sent to driver
17/03/27 22:25:48 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 3056 ms on localhost (2/5)
17/03/27 22:25:48 INFO MemoryStore: Will not store rdd_17_1 as it would require dropping another block from the same RDD
17/03/27 22:25:48 WARN MemoryStore: Not enough space to cache rdd_17_1 in memory! (computed 558.4 MB so far)
17/03/27 22:25:48 INFO MemoryStore: Memory use = 558.5 MB (blocks) + 842.7 MB (scratch space shared across 4 tasks(s)) = 1401.2 MB. Storage limit = 2.0 GB.
17/03/27 22:25:48 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 4222 bytes result sent to driver
17/03/27 22:25:48 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 3157 ms on localhost (3/5)
17/03/27 22:25:48 INFO MemoryStore: Block rdd_17_2 stored as values in memory (estimated size 558.4 MB, free 931.4 MB)
17/03/27 22:25:48 INFO BlockManagerInfo: Added rdd_17_2 in memory on localhost:53550 (size: 558.4 MB, free: 931.4 MB)
17/03/27 22:25:48 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3547 bytes result sent to driver
17/03/27 22:25:48 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 3193 ms on localhost (4/5)
17/03/27 22:25:49 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 558.4 MB, free 373.0 MB)
17/03/27 22:25:49 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:53550 (size: 558.4 MB, free: 373.0 MB)
17/03/27 22:25:49 INFO CacheManager: Partition rdd_11_4 not found, computing it
17/03/27 22:25:49 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:49 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:49 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 341.0 MB)
17/03/27 22:25:49 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:49 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:49 INFO BlockManager: Dropping block rdd_17_3 from memory
17/03/27 22:25:49 INFO BlockManagerInfo: Removed rdd_17_3 on localhost:53550 in memory (size: 558.5 MB, free: 931.5 MB)
17/03/27 22:25:49 INFO MemoryStore: Block rdd_11_4 stored as values in memory (estimated size 558.4 MB, free 341.1 MB)
17/03/27 22:25:49 INFO BlockManagerInfo: Added rdd_11_4 in memory on localhost:53550 (size: 558.4 MB, free: 373.1 MB)
17/03/27 22:25:49 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:25:49 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:49 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:49 INFO BlockManager: Dropping block rdd_17_2 from memory
17/03/27 22:25:49 INFO BlockManagerInfo: Removed rdd_17_2 on localhost:53550 in memory (size: 558.4 MB, free: 931.5 MB)
17/03/27 22:25:49 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 558.4 MB, free 341.2 MB)
17/03/27 22:25:49 INFO BlockManagerInfo: Added rdd_13_4 in memory on localhost:53550 (size: 558.4 MB, free: 373.2 MB)
17/03/27 22:25:49 INFO BlockManager: Found block rdd_11_4 locally
17/03/27 22:25:49 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:50 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:50 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:25:50 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:53550 in memory (size: 558.4 MB, free: 931.5 MB)
17/03/27 22:25:50 INFO MemoryStore: Block rdd_17_4 stored as values in memory (estimated size 558.8 MB, free 340.7 MB)
17/03/27 22:25:50 INFO BlockManagerInfo: Added rdd_17_4 in memory on localhost:53550 (size: 558.8 MB, free: 372.7 MB)
17/03/27 22:25:50 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 3640 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 1614 ms on localhost (5/5)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:50 INFO DAGScheduler: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204) finished in 4.580 s
17/03/27 22:25:50 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:50 INFO Recursion: Fixed Point Iteration # 2, time: 4635ms
17/03/27 22:25:50 INFO DAGScheduler: Submitting FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.2 KB, free 340.7 MB)
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.1 KB, free 340.7 MB)
17/03/27 22:25:50 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53550 (size: 7.1 KB, free: 372.7 MB)
17/03/27 22:25:50 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:50 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[28] at RDD at SetRDD.scala:30)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:25:50 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 15, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 16, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 17, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:50 INFO Executor: Running task 4.0 in stage 3.0 (TID 15)
17/03/27 22:25:50 INFO Executor: Running task 0.0 in stage 3.0 (TID 16)
17/03/27 22:25:50 INFO Executor: Running task 1.0 in stage 3.0 (TID 17)
17/03/27 22:25:50 INFO Executor: Running task 2.0 in stage 3.0 (TID 18)
17/03/27 22:25:50 INFO CacheManager: Partition rdd_27_4 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_27_0 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_27_1 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_23_4 not found, computing it
17/03/27 22:25:50 INFO BlockManager: Found block rdd_13_4 locally
17/03/27 22:25:50 INFO BlockManager: Found block rdd_17_4 locally
17/03/27 22:25:50 INFO SetRDDHashSetPartition: Union set size 6 for rdd 14 took 0 ms
17/03/27 22:25:50 INFO CacheManager: Partition rdd_23_0 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_27_2 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:50 ERROR Executor: Exception in task 0.0 in stage 3.0 (TID 16)
org.apache.spark.SparkException: Checkpoint block rdd_13_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:50 ERROR Executor: Exception in task 1.0 in stage 3.0 (TID 17)
org.apache.spark.SparkException: Checkpoint block rdd_13_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:50 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:25:50 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 19, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:25:50 WARN TaskSetManager: Lost task 0.0 in stage 3.0 (TID 16, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:50 ERROR TaskSetManager: Task 0 in stage 3.0 failed 1 times; aborting job
17/03/27 22:25:50 WARN TaskSetManager: Lost task 1.0 in stage 3.0 (TID 17, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:50 INFO TaskSchedulerImpl: Cancelling stage 3
17/03/27 22:25:50 INFO TaskSchedulerImpl: Stage 3 was cancelled
17/03/27 22:25:50 INFO DAGScheduler: FixedPointResultStage 3 (runFixedPointJob at Recursion.scala:204) failed in 0.012 s
17/03/27 22:25:50 INFO Executor: Running task 3.0 in stage 3.0 (TID 19)
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:50 ERROR Executor: Exception in task 2.0 in stage 3.0 (TID 18)
org.apache.spark.SparkException: Checkpoint block rdd_13_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:50 INFO Executor: Executor is trying to kill task 4.0 in stage 3.0 (TID 15)
17/03/27 22:25:50 INFO Executor: Executor is trying to kill task 3.0 in stage 3.0 (TID 19)
17/03/27 22:25:50 INFO Executor: Executor is trying to kill task 2.0 in stage 3.0 (TID 18)
17/03/27 22:25:50 INFO CacheManager: Partition rdd_27_3 not found, computing it
17/03/27 22:25:50 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 4.667312 s
[31m- Transitive Closure - LL - ff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 3.0 failed 1 times, most recent failure: Lost task 0.0 in stage 3.0 (TID 16, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_13_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  ...[0m
17/03/27 22:25:50 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:50 INFO CacheManager: Partition rdd_23_3 not found, computing it
17/03/27 22:25:50 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:50 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:50 WARN TaskSetManager: Lost task 2.0 in stage 3.0 (TID 18, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:50 ERROR Executor: Exception in task 3.0 in stage 3.0 (TID 19)
org.apache.spark.SparkException: Checkpoint block rdd_13_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:50 WARN TaskSetManager: Lost task 3.0 in stage 3.0 (TID 19, localhost): org.apache.spark.SparkException: Checkpoint block rdd_13_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:50 INFO Utils: Successfully started service 'sparkDriver' on port 53575.
17/03/27 22:25:50 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:50 INFO Remoting: Starting remoting
17/03/27 22:25:50 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53588]
17/03/27 22:25:50 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53588.
17/03/27 22:25:50 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:50 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:50 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-1660a738-382f-4844-8d2e-ff2337d4ee5a
17/03/27 22:25:50 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:50 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:50 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:50 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53605.
17/03/27 22:25:50 INFO NettyBlockTransferService: Server created on 53605
17/03/27 22:25:50 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:50 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53605 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53605)
17/03/27 22:25:50 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:50 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667950450
17/03/27 22:25:50 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$1.apply$mcV$sp(RecursiveQuerySuites.scala:37)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$1.apply(RecursiveQuerySuites.scala:32)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$1.apply(RecursiveQuerySuites.scala:32)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$2.apply$mcV$sp(RecursiveQuerySuites.scala:51)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$2.apply(RecursiveQuerySuites.scala:42)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$2.apply(RecursiveQuerySuites.scala:42)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:50 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:50 INFO BigDatalogContext: BigDatalog Query: "leftLinearPaths(A,B)."
17/03/27 22:25:50 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:50 INFO BigDatalogContext: 
0: leftLinearPaths(A, To) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: (From, From) <PROJECT>
  2: arc(From, To) <BASE_RELATION>
Recursive Rules: 
 1: (A, To) <DISTINCT PROJECT>
  2: (0.C = 1.From) <JOIN>
   3: leftLinearPaths(A, C) <RECURSIVE_RELATION>
   3: arc(From, To) <BASE_RELATION>
17/03/27 22:25:50 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:50 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:50 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery leftLinearPaths
+- 'Recursion leftLinearPaths, true, [1,0]
   :- 'Project ['arc.From,'arc.From]
   :  +- 'UnresolvedRelation `arc`, None
   +- 'Project ['leftLinearPaths1.A,'arc2.To]
      +- 'Join Inner, Some(('leftLinearPaths1.C = 'arc2.From))
         :- Subquery leftLinearPaths1
         :  +- LinearRecursiveRelation leftLinearPaths, [A#718,C#719], [1,0]
         +- 'BroadcastHint
            +- 'Subquery arc2
               +- 'Project [*]
                  +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: int, To: int
Subquery leftLinearPaths
+- Recursion leftLinearPaths, true, [1,0]
   :- Project [From#714,From#714]
   :  +- Subquery arc
   :     +- LogicalRDD [From#714,To#715], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [A#718,To#715]
      +- Join Inner, Some((C#719 = From#714))
         :- Subquery leftLinearPaths1
         :  +- LinearRecursiveRelation leftLinearPaths, [A#718,C#719], [1,0]
         +- BroadcastHint
            +- Subquery arc2
               +- Project [From#714,To#715]
                  +- Subquery arc
                     +- LogicalRDD [From#714,To#715], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion leftLinearPaths, true, [1,0]
:- Project [From#714,From#714]
:  +- LogicalRDD [From#714,To#715], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [A#718,To#715]
   +- Join Inner, Some((C#719 = From#714))
      :- LinearRecursiveRelation leftLinearPaths, [A#718,C#719], [1,0]
      +- BroadcastHint
         +- Project [From#714,To#715]
            +- LogicalRDD [From#714,To#715], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [A#718,To#715] (Linear) [leftLinearPaths][1,0]
:- TungstenExchange hashpartitioning(From#714,5), None
:  +- Project [From#714,From#714]
:     +- Scan ExistingRDD[From#714,To#715] 
+- Project [A#718,To#715]
   +- BroadcastHashJoin [C#719], [From#714], BuildRight
      :- LinearRecursiveRelation [A#718,C#719](leftLinearPaths)
      +- Project [From#714,To#715]
         +- Scan ExistingRDD[From#714,To#715]
17/03/27 22:25:50 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:50 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:50 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:50 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:50 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:50 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:50 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:50 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:50 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:50 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[8] at run at null:-1), which has no missing parents
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:50 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53605 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:50 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:50 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at run at null:-1)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:50 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:50 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:50 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1484 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:50 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:50 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1484 bytes result sent to driver
17/03/27 22:25:50 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:50 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1484 bytes result sent to driver
17/03/27 22:25:50 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:50 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1484 bytes result sent to driver
17/03/27 22:25:50 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:50 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1484 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 14 ms on localhost (1/5)
17/03/27 22:25:50 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 7 ms on localhost (2/5)
17/03/27 22:25:50 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 14 ms on localhost (3/5)
17/03/27 22:25:50 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 14 ms on localhost (4/5)
17/03/27 22:25:50 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 17 ms on localhost (5/5)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:50 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.017 s
17/03/27 22:25:50 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.020810 s
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.3 KB, free 2.0 GB)
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 296.0 B, free 2.0 GB)
17/03/27 22:25:50 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53605 (size: 296.0 B, free: 2.0 GB)
17/03/27 22:25:50 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:50 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:50 INFO Recursion: Fixed Point Iteration # 1, time: 43ms
17/03/27 22:25:50 INFO DAGScheduler: Registering RDD 3 (execute at Recursion.scala:189)
17/03/27 22:25:50 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:50 INFO DAGScheduler: Final stage: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:50 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:50 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.7 KB, free 2.0 GB)
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.2 KB, free 2.0 GB)
17/03/27 22:25:50 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53605 (size: 3.2 KB, free: 2.0 GB)
17/03/27 22:25:50 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:50 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at execute at Recursion.scala:189)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:50 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:50 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:50 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:50 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:50 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:50 INFO GenerateUnsafeProjection: Code generated in 4.648972 ms
17/03/27 22:25:50 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1367 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 34 ms on localhost (1/5)
17/03/27 22:25:50 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:50 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1367 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 39 ms on localhost (2/5)
17/03/27 22:25:50 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1367 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 12 ms on localhost (3/5)
17/03/27 22:25:50 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1367 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 53 ms on localhost (4/5)
17/03/27 22:25:50 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1367 bytes result sent to driver
17/03/27 22:25:50 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 56 ms on localhost (5/5)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:50 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.056 s
17/03/27 22:25:50 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:50 INFO DAGScheduler: running: Set()
17/03/27 22:25:50 INFO DAGScheduler: waiting: Set(FixedPointResultStage 2)
17/03/27 22:25:50 INFO DAGScheduler: failed: Set()
17/03/27 22:25:50 INFO DAGScheduler: Submitting FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 14.0 KB, free 2.0 GB)
17/03/27 22:25:50 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:50 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53605 (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:50 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:50 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:50 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:50 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:50 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:50 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:50 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:50 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:50 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:50 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_17_3 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_17_2 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:50 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:50 INFO CacheManager: Partition rdd_5_2 not found, computing it
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:50 INFO CacheManager: Partition rdd_5_0 not found, computing it
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:50 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:50 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:50 INFO BlockManager: Dropping block rdd_11_4 from memory
17/03/27 22:25:50 INFO BlockManagerInfo: Removed rdd_11_4 on localhost:53550 in memory (size: 558.4 MB, free: 931.1 MB)
17/03/27 22:25:50 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53605 in memory (size: 3.2 KB, free: 2.0 GB)
17/03/27 22:25:50 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53605 in memory (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:51 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:51 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 528.8 MB so far)
17/03/27 22:25:51 INFO MemoryStore: Memory use = 10.4 KB (blocks) + 1588.3 MB (scratch space shared across 5 tasks(s)) = 1588.4 MB. Storage limit = 2.0 GB.
17/03/27 22:25:51 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:51 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:51 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:51 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53605 in memory (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:51 INFO ContextCleaner: Cleaned accumulator 1350
17/03/27 22:25:51 INFO ContextCleaner: Cleaned accumulator 1349
17/03/27 22:25:51 INFO MemoryStore: Will not store rdd_5_2 as it would require dropping another block from the same RDD
17/03/27 22:25:51 WARN MemoryStore: Not enough space to cache rdd_5_2 in memory! (computed 528.8 MB so far)
17/03/27 22:25:51 INFO MemoryStore: Memory use = 2.6 KB (blocks) + 1589.3 MB (scratch space shared across 5 tasks(s)) = 1589.3 MB. Storage limit = 2.0 GB.
17/03/27 22:25:51 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:51 INFO CacheManager: Partition rdd_5_2 not found, computing it
17/03/27 22:25:51 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:51 INFO MemoryStore: Block rdd_23_4 stored as values in memory (estimated size 528.8 MB, free 402.3 MB)
17/03/27 22:25:51 INFO BlockManagerInfo: Added rdd_23_4 in memory on localhost:53550 (size: 528.8 MB, free: 402.3 MB)
17/03/27 22:25:51 INFO CacheManager: Partition rdd_17_4 not found, computing it
17/03/27 22:25:51 ERROR Executor: Exception in task 4.0 in stage 3.0 (TID 15)
org.apache.spark.SparkException: Checkpoint block rdd_17_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:51 WARN TaskSetManager: Lost task 4.0 in stage 3.0 (TID 15, localhost): org.apache.spark.SparkException: Checkpoint block rdd_17_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:25:51 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:25:51 INFO ContextCleaner: Cleaned accumulator 1340
17/03/27 22:25:51 INFO ContextCleaner: Cleaned accumulator 1339
17/03/27 22:25:51 INFO ContextCleaner: Cleaned accumulator 1338
17/03/27 22:25:51 INFO ContextCleaner: Cleaned accumulator 1337
17/03/27 22:25:51 INFO MemoryStore: Block rdd_5_1 stored as values in memory (estimated size 528.7 MB, free 1519.5 MB)
17/03/27 22:25:51 INFO BlockManagerInfo: Added rdd_5_1 in memory on localhost:53605 (size: 528.7 MB, free: 1519.5 MB)
17/03/27 22:25:51 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:51 INFO BlockManager: Found block rdd_5_1 locally
17/03/27 22:25:51 INFO BlockManager: Found block rdd_5_1 locally
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:51 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:51 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 528.7 MB so far)
17/03/27 22:25:51 INFO MemoryStore: Memory use = 528.7 MB (blocks) + 798.2 MB (scratch space shared across 5 tasks(s)) = 1326.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:51 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:51 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:51 INFO MemoryStore: Block rdd_5_0 stored as values in memory (estimated size 528.7 MB, free 990.8 MB)
17/03/27 22:25:51 INFO BlockManagerInfo: Added rdd_5_0 in memory on localhost:53605 (size: 528.7 MB, free: 990.8 MB)
17/03/27 22:25:51 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:51 INFO BlockManager: Found block rdd_5_0 locally
17/03/27 22:25:51 INFO BlockManager: Found block rdd_5_0 locally
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:51 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:51 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:51 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:51 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53605 (size: 296.0 B)
17/03/27 22:25:51 INFO BlockManager: Dropping block rdd_5_1 from memory
17/03/27 22:25:51 INFO BlockManagerInfo: Removed rdd_5_1 on localhost:53605 in memory (size: 528.7 MB, free: 1519.5 MB)
17/03/27 22:25:51 INFO BlockManager: Dropping block rdd_5_0 from memory
17/03/27 22:25:51 INFO BlockManagerInfo: Removed rdd_5_0 on localhost:53605 in memory (size: 528.7 MB, free: 2.0 GB)
17/03/27 22:25:51 INFO MemoryStore: Block rdd_5_2 stored as values in memory (estimated size 529.2 MB, free 1519.0 MB)
17/03/27 22:25:51 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:51 INFO BlockManagerInfo: Added rdd_5_2 in memory on localhost:53605 (size: 529.2 MB, free: 1519.0 MB)
17/03/27 22:25:51 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 529.3 MB so far)
17/03/27 22:25:51 INFO MemoryStore: Memory use = 529.2 MB (blocks) + 798.9 MB (scratch space shared across 5 tasks(s)) = 1328.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:51 INFO BlockManager: Found block rdd_5_2 locally
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:51 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:51 INFO BlockManager: Dropping block rdd_5_2 from memory
17/03/27 22:25:51 INFO BlockManagerInfo: Removed rdd_5_2 on localhost:53605 in memory (size: 529.2 MB, free: 2.0 GB)
17/03/27 22:25:51 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 529.2 MB, free 1519.0 MB)
17/03/27 22:25:51 INFO BlockManagerInfo: Added rdd_11_1 in memory on localhost:53605 (size: 529.2 MB, free: 1519.0 MB)
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 0 ms
17/03/27 22:25:51 INFO MemoryStore: Will not store rdd_11_3 as it would require dropping another block from the same RDD
17/03/27 22:25:51 WARN MemoryStore: Not enough space to cache rdd_11_3 in memory! (computed 529.2 MB so far)
17/03/27 22:25:51 INFO MemoryStore: Memory use = 529.2 MB (blocks) + 800.9 MB (scratch space shared across 5 tasks(s)) = 1330.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 0 ms
17/03/27 22:25:51 INFO MemoryStore: Will not store rdd_11_2 as it would require dropping another block from the same RDD
17/03/27 22:25:51 WARN MemoryStore: Not enough space to cache rdd_11_2 in memory! (computed 529.2 MB so far)
17/03/27 22:25:51 INFO MemoryStore: Memory use = 529.2 MB (blocks) + 801.9 MB (scratch space shared across 5 tasks(s)) = 1331.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 1 ms
17/03/27 22:25:51 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 529.2 MB, free 989.8 MB)
17/03/27 22:25:51 INFO BlockManagerInfo: Added rdd_11_0 in memory on localhost:53605 (size: 529.2 MB, free: 989.8 MB)
17/03/27 22:25:51 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 0 ms
17/03/27 22:25:52 INFO ContextCleaner: Cleaned accumulator 1342
17/03/27 22:25:52 INFO ContextCleaner: Cleaned accumulator 1341
17/03/27 22:25:52 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:25:52 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:52 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:52 INFO BlockManager: Dropping block rdd_11_1 from memory
17/03/27 22:25:52 INFO BlockManagerInfo: Removed rdd_11_1 on localhost:53605 in memory (size: 529.2 MB, free: 1519.0 MB)
17/03/27 22:25:52 INFO BlockManager: Dropping block rdd_11_0 from memory
17/03/27 22:25:52 INFO BlockManagerInfo: Removed rdd_11_0 on localhost:53605 in memory (size: 529.2 MB, free: 2.0 GB)
17/03/27 22:25:52 INFO MemoryStore: Will not store rdd_13_3 as it would require dropping another block from the same RDD
17/03/27 22:25:52 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 529.2 MB so far)
17/03/27 22:25:52 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1595.7 MB (scratch space shared across 5 tasks(s)) = 1595.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:52 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:52 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:52 INFO MemoryStore: Will not store rdd_13_2 as it would require dropping another block from the same RDD
17/03/27 22:25:52 WARN MemoryStore: Not enough space to cache rdd_13_2 in memory! (computed 529.2 MB so far)
17/03/27 22:25:52 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1596.7 MB (scratch space shared across 5 tasks(s)) = 1596.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:52 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:52 INFO CacheManager: Partition rdd_5_2 not found, computing it
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:52 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 529.2 MB, free 1519.0 MB)
17/03/27 22:25:52 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:53605 (size: 529.2 MB, free: 1519.0 MB)
17/03/27 22:25:52 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:52 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:52 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 529.2 MB, free 989.8 MB)
17/03/27 22:25:52 INFO BlockManagerInfo: Added rdd_13_0 in memory on localhost:53605 (size: 529.2 MB, free: 989.8 MB)
17/03/27 22:25:52 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:52 INFO BlockManager: Dropping block rdd_13_1 from memory
17/03/27 22:25:52 INFO BlockManagerInfo: Removed rdd_13_1 on localhost:53605 in memory (size: 529.2 MB, free: 1519.0 MB)
17/03/27 22:25:52 INFO BlockManager: Dropping block rdd_13_0 from memory
17/03/27 22:25:52 INFO BlockManagerInfo: Removed rdd_13_0 on localhost:53605 in memory (size: 529.2 MB, free: 2.0 GB)
17/03/27 22:25:52 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:52 INFO CacheManager: Partition rdd_5_0 not found, computing it
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:52 INFO MemoryStore: Will not store rdd_5_1 as it would require dropping another block from the same RDD
17/03/27 22:25:52 WARN MemoryStore: Not enough space to cache rdd_5_1 in memory! (computed 529.2 MB so far)
17/03/27 22:25:52 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1597.7 MB (scratch space shared across 5 tasks(s)) = 1597.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:52 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:52 INFO MemoryStore: Block rdd_5_2 stored as values in memory (estimated size 529.2 MB, free 1519.1 MB)
17/03/27 22:25:52 INFO BlockManagerInfo: Added rdd_5_2 in memory on localhost:53605 (size: 529.2 MB, free: 1519.1 MB)
17/03/27 22:25:52 INFO BlockManager: Found block rdd_5_2 locally
17/03/27 22:25:52 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:52 INFO MemoryStore: Block rdd_5_3 stored as values in memory (estimated size 529.2 MB, free 989.9 MB)
17/03/27 22:25:52 INFO BlockManagerInfo: Added rdd_5_3 in memory on localhost:53605 (size: 529.2 MB, free: 989.9 MB)
17/03/27 22:25:52 INFO BlockManager: Found block rdd_5_3 locally
17/03/27 22:25:52 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 1 ms
17/03/27 22:25:53 INFO MemoryStore: Will not store rdd_5_1 as it would require dropping another block from the same RDD
17/03/27 22:25:53 WARN MemoryStore: Not enough space to cache rdd_5_1 in memory! (computed 528.6 MB so far)
17/03/27 22:25:53 INFO MemoryStore: Memory use = 1058.4 MB (blocks) + 805.8 MB (scratch space shared across 5 tasks(s)) = 1864.2 MB. Storage limit = 2.0 GB.
17/03/27 22:25:53 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:53 INFO MemoryStore: Block rdd_5_0 stored as values in memory (estimated size 528.6 MB, free 461.2 MB)
17/03/27 22:25:53 INFO BlockManagerInfo: Added rdd_5_0 in memory on localhost:53605 (size: 528.6 MB, free: 461.2 MB)
17/03/27 22:25:53 INFO BlockManager: Found block rdd_5_0 locally
17/03/27 22:25:53 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:53 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:53 INFO BlockManager: Dropping block rdd_5_2 from memory
17/03/27 22:25:53 INFO BlockManagerInfo: Removed rdd_5_2 on localhost:53605 in memory (size: 529.2 MB, free: 990.4 MB)
17/03/27 22:25:53 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:53 INFO BlockManager: Dropping block rdd_5_3 from memory
17/03/27 22:25:53 INFO BlockManagerInfo: Removed rdd_5_3 on localhost:53605 in memory (size: 529.2 MB, free: 1519.6 MB)
17/03/27 22:25:53 INFO BlockManager: Dropping block rdd_5_0 from memory
17/03/27 22:25:53 INFO BlockManagerInfo: Removed rdd_5_0 on localhost:53605 in memory (size: 528.6 MB, free: 2.0 GB)
17/03/27 22:25:53 INFO MemoryStore: Will not store rdd_11_0 as it would require dropping another block from the same RDD
17/03/27 22:25:53 WARN MemoryStore: Not enough space to cache rdd_11_0 in memory! (computed 528.6 MB so far)
17/03/27 22:25:53 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1597.9 MB (scratch space shared across 5 tasks(s)) = 1597.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:53 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:53 INFO MemoryStore: Will not store rdd_11_1 as it would require dropping another block from the same RDD
17/03/27 22:25:53 WARN MemoryStore: Not enough space to cache rdd_11_1 in memory! (computed 528.6 MB so far)
17/03/27 22:25:53 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1598.9 MB (scratch space shared across 5 tasks(s)) = 1598.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:53 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 1 ms
17/03/27 22:25:53 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 528.6 MB, free 1519.6 MB)
17/03/27 22:25:53 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:53605 (size: 528.6 MB, free: 1519.6 MB)
17/03/27 22:25:53 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:53 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 528.6 MB, free 991.0 MB)
17/03/27 22:25:53 INFO BlockManagerInfo: Added rdd_11_3 in memory on localhost:53605 (size: 528.6 MB, free: 991.0 MB)
17/03/27 22:25:53 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:53 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:53 INFO BlockManager: Dropping block rdd_11_2 from memory
17/03/27 22:25:53 INFO BlockManagerInfo: Removed rdd_11_2 on localhost:53605 in memory (size: 528.6 MB, free: 1519.6 MB)
17/03/27 22:25:53 INFO BlockManager: Dropping block rdd_11_3 from memory
17/03/27 22:25:53 INFO BlockManagerInfo: Removed rdd_11_3 on localhost:53605 in memory (size: 528.6 MB, free: 2.0 GB)
17/03/27 22:25:53 INFO MemoryStore: Will not store rdd_17_1 as it would require dropping another block from the same RDD
17/03/27 22:25:53 WARN MemoryStore: Not enough space to cache rdd_17_1 in memory! (computed 528.6 MB so far)
17/03/27 22:25:53 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1599.8 MB (scratch space shared across 5 tasks(s)) = 1599.8 MB. Storage limit = 2.0 GB.
17/03/27 22:25:53 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 3574 bytes result sent to driver
17/03/27 22:25:53 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 3039 ms on localhost (1/5)
17/03/27 22:25:53 INFO MemoryStore: Will not store rdd_17_3 as it would require dropping another block from the same RDD
17/03/27 22:25:53 WARN MemoryStore: Not enough space to cache rdd_17_3 in memory! (computed 528.6 MB so far)
17/03/27 22:25:53 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1595.8 MB (scratch space shared across 4 tasks(s)) = 1595.8 MB. Storage limit = 2.0 GB.
17/03/27 22:25:53 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 3365 bytes result sent to driver
17/03/27 22:25:53 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 3048 ms on localhost (2/5)
17/03/27 22:25:53 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:53 INFO TorrentBroadcast: Started reading broadcast variable 3
17/03/27 22:25:53 ERROR Utils: Exception encountered
org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:53 ERROR Executor: Exception in task 4.0 in stage 2.0 (TID 14)
java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 11 more
17/03/27 22:25:53 WARN TaskSetManager: Lost task 4.0 in stage 2.0 (TID 14, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 11 more

17/03/27 22:25:53 ERROR TaskSetManager: Task 4 in stage 2.0 failed 1 times; aborting job
17/03/27 22:25:53 INFO TaskSchedulerImpl: Cancelling stage 2
17/03/27 22:25:53 INFO TaskSchedulerImpl: Stage 2 was cancelled
17/03/27 22:25:53 INFO DAGScheduler: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204) failed in 3.056 s
17/03/27 22:25:53 INFO Executor: Executor is trying to kill task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:53 INFO Executor: Executor is trying to kill task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:53 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 3.124219 s
17/03/27 22:25:53 INFO SparkContext: Running Spark version 1.6.3
[31m- Transitive Closure - LL 2 - ff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 2.0 failed 1 times, most recent failure: Lost task 4.0 in stage 2.0 (TID 14, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
[0m
[31m	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31mCaused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at scala.Option.getOrElse(Option.scala:121)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at scala.collection.immutable.List.foreach(List.scala:381)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
[0m
[31m	... 11 more
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)[0m
[31m  at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)[0m
[31m  at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)[0m
[31m  at org.apache.spark.scheduler.Task.run(Task.scala:89)[0m
[31m  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)[0m
[31m  at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at scala.Option.getOrElse(Option.scala:121)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at scala.collection.immutable.List.foreach(List.scala:381)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)[0m
[31m  ...[0m
17/03/27 22:25:53 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:53 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:53 INFO Utils: Successfully started service 'sparkDriver' on port 53627.
17/03/27 22:25:53 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:53 INFO Remoting: Starting remoting
17/03/27 22:25:53 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53640]
17/03/27 22:25:53 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53640.
17/03/27 22:25:53 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:53 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:53 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-d96d6dad-56fa-4f3b-a2b8-56e7c4cab71f
17/03/27 22:25:53 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:53 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:53 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:53 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53657.
17/03/27 22:25:53 INFO NettyBlockTransferService: Server created on 53657
17/03/27 22:25:53 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:53 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53657 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53657)
17/03/27 22:25:53 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:53 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667953817
17/03/27 22:25:53 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$2.apply$mcV$sp(RecursiveQuerySuites.scala:51)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$2.apply(RecursiveQuerySuites.scala:42)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$2.apply(RecursiveQuerySuites.scala:42)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$3.apply$mcV$sp(RecursiveQuerySuites.scala:66)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$3.apply(RecursiveQuerySuites.scala:56)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$3.apply(RecursiveQuerySuites.scala:56)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:53 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:53 INFO BigDatalogContext: BigDatalog Query: "rightLinearPaths(A,B)."
17/03/27 22:25:53 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:53 INFO BigDatalogContext: 
0: rightLinearPaths(From, B) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: arc(From, To) <BASE_RELATION>
Recursive Rules: 
 1: (From, B) <DISTINCT PROJECT>
  2: (0.To = 1.C) <JOIN>
   3: arc(From, To) <BASE_RELATION>
   3: rightLinearPaths(C, B) <RECURSIVE_RELATION>
17/03/27 22:25:53 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:53 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:53 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery rightLinearPaths
+- 'Recursion rightLinearPaths, true, [0,1]
   :- 'UnresolvedRelation `arc`, None
   +- 'Project ['arc1.From,'rightLinearPaths2.B]
      +- 'Join Inner, Some(('arc1.To = 'rightLinearPaths2.C))
         :- 'BroadcastHint
         :  +- 'Subquery arc1
         :     +- 'Project [*]
         :        +- 'UnresolvedRelation `arc`, None
         +- Subquery rightLinearPaths2
            +- LinearRecursiveRelation rightLinearPaths, [C#724,B#725], [0,1]

== Analyzed Logical Plan ==
From: int, B: int
Subquery rightLinearPaths
+- Recursion rightLinearPaths, true, [0,1]
   :- Subquery arc
   :  +- LogicalRDD [From#720,To#721], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [From#720,B#725]
      +- Join Inner, Some((To#721 = C#724))
         :- BroadcastHint
         :  +- Subquery arc1
         :     +- Project [From#720,To#721]
         :        +- Subquery arc
         :           +- LogicalRDD [From#720,To#721], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- Subquery rightLinearPaths2
            +- LinearRecursiveRelation rightLinearPaths, [C#724,B#725], [0,1]

== Optimized Logical Plan ==
Recursion rightLinearPaths, true, [0,1]
:- LogicalRDD [From#720,To#721], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [From#720,B#725]
   +- Join Inner, Some((To#721 = C#724))
      :- BroadcastHint
      :  +- Project [From#720,To#721]
      :     +- LogicalRDD [From#720,To#721], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- LinearRecursiveRelation rightLinearPaths, [C#724,B#725], [0,1]

== Physical Plan ==
Recursion [From#720,B#725] (Linear) [rightLinearPaths][0,1]
:- TungstenExchange hashpartitioning(To#721,5), None
:  +- ConvertToUnsafe
:     +- Scan ExistingRDD[From#720,To#721] 
+- Project [From#720,B#725]
   +- BroadcastHashJoin [To#721], [C#724], BuildLeft
      :- Project [From#720,To#721]
      :  +- Scan ExistingRDD[From#720,To#721] 
      +- LinearRecursiveRelation [C#724,B#725](rightLinearPaths)
17/03/27 22:25:53 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:53 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:53 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:53 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:53 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 530.4 MB, free 1517.9 MB)
17/03/27 22:25:53 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:53 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:53605 (size: 530.4 MB, free: 1517.9 MB)
17/03/27 22:25:53 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:53 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:53 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:53 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[8] at run at null:-1), which has no missing parents
17/03/27 22:25:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:25:53 INFO MemoryStore: Block rdd_17_2 stored as values in memory (estimated size 530.4 MB, free 987.5 MB)
17/03/27 22:25:53 INFO BlockManagerInfo: Added rdd_17_2 in memory on localhost:53605 (size: 530.4 MB, free: 987.5 MB)
17/03/27 22:25:53 INFO Executor: Executor killed task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:53 WARN TaskSetManager: Lost task 2.0 in stage 2.0 (TID 12, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53657 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:53 INFO Executor: Executor killed task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:53 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at run at null:-1)
17/03/27 22:25:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:53 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 10, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:53 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:53 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:53 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:53 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1484 bytes result sent to driver
17/03/27 22:25:53 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1484 bytes result sent to driver
17/03/27 22:25:53 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1484 bytes result sent to driver
17/03/27 22:25:53 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:53 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:53 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1484 bytes result sent to driver
17/03/27 22:25:53 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1484 bytes result sent to driver
17/03/27 22:25:53 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7 ms on localhost (1/5)
17/03/27 22:25:53 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7 ms on localhost (2/5)
17/03/27 22:25:53 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 2 ms on localhost (3/5)
17/03/27 22:25:53 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 7 ms on localhost (4/5)
17/03/27 22:25:53 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 8 ms on localhost (5/5)
17/03/27 22:25:53 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:53 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.008 s
17/03/27 22:25:53 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.009824 s
17/03/27 22:25:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.4 KB, free 2.0 GB)
17/03/27 22:25:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 293.0 B, free 2.0 GB)
17/03/27 22:25:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53657 (size: 293.0 B, free: 2.0 GB)
17/03/27 22:25:53 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:53 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:53 INFO Recursion: Fixed Point Iteration # 1, time: 52ms
17/03/27 22:25:53 INFO DAGScheduler: Registering RDD 3 (execute at Recursion.scala:189)
17/03/27 22:25:53 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:53 INFO DAGScheduler: Final stage: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/03/27 22:25:53 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/03/27 22:25:53 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[3] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:53 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:53 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:25:53 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53657 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:25:53 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:53 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[3] at execute at Recursion.scala:189)
17/03/27 22:25:53 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:53 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:53 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:53 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:53 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:53 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:53 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:54 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:25:54 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:54 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 16 ms on localhost (1/5)
17/03/27 22:25:54 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:54 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:25:54 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 17 ms on localhost (2/5)
17/03/27 22:25:54 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1222 bytes result sent to driver
17/03/27 22:25:54 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 11 ms on localhost (3/5)
17/03/27 22:25:54 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:25:54 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 29 ms on localhost (4/5)
17/03/27 22:25:54 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:25:54 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 35 ms on localhost (5/5)
17/03/27 22:25:54 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:54 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.035 s
17/03/27 22:25:54 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:54 INFO DAGScheduler: running: Set()
17/03/27 22:25:54 INFO DAGScheduler: waiting: Set(FixedPointResultStage 2)
17/03/27 22:25:54 INFO DAGScheduler: failed: Set()
17/03/27 22:25:54 INFO DAGScheduler: Submitting FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:25:54 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 13.9 KB, free 2.0 GB)
17/03/27 22:25:54 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:54 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53657 (size: 6.8 KB, free: 2.0 GB)
17/03/27 22:25:54 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:54 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 2 (SetRDD.diffRDD SetRDD[18] at RDD at SetRDD.scala:30)
17/03/27 22:25:54 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:54 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:54 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:54 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:54 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:54 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:54 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:54 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:54 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:54 INFO CacheManager: Partition rdd_17_2 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_17_1 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_17_0 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_17_3 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_0 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_2 not found, computing it
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:54 INFO MemoryStore: Will not store rdd_5_1 as it would require dropping another block from the same RDD
17/03/27 22:25:54 WARN MemoryStore: Not enough space to cache rdd_5_1 in memory! (computed 530.6 MB so far)
17/03/27 22:25:54 INFO MemoryStore: Memory use = 38.8 KB (blocks) + 1593.9 MB (scratch space shared across 5 tasks(s)) = 1593.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:54 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:54 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 530.6 MB so far)
17/03/27 22:25:54 INFO MemoryStore: Memory use = 38.8 KB (blocks) + 1593.9 MB (scratch space shared across 5 tasks(s)) = 1593.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:54 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 18 ms
17/03/27 22:25:54 INFO MemoryStore: Block rdd_5_2 stored as values in memory (estimated size 530.6 MB, free 1517.6 MB)
17/03/27 22:25:54 INFO BlockManagerInfo: Added rdd_5_2 in memory on localhost:53657 (size: 530.6 MB, free: 1517.6 MB)
17/03/27 22:25:54 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:54 INFO BlockManager: Found block rdd_5_2 locally
17/03/27 22:25:54 INFO BlockManager: Found block rdd_5_2 locally
17/03/27 22:25:54 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:54 INFO MemoryStore: Block rdd_5_0 stored as values in memory (estimated size 530.6 MB, free 987.0 MB)
17/03/27 22:25:54 INFO BlockManagerInfo: Added rdd_5_0 in memory on localhost:53657 (size: 530.6 MB, free: 987.1 MB)
17/03/27 22:25:54 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:54 INFO BlockManager: Found block rdd_5_0 locally
17/03/27 22:25:54 INFO BlockManager: Found block rdd_5_0 locally
17/03/27 22:25:54 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 6 took 0 ms
17/03/27 22:25:54 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:54 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 530.6 MB so far)
17/03/27 22:25:54 INFO MemoryStore: Memory use = 1061.2 MB (blocks) + 800.9 MB (scratch space shared across 5 tasks(s)) = 1862.1 MB. Storage limit = 2.0 GB.
17/03/27 22:25:54 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:54 INFO MemoryStore: 9 blocks selected for dropping
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:25:54 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:53657 (size: 2.7 KB)
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:25:54 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53657 (size: 293.0 B)
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:25:54 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53657 (size: 2.8 KB)
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:25:54 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53657 (size: 6.8 KB)
17/03/27 22:25:54 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:25:54 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:25:54 INFO BlockManager: Dropping block rdd_5_2 from memory
17/03/27 22:25:54 INFO BlockManagerInfo: Removed rdd_5_2 on localhost:53657 in memory (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:54 INFO BlockManager: Dropping block rdd_5_0 from memory
17/03/27 22:25:54 INFO BlockManagerInfo: Removed rdd_5_0 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:54 INFO MemoryStore: Will not store rdd_11_2 as it would require dropping another block from the same RDD
17/03/27 22:25:54 WARN MemoryStore: Not enough space to cache rdd_11_2 in memory! (computed 530.6 MB so far)
17/03/27 22:25:54 INFO MemoryStore: Memory use = 2.4 KB (blocks) + 1596.8 MB (scratch space shared across 5 tasks(s)) = 1596.8 MB. Storage limit = 2.0 GB.
17/03/27 22:25:54 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 1 ms
17/03/27 22:25:54 INFO MemoryStore: Block rdd_5_1 stored as values in memory (estimated size 530.6 MB, free 1517.7 MB)
17/03/27 22:25:54 INFO BlockManagerInfo: Added rdd_5_1 in memory on localhost:53657 (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:54 INFO BlockManager: Found block rdd_5_1 locally
17/03/27 22:25:54 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:54 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:54 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 530.6 MB so far)
17/03/27 22:25:54 INFO MemoryStore: Memory use = 530.6 MB (blocks) + 802.9 MB (scratch space shared across 5 tasks(s)) = 1333.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:54 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:55 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53657 on disk (size: 2.8 KB)
17/03/27 22:25:55 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53657 on disk (size: 6.8 KB)
17/03/27 22:25:55 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:55 INFO BlockManager: Dropping block rdd_5_1 from memory
17/03/27 22:25:55 INFO BlockManagerInfo: Removed rdd_5_1 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:55 INFO MemoryStore: Will not store rdd_11_1 as it would require dropping another block from the same RDD
17/03/27 22:25:55 WARN MemoryStore: Not enough space to cache rdd_11_1 in memory! (computed 530.6 MB so far)
17/03/27 22:25:55 INFO MemoryStore: Memory use = 2.4 KB (blocks) + 1598.8 MB (scratch space shared across 5 tasks(s)) = 1598.8 MB. Storage limit = 2.0 GB.
17/03/27 22:25:55 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 0 ms
17/03/27 22:25:55 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 530.6 MB, free 1517.6 MB)
17/03/27 22:25:55 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:55 INFO BlockManagerInfo: Added rdd_11_0 in memory on localhost:53657 (size: 530.6 MB, free: 1517.6 MB)
17/03/27 22:25:55 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:25:55 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:25:55 INFO SetRDDHashSetPartition: Union set size 2 for rdd 6 took 0 ms
17/03/27 22:25:55 INFO BlockManager: Dropping block rdd_11_0 from memory
17/03/27 22:25:55 INFO BlockManagerInfo: Removed rdd_11_0 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:55 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53657 on disk (size: 2.7 KB)
17/03/27 22:25:55 INFO ContextCleaner: Cleaned accumulator 1361
17/03/27 22:25:55 INFO ContextCleaner: Cleaned accumulator 1360
17/03/27 22:25:55 INFO ContextCleaner: Cleaned accumulator 1354
17/03/27 22:25:55 INFO ContextCleaner: Cleaned accumulator 1353
17/03/27 22:25:55 INFO ContextCleaner: Cleaned accumulator 1352
17/03/27 22:25:55 INFO ContextCleaner: Cleaned accumulator 1351
17/03/27 22:25:55 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 530.6 MB, free 1517.6 MB)
17/03/27 22:25:55 INFO BlockManagerInfo: Added rdd_11_3 in memory on localhost:53657 (size: 530.6 MB, free: 1517.6 MB)
17/03/27 22:25:55 INFO SetRDDHashSetPartition: Union set size 4 for rdd 6 took 0 ms
17/03/27 22:25:55 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:55 INFO BlockManager: Dropping block rdd_11_3 from memory
17/03/27 22:25:55 INFO BlockManagerInfo: Removed rdd_11_3 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:55 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 530.6 MB, free 1517.6 MB)
17/03/27 22:25:55 INFO BlockManagerInfo: Added rdd_13_2 in memory on localhost:53657 (size: 530.6 MB, free: 1517.6 MB)
17/03/27 22:25:55 INFO CacheManager: Partition rdd_11_2 not found, computing it
17/03/27 22:25:55 INFO CacheManager: Partition rdd_5_2 not found, computing it
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:55 INFO MemoryStore: Will not store rdd_13_0 as it would require dropping another block from the same RDD
17/03/27 22:25:55 WARN MemoryStore: Not enough space to cache rdd_13_0 in memory! (computed 530.6 MB so far)
17/03/27 22:25:55 INFO MemoryStore: Memory use = 530.6 MB (blocks) + 804.9 MB (scratch space shared across 5 tasks(s)) = 1335.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:55 INFO CacheManager: Partition rdd_11_0 not found, computing it
17/03/27 22:25:55 INFO CacheManager: Partition rdd_5_0 not found, computing it
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:55 INFO MemoryStore: Will not store rdd_13_3 as it would require dropping another block from the same RDD
17/03/27 22:25:55 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 530.6 MB so far)
17/03/27 22:25:55 INFO MemoryStore: Memory use = 530.6 MB (blocks) + 805.9 MB (scratch space shared across 5 tasks(s)) = 1336.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:55 INFO CacheManager: Partition rdd_11_3 not found, computing it
17/03/27 22:25:55 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:55 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 530.6 MB, free 987.1 MB)
17/03/27 22:25:55 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:53657 (size: 530.6 MB, free: 987.1 MB)
17/03/27 22:25:55 INFO CacheManager: Partition rdd_11_1 not found, computing it
17/03/27 22:25:55 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:55 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:55 INFO BlockManager: Dropping block rdd_13_2 from memory
17/03/27 22:25:55 INFO BlockManagerInfo: Removed rdd_13_2 on localhost:53657 in memory (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:55 INFO BlockManager: Dropping block rdd_13_1 from memory
17/03/27 22:25:55 INFO BlockManagerInfo: Removed rdd_13_1 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:56 INFO MemoryStore: Will not store rdd_5_3 as it would require dropping another block from the same RDD
17/03/27 22:25:56 WARN MemoryStore: Not enough space to cache rdd_5_3 in memory! (computed 530.6 MB so far)
17/03/27 22:25:56 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1601.7 MB (scratch space shared across 5 tasks(s)) = 1601.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:56 INFO CacheManager: Partition rdd_5_3 not found, computing it
17/03/27 22:25:56 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:56 INFO MemoryStore: Will not store rdd_5_1 as it would require dropping another block from the same RDD
17/03/27 22:25:56 WARN MemoryStore: Not enough space to cache rdd_5_1 in memory! (computed 530.6 MB so far)
17/03/27 22:25:56 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1602.7 MB (scratch space shared across 5 tasks(s)) = 1602.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:56 INFO CacheManager: Partition rdd_5_1 not found, computing it
17/03/27 22:25:56 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:56 INFO MemoryStore: Block rdd_5_2 stored as values in memory (estimated size 530.6 MB, free 1517.7 MB)
17/03/27 22:25:56 INFO BlockManagerInfo: Added rdd_5_2 in memory on localhost:53657 (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:56 INFO BlockManager: Found block rdd_5_2 locally
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:56 INFO MemoryStore: Block rdd_5_0 stored as values in memory (estimated size 530.6 MB, free 987.1 MB)
17/03/27 22:25:56 INFO BlockManagerInfo: Added rdd_5_0 in memory on localhost:53657 (size: 530.6 MB, free: 987.1 MB)
17/03/27 22:25:56 INFO BlockManager: Found block rdd_5_0 locally
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 6 took 0 ms
17/03/27 22:25:56 INFO MemoryStore: Will not store rdd_5_1 as it would require dropping another block from the same RDD
17/03/27 22:25:56 WARN MemoryStore: Not enough space to cache rdd_5_1 in memory! (computed 530.6 MB so far)
17/03/27 22:25:56 INFO MemoryStore: Memory use = 1061.2 MB (blocks) + 808.9 MB (scratch space shared across 5 tasks(s)) = 1870.0 MB. Storage limit = 2.0 GB.
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:56 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:56 INFO BlockManager: Dropping block rdd_5_2 from memory
17/03/27 22:25:56 INFO BlockManagerInfo: Removed rdd_5_2 on localhost:53657 in memory (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:56 INFO BlockManager: Dropping block rdd_5_0 from memory
17/03/27 22:25:56 INFO BlockManagerInfo: Removed rdd_5_0 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:56 INFO MemoryStore: Will not store rdd_11_0 as it would require dropping another block from the same RDD
17/03/27 22:25:56 WARN MemoryStore: Not enough space to cache rdd_11_0 in memory! (computed 530.6 MB so far)
17/03/27 22:25:56 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1604.7 MB (scratch space shared across 5 tasks(s)) = 1604.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 1 ms
17/03/27 22:25:56 INFO MemoryStore: Will not store rdd_11_1 as it would require dropping another block from the same RDD
17/03/27 22:25:56 WARN MemoryStore: Not enough space to cache rdd_11_1 in memory! (computed 530.6 MB so far)
17/03/27 22:25:56 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1605.7 MB (scratch space shared across 5 tasks(s)) = 1605.7 MB. Storage limit = 2.0 GB.
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:25:56 INFO MemoryStore: Block rdd_5_3 stored as values in memory (estimated size 530.6 MB, free 1517.7 MB)
17/03/27 22:25:56 INFO BlockManagerInfo: Added rdd_5_3 in memory on localhost:53657 (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 6 took 0 ms
17/03/27 22:25:56 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 530.6 MB, free 987.1 MB)
17/03/27 22:25:56 INFO BlockManagerInfo: Added rdd_11_2 in memory on localhost:53657 (size: 530.6 MB, free: 987.1 MB)
17/03/27 22:25:56 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:57 INFO MemoryStore: Will not store rdd_11_3 as it would require dropping another block from the same RDD
17/03/27 22:25:57 WARN MemoryStore: Not enough space to cache rdd_11_3 in memory! (computed 530.6 MB so far)
17/03/27 22:25:57 INFO MemoryStore: Memory use = 1061.2 MB (blocks) + 811.9 MB (scratch space shared across 5 tasks(s)) = 1873.0 MB. Storage limit = 2.0 GB.
17/03/27 22:25:57 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:25:57 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:57 INFO BlockManager: Dropping block rdd_5_3 from memory
17/03/27 22:25:57 INFO BlockManagerInfo: Removed rdd_5_3 on localhost:53657 in memory (size: 530.6 MB, free: 1517.7 MB)
17/03/27 22:25:57 INFO BlockManager: Dropping block rdd_11_2 from memory
17/03/27 22:25:57 INFO BlockManagerInfo: Removed rdd_11_2 on localhost:53657 in memory (size: 530.6 MB, free: 2.0 GB)
17/03/27 22:25:57 INFO MemoryStore: Will not store rdd_17_2 as it would require dropping another block from the same RDD
17/03/27 22:25:57 WARN MemoryStore: Not enough space to cache rdd_17_2 in memory! (computed 530.6 MB so far)
17/03/27 22:25:57 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1607.8 MB (scratch space shared across 5 tasks(s)) = 1607.8 MB. Storage limit = 2.0 GB.
17/03/27 22:25:57 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 3640 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:25:57 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:57 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 3058 ms on localhost (1/5)
17/03/27 22:25:57 INFO TorrentBroadcast: Started reading broadcast variable 3
17/03/27 22:25:57 ERROR Utils: Exception encountered
org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:57 ERROR Executor: Exception in task 4.0 in stage 2.0 (TID 14)
java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 11 more
17/03/27 22:25:57 WARN TaskSetManager: Lost task 4.0 in stage 2.0 (TID 14, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 11 more

17/03/27 22:25:57 ERROR TaskSetManager: Task 4 in stage 2.0 failed 1 times; aborting job
17/03/27 22:25:57 INFO TaskSchedulerImpl: Cancelling stage 2
17/03/27 22:25:57 INFO TaskSchedulerImpl: Stage 2 was cancelled
17/03/27 22:25:57 INFO DAGScheduler: FixedPointResultStage 2 (runFixedPointJob at Recursion.scala:204) failed in 3.061 s
17/03/27 22:25:57 INFO Executor: Executor is trying to kill task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:57 INFO Executor: Executor is trying to kill task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:57 INFO Executor: Executor is trying to kill task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:57 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 3.105483 s
[31m- Transitive Closure - RL - ff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 2.0 failed 1 times, most recent failure: Lost task 4.0 in stage 2.0 (TID 14, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
[0m
[31m	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31mCaused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at scala.Option.getOrElse(Option.scala:121)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at scala.collection.immutable.List.foreach(List.scala:381)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
[0m
[31m	... 11 more
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)[0m
17/03/27 22:25:57 INFO SparkContext: Running Spark version 1.6.3
[31m  at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)[0m
[31m  at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)[0m
[31m  at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:50)[0m
[31m  at org.apache.spark.scheduler.Task.run(Task.scala:89)[0m
[31m  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)[0m
[31m  at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at scala.Option.getOrElse(Option.scala:121)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at scala.collection.immutable.List.foreach(List.scala:381)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)[0m
[31m  ...[0m
17/03/27 22:25:57 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:57 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:25:57 INFO MemoryStore: Block rdd_17_0 stored as values in memory (estimated size 530.7 MB, free 1517.5 MB)
17/03/27 22:25:57 INFO BlockManagerInfo: Added rdd_17_0 in memory on localhost:53657 (size: 530.7 MB, free: 1517.5 MB)
17/03/27 22:25:57 INFO Executor: Executor killed task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:57 WARN TaskSetManager: Lost task 0.0 in stage 2.0 (TID 10, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:57 INFO Utils: Successfully started service 'sparkDriver' on port 53680.
17/03/27 22:25:57 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:57 INFO Remoting: Starting remoting
17/03/27 22:25:57 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53693]
17/03/27 22:25:57 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53693.
17/03/27 22:25:57 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:57 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:57 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-82090ca4-e62e-4e82-89dd-3409063610d7
17/03/27 22:25:57 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:57 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:57 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:57 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53710.
17/03/27 22:25:57 INFO NettyBlockTransferService: Server created on 53710
17/03/27 22:25:57 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:57 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53710 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53710)
17/03/27 22:25:57 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:57 INFO MemoryStore: Will not store rdd_17_3 as it would require dropping another block from the same RDD
17/03/27 22:25:57 WARN MemoryStore: Not enough space to cache rdd_17_3 in memory! (computed 534.4 MB so far)
17/03/27 22:25:57 INFO MemoryStore: Memory use = 530.7 MB (blocks) + 807.9 MB (scratch space shared across 3 tasks(s)) = 1338.6 MB. Storage limit = 2.0 GB.
17/03/27 22:25:57 INFO Executor: Executor killed task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:57 WARN TaskSetManager: Lost task 3.0 in stage 2.0 (TID 13, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:57 INFO MemoryStore: Block rdd_17_1 stored as values in memory (estimated size 534.4 MB, free 983.1 MB)
17/03/27 22:25:57 INFO BlockManagerInfo: Added rdd_17_1 in memory on localhost:53657 (size: 534.4 MB, free: 983.1 MB)
17/03/27 22:25:57 INFO Executor: Executor killed task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:57 WARN TaskSetManager: Lost task 1.0 in stage 2.0 (TID 11, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:57 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:25:57 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667957238
17/03/27 22:25:57 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$3.apply$mcV$sp(RecursiveQuerySuites.scala:66)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$3.apply(RecursiveQuerySuites.scala:56)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$3.apply(RecursiveQuerySuites.scala:56)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$4.apply$mcV$sp(RecursiveQuerySuites.scala:78)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$4.apply(RecursiveQuerySuites.scala:69)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$4.apply(RecursiveQuerySuites.scala:69)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:57 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:57 INFO BigDatalogContext: BigDatalog Query: "nonLinearPaths(A,B)."
17/03/27 22:25:57 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:57 INFO BigDatalogContext: 
0: nonLinearPaths(A, B) <RECURSIVE_CLIQUE>(Recursion: NONLINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: arc(From, To) <BASE_RELATION>
Recursive Rules: 
 1: (A, B) <DISTINCT PROJECT>
  2: (0.C = 1.C) <JOIN>
   3: nonLinearPaths(A, C) <RECURSIVE_RELATION>
   3: nonLinearPaths(C, B) <RECURSIVE_RELATION>
17/03/27 22:25:57 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:57 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:57 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery nonLinearPaths
+- 'Recursion nonLinearPaths, false, [1,0]
   :- 'UnresolvedRelation `arc`, None
   +- 'Project ['nonLinearPaths1.A,'nonLinearPaths2.B]
      +- 'Join Inner, Some(('nonLinearPaths1.C = 'nonLinearPaths2.C))
         :- Subquery nonLinearPaths1
         :  +- LinearRecursiveRelation nonLinearPaths, [A#730,C#731], [1,0]
         +- Subquery nonLinearPaths2
            +- NonLinearRecursiveRelation nonLinearPaths, [C#732,B#733], [1,0]

== Analyzed Logical Plan ==
A: int, B: int
Subquery nonLinearPaths
+- Recursion nonLinearPaths, false, [1,0]
   :- Subquery arc
   :  +- LogicalRDD [From#726,To#727], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [A#730,B#733]
      +- Join Inner, Some((C#731 = C#732))
         :- Subquery nonLinearPaths1
         :  +- LinearRecursiveRelation nonLinearPaths, [A#730,C#731], [1,0]
         +- Subquery nonLinearPaths2
            +- NonLinearRecursiveRelation nonLinearPaths, [C#732,B#733], [1,0]

== Optimized Logical Plan ==
Recursion nonLinearPaths, false, [1,0]
:- LogicalRDD [From#726,To#727], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [A#730,B#733]
   +- Join Inner, Some((C#731 = C#732))
      :- LinearRecursiveRelation nonLinearPaths, [A#730,C#731], [1,0]
      +- NonLinearRecursiveRelation nonLinearPaths, [C#732,B#733], [1,0]

== Physical Plan ==
Recursion [A#730,B#733] (NonLinear) [nonLinearPaths][1,0]
:- TungstenExchange hashpartitioning(From#726,5), None
:  +- ConvertToUnsafe
:     +- Scan ExistingRDD[From#726,To#727] 
+- TungstenExchange hashpartitioning(A#730,5), None
   +- Project [A#730,B#733]
      +- SortMergeJoin [C#731], [C#732]
         :- Sort [C#731 ASC], false, 0
         :  +- TungstenExchange hashpartitioning(C#731,5), None
         :     +- LinearRecursiveRelation [A#730,C#731](nonLinearPaths)
         +- Sort [C#732 ASC], false, 0
            +- NonLinearRecursiveRelation [C#732,B#733](all_nonLinearPaths)
17/03/27 22:25:57 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:57 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:57 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:57 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:57 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:57 INFO Recursion: Fixed Point Iteration # 1, time: 11ms
17/03/27 22:25:57 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:25:57 INFO DAGScheduler: Registering RDD 8 (mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 0 is 86 bytes
17/03/27 22:25:57 INFO DAGScheduler: Registering RDD 14 (execute at Recursion.scala:202)
17/03/27 22:25:57 INFO DAGScheduler: Registering RDD 20 (mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 1 is 86 bytes
17/03/27 22:25:57 INFO MapOutputTrackerMaster: Size of output statuses for shuffle 2 is 86 bytes
17/03/27 22:25:57 INFO DAGScheduler: Registering RDD 26 (execute at Recursion.scala:228)
17/03/27 22:25:57 INFO DAGScheduler: Got job 0 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:57 INFO DAGScheduler: Final stage: FixedPointResultStage 9 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 8)
17/03/27 22:25:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6, ShuffleMapStage 7, ShuffleMapStage 8)
17/03/27 22:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:57 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.8 KB, free 2.0 GB)
17/03/27 22:25:57 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:57 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53710 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:57 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:57 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:25:57 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:25:57 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:57 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:57 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:57 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:57 INFO Executor: Running task 0.0 in stage 6.0 (TID 0)
17/03/27 22:25:57 INFO Executor: Running task 1.0 in stage 6.0 (TID 1)
17/03/27 22:25:57 INFO Executor: Running task 2.0 in stage 6.0 (TID 2)
17/03/27 22:25:57 INFO Executor: Running task 3.0 in stage 6.0 (TID 3)
17/03/27 22:25:57 INFO Executor: Finished task 3.0 in stage 6.0 (TID 3). 1222 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:57 INFO Executor: Running task 4.0 in stage 6.0 (TID 4)
17/03/27 22:25:57 INFO Executor: Finished task 2.0 in stage 6.0 (TID 2). 1222 bytes result sent to driver
17/03/27 22:25:57 INFO Executor: Finished task 1.0 in stage 6.0 (TID 1). 1222 bytes result sent to driver
17/03/27 22:25:57 INFO Executor: Finished task 0.0 in stage 6.0 (TID 0). 1222 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 3) in 41 ms on localhost (1/5)
17/03/27 22:25:57 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 2) in 41 ms on localhost (2/5)
17/03/27 22:25:57 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 1) in 42 ms on localhost (3/5)
17/03/27 22:25:57 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 0) in 42 ms on localhost (4/5)
17/03/27 22:25:57 INFO Executor: Finished task 4.0 in stage 6.0 (TID 4). 1222 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 4) in 11 ms on localhost (5/5)
17/03/27 22:25:57 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:25:57 INFO DAGScheduler: ShuffleMapStage 6 (execute at Recursion.scala:189) finished in 0.044 s
17/03/27 22:25:57 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:57 INFO DAGScheduler: running: Set()
17/03/27 22:25:57 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 5, ShuffleMapStage 7, ShuffleMapStage 4, ShuffleMapStage 8)
17/03/27 22:25:57 INFO DAGScheduler: failed: Set()
17/03/27 22:25:57 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[8] at mapPartitionsInternal at SetRDD.scala:92), which has no missing parents
17/03/27 22:25:57 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 7.3 KB, free 2.0 GB)
17/03/27 22:25:57 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 4.0 KB, free 2.0 GB)
17/03/27 22:25:57 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53710 (size: 4.0 KB, free: 2.0 GB)
17/03/27 22:25:57 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:57 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[8] at mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:57 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:25:57 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:57 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 6, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:57 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 7, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:57 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 8, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:57 INFO Executor: Running task 0.0 in stage 5.0 (TID 5)
17/03/27 22:25:57 INFO Executor: Running task 1.0 in stage 5.0 (TID 6)
17/03/27 22:25:57 INFO Executor: Running task 2.0 in stage 5.0 (TID 7)
17/03/27 22:25:57 INFO Executor: Running task 3.0 in stage 5.0 (TID 8)
17/03/27 22:25:57 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:57 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:57 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:25:57 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:57 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:25:57 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 532.5 MB so far)
17/03/27 22:25:57 INFO MemoryStore: Memory use = 18.8 KB (blocks) + 1599.4 MB (scratch space shared across 5 tasks(s)) = 1599.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:57 INFO Executor: Finished task 3.0 in stage 5.0 (TID 8). 1568 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 9, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:57 INFO Executor: Running task 4.0 in stage 5.0 (TID 9)
17/03/27 22:25:57 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 8) in 316 ms on localhost (1/5)
17/03/27 22:25:57 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:57 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:57 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:57 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 532.5 MB so far)
17/03/27 22:25:57 INFO MemoryStore: Memory use = 18.8 KB (blocks) + 1599.4 MB (scratch space shared across 5 tasks(s)) = 1599.5 MB. Storage limit = 2.0 GB.
17/03/27 22:25:57 INFO Executor: Finished task 0.0 in stage 5.0 (TID 5). 1568 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 345 ms on localhost (2/5)
17/03/27 22:25:57 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 532.4 MB, free 1515.8 MB)
17/03/27 22:25:57 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:53710 (size: 532.4 MB, free: 1515.8 MB)
17/03/27 22:25:57 INFO Executor: Finished task 2.0 in stage 5.0 (TID 7). 1937 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 7) in 544 ms on localhost (3/5)
17/03/27 22:25:57 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 532.4 MB, free 983.4 MB)
17/03/27 22:25:57 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:53710 (size: 532.4 MB, free: 983.4 MB)
17/03/27 22:25:57 INFO Executor: Finished task 1.0 in stage 5.0 (TID 6). 1937 bytes result sent to driver
17/03/27 22:25:57 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 6) in 557 ms on localhost (4/5)
17/03/27 22:25:58 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 532.4 MB, free 451.0 MB)
17/03/27 22:25:58 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:53710 (size: 532.4 MB, free: 451.0 MB)
17/03/27 22:25:58 INFO Executor: Finished task 4.0 in stage 5.0 (TID 9). 1937 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 9) in 507 ms on localhost (5/5)
17/03/27 22:25:58 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:25:58 INFO DAGScheduler: ShuffleMapStage 5 (mapPartitionsInternal at SetRDD.scala:92) finished in 0.823 s
17/03/27 22:25:58 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:58 INFO DAGScheduler: running: Set()
17/03/27 22:25:58 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 7, ShuffleMapStage 4, ShuffleMapStage 8)
17/03/27 22:25:58 INFO DAGScheduler: failed: Set()
17/03/27 22:25:58 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[14] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:25:58 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.9 KB, free 451.0 MB)
17/03/27 22:25:58 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.0 KB, free 451.0 MB)
17/03/27 22:25:58 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53710 (size: 6.0 KB, free: 451.0 MB)
17/03/27 22:25:58 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:58 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[14] at execute at Recursion.scala:202)
17/03/27 22:25:58 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks
17/03/27 22:25:58 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 10, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 11, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 12, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 13, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO Executor: Running task 1.0 in stage 7.0 (TID 11)
17/03/27 22:25:58 INFO Executor: Running task 2.0 in stage 7.0 (TID 12)
17/03/27 22:25:58 INFO Executor: Running task 3.0 in stage 7.0 (TID 13)
17/03/27 22:25:58 INFO Executor: Running task 0.0 in stage 7.0 (TID 10)
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:58 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:58 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO Executor: Finished task 1.0 in stage 7.0 (TID 11). 2990 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 14, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO Executor: Running task 4.0 in stage 7.0 (TID 14)
17/03/27 22:25:58 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 11) in 27 ms on localhost (1/5)
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:58 INFO Executor: Finished task 2.0 in stage 7.0 (TID 12). 2990 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 12) in 33 ms on localhost (2/5)
17/03/27 22:25:58 INFO Executor: Finished task 4.0 in stage 7.0 (TID 14). 2990 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 14) in 9 ms on localhost (3/5)
17/03/27 22:25:58 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:25:58 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 532.6 MB so far)
17/03/27 22:25:58 INFO MemoryStore: Memory use = 1597.3 MB (blocks) + 2.0 MB (scratch space shared across 3 tasks(s)) = 1599.3 MB. Storage limit = 1984.1 MB.
17/03/27 22:25:58 INFO Executor: Finished task 3.0 in stage 7.0 (TID 13). 1970 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 13) in 245 ms on localhost (4/5)
17/03/27 22:25:58 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:58 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 500.5 MB so far)
17/03/27 22:25:58 INFO MemoryStore: Memory use = 1597.3 MB (blocks) + 1024.0 KB (scratch space shared across 2 tasks(s)) = 1598.3 MB. Storage limit = 2016.2 MB.
17/03/27 22:25:58 INFO Executor: Finished task 0.0 in stage 7.0 (TID 10). 1970 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 10) in 266 ms on localhost (5/5)
17/03/27 22:25:58 INFO DAGScheduler: ShuffleMapStage 7 (execute at Recursion.scala:202) finished in 0.267 s
17/03/27 22:25:58 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/27 22:25:58 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:58 INFO DAGScheduler: running: Set()
17/03/27 22:25:58 INFO DAGScheduler: waiting: Set(FixedPointResultStage 9, ShuffleMapStage 4, ShuffleMapStage 8)
17/03/27 22:25:58 INFO DAGScheduler: failed: Set()
17/03/27 22:25:58 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[20] at mapPartitionsInternal at SetRDD.scala:92), which has no missing parents
17/03/27 22:25:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 8.1 KB, free 451.0 MB)
17/03/27 22:25:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.4 KB, free 451.0 MB)
17/03/27 22:25:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53710 (size: 4.4 KB, free: 451.0 MB)
17/03/27 22:25:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:58 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[20] at mapPartitionsInternal at SetRDD.scala:92)
17/03/27 22:25:58 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:25:58 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 15, localhost, partition 1,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 16, localhost, partition 2,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 17, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 18, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO Executor: Running task 1.0 in stage 4.0 (TID 15)
17/03/27 22:25:58 INFO Executor: Running task 4.0 in stage 4.0 (TID 17)
17/03/27 22:25:58 INFO Executor: Running task 0.0 in stage 4.0 (TID 18)
17/03/27 22:25:58 INFO Executor: Running task 2.0 in stage 4.0 (TID 16)
17/03/27 22:25:58 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:25:58 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:25:58 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:25:58 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:25:58 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:25:58 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:25:58 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:58 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:58 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 1 ms
17/03/27 22:25:58 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53710 in memory (size: 6.0 KB, free: 451.0 MB)
17/03/27 22:25:58 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53710 in memory (size: 4.4 KB, free: 451.0 MB)
17/03/27 22:25:58 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:53710 in memory (size: 4.0 KB, free: 451.0 MB)
17/03/27 22:25:58 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53710 in memory (size: 2.7 KB, free: 451.0 MB)
17/03/27 22:25:58 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:25:58 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 544.4 MB so far)
17/03/27 22:25:58 INFO MemoryStore: Memory use = 1597.2 MB (blocks) + 4.0 MB (scratch space shared across 5 tasks(s)) = 1601.2 MB. Storage limit = 2.0 GB.
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:25:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:58 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:25:58 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:25:58 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:25:58 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:53710 in memory (size: 532.4 MB, free: 983.4 MB)
17/03/27 22:25:58 INFO ContextCleaner: Cleaned accumulator 1365
17/03/27 22:25:58 INFO ContextCleaner: Cleaned accumulator 1364
17/03/27 22:25:58 INFO ContextCleaner: Cleaned accumulator 1363
17/03/27 22:25:58 INFO ContextCleaner: Cleaned accumulator 1362
17/03/27 22:25:58 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:25:58 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:25:58 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:53710 in memory (size: 532.4 MB, free: 1515.8 MB)
17/03/27 22:25:58 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:25:58 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:53710 in memory (size: 532.4 MB, free: 2.0 GB)
17/03/27 22:25:58 INFO MemoryStore: Will not store rdd_16_2 as it would require dropping another block from the same RDD
17/03/27 22:25:58 WARN MemoryStore: Not enough space to cache rdd_16_2 in memory! (computed 544.4 MB so far)
17/03/27 22:25:58 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1636.3 MB (scratch space shared across 5 tasks(s)) = 1636.3 MB. Storage limit = 2.0 GB.
17/03/27 22:25:58 INFO Executor: Finished task 2.0 in stage 4.0 (TID 16). 2718 bytes result sent to driver
17/03/27 22:25:58 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 19, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:25:58 INFO Executor: Running task 3.0 in stage 4.0 (TID 19)
17/03/27 22:25:58 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 16) in 432 ms on localhost (1/5)
17/03/27 22:25:58 INFO TorrentBroadcast: Started reading broadcast variable 3
17/03/27 22:25:58 ERROR Utils: Exception encountered
org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:25:58 ERROR Executor: Exception in task 3.0 in stage 4.0 (TID 19)
java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 12 more
17/03/27 22:25:58 WARN TaskSetManager: Lost task 3.0 in stage 4.0 (TID 19, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 12 more

17/03/27 22:25:58 ERROR TaskSetManager: Task 3 in stage 4.0 failed 1 times; aborting job
17/03/27 22:25:58 INFO TaskSchedulerImpl: Cancelling stage 4
17/03/27 22:25:58 INFO TaskSchedulerImpl: Stage 4 was cancelled
17/03/27 22:25:58 INFO Executor: Executor is trying to kill task 1.0 in stage 4.0 (TID 15)
17/03/27 22:25:58 INFO DAGScheduler: ShuffleMapStage 4 (mapPartitionsInternal at SetRDD.scala:92) failed in 0.433 s
17/03/27 22:25:58 INFO Executor: Executor is trying to kill task 4.0 in stage 4.0 (TID 17)
17/03/27 22:25:58 INFO Executor: Executor is trying to kill task 0.0 in stage 4.0 (TID 18)
17/03/27 22:25:58 INFO DAGScheduler: Fixed Point Job 0 failed: runFixedPointJob at Recursion.scala:204, took 1.587860 s
17/03/27 22:25:58 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:25:58 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:25:58 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:25:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
[31m- Transitive Closure - NL - ff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 3 in stage 4.0 failed 1 times, most recent failure: Lost task 3.0 in stage 4.0 (TID 19, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
[0m
[31m	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31mCaused by: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at scala.Option.getOrElse(Option.scala:121)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at scala.collection.immutable.List.foreach(List.scala:381)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
[0m
[31m	... 12 more
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)[0m
[31m  at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)[0m
[31m  at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:65)[0m
[31m  at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)[0m
[31m  at org.apache.spark.scheduler.Task.run(Task.scala:89)[0m
[31m  at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Failed to get broadcast_3_piece0 of broadcast_3[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at scala.Option.getOrElse(Option.scala:121)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at scala.collection.immutable.List.foreach(List.scala:381)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)[0m
[31m  ...[0m
17/03/27 22:25:59 INFO Utils: Successfully started service 'sparkDriver' on port 53731.
17/03/27 22:25:59 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:25:59 INFO Remoting: Starting remoting
17/03/27 22:25:59 INFO MemoryStore: Will not store rdd_16_0 as it would require dropping another block from the same RDD
17/03/27 22:25:59 WARN MemoryStore: Not enough space to cache rdd_16_0 in memory! (computed 549.4 MB so far)
17/03/27 22:25:59 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1635.3 MB (scratch space shared across 4 tasks(s)) = 1635.3 MB. Storage limit = 2.0 GB.
17/03/27 22:25:59 INFO Executor: Executor killed task 0.0 in stage 4.0 (TID 18)
17/03/27 22:25:59 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 18, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:59 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 549.0 MB, free 1499.2 MB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:53710 (size: 549.0 MB, free: 1499.2 MB)
17/03/27 22:25:59 INFO Executor: Executor killed task 4.0 in stage 4.0 (TID 17)
17/03/27 22:25:59 WARN TaskSetManager: Lost task 4.0 in stage 4.0 (TID 17, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:59 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53744]
17/03/27 22:25:59 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53744.
17/03/27 22:25:59 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:25:59 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:25:59 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-26f2cb93-21d0-4d2c-9685-b4d34c3ac2cb
17/03/27 22:25:59 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:25:59 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:25:59 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 533.2 MB, free 966.0 MB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:53710 (size: 533.2 MB, free: 966.0 MB)
17/03/27 22:25:59 INFO Executor: Executor killed task 1.0 in stage 4.0 (TID 15)
17/03/27 22:25:59 WARN TaskSetManager: Lost task 1.0 in stage 4.0 (TID 15, localhost): TaskKilled (killed intentionally)
17/03/27 22:25:59 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:25:59 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:25:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53761.
17/03/27 22:25:59 INFO NettyBlockTransferService: Server created on 53761
17/03/27 22:25:59 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:25:59 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53761 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53761)
17/03/27 22:25:59 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:25:59 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667959218
17/03/27 22:25:59 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$4.apply$mcV$sp(RecursiveQuerySuites.scala:78)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$4.apply(RecursiveQuerySuites.scala:69)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$4.apply(RecursiveQuerySuites.scala:69)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$5.apply$mcV$sp(RecursiveQuerySuites.scala:93)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$5.apply(RecursiveQuerySuites.scala:81)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$5.apply(RecursiveQuerySuites.scala:81)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:25:59 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:25:59 INFO BigDatalogContext: BigDatalog Query: "leftLinearPaths(0,B)."
17/03/27 22:25:59 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:25:59 INFO BigDatalogContext: 
0: (0, To) <PROJECT>
 1: leftLinearPaths(To) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
 Exit Rules: 
  2: (To) <PROJECT>
   3: From = 0 <FILTER>
    4: arc(From, To) <BASE_RELATION>
 Recursive Rules: 
  2: (To) <DISTINCT PROJECT>
   3: (0.C = 1.From) <JOIN>
    4: leftLinearPaths(C) <RECURSIVE_RELATION>
    4: arc(From, To) <BASE_RELATION>
17/03/27 22:25:59 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:25:59 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:25:59 INFO BigDatalogContext: == Parsed Logical Plan ==
'Project [0 AS c_1#738,'leftLinearPaths.To]
+- 'Subquery leftLinearPaths
   +- 'Recursion leftLinearPaths, true, [1]
      :- 'Project ['arc.To]
      :  +- 'Filter ('arc.From = 0)
      :     +- 'UnresolvedRelation `arc`, None
      +- 'Project ['arc2.To]
         +- 'Join Inner, Some(('leftLinearPaths1.C = 'arc2.From))
            :- Subquery leftLinearPaths1
            :  +- LinearRecursiveRelation leftLinearPaths, [C#737], [1]
            +- 'BroadcastHint
               +- 'Subquery arc2
                  +- 'Project [*]
                     +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
c_1: int, To: int
Project [0 AS c_1#738,To#735]
+- Subquery leftLinearPaths
   +- Recursion leftLinearPaths, true, [1]
      :- Project [To#735]
      :  +- Filter (From#734 = 0)
      :     +- Subquery arc
      :        +- LogicalRDD [From#734,To#735], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- Project [To#735]
         +- Join Inner, Some((C#737 = From#734))
            :- Subquery leftLinearPaths1
            :  +- LinearRecursiveRelation leftLinearPaths, [C#737], [1]
            +- BroadcastHint
               +- Subquery arc2
                  +- Project [From#734,To#735]
                     +- Subquery arc
                        +- LogicalRDD [From#734,To#735], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Project [0 AS c_1#738,To#735]
+- Recursion leftLinearPaths, true, [1]
   :- Project [To#735]
   :  +- Filter (From#734 = 0)
   :     +- LogicalRDD [From#734,To#735], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [To#735]
      +- Join Inner, Some((C#737 = From#734))
         :- LinearRecursiveRelation leftLinearPaths, [C#737], [1]
         +- BroadcastHint
            +- Project [From#734,To#735]
               +- LogicalRDD [From#734,To#735], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Project [0 AS c_1#738,To#735]
+- Recursion [To#735] (Linear) [leftLinearPaths][1]
   :- TungstenExchange hashpartitioning(To#735,5), None
   :  +- Project [To#735]
   :     +- Filter (From#734 = 0)
   :        +- Scan ExistingRDD[From#734,To#735] 
   +- TungstenExchange hashpartitioning(To#735,5), None
      +- Project [To#735]
         +- BroadcastHashJoin [C#737], [From#734], BuildRight
            :- LinearRecursiveRelation [C#737](leftLinearPaths)
            +- Project [From#734,To#735]
               +- Scan ExistingRDD[From#734,To#735]
17/03/27 22:25:59 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:25:59 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:25:59 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:25:59 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:25:59 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:25:59 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:25:59 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:25:59 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:25:59 INFO DAGScheduler: Missing parents: List()
17/03/27 22:25:59 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at run at null:-1), which has no missing parents
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53761 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:25:59 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:59 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at run at null:-1)
17/03/27 22:25:59 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:25:59 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:59 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:25:59 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:25:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1484 bytes result sent to driver
17/03/27 22:25:59 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1484 bytes result sent to driver
17/03/27 22:25:59 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:25:59 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1484 bytes result sent to driver
17/03/27 22:25:59 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:25:59 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1484 bytes result sent to driver
17/03/27 22:25:59 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:25:59 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1484 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8 ms on localhost (1/5)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 7 ms on localhost (2/5)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8 ms on localhost (3/5)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 8 ms on localhost (4/5)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 3 ms on localhost (5/5)
17/03/27 22:25:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:25:59 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.008 s
17/03/27 22:25:59 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.012092 s
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.3 KB, free 2.0 GB)
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 296.0 B, free 2.0 GB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53761 (size: 296.0 B, free: 2.0 GB)
17/03/27 22:25:59 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:25:59 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:25:59 INFO Recursion: Fixed Point Iteration # 1, time: 34ms
17/03/27 22:25:59 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:25:59 INFO DAGScheduler: Registering RDD 12 (execute at Recursion.scala:202)
17/03/27 22:25:59 INFO DAGScheduler: Registering RDD 20 (execute at Recursion.scala:228)
17/03/27 22:25:59 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:25:59 INFO DAGScheduler: Final stage: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:25:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:25:59 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 6.8 KB, free 2.0 GB)
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.7 KB, free 2.0 GB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53761 (size: 3.7 KB, free: 2.0 GB)
17/03/27 22:25:59 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:59 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:25:59 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:25:59 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:59 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:25:59 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:25:59 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:25:59 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:25:59 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1400 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 7 ms on localhost (1/5)
17/03/27 22:25:59 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:25:59 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1400 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 23 ms on localhost (2/5)
17/03/27 22:25:59 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1400 bytes result sent to driver
17/03/27 22:25:59 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1400 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 24 ms on localhost (3/5)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 17 ms on localhost (4/5)
17/03/27 22:25:59 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1400 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 25 ms on localhost (5/5)
17/03/27 22:25:59 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:25:59 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.026 s
17/03/27 22:25:59 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:25:59 INFO DAGScheduler: running: Set()
17/03/27 22:25:59 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:25:59 INFO DAGScheduler: failed: Set()
17/03/27 22:25:59 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.4 KB, free 2.0 GB)
17/03/27 22:25:59 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53761 (size: 5.9 KB, free: 2.0 GB)
17/03/27 22:25:59 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:25:59 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202)
17/03/27 22:25:59 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:25:59 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:59 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:25:59 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:25:59 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:25:59 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:25:59 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:59 INFO CacheManager: Partition rdd_7_0 not found, computing it
17/03/27 22:25:59 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:59 INFO CacheManager: Partition rdd_7_1 not found, computing it
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:59 INFO MemoryStore: Will not store rdd_7_3 as it would require dropping another block from the same RDD
17/03/27 22:25:59 WARN MemoryStore: Not enough space to cache rdd_7_3 in memory! (computed 534.6 MB so far)
17/03/27 22:25:59 INFO MemoryStore: Memory use = 38.2 KB (blocks) + 1605.8 MB (scratch space shared across 5 tasks(s)) = 1605.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:59 INFO GenerateUnsafeProjection: Code generated in 4.503749 ms
17/03/27 22:25:59 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1841 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:25:59 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 340 ms on localhost (1/5)
17/03/27 22:25:59 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:25:59 INFO CacheManager: Partition rdd_7_4 not found, computing it
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:25:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:25:59 INFO MemoryStore: Will not store rdd_7_2 as it would require dropping another block from the same RDD
17/03/27 22:25:59 WARN MemoryStore: Not enough space to cache rdd_7_2 in memory! (computed 534.6 MB so far)
17/03/27 22:25:59 INFO MemoryStore: Memory use = 38.2 KB (blocks) + 1605.8 MB (scratch space shared across 5 tasks(s)) = 1605.9 MB. Storage limit = 2.0 GB.
17/03/27 22:25:59 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1841 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 360 ms on localhost (2/5)
17/03/27 22:25:59 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 534.5 MB, free 1513.7 MB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added rdd_7_1 in memory on localhost:53761 (size: 534.5 MB, free: 1513.7 MB)
17/03/27 22:25:59 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2210 bytes result sent to driver
17/03/27 22:25:59 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 596 ms on localhost (3/5)
17/03/27 22:25:59 INFO MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 534.5 MB, free 979.2 MB)
17/03/27 22:25:59 INFO BlockManagerInfo: Added rdd_7_0 in memory on localhost:53761 (size: 534.5 MB, free: 979.2 MB)
17/03/27 22:26:00 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2210 bytes result sent to driver
17/03/27 22:26:00 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 624 ms on localhost (4/5)
17/03/27 22:26:00 INFO MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 534.5 MB, free 444.7 MB)
17/03/27 22:26:00 INFO BlockManagerInfo: Added rdd_7_4 in memory on localhost:53761 (size: 534.5 MB, free: 444.7 MB)
17/03/27 22:26:00 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2210 bytes result sent to driver
17/03/27 22:26:00 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 520 ms on localhost (5/5)
17/03/27 22:26:00 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:202) finished in 0.859 s
17/03/27 22:26:00 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:00 INFO DAGScheduler: running: Set()
17/03/27 22:26:00 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:26:00 INFO DAGScheduler: failed: Set()
17/03/27 22:26:00 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:26:00 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.2 KB, free 444.7 MB)
17/03/27 22:26:00 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.2 KB, free 444.7 MB)
17/03/27 22:26:00 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53761 (size: 6.2 KB, free: 444.7 MB)
17/03/27 22:26:00 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:00 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at execute at Recursion.scala:228)
17/03/27 22:26:00 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:26:00 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:00 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:00 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 17, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:00 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:00 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:26:00 INFO Executor: Running task 4.0 in stage 3.0 (TID 17)
17/03/27 22:26:00 INFO Executor: Running task 2.0 in stage 3.0 (TID 18)
17/03/27 22:26:00 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:26:00 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:26:00 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:26:00 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:26:00 INFO BlockManager: Found block rdd_7_4 locally
17/03/27 22:26:00 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:26:00 INFO BlockManager: Found block rdd_7_0 locally
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:00 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:00 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:00 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 1 ms
17/03/27 22:26:00 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 1 ms
17/03/27 22:26:00 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 8 took 1 ms
17/03/27 22:26:00 INFO MemoryStore: 11 blocks selected for dropping
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:26:00 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:53761 (size: 2.7 KB)
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:26:00 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53761 (size: 296.0 B)
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:26:00 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53761 (size: 3.7 KB)
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:26:00 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53761 (size: 5.9 KB)
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:26:00 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:53761 (size: 6.2 KB)
17/03/27 22:26:00 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:00 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:26:00 INFO BlockManager: Dropping block rdd_7_0 from memory
17/03/27 22:26:00 INFO BlockManagerInfo: Removed rdd_7_0 on localhost:53761 in memory (size: 534.5 MB, free: 979.2 MB)
17/03/27 22:26:00 INFO MemoryStore: Will not store rdd_7_2 as it would require dropping another block from the same RDD
17/03/27 22:26:00 WARN MemoryStore: Not enough space to cache rdd_7_2 in memory! (computed 534.5 MB so far)
17/03/27 22:26:00 INFO MemoryStore: Memory use = 1069.0 MB (blocks) + 804.8 MB (scratch space shared across 5 tasks(s)) = 1873.8 MB. Storage limit = 2.0 GB.
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:00 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 0 ms
17/03/27 22:26:00 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:00 INFO BlockManager: Dropping block rdd_7_1 from memory
17/03/27 22:26:00 INFO BlockManagerInfo: Removed rdd_7_1 on localhost:53761 in memory (size: 534.5 MB, free: 1513.8 MB)
17/03/27 22:26:00 INFO BlockManager: Dropping block rdd_7_4 from memory
17/03/27 22:26:00 INFO BlockManagerInfo: Removed rdd_7_4 on localhost:53761 in memory (size: 534.5 MB, free: 2.0 GB)
17/03/27 22:26:00 INFO MemoryStore: Will not store rdd_14_4 as it would require dropping another block from the same RDD
17/03/27 22:26:00 WARN MemoryStore: Not enough space to cache rdd_14_4 in memory! (computed 534.5 MB so far)
17/03/27 22:26:00 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1606.6 MB (scratch space shared across 5 tasks(s)) = 1606.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:00 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 2016.2 MB)
17/03/27 22:26:00 INFO Executor: Finished task 4.0 in stage 3.0 (TID 17). 2991 bytes result sent to driver
17/03/27 22:26:00 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 19, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:00 INFO Executor: Running task 3.0 in stage 3.0 (TID 19)
17/03/27 22:26:00 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 17) in 463 ms on localhost (1/5)
17/03/27 22:26:00 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.2 KB, free 2016.2 MB)
17/03/27 22:26:00 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:26:00 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:00 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:00 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53761 on disk (size: 5.9 KB)
17/03/27 22:26:00 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53761 on disk (size: 3.7 KB)
17/03/27 22:26:00 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53761 on disk (size: 2.7 KB)
17/03/27 22:26:00 INFO ContextCleaner: Cleaned accumulator 1392
17/03/27 22:26:00 INFO ContextCleaner: Cleaned accumulator 1391
17/03/27 22:26:00 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 566.5 MB, free 1449.7 MB)
17/03/27 22:26:00 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:53761 (size: 566.5 MB, free: 1481.7 MB)
17/03/27 22:26:00 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 4179 bytes result sent to driver
17/03/27 22:26:00 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 698 ms on localhost (2/5)
17/03/27 22:26:00 INFO MemoryStore: Will not store rdd_14_2 as it would require dropping another block from the same RDD
17/03/27 22:26:00 WARN MemoryStore: Not enough space to cache rdd_14_2 in memory! (computed 566.5 MB so far)
17/03/27 22:26:00 INFO MemoryStore: Memory use = 598.5 MB (blocks) + 804.8 MB (scratch space shared across 4 tasks(s)) = 1403.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:00 INFO Executor: Finished task 2.0 in stage 3.0 (TID 18). 1841 bytes result sent to driver
17/03/27 22:26:00 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 730 ms on localhost (3/5)
17/03/27 22:26:00 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 566.5 MB, free 883.2 MB)
17/03/27 22:26:00 INFO BlockManagerInfo: Added rdd_14_0 in memory on localhost:53761 (size: 566.5 MB, free: 915.3 MB)
17/03/27 22:26:00 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 3486 bytes result sent to driver
17/03/27 22:26:00 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 760 ms on localhost (4/5)
17/03/27 22:26:01 INFO MemoryStore: Block rdd_7_3 stored as values in memory (estimated size 534.4 MB, free 348.8 MB)
17/03/27 22:26:01 INFO BlockManagerInfo: Added rdd_7_3 in memory on localhost:53761 (size: 534.4 MB, free: 380.8 MB)
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:01 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 0 ms
17/03/27 22:26:01 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:26:01 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:01 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:01 INFO BlockManager: Dropping block rdd_7_3 from memory
17/03/27 22:26:01 INFO BlockManagerInfo: Removed rdd_7_3 on localhost:53761 in memory (size: 534.4 MB, free: 915.3 MB)
17/03/27 22:26:01 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 502.4 MB, free 412.8 MB)
17/03/27 22:26:01 INFO BlockManagerInfo: Added rdd_14_3 in memory on localhost:53761 (size: 502.4 MB, free: 412.8 MB)
17/03/27 22:26:01 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 380.8 MB)
17/03/27 22:26:01 INFO Executor: Finished task 3.0 in stage 3.0 (TID 19). 2533 bytes result sent to driver
17/03/27 22:26:01 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 19) in 1000 ms on localhost (5/5)
17/03/27 22:26:01 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:26:01 INFO DAGScheduler: ShuffleMapStage 3 (execute at Recursion.scala:228) finished in 1.465 s
17/03/27 22:26:01 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:01 INFO DAGScheduler: running: Set()
17/03/27 22:26:01 INFO DAGScheduler: waiting: Set(FixedPointResultStage 4)
17/03/27 22:26:01 INFO DAGScheduler: failed: Set()
17/03/27 22:26:01 INFO DAGScheduler: Submitting FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[23] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:01 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.4 KB, free 380.8 MB)
17/03/27 22:26:01 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.5 KB, free 380.8 MB)
17/03/27 22:26:01 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53761 (size: 6.5 KB, free: 412.8 MB)
17/03/27 22:26:01 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:01 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[23] at RDD at SetRDD.scala:30)
17/03/27 22:26:01 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:26:01 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:01 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:01 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:01 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:01 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:26:01 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:26:01 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:26:01 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:26:01 INFO CacheManager: Partition rdd_22_0 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_22_1 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_22_2 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_22_3 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_7_0 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:26:01 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:01 INFO CacheManager: Partition rdd_7_1 not found, computing it
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:01 INFO CacheManager: Partition rdd_7_3 not found, computing it
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:01 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:02 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:02 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:26:02 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:53761 in memory (size: 566.5 MB, free: 979.4 MB)
17/03/27 22:26:02 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:02 INFO BlockManager: Dropping block rdd_14_0 from memory
17/03/27 22:26:02 INFO BlockManagerInfo: Removed rdd_14_0 on localhost:53761 in memory (size: 566.5 MB, free: 1545.8 MB)
17/03/27 22:26:02 INFO MemoryStore: Will not store rdd_7_3 as it would require dropping another block from the same RDD
17/03/27 22:26:02 WARN MemoryStore: Not enough space to cache rdd_7_3 in memory! (computed 502.5 MB so far)
17/03/27 22:26:02 INFO MemoryStore: Memory use = 534.4 MB (blocks) + 1509.6 MB (scratch space shared across 5 tasks(s)) = 2044.1 MB. Storage limit = 2.0 GB.
17/03/27 22:26:02 INFO BlockManager: Found block rdd_14_3 locally
17/03/27 22:26:02 INFO SetRDDHashSetPartition: Union set size 0 for rdd 8 took 0 ms
17/03/27 22:26:02 INFO MemoryStore: Will not store rdd_7_2 as it would require dropping another block from the same RDD
17/03/27 22:26:02 WARN MemoryStore: Not enough space to cache rdd_7_2 in memory! (computed 502.5 MB so far)
17/03/27 22:26:02 INFO MemoryStore: Memory use = 534.4 MB (blocks) + 1510.6 MB (scratch space shared across 5 tasks(s)) = 2045.1 MB. Storage limit = 2.0 GB.
17/03/27 22:26:02 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:26:02 INFO CacheManager: Partition rdd_7_2 not found, computing it
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:02 INFO MemoryStore: Block rdd_7_0 stored as values in memory (estimated size 502.5 MB, free 1011.3 MB)
17/03/27 22:26:02 INFO BlockManagerInfo: Added rdd_7_0 in memory on localhost:53761 (size: 502.5 MB, free: 1043.3 MB)
17/03/27 22:26:02 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:26:02 INFO BlockManager: Found block rdd_7_0 locally
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:02 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 0 ms
17/03/27 22:26:02 INFO MemoryStore: Block rdd_7_1 stored as values in memory (estimated size 502.5 MB, free 508.7 MB)
17/03/27 22:26:02 INFO BlockManagerInfo: Added rdd_7_1 in memory on localhost:53761 (size: 502.5 MB, free: 540.7 MB)
17/03/27 22:26:02 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:26:02 INFO BlockManager: Found block rdd_7_1 locally
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:02 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 8 took 1 ms
17/03/27 22:26:02 INFO MemoryStore: 4 blocks selected for dropping
17/03/27 22:26:02 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:02 INFO BlockManager: Dropping block broadcast_5_piece0 from memory
17/03/27 22:26:02 INFO BlockManager: Writing block broadcast_5_piece0 to disk
17/03/27 22:26:02 INFO BlockManagerInfo: Added broadcast_5_piece0 on disk on localhost:53761 (size: 6.5 KB)
17/03/27 22:26:02 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:26:02 INFO BlockManager: Writing block broadcast_5 to disk
17/03/27 22:26:02 INFO BlockManager: Dropping block rdd_14_3 from memory
17/03/27 22:26:02 INFO BlockManagerInfo: Removed rdd_14_3 on localhost:53761 in memory (size: 502.4 MB, free: 1043.2 MB)
17/03/27 22:26:02 INFO MemoryStore: Will not store rdd_7_2 as it would require dropping another block from the same RDD
17/03/27 22:26:02 WARN MemoryStore: Not enough space to cache rdd_7_2 in memory! (computed 470.5 MB so far)
17/03/27 22:26:02 INFO MemoryStore: Memory use = 1005.1 MB (blocks) + 758.8 MB (scratch space shared across 5 tasks(s)) = 1763.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:02 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 0 ms
17/03/27 22:26:02 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:02 INFO BlockManager: Dropping block rdd_7_0 from memory
17/03/27 22:26:02 INFO BlockManagerInfo: Removed rdd_7_0 on localhost:53761 in memory (size: 502.5 MB, free: 1545.7 MB)
17/03/27 22:26:02 INFO MemoryStore: Will not store rdd_14_0 as it would require dropping another block from the same RDD
17/03/27 22:26:02 WARN MemoryStore: Not enough space to cache rdd_14_0 in memory! (computed 470.5 MB so far)
17/03/27 22:26:02 INFO MemoryStore: Memory use = 502.5 MB (blocks) + 1464.6 MB (scratch space shared across 5 tasks(s)) = 1967.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:02 INFO SetRDDHashSetPartition: Union set size 2 for rdd 8 took 0 ms
17/03/27 22:26:02 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 470.5 MB, free 1075.2 MB)
17/03/27 22:26:02 INFO BlockManagerInfo: Added rdd_16_3 in memory on localhost:53761 (size: 470.5 MB, free: 1075.2 MB)
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:02 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:02 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:02 INFO BlockManager: Dropping block rdd_7_1 from memory
17/03/27 22:26:02 INFO BlockManagerInfo: Removed rdd_7_1 on localhost:53761 in memory (size: 502.5 MB, free: 1577.7 MB)
17/03/27 22:26:02 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:53761 on disk (size: 6.2 KB)
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1381
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1380
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1379
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1378
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1377
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1376
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1375
17/03/27 22:26:03 INFO ContextCleaner: Cleaned accumulator 1374
17/03/27 22:26:03 INFO MemoryStore: Will not store rdd_16_0 as it would require dropping another block from the same RDD
17/03/27 22:26:03 WARN MemoryStore: Not enough space to cache rdd_16_0 in memory! (computed 470.6 MB so far)
17/03/27 22:26:03 INFO MemoryStore: Memory use = 470.5 MB (blocks) + 1417.6 MB (scratch space shared across 5 tasks(s)) = 1888.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:03 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:03 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 470.6 MB, free 1107.1 MB)
17/03/27 22:26:03 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:53761 (size: 470.6 MB, free: 1107.1 MB)
17/03/27 22:26:03 INFO SetRDDHashSetPartition: Union set size 2 for rdd 8 took 0 ms
17/03/27 22:26:03 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 470.6 MB, free 636.6 MB)
17/03/27 22:26:03 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:03 INFO BlockManagerInfo: Added rdd_14_2 in memory on localhost:53761 (size: 470.6 MB, free: 636.6 MB)
17/03/27 22:26:03 INFO BlockManager: Dropping block rdd_16_3 from memory
17/03/27 22:26:03 INFO BlockManagerInfo: Removed rdd_16_3 on localhost:53761 in memory (size: 470.5 MB, free: 1107.1 MB)
17/03/27 22:26:03 INFO SetRDDHashSetPartition: Union set size 0 for rdd 8 took 0 ms
17/03/27 22:26:03 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:03 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:26:03 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:53761 in memory (size: 470.6 MB, free: 1577.7 MB)
17/03/27 22:26:03 INFO MemoryStore: Will not store rdd_16_2 as it would require dropping another block from the same RDD
17/03/27 22:26:03 WARN MemoryStore: Not enough space to cache rdd_16_2 in memory! (computed 470.6 MB so far)
17/03/27 22:26:03 INFO MemoryStore: Memory use = 470.6 MB (blocks) + 1418.7 MB (scratch space shared across 5 tasks(s)) = 1889.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:03 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 17 took 0 ms
17/03/27 22:26:03 INFO MemoryStore: Block rdd_22_3 stored as values in memory (estimated size 470.6 MB, free 1107.1 MB)
17/03/27 22:26:03 INFO BlockManagerInfo: Added rdd_22_3 in memory on localhost:53761 (size: 470.6 MB, free: 1107.1 MB)
17/03/27 22:26:03 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 3722 bytes result sent to driver
17/03/27 22:26:03 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:03 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:26:03 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 1726 ms on localhost (1/5)
17/03/27 22:26:03 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.4 KB, free 1107.1 MB)
17/03/27 22:26:03 INFO CacheManager: Partition rdd_22_4 not found, computing it
17/03/27 22:26:03 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:26:03 INFO CacheManager: Partition rdd_7_4 not found, computing it
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:03 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:03 INFO BlockManager: Dropping block rdd_14_2 from memory
17/03/27 22:26:03 INFO BlockManagerInfo: Removed rdd_14_2 on localhost:53761 in memory (size: 470.6 MB, free: 1577.7 MB)
17/03/27 22:26:03 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 470.6 MB, free 1107.1 MB)
17/03/27 22:26:03 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:53761 (size: 470.6 MB, free: 1107.1 MB)
17/03/27 22:26:03 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 3451 bytes result sent to driver
17/03/27 22:26:03 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 2006 ms on localhost (2/5)
17/03/27 22:26:03 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:03 INFO BlockManager: Dropping block rdd_22_3 from memory
17/03/27 22:26:03 INFO BlockManagerInfo: Removed rdd_22_3 on localhost:53761 in memory (size: 470.6 MB, free: 1577.7 MB)
17/03/27 22:26:03 INFO MemoryStore: Will not store rdd_22_2 as it would require dropping another block from the same RDD
17/03/27 22:26:03 WARN MemoryStore: Not enough space to cache rdd_22_2 in memory! (computed 470.5 MB so far)
17/03/27 22:26:03 INFO MemoryStore: Memory use = 470.6 MB (blocks) + 1415.7 MB (scratch space shared across 4 tasks(s)) = 1886.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:03 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 2186 bytes result sent to driver
17/03/27 22:26:03 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 2047 ms on localhost (3/5)
17/03/27 22:26:03 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 470.5 MB, free 1107.1 MB)
17/03/27 22:26:03 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:53761 (size: 470.5 MB, free: 1107.1 MB)
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:03 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:03 INFO MemoryStore: Block rdd_7_4 stored as values in memory (estimated size 470.5 MB, free 636.7 MB)
17/03/27 22:26:03 INFO BlockManagerInfo: Added rdd_7_4 in memory on localhost:53761 (size: 470.5 MB, free: 636.7 MB)
17/03/27 22:26:03 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:26:03 INFO BlockManager: Found block rdd_7_4 locally
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:03 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 8 took 0 ms
17/03/27 22:26:03 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:03 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:26:03 INFO BlockManager: Dropping block rdd_16_1 from memory
17/03/27 22:26:03 INFO BlockManagerInfo: Removed rdd_16_1 on localhost:53761 in memory (size: 470.5 MB, free: 1107.2 MB)
17/03/27 22:26:04 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:04 INFO BlockManager: Dropping block rdd_22_0 from memory
17/03/27 22:26:04 INFO BlockManagerInfo: Removed rdd_22_0 on localhost:53761 in memory (size: 470.6 MB, free: 1577.8 MB)
17/03/27 22:26:04 INFO MemoryStore: Block rdd_22_1 stored as values in memory (estimated size 470.5 MB, free 1107.3 MB)
17/03/27 22:26:04 INFO BlockManagerInfo: Added rdd_22_1 in memory on localhost:53761 (size: 470.5 MB, free: 1107.3 MB)
17/03/27 22:26:04 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 3820 bytes result sent to driver
17/03/27 22:26:04 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 2537 ms on localhost (4/5)
17/03/27 22:26:04 INFO MemoryStore: Block rdd_14_4 stored as values in memory (estimated size 470.4 MB, free 636.9 MB)
17/03/27 22:26:04 INFO BlockManagerInfo: Added rdd_14_4 in memory on localhost:53761 (size: 470.4 MB, free: 636.9 MB)
17/03/27 22:26:04 INFO SetRDDHashSetPartition: Union set size 0 for rdd 8 took 0 ms
17/03/27 22:26:04 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:04 INFO BlockManager: Dropping block rdd_7_4 from memory
17/03/27 22:26:04 INFO BlockManagerInfo: Removed rdd_7_4 on localhost:53761 in memory (size: 470.5 MB, free: 1107.4 MB)
17/03/27 22:26:04 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 470.4 MB, free 637.0 MB)
17/03/27 22:26:04 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:53761 (size: 470.4 MB, free: 637.0 MB)
17/03/27 22:26:04 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:04 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:04 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:05 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:05 INFO BlockManager: Dropping block rdd_14_4 from memory
17/03/27 22:26:05 INFO BlockManagerInfo: Removed rdd_14_4 on localhost:53761 in memory (size: 470.4 MB, free: 1107.4 MB)
17/03/27 22:26:05 INFO MemoryStore: Block rdd_22_4 stored as values in memory (estimated size 470.4 MB, free 637.0 MB)
17/03/27 22:26:05 INFO BlockManagerInfo: Added rdd_22_4 in memory on localhost:53761 (size: 470.4 MB, free: 637.0 MB)
17/03/27 22:26:05 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 3663 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 1894 ms on localhost (5/5)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:26:05 INFO DAGScheduler: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204) finished in 3.620 s
17/03/27 22:26:05 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:05 INFO Recursion: Fixed Point Iteration # 2, time: 5985ms
17/03/27 22:26:05 INFO DAGScheduler: Registering RDD 32 (execute at Recursion.scala:228)
17/03/27 22:26:05 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[32] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.6 KB, free 637.0 MB)
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.5 KB, free 637.0 MB)
17/03/27 22:26:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53761 (size: 5.5 KB, free: 637.0 MB)
17/03/27 22:26:05 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:05 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[32] at execute at Recursion.scala:228)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:26:05 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 26, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 27, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 28, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:05 INFO Executor: Running task 1.0 in stage 5.0 (TID 25)
17/03/27 22:26:05 INFO Executor: Running task 4.0 in stage 5.0 (TID 26)
17/03/27 22:26:05 INFO Executor: Running task 0.0 in stage 5.0 (TID 27)
17/03/27 22:26:05 INFO Executor: Running task 2.0 in stage 5.0 (TID 28)
17/03/27 22:26:05 INFO BlockManager: Found block rdd_22_1 locally
17/03/27 22:26:05 INFO BlockManager: Found block rdd_22_4 locally
17/03/27 22:26:05 INFO CacheManager: Partition rdd_22_0 not found, computing it
17/03/27 22:26:05 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 27)
org.apache.spark.SparkException: Checkpoint block rdd_22_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 605.0 MB)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 29, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:05 INFO CacheManager: Partition rdd_22_2 not found, computing it
17/03/27 22:26:05 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 27, localhost): org.apache.spark.SparkException: Checkpoint block rdd_22_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:05 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job
17/03/27 22:26:05 INFO Executor: Running task 3.0 in stage 5.0 (TID 29)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Cancelling stage 5
17/03/27 22:26:05 INFO TaskSchedulerImpl: Stage 5 was cancelled
17/03/27 22:26:05 INFO DAGScheduler: ShuffleMapStage 5 (execute at Recursion.scala:228) failed in 0.004 s
17/03/27 22:26:05 INFO Executor: Executor is trying to kill task 2.0 in stage 5.0 (TID 28)
17/03/27 22:26:05 INFO Executor: Executor is trying to kill task 1.0 in stage 5.0 (TID 25)
17/03/27 22:26:05 INFO Executor: Executor is trying to kill task 3.0 in stage 5.0 (TID 29)
17/03/27 22:26:05 INFO Executor: Executor is trying to kill task 4.0 in stage 5.0 (TID 26)
17/03/27 22:26:05 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 5.996549 s
17/03/27 22:26:05 INFO SparkContext: Running Spark version 1.6.3
[31m- Transitive Closure - LL - bf *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 27, localhost): org.apache.spark.SparkException: Checkpoint block rdd_22_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
17/03/27 22:26:05 INFO Executor: Executor killed task 1.0 in stage 5.0 (TID 25)
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_22_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  ...[0m
17/03/27 22:26:05 ERROR Executor: Exception in task 2.0 in stage 5.0 (TID 28)
org.apache.spark.SparkException: Checkpoint block rdd_22_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:05 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:26:05 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:26:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:26:05 WARN TaskSetManager: Lost task 1.0 in stage 5.0 (TID 25, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:05 WARN TaskSetManager: Lost task 2.0 in stage 5.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_22_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:05 INFO Executor: Executor killed task 4.0 in stage 5.0 (TID 26)
17/03/27 22:26:05 INFO CacheManager: Partition rdd_22_3 not found, computing it
17/03/27 22:26:05 ERROR Executor: Exception in task 3.0 in stage 5.0 (TID 29)
org.apache.spark.SparkException: Checkpoint block rdd_22_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:05 WARN TaskSetManager: Lost task 4.0 in stage 5.0 (TID 26, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:05 WARN TaskSetManager: Lost task 3.0 in stage 5.0 (TID 29, localhost): org.apache.spark.SparkException: Checkpoint block rdd_22_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:05 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:26:05 INFO Utils: Successfully started service 'sparkDriver' on port 53793.
17/03/27 22:26:05 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:26:05 INFO Remoting: Starting remoting
17/03/27 22:26:05 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53806]
17/03/27 22:26:05 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53806.
17/03/27 22:26:05 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:26:05 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:26:05 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-2044cb4e-0be4-4631-b78c-581c8139e088
17/03/27 22:26:05 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:26:05 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:26:05 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:26:05 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53824.
17/03/27 22:26:05 INFO NettyBlockTransferService: Server created on 53824
17/03/27 22:26:05 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:26:05 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53824 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53824)
17/03/27 22:26:05 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:26:05 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667965397
17/03/27 22:26:05 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$5.apply$mcV$sp(RecursiveQuerySuites.scala:93)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$5.apply(RecursiveQuerySuites.scala:81)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$5.apply(RecursiveQuerySuites.scala:81)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$6.apply$mcV$sp(RecursiveQuerySuites.scala:110)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$6.apply(RecursiveQuerySuites.scala:96)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$6.apply(RecursiveQuerySuites.scala:96)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:26:05 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:26:05 INFO BigDatalogContext: BigDatalog Query: "reach(A)."
17/03/27 22:26:05 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:26:05 INFO BigDatalogContext: 
0: reach(To) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: TUPLE(0 as A) <TUPLE>
Recursive Rules: 
 1: (To) <DISTINCT PROJECT>
  2: (0.B = 1.From) <JOIN>
   3: reach(B) <RECURSIVE_RELATION>
   3: arc(From, To) <BASE_RELATION>
17/03/27 22:26:05 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:26:05 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:26:05 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery reach
+- 'Recursion reach, true, [1]
   :- Subquery TUPLE
   :  +- LocalRelation [A#742], [[0]]
   +- 'Project ['arc.To]
      +- 'Join Inner, Some(('reach1.B = 'arc.From))
         :- Subquery reach1
         :  +- LinearRecursiveRelation reach, [B#743], [1]
         +- 'BroadcastHint
            +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
To: int
Subquery reach
+- Recursion reach, true, [1]
   :- Subquery TUPLE
   :  +- LocalRelation [A#742], [[0]]
   +- Project [To#740]
      +- Join Inner, Some((B#743 = From#739))
         :- Subquery reach1
         :  +- LinearRecursiveRelation reach, [B#743], [1]
         +- BroadcastHint
            +- Subquery arc
               +- LogicalRDD [From#739,To#740], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion reach, true, [1]
:- LocalRelation [A#742], [[0]]
+- Project [To#740]
   +- Join Inner, Some((B#743 = From#739))
      :- LinearRecursiveRelation reach, [B#743], [1]
      +- BroadcastHint
         +- LogicalRDD [From#739,To#740], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [To#740] (Linear) [reach][1]
:- TungstenExchange hashpartitioning(A#742,5), None
:  +- ConvertToUnsafe
:     +- LocalTableScan [A#742], [[0]]
+- TungstenExchange hashpartitioning(To#740,5), None
   +- Project [To#740]
      +- BroadcastHashJoin [B#743], [From#739], BuildRight
         :- LinearRecursiveRelation [B#743](reach)
         +- ConvertToUnsafe
            +- Scan ExistingRDD[From#739,To#740]
17/03/27 22:26:05 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:26:05 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:26:05 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:26:05 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:26:05 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:05 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:26:05 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:26:05 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:05 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:05 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[9] at run at null:-1), which has no missing parents
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.6 KB, free 2.0 GB)
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2.0 GB)
17/03/27 22:26:05 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53824 (size: 2.4 KB, free: 2.0 GB)
17/03/27 22:26:05 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:05 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[9] at run at null:-1)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:26:05 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:05 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:26:05 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:26:05 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:26:05 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:26:05 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1415 bytes result sent to driver
17/03/27 22:26:05 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1415 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:05 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1415 bytes result sent to driver
17/03/27 22:26:05 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:26:05 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1415 bytes result sent to driver
17/03/27 22:26:05 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1415 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 38 ms on localhost (1/5)
17/03/27 22:26:05 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 38 ms on localhost (2/5)
17/03/27 22:26:05 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 26 ms on localhost (3/5)
17/03/27 22:26:05 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 38 ms on localhost (4/5)
17/03/27 22:26:05 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 39 ms on localhost (5/5)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:26:05 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.039 s
17/03/27 22:26:05 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.042592 s
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 2.3 KB, free 2.0 GB)
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 296.0 B, free 2.0 GB)
17/03/27 22:26:05 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53824 (size: 296.0 B, free: 2.0 GB)
17/03/27 22:26:05 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1402
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1401
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1400
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1399
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1398
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1397
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1396
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1395
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1394
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1393
17/03/27 22:26:05 INFO ContextCleaner: Cleaned accumulator 1385
17/03/27 22:26:05 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:05 INFO Recursion: Fixed Point Iteration # 1, time: 70ms
17/03/27 22:26:05 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:26:05 INFO DAGScheduler: Registering RDD 12 (execute at Recursion.scala:202)
17/03/27 22:26:05 INFO DAGScheduler: Registering RDD 20 (execute at Recursion.scala:228)
17/03/27 22:26:05 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:26:05 INFO DAGScheduler: Final stage: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:26:05 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:26:05 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:26:05 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.0 KB, free 2.0 GB)
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 2.8 KB, free 2.0 GB)
17/03/27 22:26:05 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53824 (size: 2.8 KB, free: 2.0 GB)
17/03/27 22:26:05 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:05 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/03/27 22:26:05 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2063 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2300 bytes)
17/03/27 22:26:05 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:26:05 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:26:05 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:26:05 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:26:05 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1222 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 7 ms on localhost (1/4)
17/03/27 22:26:05 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1222 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 9 ms on localhost (2/4)
17/03/27 22:26:05 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1222 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 20 ms on localhost (3/4)
17/03/27 22:26:05 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1222 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 30 ms on localhost (4/4)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:26:05 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.030 s
17/03/27 22:26:05 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:05 INFO DAGScheduler: running: Set()
17/03/27 22:26:05 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:26:05 INFO DAGScheduler: failed: Set()
17/03/27 22:26:05 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.3 KB, free 2.0 GB)
17/03/27 22:26:05 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KB, free 2.0 GB)
17/03/27 22:26:05 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53824 (size: 5.9 KB, free: 2.0 GB)
17/03/27 22:26:05 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:05 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202)
17/03/27 22:26:05 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:26:05 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 9, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 10, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 11, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 12, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:05 INFO Executor: Running task 0.0 in stage 2.0 (TID 9)
17/03/27 22:26:05 INFO Executor: Running task 3.0 in stage 2.0 (TID 12)
17/03/27 22:26:05 INFO Executor: Running task 2.0 in stage 2.0 (TID 11)
17/03/27 22:26:05 INFO Executor: Running task 1.0 in stage 2.0 (TID 10)
17/03/27 22:26:05 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:26:05 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:05 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:05 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:05 INFO MemoryStore: Will not store rdd_6_1 as it would require dropping another block from the same RDD
17/03/27 22:26:05 WARN MemoryStore: Not enough space to cache rdd_6_1 in memory! (computed 472.6 MB so far)
17/03/27 22:26:05 INFO MemoryStore: Memory use = 34.6 KB (blocks) + 1419.9 MB (scratch space shared across 5 tasks(s)) = 1420.0 MB. Storage limit = 2.0 GB.
17/03/27 22:26:05 INFO Executor: Finished task 1.0 in stage 2.0 (TID 10). 1798 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 13, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:05 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 10) in 329 ms on localhost (1/5)
17/03/27 22:26:05 INFO Executor: Running task 4.0 in stage 2.0 (TID 13)
17/03/27 22:26:05 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:05 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:05 INFO MemoryStore: Will not store rdd_6_2 as it would require dropping another block from the same RDD
17/03/27 22:26:05 WARN MemoryStore: Not enough space to cache rdd_6_2 in memory! (computed 472.7 MB so far)
17/03/27 22:26:05 INFO MemoryStore: Memory use = 34.6 KB (blocks) + 1419.9 MB (scratch space shared across 5 tasks(s)) = 1420.0 MB. Storage limit = 2.0 GB.
17/03/27 22:26:05 INFO Executor: Finished task 2.0 in stage 2.0 (TID 11). 1798 bytes result sent to driver
17/03/27 22:26:05 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 11) in 356 ms on localhost (2/5)
17/03/27 22:26:06 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 472.6 MB, free 1575.6 MB)
17/03/27 22:26:06 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 472.6 MB, free 1103.0 MB)
17/03/27 22:26:06 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:53824 (size: 472.6 MB, free: 1575.6 MB)
17/03/27 22:26:06 INFO Executor: Finished task 3.0 in stage 2.0 (TID 12). 2167 bytes result sent to driver
17/03/27 22:26:06 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:53824 (size: 472.6 MB, free: 1103.0 MB)
17/03/27 22:26:06 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 12) in 589 ms on localhost (3/5)
17/03/27 22:26:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 9). 2167 bytes result sent to driver
17/03/27 22:26:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 9) in 593 ms on localhost (4/5)
17/03/27 22:26:06 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 472.5 MB, free 630.5 MB)
17/03/27 22:26:06 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:53824 (size: 472.5 MB, free: 630.5 MB)
17/03/27 22:26:06 INFO Executor: Finished task 4.0 in stage 2.0 (TID 13). 2167 bytes result sent to driver
17/03/27 22:26:06 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 13) in 490 ms on localhost (5/5)
17/03/27 22:26:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:26:06 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:202) finished in 0.819 s
17/03/27 22:26:06 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:06 INFO DAGScheduler: running: Set()
17/03/27 22:26:06 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:26:06 INFO DAGScheduler: failed: Set()
17/03/27 22:26:06 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.1 KB, free 630.4 MB)
17/03/27 22:26:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.2 KB, free 630.4 MB)
17/03/27 22:26:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53824 (size: 6.2 KB, free: 630.5 MB)
17/03/27 22:26:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:06 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at execute at Recursion.scala:228)
17/03/27 22:26:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:26:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 14, localhost, partition 0,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:06 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 15, localhost, partition 3,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:06 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 16, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:06 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 17, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:06 INFO Executor: Running task 0.0 in stage 3.0 (TID 14)
17/03/27 22:26:06 INFO Executor: Running task 3.0 in stage 3.0 (TID 15)
17/03/27 22:26:06 INFO Executor: Running task 4.0 in stage 3.0 (TID 16)
17/03/27 22:26:06 INFO Executor: Running task 1.0 in stage 3.0 (TID 17)
17/03/27 22:26:06 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:26:06 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:26:06 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:06 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:26:06 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:06 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:06 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:06 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:26:06 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:06 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:06 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:26:06 INFO MemoryStore: Will not store rdd_6_1 as it would require dropping another block from the same RDD
17/03/27 22:26:06 WARN MemoryStore: Not enough space to cache rdd_6_1 in memory! (computed 472.6 MB so far)
17/03/27 22:26:06 INFO MemoryStore: Memory use = 1417.8 MB (blocks) + 4.0 MB (scratch space shared across 5 tasks(s)) = 1421.8 MB. Storage limit = 2.0 GB.
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:06 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:06 INFO MemoryStore: 11 blocks selected for dropping
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:26:06 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:53824 (size: 2.4 KB)
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:26:06 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53824 (size: 296.0 B)
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:26:06 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53824 (size: 2.8 KB)
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:26:06 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53824 (size: 5.9 KB)
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:26:06 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:53824 (size: 6.2 KB)
17/03/27 22:26:06 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:06 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:26:06 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:26:06 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:53824 in memory (size: 472.6 MB, free: 1103.1 MB)
17/03/27 22:26:06 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:06 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:26:06 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:53824 in memory (size: 472.6 MB, free: 1575.7 MB)
17/03/27 22:26:06 INFO MemoryStore: Will not store rdd_14_0 as it would require dropping another block from the same RDD
17/03/27 22:26:06 WARN MemoryStore: Not enough space to cache rdd_14_0 in memory! (computed 472.6 MB so far)
17/03/27 22:26:06 INFO MemoryStore: Memory use = 472.5 MB (blocks) + 1420.9 MB (scratch space shared across 5 tasks(s)) = 1893.5 MB. Storage limit = 2.0 GB.
17/03/27 22:26:06 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 1543.7 MB)
17/03/27 22:26:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 14). 2948 bytes result sent to driver
17/03/27 22:26:06 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 18, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:06 INFO Executor: Running task 2.0 in stage 3.0 (TID 18)
17/03/27 22:26:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 14) in 435 ms on localhost (1/5)
17/03/27 22:26:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.1 KB, free 1543.7 MB)
17/03/27 22:26:06 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:26:06 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:07 INFO MemoryStore: Will not store rdd_14_1 as it would require dropping another block from the same RDD
17/03/27 22:26:07 WARN MemoryStore: Not enough space to cache rdd_14_1 in memory! (computed 504.6 MB so far)
17/03/27 22:26:07 INFO MemoryStore: Memory use = 504.6 MB (blocks) + 1420.9 MB (scratch space shared across 5 tasks(s)) = 1925.5 MB. Storage limit = 2.0 GB.
17/03/27 22:26:07 INFO Executor: Finished task 1.0 in stage 3.0 (TID 17). 1798 bytes result sent to driver
17/03/27 22:26:07 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 17) in 694 ms on localhost (2/5)
17/03/27 22:26:07 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 472.6 MB, free 1071.1 MB)
17/03/27 22:26:07 INFO BlockManagerInfo: Added rdd_14_3 in memory on localhost:53824 (size: 472.6 MB, free: 1103.1 MB)
17/03/27 22:26:07 INFO Executor: Finished task 3.0 in stage 3.0 (TID 15). 3383 bytes result sent to driver
17/03/27 22:26:07 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 15) in 715 ms on localhost (3/5)
17/03/27 22:26:07 INFO MemoryStore: Block rdd_14_4 stored as values in memory (estimated size 472.5 MB, free 598.6 MB)
17/03/27 22:26:07 INFO BlockManagerInfo: Added rdd_14_4 in memory on localhost:53824 (size: 472.5 MB, free: 630.6 MB)
17/03/27 22:26:07 INFO Executor: Finished task 4.0 in stage 3.0 (TID 16). 4136 bytes result sent to driver
17/03/27 22:26:07 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 16) in 725 ms on localhost (4/5)
17/03/27 22:26:07 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:07 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:07 INFO BlockManager: Dropping block rdd_14_3 from memory
17/03/27 22:26:07 INFO BlockManagerInfo: Removed rdd_14_3 on localhost:53824 in memory (size: 472.6 MB, free: 1103.2 MB)
17/03/27 22:26:07 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 472.5 MB, free 598.7 MB)
17/03/27 22:26:07 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:53824 (size: 472.5 MB, free: 630.7 MB)
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:07 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:07 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:07 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:26:07 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:53824 in memory (size: 472.5 MB, free: 1103.2 MB)
17/03/27 22:26:07 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 472.5 MB, free 598.7 MB)
17/03/27 22:26:07 INFO BlockManagerInfo: Added rdd_14_2 in memory on localhost:53824 (size: 472.5 MB, free: 630.7 MB)
17/03/27 22:26:07 INFO Executor: Finished task 2.0 in stage 3.0 (TID 18). 2496 bytes result sent to driver
17/03/27 22:26:07 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 18) in 1003 ms on localhost (5/5)
17/03/27 22:26:07 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:26:07 INFO DAGScheduler: ShuffleMapStage 3 (execute at Recursion.scala:228) finished in 1.438 s
17/03/27 22:26:07 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:07 INFO DAGScheduler: running: Set()
17/03/27 22:26:07 INFO DAGScheduler: waiting: Set(FixedPointResultStage 4)
17/03/27 22:26:07 INFO DAGScheduler: failed: Set()
17/03/27 22:26:07 INFO DAGScheduler: Submitting FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[23] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:07 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.8 KB, free 598.7 MB)
17/03/27 22:26:07 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.4 KB, free 598.7 MB)
17/03/27 22:26:07 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53824 (size: 6.4 KB, free: 630.7 MB)
17/03/27 22:26:07 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:07 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[23] at RDD at SetRDD.scala:30)
17/03/27 22:26:07 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:26:07 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 19, localhost, partition 2,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:26:07 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:07 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:07 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 22, localhost, partition 3,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:07 INFO Executor: Running task 2.0 in stage 4.0 (TID 19)
17/03/27 22:26:07 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:26:07 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:26:07 INFO Executor: Running task 3.0 in stage 4.0 (TID 22)
17/03/27 22:26:07 INFO CacheManager: Partition rdd_22_2 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_22_1 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_22_3 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_22_0 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:26:07 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:26:07 INFO BlockManager: Found block rdd_14_2 locally
17/03/27 22:26:07 INFO SetRDDHashSetPartition: Union set size 0 for rdd 7 took 0 ms
17/03/27 22:26:07 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:26:07 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:07 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:07 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:53824 on disk (size: 6.2 KB)
17/03/27 22:26:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53824 on disk (size: 5.9 KB)
17/03/27 22:26:08 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53824 on disk (size: 2.8 KB)
17/03/27 22:26:08 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53824 on disk (size: 2.4 KB)
17/03/27 22:26:08 INFO ContextCleaner: Cleaned accumulator 1408
17/03/27 22:26:08 INFO ContextCleaner: Cleaned accumulator 1407
17/03/27 22:26:08 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:08 INFO BlockManager: Dropping block rdd_14_4 from memory
17/03/27 22:26:08 INFO BlockManagerInfo: Removed rdd_14_4 on localhost:53824 in memory (size: 472.5 MB, free: 1103.3 MB)
17/03/27 22:26:08 INFO MemoryStore: 4 blocks selected for dropping
17/03/27 22:26:08 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:08 INFO BlockManager: Dropping block broadcast_5_piece0 from memory
17/03/27 22:26:08 INFO BlockManager: Writing block broadcast_5_piece0 to disk
17/03/27 22:26:08 INFO BlockManagerInfo: Added broadcast_5_piece0 on disk on localhost:53824 (size: 6.4 KB)
17/03/27 22:26:08 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:26:08 INFO BlockManager: Writing block broadcast_5 to disk
17/03/27 22:26:08 INFO BlockManager: Dropping block rdd_14_2 from memory
17/03/27 22:26:08 INFO BlockManagerInfo: Removed rdd_14_2 on localhost:53824 in memory (size: 472.5 MB, free: 1575.7 MB)
17/03/27 22:26:08 INFO MemoryStore: Will not store rdd_6_0 as it would require dropping another block from the same RDD
17/03/27 22:26:08 WARN MemoryStore: Not enough space to cache rdd_6_0 in memory! (computed 440.6 MB so far)
17/03/27 22:26:08 INFO MemoryStore: Memory use = 472.5 MB (blocks) + 1419.8 MB (scratch space shared across 5 tasks(s)) = 1892.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:08 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:26:08 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:08 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:26:08 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 440.6 MB so far)
17/03/27 22:26:08 INFO MemoryStore: Memory use = 472.5 MB (blocks) + 1420.8 MB (scratch space shared across 5 tasks(s)) = 1893.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:08 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:26:08 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:08 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 440.5 MB, free 1135.2 MB)
17/03/27 22:26:08 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:53824 (size: 440.5 MB, free: 1135.2 MB)
17/03/27 22:26:08 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:26:08 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:08 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:08 INFO MemoryStore: Block rdd_16_2 stored as values in memory (estimated size 440.5 MB, free 694.6 MB)
17/03/27 22:26:08 INFO BlockManagerInfo: Added rdd_16_2 in memory on localhost:53824 (size: 440.5 MB, free: 694.6 MB)
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/27 22:26:08 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:08 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:26:08 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 440.6 MB so far)
17/03/27 22:26:08 INFO MemoryStore: Memory use = 1353.6 MB (blocks) + 665.8 MB (scratch space shared across 5 tasks(s)) = 2019.4 MB. Storage limit = 2.0 GB.
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:08 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:08 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 440.6 MB, free 254.1 MB)
17/03/27 22:26:08 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:53824 (size: 440.6 MB, free: 254.1 MB)
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:08 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:26:08 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:08 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:26:08 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:53824 in memory (size: 472.5 MB, free: 726.6 MB)
17/03/27 22:26:08 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:08 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:26:08 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:53824 in memory (size: 440.5 MB, free: 1167.1 MB)
17/03/27 22:26:08 INFO BlockManager: Dropping block rdd_16_2 from memory
17/03/27 22:26:08 INFO BlockManagerInfo: Removed rdd_16_2 on localhost:53824 in memory (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:09 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:09 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:26:09 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:53824 in memory (size: 440.6 MB, free: 2.0 GB)
17/03/27 22:26:09 INFO MemoryStore: Block rdd_22_2 stored as values in memory (estimated size 440.5 MB, free 1607.7 MB)
17/03/27 22:26:09 INFO BlockManagerInfo: Added rdd_22_2 in memory on localhost:53824 (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:09 INFO Executor: Finished task 2.0 in stage 4.0 (TID 19). 3330 bytes result sent to driver
17/03/27 22:26:09 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 23, localhost, partition 4,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:09 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 19) in 1441 ms on localhost (1/5)
17/03/27 22:26:09 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 440.6 MB, free 1167.1 MB)
17/03/27 22:26:09 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:53824 (size: 440.6 MB, free: 1167.1 MB)
17/03/27 22:26:09 INFO SetRDDHashSetPartition: Union set size 0 for rdd 7 took 0 ms
17/03/27 22:26:09 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:09 INFO BlockManager: Dropping block rdd_22_2 from memory
17/03/27 22:26:09 INFO BlockManagerInfo: Removed rdd_22_2 on localhost:53824 in memory (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:09 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 440.5 MB, free 1167.2 MB)
17/03/27 22:26:09 INFO BlockManagerInfo: Added rdd_14_3 in memory on localhost:53824 (size: 440.5 MB, free: 1167.2 MB)
17/03/27 22:26:09 INFO SetRDDHashSetPartition: Union set size 0 for rdd 7 took 0 ms
17/03/27 22:26:09 INFO Executor: Running task 4.0 in stage 4.0 (TID 23)
17/03/27 22:26:09 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 12.8 KB, free 1167.2 MB)
17/03/27 22:26:09 INFO CacheManager: Partition rdd_22_4 not found, computing it
17/03/27 22:26:09 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:26:09 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:26:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 4 blocks
17/03/27 22:26:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:09 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 440.5 MB, free 726.6 MB)
17/03/27 22:26:09 INFO BlockManagerInfo: Added rdd_14_0 in memory on localhost:53824 (size: 440.5 MB, free: 726.6 MB)
17/03/27 22:26:09 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:26:09 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:09 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:26:09 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:53824 in memory (size: 440.6 MB, free: 1167.2 MB)
17/03/27 22:26:09 INFO BlockManager: Dropping block rdd_14_3 from memory
17/03/27 22:26:09 INFO BlockManagerInfo: Removed rdd_14_3 on localhost:53824 in memory (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:09 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:09 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:26:09 INFO BlockManager: Dropping block rdd_14_0 from memory
17/03/27 22:26:09 INFO BlockManagerInfo: Removed rdd_14_0 on localhost:53824 in memory (size: 440.5 MB, free: 2.0 GB)
17/03/27 22:26:09 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 440.5 MB, free 1607.7 MB)
17/03/27 22:26:09 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:53824 (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:09 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 17 took 0 ms
17/03/27 22:26:09 INFO MemoryStore: Will not store rdd_16_0 as it would require dropping another block from the same RDD
17/03/27 22:26:09 WARN MemoryStore: Not enough space to cache rdd_16_0 in memory! (computed 440.5 MB so far)
17/03/27 22:26:09 INFO MemoryStore: Memory use = 440.5 MB (blocks) + 1326.6 MB (scratch space shared across 5 tasks(s)) = 1767.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:09 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:09 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:10 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 440.5 MB, free 1167.2 MB)
17/03/27 22:26:10 INFO BlockManagerInfo: Added rdd_16_3 in memory on localhost:53824 (size: 440.5 MB, free: 1167.2 MB)
17/03/27 22:26:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:10 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:10 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 440.5 MB, free 726.6 MB)
17/03/27 22:26:10 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:53824 (size: 440.5 MB, free: 726.6 MB)
17/03/27 22:26:10 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:26:10 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:26:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:10 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:10 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:10 INFO BlockManager: Dropping block rdd_16_1 from memory
17/03/27 22:26:10 INFO BlockManagerInfo: Removed rdd_16_1 on localhost:53824 in memory (size: 440.5 MB, free: 1167.2 MB)
17/03/27 22:26:10 INFO BlockManager: Dropping block rdd_16_3 from memory
17/03/27 22:26:10 INFO BlockManagerInfo: Removed rdd_16_3 on localhost:53824 in memory (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:10 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:10 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:26:10 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:53824 in memory (size: 440.5 MB, free: 2.0 GB)
17/03/27 22:26:10 INFO MemoryStore: Will not store rdd_14_4 as it would require dropping another block from the same RDD
17/03/27 22:26:10 WARN MemoryStore: Not enough space to cache rdd_14_4 in memory! (computed 440.5 MB so far)
17/03/27 22:26:10 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1987.5 MB (scratch space shared across 5 tasks(s)) = 1987.5 MB. Storage limit = 2.0 GB.
17/03/27 22:26:10 INFO SetRDDHashSetPartition: Union set size 1 for rdd 7 took 0 ms
17/03/27 22:26:10 INFO MemoryStore: Block rdd_22_1 stored as values in memory (estimated size 440.5 MB, free 1607.7 MB)
17/03/27 22:26:10 INFO BlockManagerInfo: Added rdd_22_1 in memory on localhost:53824 (size: 440.5 MB, free: 1607.7 MB)
17/03/27 22:26:10 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 3669 bytes result sent to driver
17/03/27 22:26:10 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 2747 ms on localhost (2/5)
17/03/27 22:26:10 INFO MemoryStore: Block rdd_22_0 stored as values in memory (estimated size 440.5 MB, free 1167.2 MB)
17/03/27 22:26:10 INFO BlockManagerInfo: Added rdd_22_0 in memory on localhost:53824 (size: 440.5 MB, free: 1167.2 MB)
17/03/27 22:26:10 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 2244 bytes result sent to driver
17/03/27 22:26:10 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 2750 ms on localhost (3/5)
17/03/27 22:26:10 INFO MemoryStore: Block rdd_22_3 stored as values in memory (estimated size 440.5 MB, free 726.7 MB)
17/03/27 22:26:10 INFO BlockManagerInfo: Added rdd_22_3 in memory on localhost:53824 (size: 440.5 MB, free: 726.7 MB)
17/03/27 22:26:10 INFO Executor: Finished task 3.0 in stage 4.0 (TID 22). 2295 bytes result sent to driver
17/03/27 22:26:10 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 22) in 2807 ms on localhost (4/5)
17/03/27 22:26:10 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 440.4 MB, free 286.3 MB)
17/03/27 22:26:10 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:53824 (size: 440.4 MB, free: 286.3 MB)
17/03/27 22:26:10 INFO ShuffleBlockFetcherIterator: Getting 1 non-empty blocks out of 5 blocks
17/03/27 22:26:10 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:10 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 0 ms
17/03/27 22:26:11 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:11 INFO BlockManager: Dropping block rdd_16_4 from memory
17/03/27 22:26:11 INFO BlockManagerInfo: Removed rdd_16_4 on localhost:53824 in memory (size: 440.4 MB, free: 726.7 MB)
17/03/27 22:26:11 INFO MemoryStore: Block rdd_22_4 stored as values in memory (estimated size 440.4 MB, free 286.3 MB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added rdd_22_4 in memory on localhost:53824 (size: 440.4 MB, free: 286.3 MB)
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 4.0 (TID 23). 3473 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 23) in 2085 ms on localhost (5/5)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO DAGScheduler: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204) finished in 3.526 s
17/03/27 22:26:11 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:11 INFO Recursion: Fixed Point Iteration # 2, time: 5832ms
17/03/27 22:26:11 INFO DAGScheduler: Registering RDD 32 (execute at Recursion.scala:228)
17/03/27 22:26:11 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[32] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.5 KB, free 286.3 MB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.4 KB, free 286.3 MB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53824 (size: 5.4 KB, free: 286.3 MB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[32] at execute at Recursion.scala:228)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 24, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 25, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 26, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 27, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 24)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 5.0 (TID 25)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 5.0 (TID 26)
17/03/27 22:26:11 INFO Executor: Running task 4.0 in stage 5.0 (TID 27)
17/03/27 22:26:11 INFO BlockManager: Found block rdd_22_4 locally
17/03/27 22:26:11 INFO BlockManager: Found block rdd_22_0 locally
17/03/27 22:26:11 INFO BlockManager: Found block rdd_22_1 locally
17/03/27 22:26:11 INFO BlockManager: Found block rdd_22_3 locally
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 254.3 MB)
17/03/27 22:26:11 INFO Executor: Finished task 0.0 in stage 5.0 (TID 24). 2602 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 28, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 24) in 6 ms on localhost (1/5)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 5.0 (TID 28)
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 5.0 (TID 27). 2602 bytes result sent to driver
17/03/27 22:26:11 INFO CacheManager: Partition rdd_22_2 not found, computing it
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 27) in 8 ms on localhost (2/5)
17/03/27 22:26:11 ERROR Executor: Exception in task 2.0 in stage 5.0 (TID 28)
org.apache.spark.SparkException: Checkpoint block rdd_22_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:11 WARN TaskSetManager: Lost task 2.0 in stage 5.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_22_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:11 ERROR TaskSetManager: Task 2 in stage 5.0 failed 1 times; aborting job
17/03/27 22:26:11 INFO TaskSchedulerImpl: Cancelling stage 5
17/03/27 22:26:11 INFO TaskSchedulerImpl: Stage 5 was cancelled
17/03/27 22:26:11 INFO DAGScheduler: ShuffleMapStage 5 (execute at Recursion.scala:228) failed in 0.009 s
17/03/27 22:26:11 INFO Executor: Executor is trying to kill task 1.0 in stage 5.0 (TID 25)
17/03/27 22:26:11 INFO Executor: Executor is trying to kill task 3.0 in stage 5.0 (TID 26)
17/03/27 22:26:11 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 5.849994 s
17/03/27 22:26:11 INFO SparkContext: Running Spark version 1.6.3
[31m- Reach - LL - f *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 5.0 failed 1 times, most recent failure: Lost task 2.0 in stage 5.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_22_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_22_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  ...[0m
17/03/27 22:26:11 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:26:11 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:26:11 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:26:11 INFO Executor: Executor killed task 1.0 in stage 5.0 (TID 25)
17/03/27 22:26:11 WARN TaskSetManager: Lost task 1.0 in stage 5.0 (TID 25, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:11 INFO Executor: Executor killed task 3.0 in stage 5.0 (TID 26)
17/03/27 22:26:11 WARN TaskSetManager: Lost task 3.0 in stage 5.0 (TID 26, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO Utils: Successfully started service 'sparkDriver' on port 53851.
17/03/27 22:26:11 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:26:11 INFO Remoting: Starting remoting
17/03/27 22:26:11 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53864]
17/03/27 22:26:11 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53864.
17/03/27 22:26:11 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:26:11 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:26:11 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-2db08e0a-54df-4f26-ad4b-310d72c64a3f
17/03/27 22:26:11 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:26:11 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:26:11 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:26:11 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53881.
17/03/27 22:26:11 INFO NettyBlockTransferService: Server created on 53881
17/03/27 22:26:11 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:26:11 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53881 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53881)
17/03/27 22:26:11 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:26:11 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667971470
17/03/27 22:26:11 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$6.apply$mcV$sp(RecursiveQuerySuites.scala:110)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$6.apply(RecursiveQuerySuites.scala:96)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$6.apply(RecursiveQuerySuites.scala:96)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$7.apply$mcV$sp(RecursiveQuerySuites.scala:129)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$7.apply(RecursiveQuerySuites.scala:113)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$7.apply(RecursiveQuerySuites.scala:113)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:26:11 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:26:11 INFO BigDatalogContext: BigDatalog Query: "three(A,B,C)."
17/03/27 22:26:11 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:26:11 INFO BigDatalogContext: 
0: three(A, B, To) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: (From, To, To) <DISTINCT PROJECT>
  2: (0.To = 1.From) <JOIN>
   3: arc(From, To) <BASE_RELATION>
   3: arc(From, To) <BASE_RELATION>
Recursive Rules: 
 1: (A, B, To) <DISTINCT PROJECT>
  2: (0.To = 1.From) <JOIN>
   3: three2(A, B, To) <MUTUAL_RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
   Exit Rules: 
   Recursive Rules: 
    4: (A, B, To) <DISTINCT PROJECT>
     5: (0.C = 1.From) <JOIN>
      6: three(A, B, C) <RECURSIVE_RELATION>
      6: arc(From, To) <BASE_RELATION>
   3: arc(From, To) <BASE_RELATION>
17/03/27 22:26:11 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:26:11 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:26:11 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery three
+- 'Recursion three, true, [1,0,0]
   :- 'Project ['arc.From,'arc.To,'arc1.To]
   :  +- 'Join Inner, Some(('arc.To = 'arc1.From))
   :     :- 'UnresolvedRelation `arc`, None
   :     +- 'Subquery arc1
   :        +- 'Project [*]
   :           +- 'UnresolvedRelation `arc`, None
   +- 'Project ['three2.A,'three2.B,'arc4.To]
      +- 'Join Inner, Some(('three2.To = 'arc4.From))
         :- 'Subquery three2
         :  +- 'MutualRecursion three2, true, null, [1,0,0]
         :     +- 'Project ['three2.A,'three2.B,'arc3.To]
         :        +- 'Join Inner, Some(('three2.C = 'arc3.From))
         :           :- Subquery three2
         :           :  +- LinearRecursiveRelation three, [A#752,B#753,C#754], [1,0,0]
         :           +- 'BroadcastHint
         :              +- 'Subquery arc3
         :                 +- 'Project [*]
         :                    +- 'UnresolvedRelation `arc`, None
         +- 'BroadcastHint
            +- 'Subquery arc4
               +- 'Project [*]
                  +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
A: int, B: int, To: int
Subquery three
+- Recursion three, true, [1,0,0]
   :- Project [From#744,To#745,To#756]
   :  +- Join Inner, Some((To#745 = From#755))
   :     :- Subquery arc
   :     :  +- LogicalRDD [From#744,To#745], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :     +- Subquery arc1
   :        +- Project [From#755,To#756]
   :           +- Subquery arc
   :              +- LogicalRDD [From#755,To#756], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [A#752,B#753,To#758]
      +- Join Inner, Some((To#745 = From#757))
         :- Subquery three2
         :  +- MutualRecursion three2, true, null, [1,0,0]
         :     +- Project [A#752,B#753,To#745]
         :        +- Join Inner, Some((C#754 = From#744))
         :           :- Subquery three2
         :           :  +- LinearRecursiveRelation three, [A#752,B#753,C#754], [1,0,0]
         :           +- BroadcastHint
         :              +- Subquery arc3
         :                 +- Project [From#744,To#745]
         :                    +- Subquery arc
         :                       +- LogicalRDD [From#744,To#745], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         +- BroadcastHint
            +- Subquery arc4
               +- Project [From#757,To#758]
                  +- Subquery arc
                     +- LogicalRDD [From#757,To#758], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion three, true, [1,0,0]
:- Project [From#744,To#745,To#756]
:  +- Join Inner, Some((To#745 = From#755))
:     :- LogicalRDD [From#744,To#745], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
:     +- LogicalRDD [From#755,To#756], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [A#752,B#753,To#758]
   +- Join Inner, Some((To#745 = From#757))
      :- MutualRecursion three2, true, null, [1,0,0]
      :  +- Project [A#752,B#753,To#745]
      :     +- Join Inner, Some((C#754 = From#744))
      :        :- LinearRecursiveRelation three, [A#752,B#753,C#754], [1,0,0]
      :        +- BroadcastHint
      :           +- Project [From#744,To#745]
      :              +- LogicalRDD [From#744,To#745], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      +- BroadcastHint
         +- LogicalRDD [From#757,To#758], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [A#752,B#753,To#758] (Linear) [three][1,0,0]
:- TungstenExchange hashpartitioning(From#744,5), None
:  +- Project [From#744,To#745,To#756]
:     +- SortMergeJoin [To#745], [From#755]
:        :- Sort [To#745 ASC], false, 0
:        :  +- TungstenExchange hashpartitioning(To#745,5), None
:        :     +- ConvertToUnsafe
:        :        +- Scan ExistingRDD[From#744,To#745] 
:        +- Sort [From#755 ASC], false, 0
:           +- TungstenExchange hashpartitioning(From#755,5), None
:              +- ConvertToUnsafe
:                 +- Scan ExistingRDD[From#755,To#756] 
+- Project [A#752,B#753,To#758]
   +- BroadcastHashJoin [To#745], [From#757], BuildRight
      :- ConvertToUnsafe
      :  +- MutualRecursion [A#752,B#753,To#745] (Linear) [three2][1,0,0]
      :     +- Project [A#752,B#753,To#745]
      :        +- BroadcastHashJoin [C#754], [From#744], BuildRight
      :           :- LinearRecursiveRelation [A#752,B#753,C#754](three)
      :           +- Project [From#744,To#745]
      :              +- Scan ExistingRDD[From#744,To#745] 
      +- ConvertToUnsafe
         +- Scan ExistingRDD[From#757,To#758]
17/03/27 22:26:11 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:26:11 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:26:11 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:26:11 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:26:11 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:11 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:11 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:26:11 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:26:11 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:11 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[13] at run at null:-1), which has no missing parents
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.6 KB, free 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53881 (size: 2.4 KB, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[13] at run at null:-1)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:26:11 INFO DAGScheduler: Got job 1 (run at null:-1) with 5 output partitions
17/03/27 22:26:11 INFO DAGScheduler: Final stage: ResultStage 1 (run at null:-1)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:11 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[14] at run at null:-1), which has no missing parents
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53881 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[14] at run at null:-1)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:26:11 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1415 bytes result sent to driver
17/03/27 22:26:11 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1415 bytes result sent to driver
17/03/27 22:26:11 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1415 bytes result sent to driver
17/03/27 22:26:11 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1415 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1415 bytes result sent to driver
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:26:11 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1484 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1484 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:26:11 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:26:11 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1484 bytes result sent to driver
17/03/27 22:26:11 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1484 bytes result sent to driver
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1484 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 6 ms on localhost (1/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 7 ms on localhost (2/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 2 ms on localhost (1/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 3 ms on localhost (3/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 2 ms on localhost (2/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 2 ms on localhost (3/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 2 ms on localhost (4/5)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 2 ms on localhost (5/5)
17/03/27 22:26:11 INFO DAGScheduler: ResultStage 1 (run at null:-1) finished in 0.006 s
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO DAGScheduler: Job 1 finished: run at null:-1, took 0.010653 s
17/03/27 22:26:11 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 8 ms on localhost (4/5)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 2.3 KB, free 2.0 GB)
17/03/27 22:26:11 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.010 s
17/03/27 22:26:11 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.011731 s
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 296.0 B, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53881 (size: 296.0 B, free: 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 2.3 KB, free 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 2 from run at null:-1
17/03/27 22:26:11 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8 ms on localhost (5/5)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 296.0 B, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53881 (size: 296.0 B, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 3 from run at null:-1
17/03/27 22:26:11 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:11 INFO MutualRecursion: Mutual Recursion iteration: 1
17/03/27 22:26:11 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:11 INFO Recursion: Fixed Point Iteration # 1, time: 21ms
17/03/27 22:26:11 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:11 INFO MutualRecursion: Mutual Recursion iteration: 2
17/03/27 22:26:11 INFO DAGScheduler: Registering RDD 6 (execute at Recursion.scala:189)
17/03/27 22:26:11 INFO DAGScheduler: Registering RDD 10 (execute at Recursion.scala:189)
17/03/27 22:26:11 INFO DAGScheduler: Registering RDD 17 (execute at Recursion.scala:189)
17/03/27 22:26:11 INFO DAGScheduler: Got job 2 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:26:11 INFO DAGScheduler: Final stage: FixedPointResultStage 5 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:26:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
17/03/27 22:26:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 4)
17/03/27 22:26:11 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[6] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53881 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[6] at execute at Recursion.scala:189)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:26:11 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[10] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53881 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[10] at execute at Recursion.scala:189)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:26:11 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 19 ms on localhost (1/5)
17/03/27 22:26:11 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:26:11 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 22 ms on localhost (2/5)
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 16 ms on localhost (3/5)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:26:11 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 17 ms on localhost (1/5)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:26:11 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 11 ms on localhost (2/5)
17/03/27 22:26:11 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:11 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 11 ms on localhost (3/5)
17/03/27 22:26:11 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 53 ms on localhost (4/5)
17/03/27 22:26:11 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 11 ms on localhost (4/5)
17/03/27 22:26:11 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 60 ms on localhost (5/5)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:189) finished in 0.060 s
17/03/27 22:26:11 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:11 INFO DAGScheduler: running: Set(ShuffleMapStage 3)
17/03/27 22:26:11 INFO DAGScheduler: waiting: Set(FixedPointResultStage 5, ShuffleMapStage 4)
17/03/27 22:26:11 INFO DAGScheduler: failed: Set()
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 1222 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 13 ms on localhost (5/5)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO DAGScheduler: ShuffleMapStage 3 (execute at Recursion.scala:189) finished in 0.060 s
17/03/27 22:26:11 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:11 INFO DAGScheduler: running: Set()
17/03/27 22:26:11 INFO DAGScheduler: waiting: Set(FixedPointResultStage 5, ShuffleMapStage 4)
17/03/27 22:26:11 INFO DAGScheduler: failed: Set()
17/03/27 22:26:11 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[17] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.0 KB, free 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.1 KB, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53881 (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[17] at execute at Recursion.scala:189)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO GenerateUnsafeProjection: Code generated in 5.567782 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:11 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 1840 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 39 ms on localhost (1/5)
17/03/27 22:26:11 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:26:11 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 1840 bytes result sent to driver
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 40 ms on localhost (2/5)
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:11 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 1840 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 6 ms on localhost (3/5)
17/03/27 22:26:11 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 1840 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 60 ms on localhost (4/5)
17/03/27 22:26:11 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 1840 bytes result sent to driver
17/03/27 22:26:11 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 63 ms on localhost (5/5)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:26:11 INFO DAGScheduler: ShuffleMapStage 4 (execute at Recursion.scala:189) finished in 0.063 s
17/03/27 22:26:11 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:11 INFO DAGScheduler: running: Set()
17/03/27 22:26:11 INFO DAGScheduler: waiting: Set(FixedPointResultStage 5)
17/03/27 22:26:11 INFO DAGScheduler: failed: Set()
17/03/27 22:26:11 INFO DAGScheduler: Submitting FixedPointResultStage 5 (SetRDD.diffRDD SetRDD[42] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 18.6 KB, free 2.0 GB)
17/03/27 22:26:11 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 8.5 KB, free 2.0 GB)
17/03/27 22:26:11 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:53881 (size: 8.5 KB, free: 2.0 GB)
17/03/27 22:26:11 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:11 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 5 (SetRDD.diffRDD SetRDD[42] at RDD at SetRDD.scala:30)
17/03/27 22:26:11 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:26:11 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,NODE_LOCAL, 2406 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 26, localhost, partition 1,NODE_LOCAL, 2406 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 27, localhost, partition 2,NODE_LOCAL, 2406 bytes)
17/03/27 22:26:11 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 28, localhost, partition 3,NODE_LOCAL, 2406 bytes)
17/03/27 22:26:11 INFO Executor: Running task 1.0 in stage 5.0 (TID 26)
17/03/27 22:26:11 INFO Executor: Running task 2.0 in stage 5.0 (TID 27)
17/03/27 22:26:11 INFO Executor: Running task 3.0 in stage 5.0 (TID 28)
17/03/27 22:26:11 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:26:11 INFO CacheManager: Partition rdd_41_2 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_41_1 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_41_0 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_41_3 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_30_2 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_30_1 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_30_0 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_19_2 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_30_3 not found, computing it
17/03/27 22:26:11 INFO CacheManager: Partition rdd_19_1 not found, computing it
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO CacheManager: Partition rdd_19_0 not found, computing it
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO CacheManager: Partition rdd_19_3 not found, computing it
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 92
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 91
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 90
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 89
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 88
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 87
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 86
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 85
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 114
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 113
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 112
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 111
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 110
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 109
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 108
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 107
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:53881 in memory (size: 5.1 KB, free: 2.0 GB)
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53881 in memory (size: 296.0 B, free: 2.0 GB)
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53881 in memory (size: 296.0 B, free: 2.0 GB)
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1329
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1328
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1325
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1324
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1323
17/03/27 22:26:12 INFO BlockManager: Removing RDD 6
17/03/27 22:26:12 INFO ContextCleaner: Cleaned RDD 6
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1322
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1321
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1320
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1319
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1318
17/03/27 22:26:12 INFO ContextCleaner: Cleaned shuffle 0
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1317
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1316
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1315
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1314
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1313
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1312
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1311
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1310
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1309
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1308
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1307
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1306
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1305
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1304
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1303
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1302
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1301
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1300
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1299
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1298
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1297
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1296
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1295
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1294
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1293
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1292
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:53881 in memory (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1248
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1247
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1246
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1245
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1234
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:53881 in memory (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1418
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1417
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:53881 in memory (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1416
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1415
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1414
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1413
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1412
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1411
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1410
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1409
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1438
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1437
17/03/27 22:26:12 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53881 in memory (size: 2.4 KB, free: 2.0 GB)
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1435
17/03/27 22:26:12 INFO ContextCleaner: Cleaned accumulator 1434
17/03/27 22:26:12 INFO MemoryStore: Will not store rdd_19_2 as it would require dropping another block from the same RDD
17/03/27 22:26:12 WARN MemoryStore: Not enough space to cache rdd_19_2 in memory! (computed 570.2 MB so far)
17/03/27 22:26:12 INFO MemoryStore: Memory use = 27.1 KB (blocks) + 1712.6 MB (scratch space shared across 5 tasks(s)) = 1712.7 MB. Storage limit = 2.0 GB.
17/03/27 22:26:12 INFO CacheManager: Partition rdd_28_2 not found, computing it
17/03/27 22:26:12 INFO CacheManager: Partition rdd_19_2 not found, computing it
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:12 INFO MemoryStore: Will not store rdd_19_3 as it would require dropping another block from the same RDD
17/03/27 22:26:12 WARN MemoryStore: Not enough space to cache rdd_19_3 in memory! (computed 570.2 MB so far)
17/03/27 22:26:12 INFO MemoryStore: Memory use = 27.1 KB (blocks) + 1713.6 MB (scratch space shared across 5 tasks(s)) = 1713.7 MB. Storage limit = 2.0 GB.
17/03/27 22:26:12 INFO CacheManager: Partition rdd_28_3 not found, computing it
17/03/27 22:26:12 INFO CacheManager: Partition rdd_19_3 not found, computing it
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:12 INFO MemoryStore: Block rdd_19_0 stored as values in memory (estimated size 570.2 MB, free 1478.0 MB)
17/03/27 22:26:12 INFO BlockManagerInfo: Added rdd_19_0 in memory on localhost:53881 (size: 570.2 MB, free: 1478.0 MB)
17/03/27 22:26:12 INFO CacheManager: Partition rdd_28_0 not found, computing it
17/03/27 22:26:12 INFO BlockManager: Found block rdd_19_0 locally
17/03/27 22:26:12 INFO CacheManager: Partition rdd_23_0 not found, computing it
17/03/27 22:26:12 INFO BlockManager: Found block rdd_19_0 locally
17/03/27 22:26:12 INFO TorrentBroadcast: Started reading broadcast variable 2
17/03/27 22:26:12 ERROR Utils: Exception encountered
org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:12 ERROR Executor: Exception in task 0.0 in stage 5.0 (TID 25)
java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 51 more
17/03/27 22:26:12 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, localhost, partition 4,NODE_LOCAL, 2406 bytes)
17/03/27 22:26:12 INFO Executor: Running task 4.0 in stage 5.0 (TID 29)
17/03/27 22:26:12 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 25, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 51 more

17/03/27 22:26:12 ERROR TaskSetManager: Task 0 in stage 5.0 failed 1 times; aborting job
17/03/27 22:26:12 INFO TaskSchedulerImpl: Cancelling stage 5
17/03/27 22:26:12 INFO TaskSchedulerImpl: Stage 5 was cancelled
17/03/27 22:26:12 INFO DAGScheduler: FixedPointResultStage 5 (runFixedPointJob at Recursion.scala:204) failed in 1.149 s
17/03/27 22:26:12 INFO Executor: Executor is trying to kill task 2.0 in stage 5.0 (TID 27)
17/03/27 22:26:12 INFO Executor: Executor is trying to kill task 3.0 in stage 5.0 (TID 28)
17/03/27 22:26:12 INFO DAGScheduler: Fixed Point Job 2 failed: runFixedPointJob at Recursion.scala:204, took 1.295327 s
17/03/27 22:26:12 INFO Executor: Executor is trying to kill task 4.0 in stage 5.0 (TID 29)
17/03/27 22:26:12 INFO Executor: Executor is trying to kill task 1.0 in stage 5.0 (TID 26)
[31m- Mutual Recursion *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 5.0 failed 1 times, most recent failure: Lost task 0.0 in stage 5.0 (TID 25, localhost): java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
[0m
[31m	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
[0m
[31m	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)
[0m
[31m	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
[0m
[31m	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
[0m
[31m	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31mCaused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
[0m
[31m	at scala.Option.getOrElse(Option.scala:121)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
[0m
[31m	at scala.collection.immutable.List.foreach(List.scala:381)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
[0m
[31m	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
[0m
[31m	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
[0m
[31m	... 51 more
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)[0m
[31m  at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)[0m
[31m  at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)[0m
[31m  at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)[0m
[31m  at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)[0m
[31m  at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)[0m
[31m  at scala.Option.getOrElse(Option.scala:121)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)[0m
[31m  at scala.collection.immutable.List.foreach(List.scala:381)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)[0m
[31m  at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)[0m
[31m  at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)[0m
[31m  ...[0m
17/03/27 22:26:12 INFO CacheManager: Partition rdd_41_4 not found, computing it
17/03/27 22:26:12 INFO SparkContext: Running Spark version 1.6.3
17/03/27 22:26:12 INFO CacheManager: Partition rdd_30_4 not found, computing it
17/03/27 22:26:12 INFO CacheManager: Partition rdd_19_4 not found, computing it
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:12 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:26:12 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:26:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:26:12 INFO Executor: Executor killed task 4.0 in stage 5.0 (TID 29)
17/03/27 22:26:12 WARN TaskSetManager: Lost task 4.0 in stage 5.0 (TID 29, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:12 INFO MemoryStore: Will not store rdd_19_2 as it would require dropping another block from the same RDD
17/03/27 22:26:12 WARN MemoryStore: Not enough space to cache rdd_19_2 in memory! (computed 571.9 MB so far)
17/03/27 22:26:12 INFO MemoryStore: Memory use = 570.2 MB (blocks) + 859.3 MB (scratch space shared across 4 tasks(s)) = 1429.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:12 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:26:12 INFO CacheManager: Partition rdd_19_2 not found, computing it
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:12 INFO Executor: Executor killed task 2.0 in stage 5.0 (TID 27)
17/03/27 22:26:12 WARN TaskSetManager: Lost task 2.0 in stage 5.0 (TID 27, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:12 INFO MemoryStore: Block rdd_19_1 stored as values in memory (estimated size 571.9 MB, free 906.1 MB)
17/03/27 22:26:12 INFO BlockManagerInfo: Added rdd_19_1 in memory on localhost:53881 (size: 571.9 MB, free: 906.1 MB)
17/03/27 22:26:12 INFO CacheManager: Partition rdd_28_1 not found, computing it
17/03/27 22:26:12 INFO BlockManager: Found block rdd_19_1 locally
17/03/27 22:26:12 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:26:12 INFO BlockManager: Found block rdd_19_1 locally
17/03/27 22:26:12 INFO TorrentBroadcast: Started reading broadcast variable 2
17/03/27 22:26:12 ERROR Utils: Exception encountered
org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:12 INFO Utils: Successfully started service 'sparkDriver' on port 53900.
17/03/27 22:26:12 ERROR Executor: Exception in task 1.0 in stage 5.0 (TID 26)
java.io.IOException: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1212)
	at org.apache.spark.broadcast.TorrentBroadcast.readBroadcastBlock(TorrentBroadcast.scala:165)
	at org.apache.spark.broadcast.TorrentBroadcast._value$lzycompute(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast._value(TorrentBroadcast.scala:64)
	at org.apache.spark.broadcast.TorrentBroadcast.getValue(TorrentBroadcast.scala:88)
	at org.apache.spark.broadcast.Broadcast.value(Broadcast.scala:70)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:110)
	at org.apache.spark.sql.execution.joins.BroadcastHashJoin$$anonfun$2.apply(BroadcastHashJoin.scala:109)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD$$anonfun$mapPartitions$1.apply(SetRDD.scala:85)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$20.apply(RDD.scala:710)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
Caused by: org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1$$anonfun$2.apply(TorrentBroadcast.scala:138)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply$mcVI$sp(TorrentBroadcast.scala:137)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$org$apache$spark$broadcast$TorrentBroadcast$$readBlocks$1.apply(TorrentBroadcast.scala:120)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.apache.spark.broadcast.TorrentBroadcast.org$apache$spark$broadcast$TorrentBroadcast$$readBlocks(TorrentBroadcast.scala:120)
	at org.apache.spark.broadcast.TorrentBroadcast$$anonfun$readBroadcastBlock$1.apply(TorrentBroadcast.scala:175)
	at org.apache.spark.util.Utils$.tryOrIOException(Utils.scala:1205)
	... 51 more
17/03/27 22:26:12 INFO TaskSetManager: Lost task 1.0 in stage 5.0 (TID 26) on executor localhost: java.io.IOException (org.apache.spark.SparkException: Failed to get broadcast_2_piece0 of broadcast_2) [duplicate 1]
17/03/27 22:26:12 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:26:12 INFO Remoting: Starting remoting
17/03/27 22:26:12 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53913]
17/03/27 22:26:12 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53913.
17/03/27 22:26:12 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:26:12 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:26:12 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-c426bfba-0d10-4f0c-a540-04d6a6cfef64
17/03/27 22:26:12 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:26:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:26:12 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:26:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53930.
17/03/27 22:26:13 INFO NettyBlockTransferService: Server created on 53930
17/03/27 22:26:13 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:26:13 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53930 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53930)
17/03/27 22:26:13 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:26:13 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667972997
17/03/27 22:26:13 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$7.apply$mcV$sp(RecursiveQuerySuites.scala:129)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$7.apply(RecursiveQuerySuites.scala:113)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$7.apply(RecursiveQuerySuites.scala:113)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$8.apply$mcV$sp(RecursiveQuerySuites.scala:144)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$8.apply(RecursiveQuerySuites.scala:132)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$8.apply(RecursiveQuerySuites.scala:132)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:26:13 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:26:13 INFO BigDatalogContext: BigDatalog Query: "same_generation(A,B)"
17/03/27 22:26:13 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:26:13 INFO BigDatalogContext: 
0: same_generation(Child, Child) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: (Child, Child) <DISTINCT PROJECT>
  2: Child ~= Child <FILTER>
   3: (0.Parent = 1.Parent) <JOIN>
    4: parent_child(Parent, Child) <BASE_RELATION>
    4: parent_child(Parent, Child) <BASE_RELATION>
Recursive Rules: 
 1: (Child, Child) <DISTINCT PROJECT>
  2: (0.Parent = 1.A, 1.B = 2.Parent) <JOIN>
   3: parent_child(Parent, Child) <BASE_RELATION>
   3: same_generation(A, B) <RECURSIVE_RELATION>
   3: parent_child(Parent, Child) <BASE_RELATION>
17/03/27 22:26:13 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:26:13 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:26:13 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery same_generation
+- 'Recursion same_generation, true, [1,0]
   :- 'Project ['parent_child.Child,'parent_child1.Child]
   :  +- 'Filter NOT ('parent_child.Child = 'parent_child1.Child)
   :     +- 'Join Inner, Some(('parent_child.Parent = 'parent_child1.Parent))
   :        :- 'UnresolvedRelation `parent_child`, None
   :        +- 'Subquery parent_child1
   :           +- 'Project [*]
   :              +- 'UnresolvedRelation `parent_child`, None
   +- 'Project ['parent_child2.Child,'parent_child4.Child]
      +- 'Join Inner, Some(('same_generation3.B = 'parent_child4.Parent))
         :- 'Join Inner, Some(('parent_child2.Parent = 'same_generation3.A))
         :  :- 'BroadcastHint
         :  :  +- 'Subquery parent_child2
         :  :     +- 'Project [*]
         :  :        +- 'UnresolvedRelation `parent_child`, None
         :  +- Subquery same_generation3
         :     +- LinearRecursiveRelation same_generation, [A#767,B#768], [1,0]
         +- 'BroadcastHint
            +- 'Subquery parent_child4
               +- 'Project [*]
                  +- 'UnresolvedRelation `parent_child`, None

== Analyzed Logical Plan ==
Child: int, Child: int
Subquery same_generation
+- Recursion same_generation, true, [1,0]
   :- Project [Child#764,Child#770]
   :  +- Filter NOT (Child#764 = Child#770)
   :     +- Join Inner, Some((Parent#763 = Parent#769))
   :        :- Subquery parent_child
   :        :  +- LogicalRDD [Parent#763,Child#764], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :        +- Subquery parent_child1
   :           +- Project [Parent#769,Child#770]
   :              +- Subquery parent_child
   :                 +- LogicalRDD [Parent#769,Child#770], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [Child#764,Child#772]
      +- Join Inner, Some((B#768 = Parent#771))
         :- Join Inner, Some((Parent#763 = A#767))
         :  :- BroadcastHint
         :  :  +- Subquery parent_child2
         :  :     +- Project [Parent#763,Child#764]
         :  :        +- Subquery parent_child
         :  :           +- LogicalRDD [Parent#763,Child#764], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
         :  +- Subquery same_generation3
         :     +- LinearRecursiveRelation same_generation, [A#767,B#768], [1,0]
         +- BroadcastHint
            +- Subquery parent_child4
               +- Project [Parent#771,Child#772]
                  +- Subquery parent_child
                     +- LogicalRDD [Parent#771,Child#772], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion same_generation, true, [1,0]
:- Project [Child#764,Child#770]
:  +- Join Inner, Some((NOT (Child#764 = Child#770) && (Parent#763 = Parent#769)))
:     :- LogicalRDD [Parent#763,Child#764], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
:     +- LogicalRDD [Parent#769,Child#770], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [Child#764,Child#772]
   +- Join Inner, Some((B#768 = Parent#771))
      :- Project [Child#764,B#768]
      :  +- Join Inner, Some((Parent#763 = A#767))
      :     :- BroadcastHint
      :     :  +- Project [Parent#763,Child#764]
      :     :     +- LogicalRDD [Parent#763,Child#764], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
      :     +- LinearRecursiveRelation same_generation, [A#767,B#768], [1,0]
      +- BroadcastHint
         +- LogicalRDD [Parent#771,Child#772], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [Child#764,Child#772] (Linear) [same_generation][1,0]
:- TungstenExchange hashpartitioning(Child#764,5), None
:  +- Project [Child#764,Child#770]
:     +- Filter NOT (Child#764 = Child#770)
:        +- SortMergeJoin [Parent#763], [Parent#769]
:           :- Sort [Parent#763 ASC], false, 0
:           :  +- TungstenExchange hashpartitioning(Parent#763,5), None
:           :     +- ConvertToUnsafe
:           :        +- Scan ExistingRDD[Parent#763,Child#764] 
:           +- Sort [Parent#769 ASC], false, 0
:              +- TungstenExchange hashpartitioning(Parent#769,5), None
:                 +- ConvertToUnsafe
:                    +- Scan ExistingRDD[Parent#769,Child#770] 
+- TungstenExchange hashpartitioning(Child#764,5), None
   +- Project [Child#764,Child#772]
      +- BroadcastHashJoin [B#768], [Parent#771], BuildRight
         :- Project [Child#764,B#768]
         :  +- BroadcastHashJoin [Parent#763], [A#767], BuildLeft
         :     :- Project [Parent#763,Child#764]
         :     :  +- Scan ExistingRDD[Parent#763,Child#764] 
         :     +- LinearRecursiveRelation [A#767,B#768](same_generation)
         +- ConvertToUnsafe
            +- Scan ExistingRDD[Parent#771,Child#772]
17/03/27 22:26:13 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:26:13 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:26:13 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:26:13 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:26:13 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:13 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:26:13 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:26:13 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:13 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:13 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[19] at run at null:-1), which has no missing parents
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.6 KB, free 2.0 GB)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.4 KB, free 2.0 GB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53930 (size: 2.4 KB, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:13 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[19] at run at null:-1)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:13 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:13 INFO DAGScheduler: Got job 1 (run at null:-1) with 5 output partitions
17/03/27 22:26:13 INFO DAGScheduler: Final stage: ResultStage 1 (run at null:-1)
17/03/27 22:26:13 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:13 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[20] at run at null:-1), which has no missing parents
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53930 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:13 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 1 (MapPartitionsRDD[20] at run at null:-1)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:26:13 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:26:13 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1374 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:13 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:26:13 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1415 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:26:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1443 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2357 bytes)
17/03/27 22:26:13 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:26:13 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1484 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:13 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:26:13 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1443 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:13 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:26:13 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1484 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:13 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:26:13 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1484 bytes result sent to driver
17/03/27 22:26:13 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:26:13 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1415 bytes result sent to driver
17/03/27 22:26:13 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:26:13 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:26:13 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1374 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 28 ms on localhost (1/5)
17/03/27 22:26:13 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1415 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 6 ms on localhost (1/5)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 5 ms on localhost (2/5)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 4 ms on localhost (3/5)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 29 ms on localhost (2/5)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 29 ms on localhost (3/5)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 28 ms on localhost (4/5)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 13 ms on localhost (5/5)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:26:13 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.029 s
17/03/27 22:26:13 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.043548 s
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 1672.0 B, free 2.0 GB)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 12 ms on localhost (4/5)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 260.0 B, free 2.0 GB)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 10 ms on localhost (5/5)
17/03/27 22:26:13 INFO DAGScheduler: ResultStage 1 (run at null:-1) finished in 0.027 s
17/03/27 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:26:13 INFO DAGScheduler: Job 1 finished: run at null:-1, took 0.029165 s
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53930 (size: 260.0 B, free: 2.0 GB)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 1672.0 B, free 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 2 from run at null:-1
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 260.0 B, free 2.0 GB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53930 (size: 260.0 B, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 3 from run at null:-1
17/03/27 22:26:13 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:13 INFO Recursion: Fixed Point Iteration # 1, time: 82ms
17/03/27 22:26:13 INFO DAGScheduler: Registering RDD 3 (execute at Recursion.scala:189)
17/03/27 22:26:13 INFO DAGScheduler: Registering RDD 7 (execute at Recursion.scala:189)
17/03/27 22:26:13 INFO DAGScheduler: Registering RDD 13 (execute at Recursion.scala:189)
17/03/27 22:26:13 INFO DAGScheduler: Registering RDD 25 (execute at Recursion.scala:202)
17/03/27 22:26:13 INFO DAGScheduler: Registering RDD 35 (execute at Recursion.scala:228)
17/03/27 22:26:13 INFO DAGScheduler: Got job 2 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:26:13 INFO DAGScheduler: Final stage: FixedPointResultStage 7 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:26:13 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5, ShuffleMapStage 6, ShuffleMapStage 4)
17/03/27 22:26:13 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 5, ShuffleMapStage 6, ShuffleMapStage 4)
17/03/27 22:26:13 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[3] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53930 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:13 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[3] at execute at Recursion.scala:189)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:26:13 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[7] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:13 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 4.7 KB, free 2.0 GB)
17/03/27 22:26:13 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:26:13 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:13 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53930 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:13 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[7] at execute at Recursion.scala:189)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:26:13 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:13 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 32 ms on localhost (1/5)
17/03/27 22:26:13 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 34 ms on localhost (2/5)
17/03/27 22:26:13 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:26:13 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2346 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 37 ms on localhost (3/5)
17/03/27 22:26:13 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:26:13 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 17, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 39 ms on localhost (4/5)
17/03/27 22:26:13 INFO Executor: Running task 2.0 in stage 3.0 (TID 17)
17/03/27 22:26:13 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 18, localhost, partition 3,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 11 ms on localhost (1/5)
17/03/27 22:26:13 INFO Executor: Running task 3.0 in stage 3.0 (TID 18)
17/03/27 22:26:13 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 19, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:13 INFO Executor: Running task 4.0 in stage 3.0 (TID 19)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 11 ms on localhost (2/5)
17/03/27 22:26:13 INFO Executor: Finished task 2.0 in stage 3.0 (TID 17). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 17) in 11 ms on localhost (3/5)
17/03/27 22:26:13 INFO Executor: Finished task 3.0 in stage 3.0 (TID 18). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 18) in 10 ms on localhost (4/5)
17/03/27 22:26:13 INFO Executor: Finished task 4.0 in stage 3.0 (TID 19). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 19) in 10 ms on localhost (5/5)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:26:13 INFO DAGScheduler: ShuffleMapStage 3 (execute at Recursion.scala:189) finished in 0.054 s
17/03/27 22:26:13 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:13 INFO DAGScheduler: running: Set(ShuffleMapStage 2)
17/03/27 22:26:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, FixedPointResultStage 7, ShuffleMapStage 4)
17/03/27 22:26:13 INFO DAGScheduler: failed: Set()
17/03/27 22:26:13 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 1222 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 32 ms on localhost (5/5)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:26:13 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:189) finished in 0.064 s
17/03/27 22:26:13 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:13 INFO DAGScheduler: running: Set()
17/03/27 22:26:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, FixedPointResultStage 7, ShuffleMapStage 4)
17/03/27 22:26:13 INFO DAGScheduler: failed: Set()
17/03/27 22:26:13 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[13] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 10.9 KB, free 2.0 GB)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.4 KB, free 2.0 GB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:53930 (size: 5.4 KB, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:13 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[13] at execute at Recursion.scala:189)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:13 INFO Executor: Running task 0.0 in stage 4.0 (TID 20)
17/03/27 22:26:13 INFO Executor: Running task 2.0 in stage 4.0 (TID 22)
17/03/27 22:26:13 INFO Executor: Running task 1.0 in stage 4.0 (TID 21)
17/03/27 22:26:13 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO Executor: Finished task 1.0 in stage 4.0 (TID 21). 1926 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 21) in 7 ms on localhost (1/5)
17/03/27 22:26:13 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 1926 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 6 ms on localhost (2/5)
17/03/27 22:26:13 INFO Executor: Finished task 2.0 in stage 4.0 (TID 22). 1926 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 22) in 15 ms on localhost (3/5)
17/03/27 22:26:13 INFO Executor: Finished task 0.0 in stage 4.0 (TID 20). 1926 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 20) in 16 ms on localhost (4/5)
17/03/27 22:26:13 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 1926 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 24 ms on localhost (5/5)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:26:13 INFO DAGScheduler: ShuffleMapStage 4 (execute at Recursion.scala:189) finished in 0.024 s
17/03/27 22:26:13 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:13 INFO DAGScheduler: running: Set()
17/03/27 22:26:13 INFO DAGScheduler: waiting: Set(ShuffleMapStage 5, ShuffleMapStage 6, FixedPointResultStage 7)
17/03/27 22:26:13 INFO DAGScheduler: failed: Set()
17/03/27 22:26:13 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[25] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.8 KB, free 2.0 GB)
17/03/27 22:26:13 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.5 KB, free 2.0 GB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:53930 (size: 6.5 KB, free: 2.0 GB)
17/03/27 22:26:13 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:13 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[25] at execute at Recursion.scala:202)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:26:13 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 26, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 27, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 28, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:13 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:26:13 INFO Executor: Running task 1.0 in stage 5.0 (TID 26)
17/03/27 22:26:13 INFO Executor: Running task 2.0 in stage 5.0 (TID 27)
17/03/27 22:26:13 INFO Executor: Running task 3.0 in stage 5.0 (TID 28)
17/03/27 22:26:13 INFO CacheManager: Partition rdd_15_3 not found, computing it
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO CacheManager: Partition rdd_15_0 not found, computing it
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO CacheManager: Partition rdd_15_1 not found, computing it
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO CacheManager: Partition rdd_15_2 not found, computing it
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:13 INFO MemoryStore: Block rdd_19_3 stored as values in memory (estimated size 572.5 MB, free 333.7 MB)
17/03/27 22:26:13 INFO BlockManagerInfo: Added rdd_19_3 in memory on localhost:53881 (size: 572.5 MB, free: 333.7 MB)
17/03/27 22:26:13 INFO CacheManager: Partition rdd_23_3 not found, computing it
17/03/27 22:26:13 INFO CacheManager: Partition rdd_19_3 not found, computing it
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:13 INFO Executor: Executor killed task 3.0 in stage 5.0 (TID 28)
17/03/27 22:26:13 WARN TaskSetManager: Lost task 3.0 in stage 5.0 (TID 28, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:13 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:26:13 INFO MemoryStore: Will not store rdd_15_1 as it would require dropping another block from the same RDD
17/03/27 22:26:13 WARN MemoryStore: Not enough space to cache rdd_15_1 in memory! (computed 572.4 MB so far)
17/03/27 22:26:13 INFO MemoryStore: Memory use = 69.1 KB (blocks) + 1718.2 MB (scratch space shared across 5 tasks(s)) = 1718.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:13 INFO Executor: Finished task 1.0 in stage 5.0 (TID 26). 2013 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 29, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:13 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 26) in 500 ms on localhost (1/5)
17/03/27 22:26:13 INFO MemoryStore: Will not store rdd_15_2 as it would require dropping another block from the same RDD
17/03/27 22:26:13 WARN MemoryStore: Not enough space to cache rdd_15_2 in memory! (computed 572.4 MB so far)
17/03/27 22:26:13 INFO MemoryStore: Memory use = 69.1 KB (blocks) + 1717.2 MB (scratch space shared across 4 tasks(s)) = 1717.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:13 INFO Executor: Finished task 2.0 in stage 5.0 (TID 27). 2013 bytes result sent to driver
17/03/27 22:26:13 INFO TaskSetManager: Finished task 2.0 in stage 5.0 (TID 27) in 516 ms on localhost (2/5)
17/03/27 22:26:13 INFO Executor: Running task 4.0 in stage 5.0 (TID 29)
17/03/27 22:26:13 INFO CacheManager: Partition rdd_15_4 not found, computing it
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:13 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:14 INFO BlockManagerInfo: Removed broadcast_6_piece0 on localhost:53930 in memory (size: 5.4 KB, free: 2.0 GB)
17/03/27 22:26:14 INFO MemoryStore: Block rdd_15_3 stored as values in memory (estimated size 572.4 MB, free 1475.8 MB)
17/03/27 22:26:14 INFO BlockManagerInfo: Added rdd_15_3 in memory on localhost:53930 (size: 572.4 MB, free: 1475.9 MB)
17/03/27 22:26:14 INFO Executor: Finished task 3.0 in stage 5.0 (TID 28). 2382 bytes result sent to driver
17/03/27 22:26:14 INFO TaskSetManager: Finished task 3.0 in stage 5.0 (TID 28) in 849 ms on localhost (3/5)
17/03/27 22:26:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on localhost:53930 in memory (size: 2.7 KB, free: 1475.9 MB)
17/03/27 22:26:14 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:53930 in memory (size: 2.7 KB, free: 1475.9 MB)
17/03/27 22:26:14 INFO BlockManagerInfo: Removed broadcast_1_piece0 on localhost:53930 in memory (size: 2.7 KB, free: 1475.9 MB)
17/03/27 22:26:14 INFO ContextCleaner: Cleaned accumulator 1469
17/03/27 22:26:14 INFO ContextCleaner: Cleaned accumulator 1468
17/03/27 22:26:14 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53930 in memory (size: 2.4 KB, free: 1475.9 MB)
17/03/27 22:26:14 INFO ContextCleaner: Cleaned accumulator 1467
17/03/27 22:26:14 INFO ContextCleaner: Cleaned accumulator 1466
17/03/27 22:26:14 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 572.3 MB, free 903.6 MB)
17/03/27 22:26:14 INFO BlockManagerInfo: Added rdd_15_0 in memory on localhost:53930 (size: 572.3 MB, free: 903.6 MB)
17/03/27 22:26:14 INFO Executor: Finished task 0.0 in stage 5.0 (TID 25). 2382 bytes result sent to driver
17/03/27 22:26:14 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 25) in 888 ms on localhost (4/5)
17/03/27 22:26:14 INFO MemoryStore: Block rdd_15_4 stored as values in memory (estimated size 572.3 MB, free 331.3 MB)
17/03/27 22:26:14 INFO BlockManagerInfo: Added rdd_15_4 in memory on localhost:53930 (size: 572.3 MB, free: 331.3 MB)
17/03/27 22:26:14 INFO Executor: Finished task 4.0 in stage 5.0 (TID 29). 2382 bytes result sent to driver
17/03/27 22:26:14 INFO TaskSetManager: Finished task 4.0 in stage 5.0 (TID 29) in 743 ms on localhost (5/5)
17/03/27 22:26:14 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/03/27 22:26:14 INFO DAGScheduler: ShuffleMapStage 5 (execute at Recursion.scala:202) finished in 1.243 s
17/03/27 22:26:14 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:14 INFO DAGScheduler: running: Set()
17/03/27 22:26:14 INFO DAGScheduler: waiting: Set(ShuffleMapStage 6, FixedPointResultStage 7)
17/03/27 22:26:14 INFO DAGScheduler: failed: Set()
17/03/27 22:26:14 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:14 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 13.6 KB, free 331.3 MB)
17/03/27 22:26:14 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 6.8 KB, free 331.3 MB)
17/03/27 22:26:14 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:53930 (size: 6.8 KB, free: 331.3 MB)
17/03/27 22:26:14 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:14 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at execute at Recursion.scala:228)
17/03/27 22:26:14 INFO TaskSchedulerImpl: Adding task set 6.0 with 5 tasks
17/03/27 22:26:14 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 30, localhost, partition 0,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:14 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 31, localhost, partition 3,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:14 INFO TaskSetManager: Starting task 4.0 in stage 6.0 (TID 32, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:14 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 33, localhost, partition 1,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:14 INFO Executor: Running task 0.0 in stage 6.0 (TID 30)
17/03/27 22:26:14 INFO Executor: Running task 4.0 in stage 6.0 (TID 32)
17/03/27 22:26:14 INFO Executor: Running task 3.0 in stage 6.0 (TID 31)
17/03/27 22:26:14 INFO Executor: Running task 1.0 in stage 6.0 (TID 33)
17/03/27 22:26:14 INFO CacheManager: Partition rdd_27_1 not found, computing it
17/03/27 22:26:14 INFO CacheManager: Partition rdd_27_0 not found, computing it
17/03/27 22:26:14 INFO BlockManager: Found block rdd_15_0 locally
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:14 INFO CacheManager: Partition rdd_15_1 not found, computing it
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:14 INFO CacheManager: Partition rdd_27_3 not found, computing it
17/03/27 22:26:14 INFO BlockManager: Found block rdd_15_3 locally
17/03/27 22:26:14 INFO CacheManager: Partition rdd_27_4 not found, computing it
17/03/27 22:26:14 INFO BlockManager: Found block rdd_15_4 locally
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:14 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:14 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 16 took 1 ms
17/03/27 22:26:14 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 16 took 0 ms
17/03/27 22:26:14 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 16 took 0 ms
17/03/27 22:26:15 INFO MemoryStore: Will not store rdd_15_1 as it would require dropping another block from the same RDD
17/03/27 22:26:15 WARN MemoryStore: Not enough space to cache rdd_15_1 in memory! (computed 572.4 MB so far)
17/03/27 22:26:15 INFO MemoryStore: Memory use = 1717.0 MB (blocks) + 3.0 MB (scratch space shared across 6 tasks(s)) = 1720.0 MB. Storage limit = 2.0 GB.
17/03/27 22:26:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:15 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 16 took 0 ms
17/03/27 22:26:15 INFO MemoryStore: 9 blocks selected for dropping
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:26:15 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53930 (size: 260.0 B)
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:26:15 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53930 (size: 260.0 B)
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_7_piece0 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_7_piece0 to disk
17/03/27 22:26:15 INFO BlockManagerInfo: Added broadcast_7_piece0 on disk on localhost:53930 (size: 6.5 KB)
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_7 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_7 to disk
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_8_piece0 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_8_piece0 to disk
17/03/27 22:26:15 INFO BlockManagerInfo: Added broadcast_8_piece0 on disk on localhost:53930 (size: 6.8 KB)
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_8 from memory
17/03/27 22:26:15 INFO BlockManager: Writing block broadcast_8 to disk
17/03/27 22:26:15 INFO BlockManager: Dropping block rdd_15_0 from memory
17/03/27 22:26:15 INFO BlockManagerInfo: Removed rdd_15_0 on localhost:53930 in memory (size: 572.3 MB, free: 903.6 MB)
17/03/27 22:26:15 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:15 INFO BlockManager: Dropping block rdd_15_3 from memory
17/03/27 22:26:15 INFO BlockManagerInfo: Removed rdd_15_3 on localhost:53930 in memory (size: 572.4 MB, free: 1476.0 MB)
17/03/27 22:26:15 INFO BlockManager: Dropping block rdd_15_4 from memory
17/03/27 22:26:15 INFO BlockManagerInfo: Removed rdd_15_4 on localhost:53930 in memory (size: 572.3 MB, free: 2.0 GB)
17/03/27 22:26:15 INFO MemoryStore: Will not store rdd_27_3 as it would require dropping another block from the same RDD
17/03/27 22:26:15 WARN MemoryStore: Not enough space to cache rdd_27_3 in memory! (computed 572.3 MB so far)
17/03/27 22:26:15 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1719.1 MB (scratch space shared across 6 tasks(s)) = 1719.1 MB. Storage limit = 2.0 GB.
17/03/27 22:26:15 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 MB, free 2016.2 MB)
17/03/27 22:26:15 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 32.0 MB, free 1984.2 MB)
17/03/27 22:26:15 INFO Executor: Finished task 3.0 in stage 6.0 (TID 31). 3163 bytes result sent to driver
17/03/27 22:26:15 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 34, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:15 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 31) in 509 ms on localhost (1/5)
17/03/27 22:26:15 INFO Executor: Running task 2.0 in stage 6.0 (TID 34)
17/03/27 22:26:15 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 13.6 KB, free 1984.2 MB)
17/03/27 22:26:15 INFO CacheManager: Partition rdd_27_2 not found, computing it
17/03/27 22:26:15 INFO CacheManager: Partition rdd_15_2 not found, computing it
17/03/27 22:26:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:15 INFO MemoryStore: Block rdd_27_4 stored as values in memory (estimated size 572.4 MB, free 1411.9 MB)
17/03/27 22:26:15 INFO BlockManagerInfo: Added rdd_27_4 in memory on localhost:53930 (size: 572.4 MB, free: 1475.9 MB)
17/03/27 22:26:15 INFO Executor: Finished task 4.0 in stage 6.0 (TID 32). 3658 bytes result sent to driver
17/03/27 22:26:15 INFO TaskSetManager: Finished task 4.0 in stage 6.0 (TID 32) in 957 ms on localhost (2/5)
17/03/27 22:26:15 INFO MemoryStore: Will not store rdd_27_1 as it would require dropping another block from the same RDD
17/03/27 22:26:15 WARN MemoryStore: Not enough space to cache rdd_27_1 in memory! (computed 572.4 MB so far)
17/03/27 22:26:15 INFO MemoryStore: Memory use = 636.4 MB (blocks) + 860.6 MB (scratch space shared across 5 tasks(s)) = 1496.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:15 INFO Executor: Finished task 1.0 in stage 6.0 (TID 33). 2013 bytes result sent to driver
17/03/27 22:26:15 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 33) in 969 ms on localhost (3/5)
17/03/27 22:26:15 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:15 INFO BlockManager: Dropping block broadcast_8 from memory
17/03/27 22:26:15 INFO BlockManager: Dropping block rdd_27_4 from memory
17/03/27 22:26:15 INFO BlockManagerInfo: Removed rdd_27_4 on localhost:53930 in memory (size: 572.4 MB, free: 2.0 GB)
17/03/27 22:26:15 INFO MemoryStore: Block rdd_27_0 stored as values in memory (estimated size 572.4 MB, free 1411.9 MB)
17/03/27 22:26:15 INFO BlockManagerInfo: Added rdd_27_0 in memory on localhost:53930 (size: 572.4 MB, free: 1475.9 MB)
17/03/27 22:26:15 INFO Executor: Finished task 0.0 in stage 6.0 (TID 30). 4217 bytes result sent to driver
17/03/27 22:26:15 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 30) in 996 ms on localhost (4/5)
17/03/27 22:26:15 INFO MemoryStore: Block rdd_15_2 stored as values in memory (estimated size 572.2 MB, free 839.6 MB)
17/03/27 22:26:15 INFO BlockManagerInfo: Added rdd_15_2 in memory on localhost:53930 (size: 572.2 MB, free: 903.7 MB)
17/03/27 22:26:15 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:15 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:15 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 16 took 0 ms
17/03/27 22:26:16 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:16 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:16 INFO MemoryStore: Block rdd_27_2 stored as values in memory (estimated size 540.2 MB, free 331.5 MB)
17/03/27 22:26:16 INFO BlockManagerInfo: Added rdd_27_2 in memory on localhost:53930 (size: 540.2 MB, free: 363.5 MB)
17/03/27 22:26:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 32.0 MB, free 299.5 MB)
17/03/27 22:26:16 INFO Executor: Finished task 2.0 in stage 6.0 (TID 34). 2714 bytes result sent to driver
17/03/27 22:26:16 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 34) in 1396 ms on localhost (5/5)
17/03/27 22:26:16 INFO DAGScheduler: ShuffleMapStage 6 (execute at Recursion.scala:228) finished in 1.904 s
17/03/27 22:26:16 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:16 INFO DAGScheduler: running: Set()
17/03/27 22:26:16 INFO DAGScheduler: waiting: Set(FixedPointResultStage 7)
17/03/27 22:26:16 INFO DAGScheduler: failed: Set()
17/03/27 22:26:16 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/03/27 22:26:16 INFO DAGScheduler: Submitting FixedPointResultStage 7 (SetRDD.diffRDD SetRDD[38] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 16.3 KB, free 299.4 MB)
17/03/27 22:26:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 7.5 KB, free 299.4 MB)
17/03/27 22:26:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:53930 (size: 7.5 KB, free: 363.5 MB)
17/03/27 22:26:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:16 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 7 (SetRDD.diffRDD SetRDD[38] at RDD at SetRDD.scala:30)
17/03/27 22:26:16 INFO TaskSchedulerImpl: Adding task set 7.0 with 5 tasks
17/03/27 22:26:16 INFO TaskSetManager: Starting task 2.0 in stage 7.0 (TID 35, localhost, partition 2,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:26:16 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 36, localhost, partition 0,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:16 INFO TaskSetManager: Starting task 1.0 in stage 7.0 (TID 37, localhost, partition 1,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:16 INFO TaskSetManager: Starting task 3.0 in stage 7.0 (TID 38, localhost, partition 3,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:16 INFO Executor: Running task 2.0 in stage 7.0 (TID 35)
17/03/27 22:26:16 INFO Executor: Running task 0.0 in stage 7.0 (TID 36)
17/03/27 22:26:16 INFO Executor: Running task 1.0 in stage 7.0 (TID 37)
17/03/27 22:26:16 INFO Executor: Running task 3.0 in stage 7.0 (TID 38)
17/03/27 22:26:16 INFO CacheManager: Partition rdd_37_0 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_37_1 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_37_2 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_29_0 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_29_2 not found, computing it
17/03/27 22:26:16 INFO BlockManager: Found block rdd_15_2 locally
17/03/27 22:26:16 INFO BlockManager: Found block rdd_27_2 locally
17/03/27 22:26:16 INFO SetRDDHashSetPartition: Union set size 2 for rdd 16 took 0 ms
17/03/27 22:26:16 INFO CacheManager: Partition rdd_29_1 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_37_3 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_15_0 not found, computing it
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:16 INFO CacheManager: Partition rdd_15_1 not found, computing it
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:16 INFO CacheManager: Partition rdd_29_3 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_15_3 not found, computing it
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:16 INFO BlockManagerInfo: Removed broadcast_8_piece0 on localhost:53930 on disk (size: 6.8 KB)
17/03/27 22:26:16 INFO BlockManagerInfo: Removed broadcast_7_piece0 on localhost:53930 on disk (size: 6.5 KB)
17/03/27 22:26:16 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:16 INFO BlockManager: Dropping block rdd_27_0 from memory
17/03/27 22:26:16 INFO BlockManagerInfo: Removed rdd_27_0 on localhost:53930 in memory (size: 572.4 MB, free: 935.8 MB)
17/03/27 22:26:16 INFO MemoryStore: Will not store rdd_15_1 as it would require dropping another block from the same RDD
17/03/27 22:26:16 WARN MemoryStore: Not enough space to cache rdd_15_1 in memory! (computed 540.3 MB so far)
17/03/27 22:26:16 INFO MemoryStore: Memory use = 1176.4 MB (blocks) + 812.5 MB (scratch space shared across 6 tasks(s)) = 1988.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:16 INFO CacheManager: Partition rdd_27_1 not found, computing it
17/03/27 22:26:16 INFO CacheManager: Partition rdd_15_1 not found, computing it
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:16 INFO MemoryStore: 6 blocks selected for dropping
17/03/27 22:26:16 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:16 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:26:16 INFO BlockManager: Dropping block broadcast_9_piece0 from memory
17/03/27 22:26:16 INFO BlockManager: Writing block broadcast_9_piece0 to disk
17/03/27 22:26:16 INFO BlockManagerInfo: Added broadcast_9_piece0 on disk on localhost:53930 (size: 7.5 KB)
17/03/27 22:26:16 INFO BlockManager: Dropping block broadcast_9 from memory
17/03/27 22:26:16 INFO BlockManager: Writing block broadcast_9 to disk
17/03/27 22:26:16 INFO BlockManager: Dropping block rdd_15_2 from memory
17/03/27 22:26:16 INFO BlockManagerInfo: Removed rdd_15_2 on localhost:53930 in memory (size: 572.2 MB, free: 1508.1 MB)
17/03/27 22:26:16 INFO BlockManager: Dropping block rdd_27_2 from memory
17/03/27 22:26:16 INFO BlockManagerInfo: Removed rdd_27_2 on localhost:53930 in memory (size: 540.2 MB, free: 2.0 GB)
17/03/27 22:26:17 INFO MemoryStore: Will not store rdd_15_3 as it would require dropping another block from the same RDD
17/03/27 22:26:17 WARN MemoryStore: Not enough space to cache rdd_15_3 in memory! (computed 476.3 MB so far)
17/03/27 22:26:17 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1623.0 MB (scratch space shared across 6 tasks(s)) = 1623.0 MB. Storage limit = 2.0 GB.
17/03/27 22:26:17 INFO CacheManager: Partition rdd_27_3 not found, computing it
17/03/27 22:26:17 INFO CacheManager: Partition rdd_15_3 not found, computing it
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:17 INFO MemoryStore: Will not store rdd_15_1 as it would require dropping another block from the same RDD
17/03/27 22:26:17 WARN MemoryStore: Not enough space to cache rdd_15_1 in memory! (computed 476.3 MB so far)
17/03/27 22:26:17 INFO MemoryStore: Memory use = 0.0 B (blocks) + 1624.0 MB (scratch space shared across 6 tasks(s)) = 1624.0 MB. Storage limit = 2.0 GB.
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 16 took 0 ms
17/03/27 22:26:17 INFO MemoryStore: Block rdd_15_0 stored as values in memory (estimated size 476.3 MB, free 1571.9 MB)
17/03/27 22:26:17 INFO BlockManagerInfo: Added rdd_15_0 in memory on localhost:53930 (size: 476.3 MB, free: 1571.9 MB)
17/03/27 22:26:17 INFO CacheManager: Partition rdd_27_0 not found, computing it
17/03/27 22:26:17 INFO BlockManager: Found block rdd_15_0 locally
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:17 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 16 took 1 ms
17/03/27 22:26:17 INFO MemoryStore: Block rdd_29_2 stored as values in memory (estimated size 476.3 MB, free 1095.6 MB)
17/03/27 22:26:17 INFO BlockManagerInfo: Added rdd_29_2 in memory on localhost:53930 (size: 476.3 MB, free: 1095.6 MB)
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:17 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 30 took 0 ms
17/03/27 22:26:17 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:17 INFO BlockManager: Dropping block rdd_15_0 from memory
17/03/27 22:26:17 INFO BlockManagerInfo: Removed rdd_15_0 on localhost:53930 in memory (size: 476.3 MB, free: 1571.9 MB)
17/03/27 22:26:17 INFO MemoryStore: Will not store rdd_27_0 as it would require dropping another block from the same RDD
17/03/27 22:26:17 WARN MemoryStore: Not enough space to cache rdd_27_0 in memory! (computed 476.3 MB so far)
17/03/27 22:26:17 INFO MemoryStore: Memory use = 476.3 MB (blocks) + 1432.9 MB (scratch space shared across 6 tasks(s)) = 1909.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:17 INFO SetRDDHashSetPartition: Union set size 2 for rdd 16 took 0 ms
17/03/27 22:26:17 INFO MemoryStore: Will not store rdd_37_2 as it would require dropping another block from the same RDD
17/03/27 22:26:17 WARN MemoryStore: Not enough space to cache rdd_37_2 in memory! (computed 476.3 MB so far)
17/03/27 22:26:17 INFO MemoryStore: Memory use = 476.3 MB (blocks) + 1433.9 MB (scratch space shared across 6 tasks(s)) = 1910.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:17 INFO Executor: Finished task 2.0 in stage 7.0 (TID 35). 4212 bytes result sent to driver
17/03/27 22:26:17 INFO TaskSetManager: Starting task 4.0 in stage 7.0 (TID 39, localhost, partition 4,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:17 INFO Executor: Running task 4.0 in stage 7.0 (TID 39)
17/03/27 22:26:17 INFO TaskSetManager: Finished task 2.0 in stage 7.0 (TID 35) in 1398 ms on localhost (1/5)
17/03/27 22:26:17 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 16.3 KB, free 1571.9 MB)
17/03/27 22:26:17 INFO CacheManager: Partition rdd_37_4 not found, computing it
17/03/27 22:26:17 INFO CacheManager: Partition rdd_29_4 not found, computing it
17/03/27 22:26:17 INFO CacheManager: Partition rdd_15_4 not found, computing it
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:17 INFO MemoryStore: Block rdd_15_3 stored as values in memory (estimated size 478.8 MB, free 1093.1 MB)
17/03/27 22:26:17 INFO BlockManagerInfo: Added rdd_15_3 in memory on localhost:53930 (size: 478.8 MB, free: 1093.1 MB)
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:17 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 16 took 1 ms
17/03/27 22:26:18 INFO MemoryStore: Block rdd_27_1 stored as values in memory (estimated size 478.8 MB, free 614.3 MB)
17/03/27 22:26:18 INFO BlockManagerInfo: Added rdd_27_1 in memory on localhost:53930 (size: 478.8 MB, free: 614.3 MB)
17/03/27 22:26:18 INFO SetRDDHashSetPartition: Union set size 0 for rdd 16 took 0 ms
17/03/27 22:26:18 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:18 INFO BlockManager: Dropping block broadcast_9 from memory
17/03/27 22:26:18 INFO BlockManager: Dropping block rdd_15_3 from memory
17/03/27 22:26:18 INFO BlockManagerInfo: Removed rdd_15_3 on localhost:53930 in memory (size: 478.8 MB, free: 1093.1 MB)
17/03/27 22:26:18 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:18 INFO BlockManager: Dropping block rdd_29_2 from memory
17/03/27 22:26:18 INFO BlockManagerInfo: Removed rdd_29_2 on localhost:53930 in memory (size: 476.3 MB, free: 1569.5 MB)
17/03/27 22:26:18 INFO MemoryStore: Will not store rdd_27_3 as it would require dropping another block from the same RDD
17/03/27 22:26:18 WARN MemoryStore: Not enough space to cache rdd_27_3 in memory! (computed 478.8 MB so far)
17/03/27 22:26:18 INFO MemoryStore: Memory use = 478.8 MB (blocks) + 1441.3 MB (scratch space shared across 6 tasks(s)) = 1920.1 MB. Storage limit = 2.0 GB.
17/03/27 22:26:18 INFO SetRDDHashSetPartition: Union set size 3 for rdd 16 took 0 ms
17/03/27 22:26:18 INFO MemoryStore: Will not store rdd_29_1 as it would require dropping another block from the same RDD
17/03/27 22:26:18 WARN MemoryStore: Not enough space to cache rdd_29_1 in memory! (computed 476.2 MB so far)
17/03/27 22:26:18 INFO MemoryStore: Memory use = 478.8 MB (blocks) + 1442.3 MB (scratch space shared across 6 tasks(s)) = 1921.1 MB. Storage limit = 2.0 GB.
17/03/27 22:26:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:26:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 30 took 0 ms
17/03/27 22:26:18 INFO MemoryStore: Block rdd_29_0 stored as values in memory (estimated size 476.2 MB, free 1093.2 MB)
17/03/27 22:26:18 INFO BlockManagerInfo: Added rdd_29_0 in memory on localhost:53930 (size: 476.2 MB, free: 1093.2 MB)
17/03/27 22:26:18 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:26:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 30 took 0 ms
17/03/27 22:26:18 INFO MemoryStore: Block rdd_15_4 stored as values in memory (estimated size 476.2 MB, free 617.0 MB)
17/03/27 22:26:18 INFO BlockManagerInfo: Added rdd_15_4 in memory on localhost:53930 (size: 476.2 MB, free: 617.0 MB)
17/03/27 22:26:18 INFO CacheManager: Partition rdd_27_4 not found, computing it
17/03/27 22:26:18 INFO BlockManager: Found block rdd_15_4 locally
17/03/27 22:26:18 INFO ShuffleBlockFetcherIterator: Getting 2 non-empty blocks out of 5 blocks
17/03/27 22:26:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:18 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 16 took 1 ms
17/03/27 22:26:18 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:18 INFO BlockManager: Dropping block rdd_27_1 from memory
17/03/27 22:26:18 INFO BlockManagerInfo: Removed rdd_27_1 on localhost:53930 in memory (size: 478.8 MB, free: 1095.8 MB)
17/03/27 22:26:19 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:19 INFO BlockManager: Dropping block rdd_29_0 from memory
17/03/27 22:26:19 INFO BlockManagerInfo: Removed rdd_29_0 on localhost:53930 in memory (size: 476.2 MB, free: 1572.0 MB)
17/03/27 22:26:19 INFO MemoryStore: Will not store rdd_37_0 as it would require dropping another block from the same RDD
17/03/27 22:26:19 WARN MemoryStore: Not enough space to cache rdd_37_0 in memory! (computed 476.2 MB so far)
17/03/27 22:26:19 INFO MemoryStore: Memory use = 476.2 MB (blocks) + 1435.7 MB (scratch space shared across 6 tasks(s)) = 1911.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 36). 4072 bytes result sent to driver
17/03/27 22:26:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 36) in 2734 ms on localhost (2/5)
17/03/27 22:26:19 INFO MemoryStore: Will not store rdd_27_4 as it would require dropping another block from the same RDD
17/03/27 22:26:19 WARN MemoryStore: Not enough space to cache rdd_27_4 in memory! (computed 476.2 MB so far)
17/03/27 22:26:19 INFO MemoryStore: Memory use = 476.2 MB (blocks) + 1433.7 MB (scratch space shared across 5 tasks(s)) = 1909.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:19 INFO SetRDDHashSetPartition: Union set size 1 for rdd 16 took 0 ms
17/03/27 22:26:19 INFO MemoryStore: Block rdd_29_3 stored as values in memory (estimated size 476.2 MB, free 1095.8 MB)
17/03/27 22:26:19 INFO BlockManagerInfo: Added rdd_29_3 in memory on localhost:53930 (size: 476.2 MB, free: 1095.8 MB)
17/03/27 22:26:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:26:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:19 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 30 took 0 ms
17/03/27 22:26:19 INFO MemoryStore: Block rdd_37_1 stored as values in memory (estimated size 476.2 MB, free 619.6 MB)
17/03/27 22:26:19 INFO BlockManagerInfo: Added rdd_37_1 in memory on localhost:53930 (size: 476.2 MB, free: 619.6 MB)
17/03/27 22:26:19 INFO Executor: Finished task 1.0 in stage 7.0 (TID 37). 2774 bytes result sent to driver
17/03/27 22:26:19 INFO TaskSetManager: Finished task 1.0 in stage 7.0 (TID 37) in 3067 ms on localhost (3/5)
17/03/27 22:26:19 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:19 INFO BlockManager: Dropping block rdd_15_4 from memory
17/03/27 22:26:19 INFO BlockManagerInfo: Removed rdd_15_4 on localhost:53930 in memory (size: 476.2 MB, free: 1095.9 MB)
17/03/27 22:26:19 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:19 INFO BlockManager: Dropping block rdd_29_3 from memory
17/03/27 22:26:19 INFO BlockManagerInfo: Removed rdd_29_3 on localhost:53930 in memory (size: 476.2 MB, free: 1572.1 MB)
17/03/27 22:26:19 INFO MemoryStore: Block rdd_29_4 stored as values in memory (estimated size 476.2 MB, free 1095.9 MB)
17/03/27 22:26:19 INFO BlockManagerInfo: Added rdd_29_4 in memory on localhost:53930 (size: 476.2 MB, free: 1095.9 MB)
17/03/27 22:26:19 INFO ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 5 blocks
17/03/27 22:26:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:19 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 30 took 0 ms
17/03/27 22:26:20 INFO MemoryStore: Block rdd_37_3 stored as values in memory (estimated size 476.2 MB, free 619.8 MB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added rdd_37_3 in memory on localhost:53930 (size: 476.2 MB, free: 619.8 MB)
17/03/27 22:26:20 INFO Executor: Finished task 3.0 in stage 7.0 (TID 38). 2820 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 3.0 in stage 7.0 (TID 38) in 3558 ms on localhost (4/5)
17/03/27 22:26:20 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:20 INFO BlockManager: Dropping block rdd_29_4 from memory
17/03/27 22:26:20 INFO BlockManagerInfo: Removed rdd_29_4 on localhost:53930 in memory (size: 476.2 MB, free: 1095.9 MB)
17/03/27 22:26:20 INFO MemoryStore: Block rdd_37_4 stored as values in memory (estimated size 475.8 MB, free 620.1 MB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added rdd_37_4 in memory on localhost:53930 (size: 475.8 MB, free: 620.1 MB)
17/03/27 22:26:20 INFO Executor: Finished task 4.0 in stage 7.0 (TID 39). 4021 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 4.0 in stage 7.0 (TID 39) in 2678 ms on localhost (5/5)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/03/27 22:26:20 INFO DAGScheduler: FixedPointResultStage 7 (runFixedPointJob at Recursion.scala:204) finished in 4.075 s
17/03/27 22:26:20 INFO DAGScheduler: Fixed Point reached for job 2
17/03/27 22:26:20 INFO DAGScheduler: Fixed Point Job 2 finished: runFixedPointJob at Recursion.scala:204, took 7.332600 s
17/03/27 22:26:20 INFO SparkContext: Starting job: collect at QuerySuite.scala:64
17/03/27 22:26:20 INFO DAGScheduler: Got job 3 (collect at QuerySuite.scala:64) with 5 output partitions
17/03/27 22:26:20 INFO DAGScheduler: Final stage: ResultStage 8 (collect at QuerySuite.scala:64)
17/03/27 22:26:20 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:20 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:20 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[40] at mapPartitions at SetRDD.scala:85), which has no missing parents
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 4.3 KB, free 620.1 MB)
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 2.4 KB, free 620.1 MB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:53930 (size: 2.4 KB, free: 620.1 MB)
17/03/27 22:26:20 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:20 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 8 (MapPartitionsRDD[40] at mapPartitions at SetRDD.scala:85)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Adding task set 8.0 with 5 tasks
17/03/27 22:26:20 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 40, localhost, partition 0,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 41, localhost, partition 1,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 42, localhost, partition 2,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 43, localhost, partition 3,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:26:20 INFO Executor: Running task 0.0 in stage 8.0 (TID 40)
17/03/27 22:26:20 INFO Executor: Running task 1.0 in stage 8.0 (TID 41)
17/03/27 22:26:20 INFO Executor: Running task 2.0 in stage 8.0 (TID 42)
17/03/27 22:26:20 INFO Executor: Running task 3.0 in stage 8.0 (TID 43)
17/03/27 22:26:20 INFO CacheManager: Partition rdd_29_1 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_29_3 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_29_2 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_29_0 not found, computing it
17/03/27 22:26:20 ERROR Executor: Exception in task 1.0 in stage 8.0 (TID 41)
org.apache.spark.SparkException: Checkpoint block rdd_29_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:20 ERROR Executor: Exception in task 2.0 in stage 8.0 (TID 42)
org.apache.spark.SparkException: Checkpoint block rdd_29_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:20 ERROR Executor: Exception in task 3.0 in stage 8.0 (TID 43)
org.apache.spark.SparkException: Checkpoint block rdd_29_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:20 ERROR Executor: Exception in task 0.0 in stage 8.0 (TID 40)
org.apache.spark.SparkException: Checkpoint block rdd_29_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 4.0 in stage 8.0 (TID 44, localhost, partition 4,PROCESS_LOCAL, 1855 bytes)
17/03/27 22:26:20 INFO Executor: Running task 4.0 in stage 8.0 (TID 44)
17/03/27 22:26:20 WARN TaskSetManager: Lost task 1.0 in stage 8.0 (TID 41, localhost): org.apache.spark.SparkException: Checkpoint block rdd_29_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:20 ERROR TaskSetManager: Task 1 in stage 8.0 failed 1 times; aborting job
17/03/27 22:26:20 WARN TaskSetManager: Lost task 3.0 in stage 8.0 (TID 43, localhost): org.apache.spark.SparkException: Checkpoint block rdd_29_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:20 WARN TaskSetManager: Lost task 0.0 in stage 8.0 (TID 40, localhost): org.apache.spark.SparkException: Checkpoint block rdd_29_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:20 WARN TaskSetManager: Lost task 2.0 in stage 8.0 (TID 42, localhost): org.apache.spark.SparkException: Checkpoint block rdd_29_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:20 INFO CacheManager: Partition rdd_29_4 not found, computing it
17/03/27 22:26:20 INFO TaskSchedulerImpl: Cancelling stage 8
17/03/27 22:26:20 INFO TaskSchedulerImpl: Stage 8 was cancelled
17/03/27 22:26:20 INFO DAGScheduler: ResultStage 8 (collect at QuerySuite.scala:64) failed in 0.003 s
17/03/27 22:26:20 INFO Executor: Executor is trying to kill task 4.0 in stage 8.0 (TID 44)
17/03/27 22:26:20 ERROR Executor: Exception in task 4.0 in stage 8.0 (TID 44)
org.apache.spark.SparkException: Checkpoint block rdd_29_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:20 INFO DAGScheduler: Job 3 failed: collect at QuerySuite.scala:64, took 0.006423 s
17/03/27 22:26:20 WARN TaskSetManager: Lost task 4.0 in stage 8.0 (TID 44, localhost): org.apache.spark.SparkException: Checkpoint block rdd_29_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

[31m- Same Generation Queries *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 8.0 failed 1 times, most recent failure: Lost task 1.0 in stage 8.0 (TID 41, localhost): org.apache.spark.SparkException: Checkpoint block rdd_29_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
17/03/27 22:26:20 INFO SparkContext: Running Spark version 1.6.3
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_29_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
17/03/27 22:26:20 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)[0m
[31m  ...[0m
17/03/27 22:26:20 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:26:20 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:26:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:26:20 INFO Utils: Successfully started service 'sparkDriver' on port 53960.
17/03/27 22:26:20 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:26:20 INFO Remoting: Starting remoting
17/03/27 22:26:20 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:53973]
17/03/27 22:26:20 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 53973.
17/03/27 22:26:20 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:26:20 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:26:20 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-fa286159-c64d-47be-8e49-61d02bb81b78
17/03/27 22:26:20 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:26:20 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:26:20 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:26:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53990.
17/03/27 22:26:20 INFO NettyBlockTransferService: Server created on 53990
17/03/27 22:26:20 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:26:20 INFO BlockManagerMasterEndpoint: Registering block manager localhost:53990 with 2.0 GB RAM, BlockManagerId(driver, localhost, 53990)
17/03/27 22:26:20 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:26:20 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667980603
17/03/27 22:26:20 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$8.apply$mcV$sp(RecursiveQuerySuites.scala:144)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$8.apply(RecursiveQuerySuites.scala:132)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$8.apply(RecursiveQuerySuites.scala:132)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$9.apply$mcV$sp(RecursiveQuerySuites.scala:176)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$9.apply(RecursiveQuerySuites.scala:147)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$9.apply(RecursiveQuerySuites.scala:147)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:26:20 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:26:20 INFO BigDatalogContext: BigDatalog Query: "network_tc(A,B)"
17/03/27 22:26:20 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:26:20 INFO BigDatalogContext: 
0: network_tc(M, NM) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: network_tc(M, M) <UNION>
  2: (M, M) <PROJECT>
   3: sponsor(M, NM) <BASE_RELATION>
  2: (NM, NM) <PROJECT>
   3: sponsor(M, NM) <BASE_RELATION>
Recursive Rules: 
 1: (M, NM) <DISTINCT PROJECT>
  2: (0.M1 = 1.M) <JOIN>
   3: network_tc(M, M1) <RECURSIVE_RELATION>
   3: sponsor(M, NM) <BASE_RELATION>
17/03/27 22:26:20 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:26:20 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:26:20 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery network_tc
+- 'Recursion network_tc, true, [1,0]
   :- 'Distinct
   :  +- 'Subquery network_tc
   :     +- 'Union
   :        :- 'Project ['sponsor.M,'sponsor.M]
   :        :  +- 'UnresolvedRelation `sponsor`, None
   :        +- 'Project ['sponsor1.NM,'sponsor1.NM]
   :           +- 'Subquery sponsor1
   :              +- 'Project [*]
   :                 +- 'UnresolvedRelation `sponsor`, None
   +- 'Project ['network_tc2.M,'sponsor3.NM]
      +- 'Join Inner, Some(('network_tc2.M1 = 'sponsor3.M))
         :- Subquery network_tc2
         :  +- LinearRecursiveRelation network_tc, [M#787,M1#788], [1,0]
         +- 'BroadcastHint
            +- 'Subquery sponsor3
               +- 'Project [*]
                  +- 'UnresolvedRelation `sponsor`, None

== Analyzed Logical Plan ==
M: int, NM: int
Subquery network_tc
+- Recursion network_tc, true, [1,0]
   :- Distinct
   :  +- Subquery network_tc
   :     +- Union
   :        :- Project [M#777,M#777]
   :        :  +- Subquery sponsor
   :        :     +- LogicalRDD [M#777,NM#778], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   :        +- Project [NM#778,NM#778]
   :           +- Subquery sponsor1
   :              +- Project [M#777,NM#778]
   :                 +- Subquery sponsor
   :                    +- LogicalRDD [M#777,NM#778], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [M#787,NM#778]
      +- Join Inner, Some((M1#788 = M#777))
         :- Subquery network_tc2
         :  +- LinearRecursiveRelation network_tc, [M#787,M1#788], [1,0]
         +- BroadcastHint
            +- Subquery sponsor3
               +- Project [M#777,NM#778]
                  +- Subquery sponsor
                     +- LogicalRDD [M#777,NM#778], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion network_tc, true, [1,0]
:- Aggregate [M#777,M#777], [M#777,M#777]
:  +- Union
:     :- Project [M#777,M#777]
:     :  +- LogicalRDD [M#777,NM#778], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
:     +- Project [NM#778,NM#778]
:        +- LogicalRDD [M#777,NM#778], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [M#787,NM#778]
   +- Join Inner, Some((M1#788 = M#777))
      :- LinearRecursiveRelation network_tc, [M#787,M1#788], [1,0]
      +- BroadcastHint
         +- Project [M#777,NM#778]
            +- LogicalRDD [M#777,NM#778], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [M#787,NM#778] (Linear) [network_tc][1,0]
:- TungstenExchange hashpartitioning(M#777,5), None
:  +- TungstenAggregate(key=[M#777,M#777], functions=[], output=[M#777,M#777])
:     +- TungstenExchange hashpartitioning(M#777,M#777,5), None
:        +- TungstenAggregate(key=[M#777,M#777], functions=[], output=[M#777,M#777])
:           +- Union
:              :- Project [M#777,M#777]
:              :  +- Scan ExistingRDD[M#777,NM#778] 
:              +- Project [NM#778,NM#778]
:                 +- Scan ExistingRDD[M#777,NM#778] 
+- Project [M#787,NM#778]
   +- BroadcastHashJoin [M1#788], [M#777], BuildRight
      :- LinearRecursiveRelation [M#787,M1#788](network_tc)
      +- Project [M#777,NM#778]
         +- Scan ExistingRDD[M#777,NM#778]
17/03/27 22:26:20 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:26:20 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:26:20 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:26:20 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:26:20 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:20 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:26:20 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:26:20 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:20 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:20 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[16] at run at null:-1), which has no missing parents
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:53990 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:20 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[16] at run at null:-1)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:26:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2074 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:26:20 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:26:20 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:26:20 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1443 bytes result sent to driver
17/03/27 22:26:20 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1214 bytes result sent to driver
17/03/27 22:26:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1214 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:20 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:26:20 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1443 bytes result sent to driver
17/03/27 22:26:20 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 7 ms on localhost (1/5)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 7 ms on localhost (2/5)
17/03/27 22:26:20 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1443 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 8 ms on localhost (3/5)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8 ms on localhost (4/5)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 3 ms on localhost (5/5)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:26:20 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.008 s
17/03/27 22:26:20 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.010292 s
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 648.0 B, free 2.0 GB)
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 178.0 B, free 2.0 GB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:53990 (size: 178.0 B, free: 2.0 GB)
17/03/27 22:26:20 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:26:20 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:20 INFO Recursion: Fixed Point Iteration # 1, time: 28ms
17/03/27 22:26:20 INFO DAGScheduler: Registering RDD 8 (execute at Recursion.scala:189)
17/03/27 22:26:20 INFO DAGScheduler: Registering RDD 11 (execute at Recursion.scala:189)
17/03/27 22:26:20 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:26:20 INFO DAGScheduler: Final stage: FixedPointResultStage 3 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:26:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
17/03/27 22:26:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 2)
17/03/27 22:26:20 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[8] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 8.5 KB, free 2.0 GB)
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 4.3 KB, free 2.0 GB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:53990 (size: 4.3 KB, free: 2.0 GB)
17/03/27 22:26:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:20 INFO DAGScheduler: Submitting 10 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[8] at execute at Recursion.scala:189)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 10 tasks
17/03/27 22:26:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:26:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:26:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:26:20 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:26:20 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:26:20 INFO GenerateMutableProjection: Code generated in 10.96893 ms
17/03/27 22:26:20 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1529 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:26:20 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 24 ms on localhost (1/10)
17/03/27 22:26:20 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1529 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 5.0 in stage 1.0 (TID 10, localhost, partition 5,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:26:20 INFO Executor: Running task 5.0 in stage 1.0 (TID 10)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 28 ms on localhost (2/10)
17/03/27 22:26:20 INFO Executor: Finished task 5.0 in stage 1.0 (TID 10). 1529 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 6.0 in stage 1.0 (TID 11, localhost, partition 6,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 5.0 in stage 1.0 (TID 10) in 4 ms on localhost (3/10)
17/03/27 22:26:20 INFO Executor: Running task 6.0 in stage 1.0 (TID 11)
17/03/27 22:26:20 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1538 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 7.0 in stage 1.0 (TID 12, localhost, partition 7,PROCESS_LOCAL, 2172 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 13 ms on localhost (4/10)
17/03/27 22:26:20 INFO Executor: Running task 7.0 in stage 1.0 (TID 12)
17/03/27 22:26:20 INFO Executor: Finished task 7.0 in stage 1.0 (TID 12). 1529 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 8.0 in stage 1.0 (TID 13, localhost, partition 8,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 7.0 in stage 1.0 (TID 12) in 4 ms on localhost (5/10)
17/03/27 22:26:20 INFO Executor: Running task 8.0 in stage 1.0 (TID 13)
17/03/27 22:26:20 INFO Executor: Finished task 6.0 in stage 1.0 (TID 11). 1538 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 9.0 in stage 1.0 (TID 14, localhost, partition 9,PROCESS_LOCAL, 2419 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 6.0 in stage 1.0 (TID 11) in 14 ms on localhost (6/10)
17/03/27 22:26:20 INFO Executor: Running task 9.0 in stage 1.0 (TID 14)
17/03/27 22:26:20 INFO Executor: Finished task 9.0 in stage 1.0 (TID 14). 1538 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 9.0 in stage 1.0 (TID 14) in 25 ms on localhost (7/10)
17/03/27 22:26:20 INFO Executor: Finished task 8.0 in stage 1.0 (TID 13). 1538 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 8.0 in stage 1.0 (TID 13) in 31 ms on localhost (8/10)
17/03/27 22:26:20 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1538 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 73 ms on localhost (9/10)
17/03/27 22:26:20 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1538 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 75 ms on localhost (10/10)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:26:20 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.075 s
17/03/27 22:26:20 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:20 INFO DAGScheduler: running: Set()
17/03/27 22:26:20 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, FixedPointResultStage 3)
17/03/27 22:26:20 INFO DAGScheduler: failed: Set()
17/03/27 22:26:20 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[11] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 9.0 KB, free 2.0 GB)
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 4.5 KB, free 2.0 GB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:53990 (size: 4.5 KB, free: 2.0 GB)
17/03/27 22:26:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:20 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[11] at execute at Recursion.scala:189)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:26:20 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 15, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 16, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 17, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 18, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:20 INFO Executor: Running task 0.0 in stage 2.0 (TID 15)
17/03/27 22:26:20 INFO Executor: Running task 2.0 in stage 2.0 (TID 17)
17/03/27 22:26:20 INFO Executor: Running task 1.0 in stage 2.0 (TID 16)
17/03/27 22:26:20 INFO Executor: Running task 3.0 in stage 2.0 (TID 18)
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:20 INFO Executor: Finished task 3.0 in stage 2.0 (TID 18). 1917 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 19, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:20 INFO Executor: Running task 4.0 in stage 2.0 (TID 19)
17/03/27 22:26:20 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 18) in 7 ms on localhost (1/5)
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 6 non-empty blocks out of 10 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:20 INFO Executor: Finished task 1.0 in stage 2.0 (TID 16). 1926 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 16) in 15 ms on localhost (2/5)
17/03/27 22:26:20 INFO Executor: Finished task 2.0 in stage 2.0 (TID 17). 1926 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 17) in 17 ms on localhost (3/5)
17/03/27 22:26:20 INFO Executor: Finished task 0.0 in stage 2.0 (TID 15). 1926 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 15) in 18 ms on localhost (4/5)
17/03/27 22:26:20 INFO Executor: Finished task 4.0 in stage 2.0 (TID 19). 1926 bytes result sent to driver
17/03/27 22:26:20 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 19) in 16 ms on localhost (5/5)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:26:20 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:189) finished in 0.024 s
17/03/27 22:26:20 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:20 INFO DAGScheduler: running: Set()
17/03/27 22:26:20 INFO DAGScheduler: waiting: Set(FixedPointResultStage 3)
17/03/27 22:26:20 INFO DAGScheduler: failed: Set()
17/03/27 22:26:20 INFO DAGScheduler: Submitting FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[26] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.3 KB, free 2.0 GB)
17/03/27 22:26:20 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 7.6 KB, free 2.0 GB)
17/03/27 22:26:20 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:53990 (size: 7.6 KB, free: 2.0 GB)
17/03/27 22:26:20 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:20 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 3 (SetRDD.diffRDD SetRDD[26] at RDD at SetRDD.scala:30)
17/03/27 22:26:20 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:26:20 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 20, localhost, partition 0,NODE_LOCAL, 2374 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 21, localhost, partition 1,NODE_LOCAL, 2374 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 22, localhost, partition 2,NODE_LOCAL, 2374 bytes)
17/03/27 22:26:20 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2374 bytes)
17/03/27 22:26:20 INFO Executor: Running task 1.0 in stage 3.0 (TID 21)
17/03/27 22:26:20 INFO Executor: Running task 3.0 in stage 3.0 (TID 23)
17/03/27 22:26:20 INFO Executor: Running task 2.0 in stage 3.0 (TID 22)
17/03/27 22:26:20 INFO Executor: Running task 0.0 in stage 3.0 (TID 20)
17/03/27 22:26:20 INFO CacheManager: Partition rdd_25_2 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_25_1 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_25_3 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_21_2 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_21_1 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_21_3 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_25_0 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_13_2 not found, computing it
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:20 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:26:20 INFO CacheManager: Partition rdd_21_0 not found, computing it
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:20 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:20 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:21 INFO MemoryStore: Will not store rdd_13_0 as it would require dropping another block from the same RDD
17/03/27 22:26:21 WARN MemoryStore: Not enough space to cache rdd_13_0 in memory! (computed 478.4 MB so far)
17/03/27 22:26:21 INFO MemoryStore: Memory use = 58.7 KB (blocks) + 1437.2 MB (scratch space shared across 5 tasks(s)) = 1437.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:21 INFO CacheManager: Partition rdd_19_0 not found, computing it
17/03/27 22:26:21 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:26:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:21 INFO MemoryStore: Will not store rdd_13_3 as it would require dropping another block from the same RDD
17/03/27 22:26:21 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 478.4 MB so far)
17/03/27 22:26:21 INFO MemoryStore: Memory use = 58.7 KB (blocks) + 1438.2 MB (scratch space shared across 5 tasks(s)) = 1438.2 MB. Storage limit = 2.0 GB.
17/03/27 22:26:21 INFO CacheManager: Partition rdd_19_3 not found, computing it
17/03/27 22:26:21 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:26:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:21 INFO MemoryStore: Block rdd_13_2 stored as values in memory (estimated size 478.3 MB, free 1569.9 MB)
17/03/27 22:26:21 INFO BlockManagerInfo: Added rdd_13_2 in memory on localhost:53990 (size: 478.3 MB, free: 1569.9 MB)
17/03/27 22:26:21 INFO CacheManager: Partition rdd_19_2 not found, computing it
17/03/27 22:26:21 INFO BlockManager: Found block rdd_13_2 locally
17/03/27 22:26:21 INFO BlockManager: Found block rdd_13_2 locally
17/03/27 22:26:21 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:26:21 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 478.3 MB, free 1091.6 MB)
17/03/27 22:26:21 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:53990 (size: 478.3 MB, free: 1091.7 MB)
17/03/27 22:26:21 INFO CacheManager: Partition rdd_19_1 not found, computing it
17/03/27 22:26:21 INFO BlockManager: Found block rdd_13_1 locally
17/03/27 22:26:21 INFO BlockManager: Found block rdd_13_1 locally
17/03/27 22:26:21 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 14 took 0 ms
17/03/27 22:26:21 INFO MemoryStore: Will not store rdd_13_3 as it would require dropping another block from the same RDD
17/03/27 22:26:21 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 478.2 MB so far)
17/03/27 22:26:21 INFO MemoryStore: Memory use = 956.6 MB (blocks) + 722.4 MB (scratch space shared across 5 tasks(s)) = 1679.0 MB. Storage limit = 2.0 GB.
17/03/27 22:26:21 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:26:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:22 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 478.2 MB, free 613.4 MB)
17/03/27 22:26:22 INFO BlockManagerInfo: Added rdd_13_0 in memory on localhost:53990 (size: 478.2 MB, free: 613.4 MB)
17/03/27 22:26:22 INFO BlockManager: Found block rdd_13_0 locally
17/03/27 22:26:22 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:26:22 INFO MemoryStore: 10 blocks selected for dropping
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_0_piece0 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_0_piece0 to disk
17/03/27 22:26:22 INFO BlockManagerInfo: Added broadcast_0_piece0 on disk on localhost:53990 (size: 2.7 KB)
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_0 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_0 to disk
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:26:22 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:53990 (size: 178.0 B)
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_2_piece0 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_2_piece0 to disk
17/03/27 22:26:22 INFO BlockManagerInfo: Added broadcast_2_piece0 on disk on localhost:53990 (size: 4.3 KB)
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_2 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_2 to disk
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:26:22 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:53990 (size: 4.5 KB)
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:26:22 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:53990 (size: 7.6 KB)
17/03/27 22:26:22 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:22 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:26:22 INFO BlockManager: Dropping block rdd_13_2 from memory
17/03/27 22:26:22 INFO BlockManagerInfo: Removed rdd_13_2 on localhost:53990 in memory (size: 478.3 MB, free: 1091.7 MB)
17/03/27 22:26:22 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:22 INFO BlockManager: Dropping block rdd_13_1 from memory
17/03/27 22:26:22 INFO BlockManagerInfo: Removed rdd_13_1 on localhost:53990 in memory (size: 478.3 MB, free: 1570.0 MB)
17/03/27 22:26:22 INFO MemoryStore: Will not store rdd_13_3 as it would require dropping another block from the same RDD
17/03/27 22:26:22 WARN MemoryStore: Not enough space to cache rdd_13_3 in memory! (computed 478.2 MB so far)
17/03/27 22:26:22 INFO MemoryStore: Memory use = 478.2 MB (blocks) + 1439.7 MB (scratch space shared across 5 tasks(s)) = 1917.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:22 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 0 ms
17/03/27 22:26:22 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:53990 on disk (size: 4.5 KB)
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1484
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1483
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1482
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1481
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1480
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1479
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1478
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1477
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1476
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1475
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1474
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1473
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1472
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1471
17/03/27 22:26:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:53990 on disk (size: 4.3 KB)
17/03/27 22:26:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:53990 on disk (size: 2.7 KB)
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1501
17/03/27 22:26:22 INFO ContextCleaner: Cleaned accumulator 1500
17/03/27 22:26:22 INFO MemoryStore: Will not store rdd_19_0 as it would require dropping another block from the same RDD
17/03/27 22:26:22 WARN MemoryStore: Not enough space to cache rdd_19_0 in memory! (computed 480.6 MB so far)
17/03/27 22:26:22 INFO MemoryStore: Memory use = 478.2 MB (blocks) + 1440.7 MB (scratch space shared across 5 tasks(s)) = 1918.9 MB. Storage limit = 2.0 GB.
17/03/27 22:26:22 INFO SetRDDHashSetPartition: Union set size 3 for rdd 14 took 0 ms
17/03/27 22:26:22 INFO MemoryStore: Block rdd_19_1 stored as values in memory (estimated size 480.6 MB, free 1089.4 MB)
17/03/27 22:26:22 INFO BlockManagerInfo: Added rdd_19_1 in memory on localhost:53990 (size: 480.6 MB, free: 1089.4 MB)
17/03/27 22:26:22 INFO SetRDDHashSetPartition: Union set size 2 for rdd 14 took 0 ms
17/03/27 22:26:22 INFO MemoryStore: Block rdd_19_2 stored as values in memory (estimated size 480.6 MB, free 608.8 MB)
17/03/27 22:26:22 INFO BlockManagerInfo: Added rdd_19_2 in memory on localhost:53990 (size: 480.6 MB, free: 608.8 MB)
17/03/27 22:26:22 INFO SetRDDHashSetPartition: Union set size 1 for rdd 14 took 0 ms
17/03/27 22:26:22 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:22 INFO BlockManager: Dropping block rdd_13_0 from memory
17/03/27 22:26:22 INFO BlockManagerInfo: Removed rdd_13_0 on localhost:53990 in memory (size: 478.2 MB, free: 1087.0 MB)
17/03/27 22:26:23 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:23 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:23 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:26:23 INFO BlockManager: Dropping block rdd_19_1 from memory
17/03/27 22:26:23 INFO BlockManagerInfo: Removed rdd_19_1 on localhost:53990 in memory (size: 480.6 MB, free: 1567.6 MB)
17/03/27 22:26:23 INFO MemoryStore: Will not store rdd_21_1 as it would require dropping another block from the same RDD
17/03/27 22:26:23 WARN MemoryStore: Not enough space to cache rdd_21_1 in memory! (computed 478.2 MB so far)
17/03/27 22:26:23 INFO MemoryStore: Memory use = 480.6 MB (blocks) + 1445.1 MB (scratch space shared across 5 tasks(s)) = 1925.8 MB. Storage limit = 2.0 GB.
17/03/27 22:26:23 INFO CacheManager: Partition rdd_19_1 not found, computing it
17/03/27 22:26:23 INFO CacheManager: Partition rdd_13_1 not found, computing it
17/03/27 22:26:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:23 INFO MemoryStore: Will not store rdd_21_2 as it would require dropping another block from the same RDD
17/03/27 22:26:23 WARN MemoryStore: Not enough space to cache rdd_21_2 in memory! (computed 478.2 MB so far)
17/03/27 22:26:23 INFO MemoryStore: Memory use = 480.6 MB (blocks) + 1446.1 MB (scratch space shared across 5 tasks(s)) = 1926.8 MB. Storage limit = 2.0 GB.
17/03/27 22:26:23 INFO BlockManager: Found block rdd_19_2 locally
17/03/27 22:26:23 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 22 took 0 ms
17/03/27 22:26:23 INFO MemoryStore: Block rdd_19_3 stored as values in memory (estimated size 478.2 MB, free 1089.5 MB)
17/03/27 22:26:23 INFO BlockManagerInfo: Added rdd_19_3 in memory on localhost:53990 (size: 478.2 MB, free: 1089.5 MB)
17/03/27 22:26:23 INFO SetRDDHashSetPartition: Union set size 1 for rdd 14 took 0 ms
17/03/27 22:26:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:23 INFO BlockManager: Dropping block rdd_19_2 from memory
17/03/27 22:26:23 INFO BlockManagerInfo: Removed rdd_19_2 on localhost:53990 in memory (size: 480.6 MB, free: 1570.1 MB)
17/03/27 22:26:23 INFO MemoryStore: Block rdd_21_0 stored as values in memory (estimated size 478.2 MB, free 1091.9 MB)
17/03/27 22:26:23 INFO BlockManagerInfo: Added rdd_21_0 in memory on localhost:53990 (size: 478.2 MB, free: 1091.9 MB)
17/03/27 22:26:23 INFO CacheManager: Partition rdd_19_0 not found, computing it
17/03/27 22:26:23 INFO CacheManager: Partition rdd_13_0 not found, computing it
17/03/27 22:26:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:23 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:23 INFO BlockManager: Dropping block rdd_19_3 from memory
17/03/27 22:26:23 INFO BlockManagerInfo: Removed rdd_19_3 on localhost:53990 in memory (size: 478.2 MB, free: 1570.1 MB)
17/03/27 22:26:23 INFO MemoryStore: Will not store rdd_21_3 as it would require dropping another block from the same RDD
17/03/27 22:26:23 WARN MemoryStore: Not enough space to cache rdd_21_3 in memory! (computed 478.2 MB so far)
17/03/27 22:26:23 INFO MemoryStore: Memory use = 478.2 MB (blocks) + 1443.5 MB (scratch space shared across 5 tasks(s)) = 1921.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:23 INFO CacheManager: Partition rdd_19_3 not found, computing it
17/03/27 22:26:23 INFO CacheManager: Partition rdd_13_3 not found, computing it
17/03/27 22:26:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:24 INFO MemoryStore: Block rdd_13_1 stored as values in memory (estimated size 478.2 MB, free 1091.9 MB)
17/03/27 22:26:24 INFO BlockManagerInfo: Added rdd_13_1 in memory on localhost:53990 (size: 478.2 MB, free: 1091.9 MB)
17/03/27 22:26:24 INFO BlockManager: Found block rdd_13_1 locally
17/03/27 22:26:24 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 14 took 0 ms
17/03/27 22:26:24 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:24 INFO BlockManager: Dropping block rdd_21_0 from memory
17/03/27 22:26:24 INFO BlockManagerInfo: Removed rdd_21_0 on localhost:53990 in memory (size: 478.2 MB, free: 1570.1 MB)
17/03/27 22:26:24 INFO MemoryStore: Block rdd_25_2 stored as values in memory (estimated size 478.2 MB, free 1091.9 MB)
17/03/27 22:26:24 INFO BlockManagerInfo: Added rdd_25_2 in memory on localhost:53990 (size: 478.2 MB, free: 1091.9 MB)
17/03/27 22:26:24 INFO Executor: Finished task 2.0 in stage 3.0 (TID 22). 3807 bytes result sent to driver
17/03/27 22:26:24 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2374 bytes)
17/03/27 22:26:24 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 22) in 3270 ms on localhost (1/5)
17/03/27 22:26:24 INFO Executor: Running task 4.0 in stage 3.0 (TID 24)
17/03/27 22:26:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 16.3 KB, free 1091.9 MB)
17/03/27 22:26:24 INFO CacheManager: Partition rdd_25_4 not found, computing it
17/03/27 22:26:24 INFO CacheManager: Partition rdd_21_4 not found, computing it
17/03/27 22:26:24 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:26:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:24 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:24 INFO BlockManager: Dropping block rdd_25_2 from memory
17/03/27 22:26:24 INFO BlockManagerInfo: Removed rdd_25_2 on localhost:53990 in memory (size: 478.2 MB, free: 1570.1 MB)
17/03/27 22:26:24 INFO MemoryStore: Will not store rdd_19_1 as it would require dropping another block from the same RDD
17/03/27 22:26:24 WARN MemoryStore: Not enough space to cache rdd_19_1 in memory! (computed 478.2 MB so far)
17/03/27 22:26:24 INFO MemoryStore: Memory use = 478.2 MB (blocks) + 1443.5 MB (scratch space shared across 5 tasks(s)) = 1921.7 MB. Storage limit = 2.0 GB.
17/03/27 22:26:24 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 22 took 0 ms
17/03/27 22:26:24 INFO MemoryStore: Block rdd_13_0 stored as values in memory (estimated size 478.2 MB, free 1091.9 MB)
17/03/27 22:26:24 INFO BlockManagerInfo: Added rdd_13_0 in memory on localhost:53990 (size: 478.2 MB, free: 1091.9 MB)
17/03/27 22:26:24 INFO BlockManager: Found block rdd_13_0 locally
17/03/27 22:26:24 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 14 took 0 ms
17/03/27 22:26:24 INFO MemoryStore: Will not store rdd_13_4 as it would require dropping another block from the same RDD
17/03/27 22:26:24 WARN MemoryStore: Not enough space to cache rdd_13_4 in memory! (computed 478.2 MB so far)
17/03/27 22:26:24 INFO MemoryStore: Memory use = 956.3 MB (blocks) + 728.3 MB (scratch space shared across 5 tasks(s)) = 1684.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:24 INFO CacheManager: Partition rdd_19_4 not found, computing it
17/03/27 22:26:24 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:26:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:24 INFO MemoryStore: Block rdd_13_3 stored as values in memory (estimated size 478.2 MB, free 613.7 MB)
17/03/27 22:26:24 INFO BlockManagerInfo: Added rdd_13_3 in memory on localhost:53990 (size: 478.2 MB, free: 613.7 MB)
17/03/27 22:26:24 INFO BlockManager: Found block rdd_13_3 locally
17/03/27 22:26:24 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 1 ms
17/03/27 22:26:25 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:25 INFO BlockManager: Dropping block rdd_13_1 from memory
17/03/27 22:26:25 INFO BlockManagerInfo: Removed rdd_13_1 on localhost:53990 in memory (size: 478.2 MB, free: 1091.9 MB)
17/03/27 22:26:25 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:25 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:25 INFO BlockManager: Dropping block rdd_13_0 from memory
17/03/27 22:26:25 INFO BlockManagerInfo: Removed rdd_13_0 on localhost:53990 in memory (size: 478.2 MB, free: 1570.1 MB)
17/03/27 22:26:25 INFO MemoryStore: Will not store rdd_13_4 as it would require dropping another block from the same RDD
17/03/27 22:26:25 WARN MemoryStore: Not enough space to cache rdd_13_4 in memory! (computed 478.1 MB so far)
17/03/27 22:26:25 INFO MemoryStore: Memory use = 478.2 MB (blocks) + 1445.4 MB (scratch space shared across 5 tasks(s)) = 1923.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:25 INFO CacheManager: Partition rdd_13_4 not found, computing it
17/03/27 22:26:25 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:25 INFO MemoryStore: Will not store rdd_19_3 as it would require dropping another block from the same RDD
17/03/27 22:26:25 WARN MemoryStore: Not enough space to cache rdd_19_3 in memory! (computed 478.1 MB so far)
17/03/27 22:26:25 INFO MemoryStore: Memory use = 478.2 MB (blocks) + 1446.4 MB (scratch space shared across 5 tasks(s)) = 1924.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:25 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 22 took 0 ms
17/03/27 22:26:25 INFO MemoryStore: Block rdd_25_1 stored as values in memory (estimated size 478.1 MB, free 1091.9 MB)
17/03/27 22:26:25 INFO BlockManagerInfo: Added rdd_25_1 in memory on localhost:53990 (size: 478.1 MB, free: 1091.9 MB)
17/03/27 22:26:25 INFO Executor: Finished task 1.0 in stage 3.0 (TID 21). 4610 bytes result sent to driver
17/03/27 22:26:25 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 21) in 4613 ms on localhost (2/5)
17/03/27 22:26:25 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:25 INFO BlockManager: Dropping block rdd_13_3 from memory
17/03/27 22:26:25 INFO BlockManagerInfo: Removed rdd_13_3 on localhost:53990 in memory (size: 478.2 MB, free: 1570.1 MB)
17/03/27 22:26:25 INFO MemoryStore: Block rdd_19_0 stored as values in memory (estimated size 478.1 MB, free 1092.0 MB)
17/03/27 22:26:25 INFO BlockManagerInfo: Added rdd_19_0 in memory on localhost:53990 (size: 478.1 MB, free: 1092.0 MB)
17/03/27 22:26:25 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 22 took 0 ms
17/03/27 22:26:25 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:25 INFO BlockManager: Dropping block rdd_25_1 from memory
17/03/27 22:26:25 INFO BlockManagerInfo: Removed rdd_25_1 on localhost:53990 in memory (size: 478.1 MB, free: 1570.1 MB)
17/03/27 22:26:25 INFO MemoryStore: Block rdd_25_3 stored as values in memory (estimated size 478.1 MB, free 1092.0 MB)
17/03/27 22:26:25 INFO BlockManagerInfo: Added rdd_25_3 in memory on localhost:53990 (size: 478.1 MB, free: 1092.0 MB)
17/03/27 22:26:25 INFO Executor: Finished task 3.0 in stage 3.0 (TID 23). 3867 bytes result sent to driver
17/03/27 22:26:25 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 23) in 5010 ms on localhost (3/5)
17/03/27 22:26:25 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:25 INFO BlockManager: Dropping block rdd_19_0 from memory
17/03/27 22:26:25 INFO BlockManagerInfo: Removed rdd_19_0 on localhost:53990 in memory (size: 478.1 MB, free: 1570.1 MB)
17/03/27 22:26:25 INFO MemoryStore: Block rdd_13_4 stored as values in memory (estimated size 478.1 MB, free 1092.1 MB)
17/03/27 22:26:25 INFO BlockManagerInfo: Added rdd_13_4 in memory on localhost:53990 (size: 478.1 MB, free: 1092.1 MB)
17/03/27 22:26:25 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 1060.1 MB)
17/03/27 22:26:25 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 14 took 1 ms
17/03/27 22:26:26 INFO MemoryStore: Block rdd_25_0 stored as values in memory (estimated size 478.1 MB, free 582.0 MB)
17/03/27 22:26:26 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:26 INFO BlockManagerInfo: Added rdd_25_0 in memory on localhost:53990 (size: 478.1 MB, free: 614.0 MB)
17/03/27 22:26:26 INFO BlockManager: Dropping block rdd_25_3 from memory
17/03/27 22:26:26 INFO BlockManagerInfo: Removed rdd_25_3 on localhost:53990 in memory (size: 478.1 MB, free: 1092.1 MB)
17/03/27 22:26:26 INFO Executor: Finished task 0.0 in stage 3.0 (TID 20). 4230 bytes result sent to driver
17/03/27 22:26:26 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 20) in 5343 ms on localhost (4/5)
17/03/27 22:26:26 INFO MemoryStore: Block rdd_19_4 stored as values in memory (estimated size 480.4 MB, free 579.7 MB)
17/03/27 22:26:26 INFO BlockManagerInfo: Added rdd_19_4 in memory on localhost:53990 (size: 480.4 MB, free: 611.7 MB)
17/03/27 22:26:26 INFO SetRDDHashSetPartition: Union set size 0 for rdd 14 took 0 ms
17/03/27 22:26:26 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:26 INFO BlockManager: Dropping block rdd_13_4 from memory
17/03/27 22:26:26 INFO BlockManagerInfo: Removed rdd_13_4 on localhost:53990 in memory (size: 478.1 MB, free: 1089.8 MB)
17/03/27 22:26:27 INFO MemoryStore: Block rdd_21_4 stored as values in memory (estimated size 480.4 MB, free 577.4 MB)
17/03/27 22:26:27 INFO BlockManagerInfo: Added rdd_21_4 in memory on localhost:53990 (size: 480.4 MB, free: 609.4 MB)
17/03/27 22:26:27 INFO BlockManager: Found block rdd_19_4 locally
17/03/27 22:26:27 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 22 took 0 ms
17/03/27 22:26:27 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:27 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:27 INFO BlockManager: Dropping block rdd_21_4 from memory
17/03/27 22:26:27 INFO BlockManagerInfo: Removed rdd_21_4 on localhost:53990 in memory (size: 480.4 MB, free: 1089.8 MB)
17/03/27 22:26:27 INFO MemoryStore: Block rdd_25_4 stored as values in memory (estimated size 448.4 MB, free 641.4 MB)
17/03/27 22:26:27 INFO BlockManagerInfo: Added rdd_25_4 in memory on localhost:53990 (size: 448.4 MB, free: 641.4 MB)
17/03/27 22:26:27 INFO Executor: Finished task 4.0 in stage 3.0 (TID 24). 4121 bytes result sent to driver
17/03/27 22:26:27 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 24) in 3684 ms on localhost (5/5)
17/03/27 22:26:27 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:26:27 INFO DAGScheduler: FixedPointResultStage 3 (runFixedPointJob at Recursion.scala:204) finished in 6.954 s
17/03/27 22:26:27 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:27 INFO Recursion: Fixed Point Iteration # 2, time: 7065ms
17/03/27 22:26:27 INFO DAGScheduler: Submitting FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[36] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:27 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.6 KB, free 641.4 MB)
17/03/27 22:26:27 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.8 KB, free 641.4 MB)
17/03/27 22:26:27 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:53990 (size: 7.8 KB, free: 641.4 MB)
17/03/27 22:26:27 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:27 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[36] at RDD at SetRDD.scala:30)
17/03/27 22:26:27 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:26:27 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 26, localhost, partition 4,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 27, localhost, partition 1,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 28, localhost, partition 2,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:26:27 INFO Executor: Running task 0.0 in stage 4.0 (TID 25)
17/03/27 22:26:27 INFO Executor: Running task 1.0 in stage 4.0 (TID 27)
17/03/27 22:26:27 INFO Executor: Running task 4.0 in stage 4.0 (TID 26)
17/03/27 22:26:27 INFO Executor: Running task 2.0 in stage 4.0 (TID 28)
17/03/27 22:26:27 INFO CacheManager: Partition rdd_35_0 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_35_2 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_35_4 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_35_1 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_31_0 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_31_2 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_31_4 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_31_1 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_21_4 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_21_2 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_21_1 not found, computing it
17/03/27 22:26:27 ERROR Executor: Exception in task 2.0 in stage 4.0 (TID 28)
org.apache.spark.SparkException: Checkpoint block rdd_21_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:27 INFO CacheManager: Partition rdd_21_0 not found, computing it
17/03/27 22:26:27 ERROR Executor: Exception in task 0.0 in stage 4.0 (TID 25)
org.apache.spark.SparkException: Checkpoint block rdd_21_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:27 ERROR Executor: Exception in task 1.0 in stage 4.0 (TID 27)
org.apache.spark.SparkException: Checkpoint block rdd_21_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:27 ERROR Executor: Exception in task 4.0 in stage 4.0 (TID 26)
org.apache.spark.SparkException: Checkpoint block rdd_21_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 29, localhost, partition 3,PROCESS_LOCAL, 2234 bytes)
17/03/27 22:26:27 INFO Executor: Running task 3.0 in stage 4.0 (TID 29)
17/03/27 22:26:27 WARN TaskSetManager: Lost task 2.0 in stage 4.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_21_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:27 ERROR TaskSetManager: Task 2 in stage 4.0 failed 1 times; aborting job
17/03/27 22:26:27 INFO TaskSchedulerImpl: Cancelling stage 4
17/03/27 22:26:27 INFO TaskSchedulerImpl: Stage 4 was cancelled
17/03/27 22:26:27 INFO DAGScheduler: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204) failed in 0.003 s
17/03/27 22:26:27 WARN TaskSetManager: Lost task 0.0 in stage 4.0 (TID 25, localhost): org.apache.spark.SparkException: Checkpoint block rdd_21_0 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:27 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 7.075261 s
17/03/27 22:26:27 INFO Executor: Executor is trying to kill task 3.0 in stage 4.0 (TID 29)
17/03/27 22:26:27 INFO SparkContext: Running Spark version 1.6.3
[31m- Multi-Level Marketing *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 2 in stage 4.0 failed 1 times, most recent failure: Lost task 2.0 in stage 4.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_21_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
[0m
[31m	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_21_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  ...[0m
17/03/27 22:26:27 WARN TaskSetManager: Lost task 1.0 in stage 4.0 (TID 27, localhost): org.apache.spark.SparkException: Checkpoint block rdd_21_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:27 WARN TaskSetManager: Lost task 4.0 in stage 4.0 (TID 26, localhost): org.apache.spark.SparkException: Checkpoint block rdd_21_4 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:27 INFO SecurityManager: Changing view acls to: Mike
17/03/27 22:26:27 INFO SecurityManager: Changing modify acls to: Mike
17/03/27 22:26:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(Mike); users with modify permissions: Set(Mike)
17/03/27 22:26:27 INFO CacheManager: Partition rdd_35_3 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_31_3 not found, computing it
17/03/27 22:26:27 INFO CacheManager: Partition rdd_21_3 not found, computing it
17/03/27 22:26:27 ERROR Executor: Exception in task 3.0 in stage 4.0 (TID 29)
org.apache.spark.SparkException: Checkpoint block rdd_21_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:27 WARN TaskSetManager: Lost task 3.0 in stage 4.0 (TID 29, localhost): org.apache.spark.SparkException: Checkpoint block rdd_21_3 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.ZippedPartitionsRDD2.compute(ZippedPartitionsRDD.scala:88)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.compute(SetRDD.scala:121)
	at edu.ucla.cs.wis.bigdatalog.spark.execution.setrdd.SetRDD.computeOrReadCheckpoint(SetRDD.scala:115)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.fixedpoint.FixedPointResultTask.runTask(FixedPointResultTask.scala:55)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:27 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:26:27 INFO Utils: Successfully started service 'sparkDriver' on port 54019.
17/03/27 22:26:27 INFO Slf4jLogger: Slf4jLogger started
17/03/27 22:26:27 INFO Remoting: Starting remoting
17/03/27 22:26:27 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriverActorSystem@localhost:54032]
17/03/27 22:26:27 INFO Utils: Successfully started service 'sparkDriverActorSystem' on port 54032.
17/03/27 22:26:27 INFO SparkEnv: Registering MapOutputTracker
17/03/27 22:26:27 INFO SparkEnv: Registering BlockManagerMaster
17/03/27 22:26:27 INFO DiskBlockManager: Created local directory at C:\java\BigDatalogLatest\datalog\target\tmp\blockmgr-895a169a-9743-4169-902e-d6eac7fd6aa8
17/03/27 22:26:27 INFO MemoryStore: MemoryStore started with capacity 2.0 GB
17/03/27 22:26:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/27 22:26:27 INFO Executor: Starting executor ID driver on host localhost
17/03/27 22:26:27 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54049.
17/03/27 22:26:27 INFO NettyBlockTransferService: Server created on 54049
17/03/27 22:26:27 INFO BlockManagerMaster: Trying to register BlockManager
17/03/27 22:26:27 INFO BlockManagerMasterEndpoint: Registering block manager localhost:54049 with 2.0 GB RAM, BlockManagerId(driver, localhost, 54049)
17/03/27 22:26:27 INFO BlockManagerMaster: Registered BlockManager
17/03/27 22:26:27 INFO EventLoggingListener: Logging events to file:/C:/tmp/spark-events/local-1490667987893
17/03/27 22:26:27 WARN SparkContext: Multiple running SparkContexts detected in the same JVM!
org.apache.spark.SparkException: Only one SparkContext may be running in this JVM (see SPARK-2243). To ignore this error, set spark.driver.allowMultipleContexts = true. The currently running SparkContext was created at:
org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$9.apply$mcV$sp(RecursiveQuerySuites.scala:176)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$9.apply(RecursiveQuerySuites.scala:147)
edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$9.apply(RecursiveQuerySuites.scala:147)
org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
org.scalatest.Transformer.apply(Transformer.scala:22)
org.scalatest.Transformer.apply(Transformer.scala:20)
org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
org.scalatest.Suite$class.withFixture(Suite.scala:1122)
org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2275)
	at org.apache.spark.SparkContext$$anonfun$assertNoOtherContextIsRunning$1.apply(SparkContext.scala:2257)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.SparkContext$.assertNoOtherContextIsRunning(SparkContext.scala:2257)
	at org.apache.spark.SparkContext$.setActiveContext(SparkContext.scala:2343)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:2215)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:146)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTests(QuerySuite.scala:36)
	at edu.ucla.cs.wis.bigdatalog.spark.QuerySuite.runTest(QuerySuite.scala:33)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$10.apply$mcV$sp(RecursiveQuerySuites.scala:187)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$10.apply(RecursiveQuerySuites.scala:179)
	at edu.ucla.cs.wis.bigdatalog.spark.RecursiveQuerySuite$$anonfun$10.apply(RecursiveQuerySuites.scala:179)
	at org.scalatest.Transformer$$anonfun$apply$1.apply$mcV$sp(Transformer.scala:22)
	at org.scalatest.OutcomeOf$class.outcomeOf(OutcomeOf.scala:85)
	at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104)
	at org.scalatest.Transformer.apply(Transformer.scala:22)
	at org.scalatest.Transformer.apply(Transformer.scala:20)
	at org.scalatest.FunSuiteLike$$anon$1.apply(FunSuiteLike.scala:166)
	at org.scalatest.Suite$class.withFixture(Suite.scala:1122)
	at org.scalatest.FunSuite.withFixture(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$class.invokeWithFixture$1(FunSuiteLike.scala:163)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.FunSuiteLike$$anonfun$runTest$1.apply(FunSuiteLike.scala:175)
	at org.scalatest.SuperEngine.runTestImpl(Engine.scala:306)
	at org.scalatest.FunSuiteLike$class.runTest(FunSuiteLike.scala:175)
	at org.scalatest.FunSuite.runTest(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.FunSuiteLike$$anonfun$runTests$1.apply(FunSuiteLike.scala:208)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:413)
	at org.scalatest.SuperEngine$$anonfun$traverseSubNodes$1$1.apply(Engine.scala:401)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.SuperEngine.traverseSubNodes$1(Engine.scala:401)
	at org.scalatest.SuperEngine.org$scalatest$SuperEngine$$runTestsInBranch(Engine.scala:396)
	at org.scalatest.SuperEngine.runTestsImpl(Engine.scala:483)
	at org.scalatest.FunSuiteLike$class.runTests(FunSuiteLike.scala:208)
	at org.scalatest.FunSuite.runTests(FunSuite.scala:1555)
	at org.scalatest.Suite$class.run(Suite.scala:1424)
	at org.scalatest.FunSuite.org$scalatest$FunSuiteLike$$super$run(FunSuite.scala:1555)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.FunSuiteLike$$anonfun$run$1.apply(FunSuiteLike.scala:212)
	at org.scalatest.SuperEngine.runImpl(Engine.scala:545)
	at org.scalatest.FunSuiteLike$class.run(FunSuiteLike.scala:212)
	at org.scalatest.FunSuite.run(FunSuite.scala:1555)
	at org.scalatest.Suite$class.callExecuteOnSuite$1(Suite.scala:1492)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1528)
	at org.scalatest.Suite$$anonfun$runNestedSuites$1.apply(Suite.scala:1526)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.scalatest.Suite$class.runNestedSuites(Suite.scala:1526)
	at org.scalatest.tools.DiscoverySuite.runNestedSuites(DiscoverySuite.scala:29)
	at org.scalatest.Suite$class.run(Suite.scala:1421)
	at org.scalatest.tools.DiscoverySuite.run(DiscoverySuite.scala:29)
	at org.scalatest.tools.SuiteRunner.run(SuiteRunner.scala:55)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2563)
	at org.scalatest.tools.Runner$$anonfun$doRunRunRunDaDoRunRun$3.apply(Runner.scala:2557)
	at scala.collection.immutable.List.foreach(List.scala:381)
	at org.scalatest.tools.Runner$.doRunRunRunDaDoRunRun(Runner.scala:2557)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1044)
	at org.scalatest.tools.Runner$$anonfun$runOptionallyWithPassFailReporter$2.apply(Runner.scala:1043)
	at org.scalatest.tools.Runner$.withClassLoaderAndDispatchReporter(Runner.scala:2722)
	at org.scalatest.tools.Runner$.runOptionallyWithPassFailReporter(Runner.scala:1043)
	at org.scalatest.tools.Runner$.main(Runner.scala:860)
	at org.scalatest.tools.Runner.main(Runner.scala)
17/03/27 22:26:27 INFO RecursiveQuerySuite: ========== START BigDatalog Query 1 START ==========
17/03/27 22:26:27 INFO BigDatalogContext: BigDatalog Query: "leftLinearPaths(A,B,C)."
17/03/27 22:26:27 INFO BigDatalogContext: ** START Operator Program START **
17/03/27 22:26:27 INFO BigDatalogContext: 
0: leftLinearPaths(B, C, To) <RECURSIVE_CLIQUE>(Recursion: LINEAR, Evaluation Type: SemiNaive)
Exit Rules: 
 1: (From, To, To) <DISTINCT PROJECT>
  2: arc(From, To) <BASE_RELATION>
Recursive Rules: 
 1: (B, C, To) <DISTINCT PROJECT>
  2: (0.C = 1.From) <JOIN>
   3: leftLinearPaths(A, B, C) <RECURSIVE_RELATION>
   3: arc(From, To) <BASE_RELATION>
17/03/27 22:26:27 INFO BigDatalogContext: ** END Operator Program END **
17/03/27 22:26:27 INFO BigDatalogContext: ** START BigDatalog Program START **
17/03/27 22:26:27 INFO BigDatalogContext: == Parsed Logical Plan ==
'Subquery leftLinearPaths
+- 'Recursion leftLinearPaths, true, [1,0,0]
   :- 'Project ['arc.From,'arc.To,'arc.To]
   :  +- 'UnresolvedRelation `arc`, None
   +- 'Project ['leftLinearPaths1.B,'leftLinearPaths1.C,'arc2.To]
      +- 'Join Inner, Some(('leftLinearPaths1.C = 'arc2.From))
         :- Subquery leftLinearPaths1
         :  +- LinearRecursiveRelation leftLinearPaths, [A#794,B#795,C#796], [1,0,0]
         +- 'BroadcastHint
            +- 'Subquery arc2
               +- 'Project [*]
                  +- 'UnresolvedRelation `arc`, None

== Analyzed Logical Plan ==
B: int, C: int, To: int
Subquery leftLinearPaths
+- Recursion leftLinearPaths, true, [1,0,0]
   :- Project [From#789,To#790,To#790]
   :  +- Subquery arc
   :     +- LogicalRDD [From#789,To#790], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
   +- Project [B#795,C#796,To#790]
      +- Join Inner, Some((C#796 = From#789))
         :- Subquery leftLinearPaths1
         :  +- LinearRecursiveRelation leftLinearPaths, [A#794,B#795,C#796], [1,0,0]
         +- BroadcastHint
            +- Subquery arc2
               +- Project [From#789,To#790]
                  +- Subquery arc
                     +- LogicalRDD [From#789,To#790], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Optimized Logical Plan ==
Recursion leftLinearPaths, true, [1,0,0]
:- Project [From#789,To#790,To#790]
:  +- LogicalRDD [From#789,To#790], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168
+- Project [B#795,C#796,To#790]
   +- Join Inner, Some((C#796 = From#789))
      :- Project [B#795,C#796]
      :  +- LinearRecursiveRelation leftLinearPaths, [A#794,B#795,C#796], [1,0,0]
      +- BroadcastHint
         +- Project [From#789,To#790]
            +- LogicalRDD [From#789,To#790], ParallelCollectionRDD[0] at parallelize at Utilities.scala:168

== Physical Plan ==
Recursion [B#795,C#796,To#790] (Linear) [leftLinearPaths][1,0,0]
:- TungstenExchange hashpartitioning(From#789,5), None
:  +- Project [From#789,To#790,To#790]
:     +- Scan ExistingRDD[From#789,To#790] 
+- TungstenExchange hashpartitioning(B#795,5), None
   +- Project [B#795,C#796,To#790]
      +- BroadcastHashJoin [C#796], [From#789], BuildRight
         :- Project [B#795,C#796]
         :  +- LinearRecursiveRelation [A#794,B#795,C#796](leftLinearPaths)
         +- Project [From#789,To#790]
            +- Scan ExistingRDD[From#789,To#790]
17/03/27 22:26:27 INFO BigDatalogContext: ** END BigDatalog Program END **
17/03/27 22:26:27 INFO Recursion: Recursion operator configuration settings:
17/03/27 22:26:27 INFO Recursion:   Using memory checkpointing with StorageLevel(false, true, false, true, 1)
17/03/27 22:26:27 INFO Recursion: Recursion version: Single-Job-PSN w/ SetRDD
17/03/27 22:26:27 INFO SparkContext: Starting job: run at null:-1
17/03/27 22:26:27 INFO DAGScheduler: Got job 0 (run at null:-1) with 5 output partitions
17/03/27 22:26:27 INFO DAGScheduler: Final stage: ResultStage 0 (run at null:-1)
17/03/27 22:26:27 INFO DAGScheduler: Parents of final stage: List()
17/03/27 22:26:27 INFO DAGScheduler: Missing parents: List()
17/03/27 22:26:27 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[8] at run at null:-1), which has no missing parents
17/03/27 22:26:27 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 5.2 KB, free 2.0 GB)
17/03/27 22:26:27 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.7 KB, free 2.0 GB)
17/03/27 22:26:27 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:54049 (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:27 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:27 INFO DAGScheduler: Submitting 5 missing tasks from ResultStage 0 (MapPartitionsRDD[8] at run at null:-1)
17/03/27 22:26:27 INFO TaskSchedulerImpl: Adding task set 0.0 with 5 tasks
17/03/27 22:26:27 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, partition 0,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, localhost, partition 1,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2, localhost, partition 2,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:27 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3, localhost, partition 3,PROCESS_LOCAL, 2321 bytes)
17/03/27 22:26:27 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/27 22:26:27 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/27 22:26:27 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
17/03/27 22:26:27 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1443 bytes result sent to driver
17/03/27 22:26:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1443 bytes result sent to driver
17/03/27 22:26:27 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
17/03/27 22:26:27 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1443 bytes result sent to driver
17/03/27 22:26:27 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4, localhost, partition 4,PROCESS_LOCAL, 2352 bytes)
17/03/27 22:26:27 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
17/03/27 22:26:27 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1443 bytes result sent to driver
17/03/27 22:26:27 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 1484 bytes result sent to driver
17/03/27 22:26:27 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 4 ms on localhost (1/5)
17/03/27 22:26:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 5 ms on localhost (2/5)
17/03/27 22:26:27 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 4 ms on localhost (3/5)
17/03/27 22:26:27 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 1 ms on localhost (4/5)
17/03/27 22:26:27 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 5 ms on localhost (5/5)
17/03/27 22:26:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/03/27 22:26:27 INFO DAGScheduler: ResultStage 0 (run at null:-1) finished in 0.006 s
17/03/27 22:26:27 INFO DAGScheduler: Job 0 finished: run at null:-1, took 0.007615 s
17/03/27 22:26:27 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 1208.0 B, free 2.0 GB)
17/03/27 22:26:27 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 218.0 B, free 2.0 GB)
17/03/27 22:26:27 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:54049 (size: 218.0 B, free: 2.0 GB)
17/03/27 22:26:27 INFO SparkContext: Created broadcast 1 from run at null:-1
17/03/27 22:26:27 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:27 INFO Recursion: Fixed Point Iteration # 1, time: 23ms
17/03/27 22:26:28 INFO DAGScheduler: Registering RDD 4 (execute at Recursion.scala:189)
17/03/27 22:26:28 INFO DAGScheduler: Registering RDD 12 (execute at Recursion.scala:202)
17/03/27 22:26:28 INFO DAGScheduler: Registering RDD 21 (execute at Recursion.scala:228)
17/03/27 22:26:28 INFO DAGScheduler: Got job 1 (runFixedPointJob at Recursion.scala:204) with 5 output partitions
17/03/27 22:26:28 INFO DAGScheduler: Final stage: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204)
17/03/27 22:26:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:26:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1, ShuffleMapStage 2, ShuffleMapStage 3)
17/03/27 22:26:28 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189), which has no missing parents
17/03/27 22:26:28 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 5.8 KB, free 2.0 GB)
17/03/27 22:26:28 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 3.3 KB, free 2.0 GB)
17/03/27 22:26:28 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:54049 (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:26:28 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:28 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[4] at execute at Recursion.scala:189)
17/03/27 22:26:28 INFO TaskSchedulerImpl: Adding task set 1.0 with 5 tasks
17/03/27 22:26:28 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 5, localhost, partition 0,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 6, localhost, partition 1,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 7, localhost, partition 2,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 8, localhost, partition 3,PROCESS_LOCAL, 2310 bytes)
17/03/27 22:26:28 INFO Executor: Running task 1.0 in stage 1.0 (TID 6)
17/03/27 22:26:28 INFO Executor: Running task 3.0 in stage 1.0 (TID 8)
17/03/27 22:26:28 INFO Executor: Running task 2.0 in stage 1.0 (TID 7)
17/03/27 22:26:28 INFO Executor: Running task 0.0 in stage 1.0 (TID 5)
17/03/27 22:26:28 INFO GenerateUnsafeProjection: Code generated in 3.915103 ms
17/03/27 22:26:28 INFO Executor: Finished task 2.0 in stage 1.0 (TID 7). 1367 bytes result sent to driver
17/03/27 22:26:28 INFO TaskSetManager: Starting task 4.0 in stage 1.0 (TID 9, localhost, partition 4,PROCESS_LOCAL, 2341 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 7) in 23 ms on localhost (1/5)
17/03/27 22:26:28 INFO Executor: Running task 4.0 in stage 1.0 (TID 9)
17/03/27 22:26:28 INFO Executor: Finished task 0.0 in stage 1.0 (TID 5). 1367 bytes result sent to driver
17/03/27 22:26:28 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 5) in 27 ms on localhost (2/5)
17/03/27 22:26:28 INFO Executor: Finished task 1.0 in stage 1.0 (TID 6). 1367 bytes result sent to driver
17/03/27 22:26:28 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 6) in 29 ms on localhost (3/5)
17/03/27 22:26:28 INFO Executor: Finished task 4.0 in stage 1.0 (TID 9). 1367 bytes result sent to driver
17/03/27 22:26:28 INFO TaskSetManager: Finished task 4.0 in stage 1.0 (TID 9) in 11 ms on localhost (4/5)
17/03/27 22:26:28 INFO Executor: Finished task 3.0 in stage 1.0 (TID 8). 1367 bytes result sent to driver
17/03/27 22:26:28 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 8) in 36 ms on localhost (5/5)
17/03/27 22:26:28 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/03/27 22:26:28 INFO DAGScheduler: ShuffleMapStage 1 (execute at Recursion.scala:189) finished in 0.036 s
17/03/27 22:26:28 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:28 INFO DAGScheduler: running: Set()
17/03/27 22:26:28 INFO DAGScheduler: waiting: Set(ShuffleMapStage 2, ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:26:28 INFO DAGScheduler: failed: Set()
17/03/27 22:26:28 INFO DAGScheduler: Submitting ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202), which has no missing parents
17/03/27 22:26:28 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.1 KB, free 2.0 GB)
17/03/27 22:26:28 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 6.1 KB, free 2.0 GB)
17/03/27 22:26:28 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:54049 (size: 6.1 KB, free: 2.0 GB)
17/03/27 22:26:28 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:28 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 2 (MapPartitionsRDD[12] at execute at Recursion.scala:202)
17/03/27 22:26:28 INFO TaskSchedulerImpl: Adding task set 2.0 with 5 tasks
17/03/27 22:26:28 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 10, localhost, partition 0,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Starting task 1.0 in stage 2.0 (TID 11, localhost, partition 1,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Starting task 2.0 in stage 2.0 (TID 12, localhost, partition 2,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Starting task 3.0 in stage 2.0 (TID 13, localhost, partition 3,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:28 INFO Executor: Running task 0.0 in stage 2.0 (TID 10)
17/03/27 22:26:28 INFO Executor: Running task 1.0 in stage 2.0 (TID 11)
17/03/27 22:26:28 INFO Executor: Running task 2.0 in stage 2.0 (TID 12)
17/03/27 22:26:28 INFO Executor: Running task 3.0 in stage 2.0 (TID 13)
17/03/27 22:26:28 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:26:28 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:28 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:28 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:28 INFO BlockManagerInfo: Removed broadcast_0_piece0 on localhost:54049 in memory (size: 2.7 KB, free: 2.0 GB)
17/03/27 22:26:28 INFO ContextCleaner: Cleaned accumulator 1517
17/03/27 22:26:28 INFO ContextCleaner: Cleaned accumulator 1516
17/03/27 22:26:28 INFO BlockManagerInfo: Removed broadcast_2_piece0 on localhost:54049 in memory (size: 3.3 KB, free: 2.0 GB)
17/03/27 22:26:28 INFO MemoryStore: Will not store rdd_6_2 as it would require dropping another block from the same RDD
17/03/27 22:26:28 WARN MemoryStore: Not enough space to cache rdd_6_2 in memory! (computed 450.8 MB so far)
17/03/27 22:26:28 INFO MemoryStore: Memory use = 19.6 KB (blocks) + 2029.8 MB (scratch space shared across 5 tasks(s)) = 2029.8 MB. Storage limit = 2.0 GB.
17/03/27 22:26:28 INFO Executor: Finished task 2.0 in stage 2.0 (TID 12). 1884 bytes result sent to driver
17/03/27 22:26:28 INFO TaskSetManager: Starting task 4.0 in stage 2.0 (TID 14, localhost, partition 4,NODE_LOCAL, 1957 bytes)
17/03/27 22:26:28 INFO TaskSetManager: Finished task 2.0 in stage 2.0 (TID 12) in 532 ms on localhost (1/5)
17/03/27 22:26:28 INFO Executor: Running task 4.0 in stage 2.0 (TID 14)
17/03/27 22:26:28 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:29 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 450.9 MB, free 1597.4 MB)
17/03/27 22:26:29 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:54049 (size: 450.9 MB, free: 1597.4 MB)
17/03/27 22:26:29 INFO Executor: Finished task 0.0 in stage 2.0 (TID 10). 2253 bytes result sent to driver
17/03/27 22:26:29 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 10) in 985 ms on localhost (2/5)
17/03/27 22:26:29 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 450.8 MB, free 1146.5 MB)
17/03/27 22:26:29 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:54049 (size: 450.8 MB, free: 1146.6 MB)
17/03/27 22:26:29 INFO MemoryStore: Block rdd_6_3 stored as values in memory (estimated size 450.8 MB, free 695.7 MB)
17/03/27 22:26:29 INFO BlockManagerInfo: Added rdd_6_3 in memory on localhost:54049 (size: 450.8 MB, free: 695.7 MB)
17/03/27 22:26:29 INFO Executor: Finished task 1.0 in stage 2.0 (TID 11). 2253 bytes result sent to driver
17/03/27 22:26:29 INFO TaskSetManager: Finished task 1.0 in stage 2.0 (TID 11) in 1007 ms on localhost (3/5)
17/03/27 22:26:29 INFO Executor: Finished task 3.0 in stage 2.0 (TID 13). 2253 bytes result sent to driver
17/03/27 22:26:29 INFO TaskSetManager: Finished task 3.0 in stage 2.0 (TID 13) in 1010 ms on localhost (4/5)
17/03/27 22:26:29 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 450.8 MB, free 245.0 MB)
17/03/27 22:26:29 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:54049 (size: 450.8 MB, free: 245.0 MB)
17/03/27 22:26:29 INFO Executor: Finished task 4.0 in stage 2.0 (TID 14). 2253 bytes result sent to driver
17/03/27 22:26:29 INFO TaskSetManager: Finished task 4.0 in stage 2.0 (TID 14) in 876 ms on localhost (5/5)
17/03/27 22:26:29 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/03/27 22:26:29 INFO DAGScheduler: ShuffleMapStage 2 (execute at Recursion.scala:202) finished in 1.408 s
17/03/27 22:26:29 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:29 INFO DAGScheduler: running: Set()
17/03/27 22:26:29 INFO DAGScheduler: waiting: Set(ShuffleMapStage 3, FixedPointResultStage 4)
17/03/27 22:26:29 INFO DAGScheduler: failed: Set()
17/03/27 22:26:29 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.8 KB, free 245.0 MB)
17/03/27 22:26:29 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.4 KB, free 245.0 MB)
17/03/27 22:26:29 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:54049 (size: 6.4 KB, free: 245.0 MB)
17/03/27 22:26:29 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:29 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at execute at Recursion.scala:228)
17/03/27 22:26:29 INFO TaskSchedulerImpl: Adding task set 3.0 with 5 tasks
17/03/27 22:26:29 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 15, localhost, partition 0,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:29 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 16, localhost, partition 1,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:29 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 17, localhost, partition 3,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:29 INFO TaskSetManager: Starting task 4.0 in stage 3.0 (TID 18, localhost, partition 4,PROCESS_LOCAL, 2148 bytes)
17/03/27 22:26:29 INFO Executor: Running task 0.0 in stage 3.0 (TID 15)
17/03/27 22:26:29 INFO Executor: Running task 1.0 in stage 3.0 (TID 16)
17/03/27 22:26:29 INFO Executor: Running task 3.0 in stage 3.0 (TID 17)
17/03/27 22:26:29 INFO Executor: Running task 4.0 in stage 3.0 (TID 18)
17/03/27 22:26:29 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:26:29 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:29 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:26:29 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:29 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:26:29 INFO BlockManager: Found block rdd_6_3 locally
17/03/27 22:26:29 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 7 took 0 ms
17/03/27 22:26:29 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
17/03/27 22:26:29 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:29 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:26:29 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:29 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 2 ms
17/03/27 22:26:29 INFO MemoryStore: 7 blocks selected for dropping
17/03/27 22:26:29 INFO BlockManager: Dropping block broadcast_1_piece0 from memory
17/03/27 22:26:29 INFO BlockManager: Writing block broadcast_1_piece0 to disk
17/03/27 22:26:29 INFO BlockManagerInfo: Added broadcast_1_piece0 on disk on localhost:54049 (size: 218.0 B)
17/03/27 22:26:29 INFO BlockManager: Dropping block broadcast_3_piece0 from memory
17/03/27 22:26:29 INFO BlockManager: Writing block broadcast_3_piece0 to disk
17/03/27 22:26:29 INFO BlockManagerInfo: Added broadcast_3_piece0 on disk on localhost:54049 (size: 6.1 KB)
17/03/27 22:26:29 INFO BlockManager: Dropping block broadcast_3 from memory
17/03/27 22:26:29 INFO BlockManager: Writing block broadcast_3 to disk
17/03/27 22:26:29 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:29 INFO BlockManager: Writing block broadcast_1 to disk
17/03/27 22:26:29 INFO BlockManager: Dropping block broadcast_4_piece0 from memory
17/03/27 22:26:29 INFO BlockManager: Writing block broadcast_4_piece0 to disk
17/03/27 22:26:29 INFO BlockManagerInfo: Added broadcast_4_piece0 on disk on localhost:54049 (size: 6.4 KB)
17/03/27 22:26:29 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:29 INFO BlockManager: Writing block broadcast_4 to disk
17/03/27 22:26:29 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:26:29 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:54049 in memory (size: 450.8 MB, free: 695.8 MB)
17/03/27 22:26:29 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:29 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:26:29 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:54049 in memory (size: 450.8 MB, free: 1146.6 MB)
17/03/27 22:26:29 INFO BlockManager: Dropping block rdd_6_3 from memory
17/03/27 22:26:29 INFO BlockManagerInfo: Removed rdd_6_3 on localhost:54049 in memory (size: 450.8 MB, free: 1597.4 MB)
17/03/27 22:26:29 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:29 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:26:29 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:54049 in memory (size: 450.9 MB, free: 2.0 GB)
17/03/27 22:26:29 INFO MemoryStore: Will not store rdd_14_0 as it would require dropping another block from the same RDD
17/03/27 22:26:29 WARN MemoryStore: Not enough space to cache rdd_14_0 in memory! (computed 448.3 MB so far)
17/03/27 22:26:29 INFO MemoryStore: Memory use = 0.0 B (blocks) + 2018.3 MB (scratch space shared across 5 tasks(s)) = 2018.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:29 INFO MemoryStore: Will not store broadcast_1 as it would require dropping another block from the same RDD
17/03/27 22:26:29 WARN MemoryStore: Not enough space to cache broadcast_1 in memory! (computed 32.0 MB so far)
17/03/27 22:26:29 INFO MemoryStore: Memory use = 0.0 B (blocks) + 2019.3 MB (scratch space shared across 5 tasks(s)) = 2019.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:29 INFO Executor: Finished task 0.0 in stage 3.0 (TID 15). 3034 bytes result sent to driver
17/03/27 22:26:29 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 19, localhost, partition 2,NODE_LOCAL, 2148 bytes)
17/03/27 22:26:29 INFO Executor: Running task 2.0 in stage 3.0 (TID 19)
17/03/27 22:26:29 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 15) in 506 ms on localhost (1/5)
17/03/27 22:26:29 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 12.8 KB, free 2.0 GB)
17/03/27 22:26:29 INFO CacheManager: Partition rdd_14_2 not found, computing it
17/03/27 22:26:29 INFO CacheManager: Partition rdd_6_2 not found, computing it
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:29 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:30 INFO MemoryStore: Block rdd_14_3 stored as values in memory (estimated size 448.2 MB, free 1600.0 MB)
17/03/27 22:26:30 INFO BlockManagerInfo: Added rdd_14_3 in memory on localhost:54049 (size: 448.2 MB, free: 1600.0 MB)
17/03/27 22:26:30 INFO MemoryStore: Block rdd_14_4 stored as values in memory (estimated size 448.2 MB, free 1151.8 MB)
17/03/27 22:26:30 INFO BlockManagerInfo: Added rdd_14_4 in memory on localhost:54049 (size: 448.2 MB, free: 1151.8 MB)
17/03/27 22:26:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 1119.8 MB)
17/03/27 22:26:30 INFO Executor: Finished task 3.0 in stage 3.0 (TID 17). 3954 bytes result sent to driver
17/03/27 22:26:30 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 17) in 951 ms on localhost (2/5)
17/03/27 22:26:30 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 480.2 MB, free 639.5 MB)
17/03/27 22:26:30 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:54049 (size: 480.2 MB, free: 671.5 MB)
17/03/27 22:26:30 INFO Executor: Finished task 4.0 in stage 3.0 (TID 18). 3529 bytes result sent to driver
17/03/27 22:26:30 INFO TaskSetManager: Finished task 4.0 in stage 3.0 (TID 18) in 964 ms on localhost (3/5)
17/03/27 22:26:30 INFO Executor: Finished task 1.0 in stage 3.0 (TID 16). 3469 bytes result sent to driver
17/03/27 22:26:30 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 16) in 969 ms on localhost (4/5)
17/03/27 22:26:30 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:30 INFO BlockManager: Dropping block broadcast_4 from memory
17/03/27 22:26:30 INFO BlockManager: Dropping block rdd_14_3 from memory
17/03/27 22:26:30 INFO BlockManagerInfo: Removed rdd_14_3 on localhost:54049 in memory (size: 448.2 MB, free: 1119.8 MB)
17/03/27 22:26:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on localhost:54049 on disk (size: 6.1 KB)
17/03/27 22:26:30 INFO MemoryStore: Block rdd_6_2 stored as values in memory (estimated size 416.1 MB, free 671.7 MB)
17/03/27 22:26:30 INFO BlockManagerInfo: Added rdd_6_2 in memory on localhost:54049 (size: 416.1 MB, free: 703.7 MB)
17/03/27 22:26:30 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:30 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 7 took 1 ms
17/03/27 22:26:31 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:31 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:31 INFO MemoryStore: Block rdd_14_2 stored as values in memory (estimated size 682.4 MB, free 21.2 MB)
17/03/27 22:26:31 INFO BlockManagerInfo: Added rdd_14_2 in memory on localhost:54049 (size: 682.4 MB, free: 21.2 MB)
17/03/27 22:26:31 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:31 INFO BlockManager: Dropping block rdd_14_4 from memory
17/03/27 22:26:31 INFO BlockManagerInfo: Removed rdd_14_4 on localhost:54049 in memory (size: 448.2 MB, free: 469.5 MB)
17/03/27 22:26:31 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 437.5 MB)
17/03/27 22:26:31 INFO Executor: Finished task 2.0 in stage 3.0 (TID 19). 2640 bytes result sent to driver
17/03/27 22:26:31 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 19) in 1508 ms on localhost (5/5)
17/03/27 22:26:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/03/27 22:26:31 INFO DAGScheduler: ShuffleMapStage 3 (execute at Recursion.scala:228) finished in 2.014 s
17/03/27 22:26:31 INFO DAGScheduler: looking for newly runnable stages
17/03/27 22:26:31 INFO DAGScheduler: running: Set()
17/03/27 22:26:31 INFO DAGScheduler: waiting: Set(FixedPointResultStage 4)
17/03/27 22:26:31 INFO DAGScheduler: failed: Set()
17/03/27 22:26:31 INFO DAGScheduler: Submitting FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[24] at RDD at SetRDD.scala:30), which has no missing parents
17/03/27 22:26:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.3 KB, free 437.5 MB)
17/03/27 22:26:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 6.6 KB, free 437.5 MB)
17/03/27 22:26:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:54049 (size: 6.6 KB, free: 469.5 MB)
17/03/27 22:26:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:31 INFO DAGScheduler: Submitting 5 missing tasks from FixedPointResultStage 4 (SetRDD.diffRDD SetRDD[24] at RDD at SetRDD.scala:30)
17/03/27 22:26:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 5 tasks
17/03/27 22:26:31 INFO TaskSetManager: Starting task 2.0 in stage 4.0 (TID 20, localhost, partition 2,PROCESS_LOCAL, 2408 bytes)
17/03/27 22:26:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 21, localhost, partition 0,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:31 INFO TaskSetManager: Starting task 1.0 in stage 4.0 (TID 22, localhost, partition 1,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:31 INFO TaskSetManager: Starting task 3.0 in stage 4.0 (TID 23, localhost, partition 3,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:31 INFO Executor: Running task 2.0 in stage 4.0 (TID 20)
17/03/27 22:26:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 21)
17/03/27 22:26:31 INFO Executor: Running task 1.0 in stage 4.0 (TID 22)
17/03/27 22:26:31 INFO Executor: Running task 3.0 in stage 4.0 (TID 23)
17/03/27 22:26:31 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_23_0 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_16_2 not found, computing it
17/03/27 22:26:31 INFO BlockManager: Found block rdd_6_2 locally
17/03/27 22:26:31 INFO BlockManager: Found block rdd_14_2 locally
17/03/27 22:26:31 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:26:31 INFO CacheManager: Partition rdd_16_0 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_16_1 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_6_0 not found, computing it
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:31 INFO CacheManager: Partition rdd_23_3 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_6_1 not found, computing it
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:31 INFO CacheManager: Partition rdd_16_3 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:31 INFO MemoryStore: 5 blocks selected for dropping
17/03/27 22:26:31 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:26:31 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:54049 in memory (size: 480.2 MB, free: 949.7 MB)
17/03/27 22:26:31 INFO BlockManager: Dropping block broadcast_1 from memory
17/03/27 22:26:31 INFO BlockManager: Dropping block broadcast_5_piece0 from memory
17/03/27 22:26:31 INFO BlockManager: Writing block broadcast_5_piece0 to disk
17/03/27 22:26:31 INFO BlockManagerInfo: Added broadcast_5_piece0 on disk on localhost:54049 (size: 6.6 KB)
17/03/27 22:26:31 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:26:31 INFO BlockManager: Writing block broadcast_5 to disk
17/03/27 22:26:31 INFO BlockManager: Dropping block rdd_14_2 from memory
17/03/27 22:26:31 INFO BlockManagerInfo: Removed rdd_14_2 on localhost:54049 in memory (size: 682.4 MB, free: 1632.2 MB)
17/03/27 22:26:31 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:26:31 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 363.5 MB so far)
17/03/27 22:26:31 INFO MemoryStore: Memory use = 416.1 MB (blocks) + 1524.5 MB (scratch space shared across 5 tasks(s)) = 1940.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:31 INFO CacheManager: Partition rdd_14_3 not found, computing it
17/03/27 22:26:31 INFO CacheManager: Partition rdd_6_3 not found, computing it
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:31 INFO MemoryStore: Will not store rdd_16_2 as it would require dropping another block from the same RDD
17/03/27 22:26:31 WARN MemoryStore: Not enough space to cache rdd_16_2 in memory! (computed 363.5 MB so far)
17/03/27 22:26:31 INFO MemoryStore: Memory use = 416.1 MB (blocks) + 1525.5 MB (scratch space shared across 5 tasks(s)) = 1941.6 MB. Storage limit = 2.0 GB.
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/03/27 22:26:31 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 17 took 1 ms
17/03/27 22:26:32 INFO MemoryStore: Block rdd_6_0 stored as values in memory (estimated size 363.5 MB, free 1268.7 MB)
17/03/27 22:26:32 INFO BlockManagerInfo: Added rdd_6_0 in memory on localhost:54049 (size: 363.5 MB, free: 1268.7 MB)
17/03/27 22:26:32 INFO CacheManager: Partition rdd_14_0 not found, computing it
17/03/27 22:26:32 INFO BlockManager: Found block rdd_6_0 locally
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:32 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:26:32 INFO MemoryStore: Block rdd_6_1 stored as values in memory (estimated size 363.5 MB, free 905.1 MB)
17/03/27 22:26:32 INFO BlockManagerInfo: Added rdd_6_1 in memory on localhost:54049 (size: 363.5 MB, free: 905.1 MB)
17/03/27 22:26:32 INFO CacheManager: Partition rdd_14_1 not found, computing it
17/03/27 22:26:32 INFO BlockManager: Found block rdd_6_1 locally
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:32 INFO SetRDDHashSetPartition: Diff set size 1 for rdd 7 took 1 ms
17/03/27 22:26:32 INFO MemoryStore: Will not store rdd_6_3 as it would require dropping another block from the same RDD
17/03/27 22:26:32 WARN MemoryStore: Not enough space to cache rdd_6_3 in memory! (computed 363.5 MB so far)
17/03/27 22:26:32 INFO MemoryStore: Memory use = 1143.1 MB (blocks) + 550.3 MB (scratch space shared across 5 tasks(s)) = 1693.4 MB. Storage limit = 2.0 GB.
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:32 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 7 took 0 ms
17/03/27 22:26:32 INFO BlockManagerInfo: Removed broadcast_4_piece0 on localhost:54049 on disk (size: 6.4 KB)
17/03/27 22:26:32 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:32 INFO BlockManager: Dropping block rdd_6_2 from memory
17/03/27 22:26:32 INFO BlockManagerInfo: Removed rdd_6_2 on localhost:54049 in memory (size: 416.1 MB, free: 1321.2 MB)
17/03/27 22:26:32 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:32 INFO BlockManager: Dropping block rdd_6_0 from memory
17/03/27 22:26:32 INFO BlockManagerInfo: Removed rdd_6_0 on localhost:54049 in memory (size: 363.5 MB, free: 1684.7 MB)
17/03/27 22:26:32 INFO MemoryStore: Will not store rdd_14_3 as it would require dropping another block from the same RDD
17/03/27 22:26:32 WARN MemoryStore: Not enough space to cache rdd_14_3 in memory! (computed 352.1 MB so far)
17/03/27 22:26:32 INFO MemoryStore: Memory use = 363.5 MB (blocks) + 1605.6 MB (scratch space shared across 5 tasks(s)) = 1969.1 MB. Storage limit = 2.0 GB.
17/03/27 22:26:32 INFO SetRDDHashSetPartition: Union set size 0 for rdd 7 took 0 ms
17/03/27 22:26:32 INFO MemoryStore: Block rdd_23_2 stored as values in memory (estimated size 352.1 MB, free 1332.6 MB)
17/03/27 22:26:32 INFO BlockManagerInfo: Added rdd_23_2 in memory on localhost:54049 (size: 352.1 MB, free: 1332.6 MB)
17/03/27 22:26:32 INFO Executor: Finished task 2.0 in stage 4.0 (TID 20). 3227 bytes result sent to driver
17/03/27 22:26:32 INFO TaskSetManager: Starting task 4.0 in stage 4.0 (TID 24, localhost, partition 4,NODE_LOCAL, 2408 bytes)
17/03/27 22:26:32 INFO Executor: Running task 4.0 in stage 4.0 (TID 24)
17/03/27 22:26:32 INFO TaskSetManager: Finished task 2.0 in stage 4.0 (TID 20) in 1409 ms on localhost (1/5)
17/03/27 22:26:32 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 13.3 KB, free 1332.6 MB)
17/03/27 22:26:32 INFO CacheManager: Partition rdd_23_4 not found, computing it
17/03/27 22:26:32 INFO CacheManager: Partition rdd_16_4 not found, computing it
17/03/27 22:26:32 INFO CacheManager: Partition rdd_6_4 not found, computing it
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Getting 5 non-empty blocks out of 5 blocks
17/03/27 22:26:32 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:33 INFO MemoryStore: Block rdd_14_1 stored as values in memory (estimated size 352.1 MB, free 980.5 MB)
17/03/27 22:26:33 INFO BlockManagerInfo: Added rdd_14_1 in memory on localhost:54049 (size: 352.1 MB, free: 980.6 MB)
17/03/27 22:26:33 INFO SetRDDHashSetPartition: Union set size 2 for rdd 7 took 0 ms
17/03/27 22:26:33 INFO MemoryStore: Block rdd_14_0 stored as values in memory (estimated size 352.1 MB, free 628.5 MB)
17/03/27 22:26:33 INFO BlockManagerInfo: Added rdd_14_0 in memory on localhost:54049 (size: 352.1 MB, free: 628.5 MB)
17/03/27 22:26:33 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:26:33 INFO MemoryStore: 3 blocks selected for dropping
17/03/27 22:26:33 INFO BlockManager: Dropping block rdd_23_2 from memory
17/03/27 22:26:33 INFO BlockManagerInfo: Removed rdd_23_2 on localhost:54049 in memory (size: 352.1 MB, free: 980.6 MB)
17/03/27 22:26:33 INFO BlockManager: Dropping block broadcast_5 from memory
17/03/27 22:26:33 INFO BlockManager: Dropping block rdd_14_1 from memory
17/03/27 22:26:33 INFO BlockManagerInfo: Removed rdd_14_1 on localhost:54049 in memory (size: 352.1 MB, free: 1332.6 MB)
17/03/27 22:26:33 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:33 INFO BlockManager: Dropping block rdd_6_1 from memory
17/03/27 22:26:33 INFO BlockManagerInfo: Removed rdd_6_1 on localhost:54049 in memory (size: 363.5 MB, free: 1696.2 MB)
17/03/27 22:26:33 INFO MemoryStore: Will not store rdd_16_0 as it would require dropping another block from the same RDD
17/03/27 22:26:33 WARN MemoryStore: Not enough space to cache rdd_16_0 in memory! (computed 352.0 MB so far)
17/03/27 22:26:33 INFO MemoryStore: Memory use = 352.1 MB (blocks) + 1588.3 MB (scratch space shared across 5 tasks(s)) = 1940.4 MB. Storage limit = 2.0 GB.
17/03/27 22:26:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:33 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 17 took 0 ms
17/03/27 22:26:33 INFO MemoryStore: Block rdd_16_3 stored as values in memory (estimated size 352.0 MB, free 1344.1 MB)
17/03/27 22:26:33 INFO BlockManagerInfo: Added rdd_16_3 in memory on localhost:54049 (size: 352.0 MB, free: 1344.1 MB)
17/03/27 22:26:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:33 INFO SetRDDHashSetPartition: Diff set size 0 for rdd 17 took 1 ms
17/03/27 22:26:33 INFO MemoryStore: Block rdd_6_4 stored as values in memory (estimated size 352.0 MB, free 992.1 MB)
17/03/27 22:26:33 INFO BlockManagerInfo: Added rdd_6_4 in memory on localhost:54049 (size: 352.0 MB, free: 992.1 MB)
17/03/27 22:26:33 INFO CacheManager: Partition rdd_14_4 not found, computing it
17/03/27 22:26:33 INFO BlockManager: Found block rdd_6_4 locally
17/03/27 22:26:33 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:33 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:33 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 7 took 0 ms
17/03/27 22:26:34 INFO MemoryStore: Block rdd_16_1 stored as values in memory (estimated size 352.0 MB, free 640.0 MB)
17/03/27 22:26:34 INFO BlockManagerInfo: Added rdd_16_1 in memory on localhost:54049 (size: 352.0 MB, free: 640.0 MB)
17/03/27 22:26:34 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:34 INFO SetRDDHashSetPartition: Diff set size 2 for rdd 17 took 1 ms
17/03/27 22:26:34 INFO MemoryStore: 2 blocks selected for dropping
17/03/27 22:26:34 INFO BlockManager: Dropping block rdd_16_3 from memory
17/03/27 22:26:34 INFO BlockManagerInfo: Removed rdd_16_3 on localhost:54049 in memory (size: 352.0 MB, free: 992.1 MB)
17/03/27 22:26:34 INFO BlockManager: Dropping block rdd_6_4 from memory
17/03/27 22:26:34 INFO BlockManagerInfo: Removed rdd_6_4 on localhost:54049 in memory (size: 352.0 MB, free: 1344.1 MB)
17/03/27 22:26:34 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:34 INFO BlockManager: Dropping block rdd_14_0 from memory
17/03/27 22:26:34 INFO BlockManagerInfo: Removed rdd_14_0 on localhost:54049 in memory (size: 352.1 MB, free: 1696.2 MB)
17/03/27 22:26:34 INFO MemoryStore: Will not store rdd_23_1 as it would require dropping another block from the same RDD
17/03/27 22:26:34 WARN MemoryStore: Not enough space to cache rdd_23_1 in memory! (computed 352.0 MB so far)
17/03/27 22:26:34 INFO MemoryStore: Memory use = 352.0 MB (blocks) + 1589.2 MB (scratch space shared across 5 tasks(s)) = 1941.3 MB. Storage limit = 2.0 GB.
17/03/27 22:26:34 INFO Executor: Finished task 1.0 in stage 4.0 (TID 22). 3454 bytes result sent to driver
17/03/27 22:26:34 INFO TaskSetManager: Finished task 1.0 in stage 4.0 (TID 22) in 3187 ms on localhost (2/5)
17/03/27 22:26:34 INFO MemoryStore: Block rdd_23_0 stored as values in memory (estimated size 352.0 MB, free 1344.2 MB)
17/03/27 22:26:34 INFO BlockManagerInfo: Added rdd_23_0 in memory on localhost:54049 (size: 352.0 MB, free: 1344.2 MB)
17/03/27 22:26:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 21). 3794 bytes result sent to driver
17/03/27 22:26:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 21) in 3193 ms on localhost (3/5)
17/03/27 22:26:34 INFO MemoryStore: Block rdd_23_3 stored as values in memory (estimated size 352.0 MB, free 992.2 MB)
17/03/27 22:26:34 INFO BlockManagerInfo: Added rdd_23_3 in memory on localhost:54049 (size: 352.0 MB, free: 992.2 MB)
17/03/27 22:26:34 INFO Executor: Finished task 3.0 in stage 4.0 (TID 23). 2198 bytes result sent to driver
17/03/27 22:26:34 INFO TaskSetManager: Finished task 3.0 in stage 4.0 (TID 23) in 3225 ms on localhost (4/5)
17/03/27 22:26:34 INFO MemoryStore: Block rdd_14_4 stored as values in memory (estimated size 351.9 MB, free 640.3 MB)
17/03/27 22:26:34 INFO BlockManagerInfo: Added rdd_14_4 in memory on localhost:54049 (size: 351.9 MB, free: 640.3 MB)
17/03/27 22:26:34 INFO SetRDDHashSetPartition: Union set size 4 for rdd 7 took 0 ms
17/03/27 22:26:35 INFO MemoryStore: Block rdd_16_4 stored as values in memory (estimated size 362.9 MB, free 277.4 MB)
17/03/27 22:26:35 INFO BlockManagerInfo: Added rdd_16_4 in memory on localhost:54049 (size: 362.9 MB, free: 277.4 MB)
17/03/27 22:26:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 5 blocks
17/03/27 22:26:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/03/27 22:26:35 INFO SetRDDHashSetPartition: Diff set size 3 for rdd 17 took 0 ms
17/03/27 22:26:35 INFO MemoryStore: 1 blocks selected for dropping
17/03/27 22:26:35 INFO BlockManager: Dropping block rdd_16_1 from memory
17/03/27 22:26:35 INFO BlockManagerInfo: Removed rdd_16_1 on localhost:54049 in memory (size: 352.0 MB, free: 629.5 MB)
17/03/27 22:26:36 INFO MemoryStore: Block rdd_23_4 stored as values in memory (estimated size 351.5 MB, free 277.9 MB)
17/03/27 22:26:36 INFO BlockManagerInfo: Added rdd_23_4 in memory on localhost:54049 (size: 351.5 MB, free: 277.9 MB)
17/03/27 22:26:36 INFO Executor: Finished task 4.0 in stage 4.0 (TID 24). 3837 bytes result sent to driver
17/03/27 22:26:36 INFO TaskSetManager: Finished task 4.0 in stage 4.0 (TID 24) in 3252 ms on localhost (5/5)
17/03/27 22:26:36 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/03/27 22:26:36 INFO DAGScheduler: FixedPointResultStage 4 (runFixedPointJob at Recursion.scala:204) finished in 4.660 s
17/03/27 22:26:36 INFO CachedRDDManager: CleanUpIteration took 0 ms
17/03/27 22:26:36 INFO Recursion: Fixed Point Iteration # 2, time: 8136ms
17/03/27 22:26:36 INFO DAGScheduler: Registering RDD 34 (execute at Recursion.scala:228)
17/03/27 22:26:36 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[34] at execute at Recursion.scala:228), which has no missing parents
17/03/27 22:26:36 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 11.2 KB, free 277.9 MB)
17/03/27 22:26:36 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 5.7 KB, free 277.9 MB)
17/03/27 22:26:36 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:54049 (size: 5.7 KB, free: 277.9 MB)
17/03/27 22:26:36 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1102
17/03/27 22:26:36 INFO DAGScheduler: Submitting 5 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[34] at execute at Recursion.scala:228)
17/03/27 22:26:36 INFO TaskSchedulerImpl: Adding task set 5.0 with 5 tasks
17/03/27 22:26:36 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 25, localhost, partition 0,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:36 INFO TaskSetManager: Starting task 3.0 in stage 5.0 (TID 26, localhost, partition 3,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:36 INFO TaskSetManager: Starting task 4.0 in stage 5.0 (TID 27, localhost, partition 4,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:36 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 28, localhost, partition 1,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:36 INFO Executor: Running task 0.0 in stage 5.0 (TID 25)
17/03/27 22:26:36 INFO Executor: Running task 4.0 in stage 5.0 (TID 27)
17/03/27 22:26:36 INFO Executor: Running task 1.0 in stage 5.0 (TID 28)
17/03/27 22:26:36 INFO Executor: Running task 3.0 in stage 5.0 (TID 26)
17/03/27 22:26:36 INFO BlockManager: Found block rdd_23_3 locally
17/03/27 22:26:36 INFO BlockManager: Found block rdd_23_0 locally
17/03/27 22:26:36 INFO CacheManager: Partition rdd_23_1 not found, computing it
17/03/27 22:26:36 INFO BlockManager: Found block rdd_23_4 locally
17/03/27 22:26:36 ERROR Executor: Exception in task 1.0 in stage 5.0 (TID 28)
org.apache.spark.SparkException: Checkpoint block rdd_23_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:36 INFO TaskSetManager: Starting task 2.0 in stage 5.0 (TID 29, localhost, partition 2,PROCESS_LOCAL, 1844 bytes)
17/03/27 22:26:36 INFO Executor: Running task 2.0 in stage 5.0 (TID 29)
17/03/27 22:26:36 WARN TaskSetManager: Lost task 1.0 in stage 5.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_23_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:36 ERROR TaskSetManager: Task 1 in stage 5.0 failed 1 times; aborting job
17/03/27 22:26:36 INFO TaskSchedulerImpl: Cancelling stage 5
17/03/27 22:26:36 INFO TaskSchedulerImpl: Stage 5 was cancelled
17/03/27 22:26:36 INFO DAGScheduler: ShuffleMapStage 5 (execute at Recursion.scala:228) failed in 0.004 s
17/03/27 22:26:36 INFO Executor: Executor is trying to kill task 4.0 in stage 5.0 (TID 27)
17/03/27 22:26:36 INFO Executor: Executor is trying to kill task 0.0 in stage 5.0 (TID 25)
17/03/27 22:26:36 INFO Executor: Executor is trying to kill task 2.0 in stage 5.0 (TID 29)
17/03/27 22:26:36 INFO Executor: Executor is trying to kill task 3.0 in stage 5.0 (TID 26)
17/03/27 22:26:36 INFO DAGScheduler: Fixed Point Job 1 failed: runFixedPointJob at Recursion.scala:204, took 8.147560 s
[31m- Transitive Closure - LL - fff *** FAILED ***[0m
[31m  org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 5.0 failed 1 times, most recent failure: Lost task 1.0 in stage 5.0 (TID 28, localhost): org.apache.spark.SparkException: Checkpoint block rdd_23_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
[0m
[31m	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
[0m
[31m	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
[0m
[31m	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
[0m
[31m	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
[0m
[31m	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
[0m
[31m	at org.apache.spark.scheduler.Task.run(Task.scala:89)
[0m
[31m	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
[0m
[31m	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
[0m
[31m	at java.lang.Thread.run(Unknown Source)
[0m
[31m[0m
[31mDriver stacktrace:[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1600)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1588)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1587)[0m
[31m  at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)[0m
[31m  at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1587)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:844)[0m
[31m  at scala.Option.foreach(Option.scala:257)[0m
[31m  at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:844)[0m
[31m  ...[0m
[31m  Cause: org.apache.spark.SparkException: Checkpoint block rdd_23_1 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.[0m
[31m  at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)[0m
[31m  at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)[0m
[31m  at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)[0m
[31m  at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)[0m
[31m  ...[0m
17/03/27 22:26:36 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 32.0 MB, free 245.9 MB)
17/03/27 22:26:36 INFO CacheManager: Partition rdd_23_2 not found, computing it
17/03/27 22:26:36 ERROR Executor: Exception in task 2.0 in stage 5.0 (TID 29)
org.apache.spark.SparkException: Checkpoint block rdd_23_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)
17/03/27 22:26:36 INFO Executor: Executor killed task 3.0 in stage 5.0 (TID 26)
17/03/27 22:26:36 WARN TaskSetManager: Lost task 2.0 in stage 5.0 (TID 29, localhost): org.apache.spark.SparkException: Checkpoint block rdd_23_2 not found! Either the executor that originally checkpointed this partition is no longer alive, or the original RDD is unpersisted. If this problem persists, you may consider using `rdd.checkpoint()` or `rdd.localcheckpoint()` instead, which are slower than memory checkpointing but more fault-tolerant.
	at org.apache.spark.rdd.MemoryCheckpointRDD.compute(MemoryCheckpointRDD.scala:44)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:304)
	at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:69)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:268)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:270)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:89)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:227)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
	at java.lang.Thread.run(Unknown Source)

17/03/27 22:26:36 WARN TaskSetManager: Lost task 3.0 in stage 5.0 (TID 26, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:36 INFO Executor: Executor killed task 4.0 in stage 5.0 (TID 27)
17/03/27 22:26:36 WARN TaskSetManager: Lost task 4.0 in stage 5.0 (TID 27, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:36 INFO Executor: Executor killed task 0.0 in stage 5.0 (TID 25)
17/03/27 22:26:36 WARN TaskSetManager: Lost task 0.0 in stage 5.0 (TID 25, localhost): TaskKilled (killed intentionally)
17/03/27 22:26:36 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
[36mRun completed in 1 minute, 26 seconds.[0m
[36mTotal number of tests run: 50[0m
[36mSuites: completed 8, aborted 0[0m
[36mTests: succeeded 33, failed 17, canceled 0, ignored 0, pending 0[0m
[31m*** 17 TESTS FAILED ***[0m
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO SparkContext: Invoking stop() from shutdown hook
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
17/03/27 22:26:36 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/03/27 22:26:36 INFO MemoryStore: MemoryStore cleared
17/03/27 22:26:36 INFO BlockManager: BlockManager stopped
17/03/27 22:26:36 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/27 22:26:36 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
17/03/27 22:26:36 INFO SparkContext: Successfully stopped SparkContext
17/03/27 22:26:36 INFO ShutdownHookManager: Shutdown hook called
17/03/27 22:26:36 INFO ShutdownHookManager: Deleting directory C:\java\BigDatalogLatest\datalog\target\tmp\spark-3c7783c5-fe75-4b11-a027-ecfc98fe252a
17/03/27 22:26:36 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 02:04 min
[INFO] Finished at: 2017-03-27T22:26:37-04:00
[INFO] Final Memory: 60M/1233M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.scalatest:scalatest-maven-plugin:1.0:test (test) on project spark-datalog_2.11: There are test failures -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/MojoFailureException
